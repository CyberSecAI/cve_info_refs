=== Content from github.com_af626c0d_20250125_090815.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftorvalds%2Flinux%2Fcommit%2F8141c7f3e7aee618312fa1c15109e1219de784a7)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  + [Nonprofits](/solutions/industry/nonprofits)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftorvalds%2Flinux%2Fcommit%2F8141c7f3e7aee618312fa1c15109e1219de784a7)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fcommit_fragments%2Frepo_layout&source=header-repo&source_repo=torvalds%2Flinux)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[torvalds](/torvalds)
/
**[linux](/torvalds/linux)**
Public

* [Notifications](/login?return_to=%2Ftorvalds%2Flinux) You must be signed in to change notification settings
* [Fork
  54.9k](/login?return_to=%2Ftorvalds%2Flinux)
* [Star
   186k](/login?return_to=%2Ftorvalds%2Flinux)

* [Code](/torvalds/linux)
* [Pull requests
  437](/torvalds/linux/pulls)
* [Actions](/torvalds/linux/actions)
* [Projects
  0](/torvalds/linux/projects)
* [Security](/torvalds/linux/security)
* [Insights](/torvalds/linux/pulse)

Additional navigation options

* [Code](/torvalds/linux)
* [Pull requests](/torvalds/linux/pulls)
* [Actions](/torvalds/linux/actions)
* [Projects](/torvalds/linux/projects)
* [Security](/torvalds/linux/security)
* [Insights](/torvalds/linux/pulse)

## Commit

[Permalink](/torvalds/linux/commit/8141c7f3e7aee618312fa1c15109e1219de784a7)

This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.

Move "exit\_robust\_list" into mm\_release()

[Browse files](/torvalds/linux/tree/8141c7f3e7aee618312fa1c15109e1219de784a7)
Browse the repository at this point in the history

```
We don't want to get rid of the futexes just at exit() time, we want to
drop them when doing an execve() too, since that gets rid of the
previous VM image too.

Doing it at mm_release() time means that we automatically always do it
when we disassociate a VM map from the task.

Reported-by: pageexec@freemail.hu
Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Nick Piggin <npiggin@suse.de>
Cc: Hugh Dickins <hugh@veritas.com>
Cc: Ingo Molnar <mingo@elte.hu>
Cc: Thomas Gleixner <tglx@linutronix.de>
Cc: Brad Spengler <spender@grsecurity.net>
Cc: Alex Efros <powerman@powerman.name>
Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
Cc: Oleg Nesterov <oleg@redhat.com>
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
```

* Loading branch information

[![@torvalds](https://avatars.githubusercontent.com/u/1024025?s=40&v=4)](/torvalds)

[torvalds](/torvalds/linux/commits?author=torvalds "View all commits by torvalds")
committed
Nov 15, 2008

1 parent
[9c7c354](/torvalds/linux/commit/9c7c354645535555785eb937dd46388b55e690d0)

commit 8141c7f

 Show file tree

 Hide file tree

Showing
**2 changed files**
with
**11 additions**
and
**9 deletions**.

* Whitespace
* Ignore whitespace

* Split
* Unified

* kernel

  + kernel/exit.c
    [exit.c](#diff-3ffe5a77ace5e673b331541e3096434cc645c6d0809664d970bb7e6b80f0aedc)
  + kernel/fork.c
    [fork.c](#diff-e37b5cb4c23f6ab27741c60ec48674eff0268624a228c9a1cddddb9e4ee2922d)

## There are no files selected for viewing

9 changes: 0 additions & 9 deletions

9
[kernel/exit.c](#diff-3ffe5a77ace5e673b331541e3096434cc645c6d0809664d970bb7e6b80f0aedc "kernel/exit.c")

Show comments

[View file](/torvalds/linux/blob/8141c7f3e7aee618312fa1c15109e1219de784a7/kernel/exit.c)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -40,7 +40,6 @@ |
|  |  | #include <linux/cn\_proc.h> |
|  |  | #include <linux/mutex.h> |
|  |  | #include <linux/futex.h> |
|  |  | #include <linux/compat.h> |
|  |  | #include <linux/pipe\_fs\_i.h> |
|  |  | #include <linux/audit.h> /\* for audit\_free() \*/ |
|  |  | #include <linux/resource.h> |
| Expand Down  Expand Up | | @@ -1059,14 +1058,6 @@ NORET\_TYPE void do\_exit(long code) |
|  |  | exit\_itimers(tsk->signal); |
|  |  | } |
|  |  | acct\_collect(code, group\_dead); |
|  |  | #ifdef CONFIG\_FUTEX |
|  |  | if (unlikely(tsk->robust\_list)) |
|  |  | exit\_robust\_list(tsk); |
|  |  | #ifdef CONFIG\_COMPAT |
|  |  | if (unlikely(tsk->compat\_robust\_list)) |
|  |  | compat\_exit\_robust\_list(tsk); |
|  |  | #endif |
|  |  | #endif |
|  |  | if (group\_dead) |
|  |  | tty\_audit\_exit(); |
|  |  | if (unlikely(tsk->audit\_context)) |
| Expand Down | |  |

11 changes: 11 additions & 0 deletions

11
[kernel/fork.c](#diff-e37b5cb4c23f6ab27741c60ec48674eff0268624a228c9a1cddddb9e4ee2922d "kernel/fork.c")

Show comments

[View file](/torvalds/linux/blob/8141c7f3e7aee618312fa1c15109e1219de784a7/kernel/fork.c)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -40,6 +40,7 @@ |
|  |  | #include <linux/jiffies.h> |
|  |  | #include <linux/tracehook.h> |
|  |  | #include <linux/futex.h> |
|  |  | #include <linux/compat.h> |
|  |  | #include <linux/task\_io\_accounting\_ops.h> |
|  |  | #include <linux/rcupdate.h> |
|  |  | #include <linux/ptrace.h> |
| Expand Down  Expand Up | | @@ -519,6 +520,16 @@ void mm\_release(struct task\_struct \*tsk, struct mm\_struct \*mm) |
|  |  | { |
|  |  | struct completion \*vfork\_done = tsk->vfork\_done; |
|  |  |  |
|  |  | /\* Get rid of any futexes when releasing the mm \*/ |
|  |  | #ifdef CONFIG\_FUTEX |
|  |  | if (unlikely(tsk->robust\_list)) |
|  |  | exit\_robust\_list(tsk); |
|  |  | #ifdef CONFIG\_COMPAT |
|  |  | if (unlikely(tsk->compat\_robust\_list)) |
|  |  | compat\_exit\_robust\_list(tsk); |
|  |  | #endif |
|  |  | #endif |
|  |  |  |
|  |  | /\* Get rid of any cached register state \*/ |
|  |  | deactivate\_mm(tsk, mm); |
|  |  |  |
| Expand Down | |  |

Toggle all file notes
Toggle all file annotations

### 0 comments on commit `8141c7f`

Please
[sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftorvalds%2Flinux%2Fcommit%2F8141c7f3e7aee618312fa1c15109e1219de784a7) to comment.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from bugzilla.redhat.com_6ed3770f_20250125_090815.html ===


* Login
  + Log in using an SSO provider:- [Fedora Account System](saml2_login.cgi?idp=Fedora%20Account%20System&target=show_bug.cgi%3Fid%3D771764)
    - [Red Hat Associate](saml2_login.cgi?idp=Red%20Hat%20Associate&target=show_bug.cgi%3Fid%3D771764)
    - [Red Hat Customer](saml2_login.cgi?idp=Red%20Hat%20Customer&target=show_bug.cgi%3Fid%3D771764)+ Login using a Red Hat Bugzilla account
  + Forgot Password
  + [Create an Account](createaccount.cgi)

Red Hat Bugzilla – Bug 771764

* [Home](./)
* [New](enter_bug.cgi)
* Search
  + [Simple Search](query.cgi?format=specific)
  + [Advanced Search](query.cgi?format=advanced)
* My Links
  + [Browse](describecomponents.cgi)
  + [Requests](request.cgi)
  + Reports
  + Current State
    - [Search](query.cgi)
    - [Tabular reports](query.cgi?format=report-table)
    - [Graphical reports](query.cgi?format=report-graph)
    - [Duplicates](duplicates.cgi)
  + Other Reports
    - [User Changes](https://bugzilla.redhat.com/page.cgi?id=user_activity.html)
  + Plotly Reports
    - [Bug Status](https://bugzilla.redhat.com/page.cgi?id=bug_status.html)
    - [Bug Severity](https://bugzilla.redhat.com/page.cgi?id=bug_severity.html)
    - [Non-Defaults](https://bugzilla.redhat.com/page.cgi?id=non_defaults.html)
* [Product Dashboard](page.cgi?id=productdashboard.html)

- Help
  * [Page Help!](docs/en/html/using/understanding.html)
  * [Bug Writing Guidelines](page.cgi?id=bug-writing.html)
  * [What's new](page.cgi?id=whats-new.html)
  * [Browser Support Policy](https://access.redhat.com/help/browsers)
  * [5.0.4.rh103 Release notes](page.cgi?id=release-notes.html)
  * [FAQ](page.cgi?id=faq.html)
  * [Guides index](docs/en/html/index.html)
  * [User guide](docs/en/html/using/index.html)
  * [Web Services](docs/en/html/integrating/api/Bugzilla/WebService/Bug.html)
  * [Contact](page.cgi?id=redhat/contact.html)
  * [Legal](page.cgi?id=terms-conditions.html)
- [[?]](page.cgi?id=quicksearch.html "Quicksearch Help")

This site requires JavaScript to be enabled to function correctly, please enable it.

[**Bug 771764**](show_bug.cgi?id=771764)
(CVE-2012-0028)
- [CVE-2012-0028](https://access.redhat.com/security/cve/CVE-2012-0028) kernel: futex: clear robust\_list on execve

[Summary:](page.cgi?id=fields.html#short_desc "The bug summary is a short sentence which succinctly describes what the bug is about.")
CVE-2012-0028 kernel: futex: clear robust\_list on execve

| | [Keywords](describekeywords.cgi): | Security | | --- | --- | | [Status](page.cgi?id=fields.html#bug_status): | CLOSED ERRATA | | [Alias:](page.cgi?id=fields.html#alias "A short, unique name assigned to a bug in order to assist with looking it up and referring to it in other places in Bugzilla.") | CVE-2012-0028 | | [Product:](describecomponents.cgi "Bugs are categorised into Products and Components. Select a Classification to narrow down this list.") | Security Response | | [Classification:](page.cgi?id=fields.html#classification "Bugs are categorised into Classifications, Products and Components. classifications is the top-level categorisation.") | Other | | [Component:](describecomponents.cgi?product=Security Response "Components are second-level categories; each belongs to a particular Product. Select a Product to narrow down this list.") | vulnerability | | [Sub Component:](page.cgi?id=fields.html#rh_sub_components "The sub component of a specific component") | --- | | [Version:](page.cgi?id=fields.html#version "The version field defines the version of the software the bug was found in.") | unspecified | | [Hardware:](page.cgi?id=fields.html#rep_platform "The hardware platform the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | All | | [OS:](page.cgi?id=fields.html#op_sys "The operating system the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | Linux | | [Priority:](page.cgi?id=fields.html#priority) | high | | [Severity:](page.cgi?id=fields.html#bug_severity) | high | | [Target Milestone:](page.cgi?id=fields.html#target_milestone "The Target Milestone field is used to define when the engineer the bug is assigned to expects to fix it.") | --- | | [Assignee:](page.cgi?id=fields.html#assigned_to "The person in charge of resolving the bug.") | Red Hat Product Security | | [QA Contact:](page.cgi?id=fields.html#qa_contact "The person responsible for confirming this bug if it is unconfirmed, and for verifying the fix once the bug has been resolved.") |  | | [Docs Contact:](page.cgi?id=fields.html#docs_contact "The person responsible for documenting once the bug has been resolved.") |  | | [URL:](page.cgi?id=fields.html#bug_file_loc "Bugs can have a URL associated with them - for example, a pointer to a web site where the problem is seen.") |  | | [Whiteboard:](page.cgi?id=fields.html#status_whiteboard "Each bug has a free-form single line text entry box for adding tags and status information.") |  | | [Depends On:](page.cgi?id=fields.html#dependson "The bugs listed here must be resolved before this bug can be resolved.") | [750283](show_bug.cgi?id=750283) [771774](show_bug.cgi?id=771774) [789370](show_bug.cgi?id=789370) | | [Blocks:](page.cgi?id=fields.html#blocked "This bug must be resolved before the bugs listed in this field can be resolved.") | [770893](show_bug.cgi?id=770893) | | TreeView+ | [depends on](buglist.cgi?bug_id=771764&bug_id_type=anddependson&format=tvp) / [blocked](buglist.cgi?bug_id=771764&bug_id_type=andblocked&format=tvp&tvp_dir=blocked) |  | |  | | [Reported:](page.cgi?id=fields.html#reporter) | 2012-01-04 22:08 UTC by Petr Matousek | | --- | --- | | [Modified:](page.cgi?id=fields.html#modified) | 2021-02-24 13:32 UTC ([History](show_activity.cgi?id=771764)) | | [CC List:](page.cgi?id=fields.html#cclist) | 22 users (show)  agordeev anton arozansk bhu davej dhoward fhrbata gansalmon itamar jkacur jonathan jwboyer kernel-maint kernel-mgr lgoncalv lwang madhu.chinakonda plougher rt-maint sforsber vgoyal williams | | Fixed In Version: |  | | | Doc Type: | Bug Fix | | | Doc Text: |  | | | Clone Of: |  | | | Environment: |  | | | Last Closed: | 2012-05-04 08:48:04 UTC | | | Embargoed: |  | | |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| --- | | |

| | Attachments | [(Terms of Use)](page.cgi?id=terms-conditions.html) | | | --- | --- | --- | |  | | |    Links | System | ID | Private | Priority | Status | Summary | Last Updated | | Red Hat Product Errata | [RHSA-2012:0107](https://access.redhat.com/errata/RHSA-2012%3A0107) | 0 | normal | SHIPPED\_LIVE | Important: kernel security and bug fix update | 2012-02-09 21:37:09 UTC | | Red Hat Product Errata | [RHSA-2012:0358](https://access.redhat.com/errata/RHSA-2012%3A0358) | 0 | normal | SHIPPED\_LIVE | Important: kernel security and bug fix update | 2012-03-06 22:42:05 UTC | |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |

| [Description](show_bug.cgi?id=771764#c0)  Petr Matousek    2012-01-04 22:08:20 UTC  ``` Move "exit_robust_list" into mm_release() and clear them  We don't want to get rid of the futexes just at exit() time, we want to drop them when doing an execve() too, since that gets rid of the previous VM image too.  Doing it at mm_release() time means that we automatically always do it when we disassociate a VM map from the task.  Upstream patches: 8141c7f3e7aee618312fa1c15109e1219de784a7 fc6b177dee33365ccb29fe6d2092223cf8d679f9   ```  [Comment 1](show_bug.cgi?id=771764#c1)  Kurt Seifried    2012-01-04 22:20:23 UTC  ``` Assigned [CVE-2012-0028](https://access.redhat.com/security/cve/CVE-2012-0028) as per <http://www.openwall.com/lists/oss-security/2012/01/04/18>   ```  [Comment 4](show_bug.cgi?id=771764#c4)  Petr Matousek    2012-02-01 16:40:24 UTC  ``` Below are the most relevant comments that were extracted from our per product tracking bug (which we do not open to the public). These comments describe the steps that were undertaken to find the root cause of the problem.  ---------------------------------------------------------------------------  Description of problem:  On ia64 HVM guest I see this:   1) after the guest is installed and rebooted virt-manager's UI will show the guest console in a VNC window 2) I can see the console messages before firstboot.  3) Then firstboot starts and I go through all the steps 4) At the end firstboot exits and the OS should load GDM login window 5) At this point the vnc widget disconnects from the guest and can't connect anymore.  Version-Release number of selected component (if applicable): 2.6.18-294  How reproducible: 1/1  Steps to Reproduce: 1. See above. Tried with 5.7 Server ia64 host and 5.8 Beta 1.0 guest.  2. Created HVM guest and used NFS iso as the source. 3.     Additional info: Booting in runlevel 3 has no issues, I can see the login prompt.   After logged into runlevel 3 and doing init 5 - loads Xorg + GDM just fine.   I'm not sure if this has something to do with the guest (kernel or Xorg drivers) or with the host (VNC widget).  This is on host hp-rx2660-01.rhts.eng.brq.redhat.com.  --- Additional comment from mrezanin on 2011-12-13 09:05:23 EST ---  Problem is, that qemu crash. So guest is on from xen point of view but not running. You can verify this by 'xm list' - there should be no state for guest.  --- Additional comment from mrezanin on 2011-12-16 10:23:21 EST ---  I retested the problem with RHEL 5.7 guest - it's working ok and without problems. I updated guest kernel to RHEL 5.8 Beta version and it is still ok. So this is definitely regression but not xen one.     As logs show, problem is in bad io request - addr: 33a8 size: 8. Package bisecting revealed the problem to be in glibc update (glibc, glibc-common,nscd). Futher bisecting in this is needed to find out the cause of problem. Problem is somewhere between glibc 2.5-66 and 2.5-72. I was unable to test older glibc than 2.5-72.   Reassign to glibc for bisecting.  --- Additional comment from drjones on 2011-12-21 07:52:03 EST ---  glibc changelog for -67  * Wed Aug 17 2011 Andreas Schwab <schwab> - 2.5-67 - ldd: never run file directly (#531160) - Implement greedy matching of weekday and month names (#657570) - Fix incorrect numeric settings (#675259) - Implement new mode for NIS passwd.adjunct.byname table (#678318) - Query NIS domain only when needed (#703345) - Count total processors using sysfs (#706894) - Translate clone error if necessary (#707998) - Workaround kernel clobbering robust list (#711531)  Back on the xen side, Miro says he found a qemu log  inp: bad size: 4004 8  which means that something in the guest attempted to read ioport 0x4004, and attempted to read 8 bytes at once, which isn't legal. That I/O address isn't mapped in the guest either, see the guest's ioports below.  Now we also see that the reason qemu exits is because it was designed to do so in this case  unsigned long do_inp(CPUState *env, unsigned long addr, unsigned long size) {     switch(size) {     case 1:         return cpu_inb(env, addr);     case 2:         return cpu_inw(env, addr);     case 4:         return cpu_inl(env, addr);     default:         fprintf(logfile, "inp: bad size: %lx %lx\n", addr, size);         exit(-1);     } }     I don't see how that error is related to the glibc version unless the _inb() function and friends (which are written in C for ia64) are somehow compiled differently with -67. Would "ldd: never run file directly (#531160)" have changed anything like that?  ---  # cat /proc/ioports  00000000-00000cf7 : PCI Bus 0000:00   00000170-00000177 : ide1   000001f0-000001f7 : ide0   00000376-00000376 : ide1   000003c0-000003df : vga+   000003f6-000003f6 : ide0   000003f8-000003ff : serial 00000d00-0000ffff : PCI Bus 0000:00   00001f40-00001f7f : 0000:00:01.2     00001f40-00001f43 : ACPI PM1a_EVT_BLK     00001f44-00001f45 : ACPI PM1a_CNT_BLK     00001f48-00001f4b : ACPI PM_TMR   00002000-000020ff : 0000:00:04.0     00002000-000020ff : 8139cp   00002100-000021ff : 0000:00:03.0     00002100-000021ff : xen-platform-pci   00002200-0000220f : 0000:00:01.1     00002200-00002207 : ide0     00002208-0000220f : ide1  --- Additional comment from lersek on 2011-12-22 06:19:45 EST ---  (In reply to [comment #23](show_bug.cgi?id=771764#c23))  > If that's true, can we use the qemu state to map back to the executing code in > the guest kernel?  We discussed this with Drew yesterday. Let me build a xen package that hangs (pauses) qemu-dm instead of exiting on that error path. This way the insn emulation will take very long for the guest, and we should have a chance to dump the guest's core for analysis with crash.  --- Additional comment from lersek on 2011-12-22 09:23:09 EST ---  Guys in the CC, any help would be greatly appreciated. Thanks!  Analysing the guest coredump. Looking at "docs/misc/dump-core-format.txt" and "tools/libxc/xc_core.c" in xen-userspace:      +--------------------------------------------------------+     |ELF header                                              |     +--------------------------------------------------------+     |section headers                                         |     |    [...]                                               |     +--------------------------------------------------------+     |.note.Xen:note section                                  |     |    [...]                                               |     +--------------------------------------------------------+     |.xen_prstatus                                           |     |       vcpu_guest_context_t[nr_vcpus]                   |     +--------------------------------------------------------+   Hypervisor source, "include/public/arch-ia64.h", extract:      struct vcpu_guest_context {         unsigned long flags;       /* VGCF_* flags */         struct cpu_user_regs user_regs;      struct cpu_user_regs {         /* The following registers are saved by SAVE_MIN: */         unsigned long b6;  /* scratch */         unsigned long b7;  /* scratch */          unsigned long ar_csd; /* used by cmp8xchg16 (scratch) */         unsigned long ar_ssd; /* reserved for future use (scratch) */          unsigned long r8;  /* scratch (return value register 0) */         unsigned long r9;  /* scratch (return value register 1) */         unsigned long r10; /* scratch (return value register 2) */         unsigned long r11; /* scratch (return value register 3) */          unsigned long cr_ipsr; /* interrupted task's psr */         unsigned long cr_iip;  /* interrupted task's instruction pointer */  So we have to skip 10 u64's to get at the instruction pointer.      [root@hp-rx2660-02 dump]# readelf -x \         .xen_prstatus 2011-1222-0707.03-virt2.27.core      Hex dump of section '.xen_prstatus':       0x00000000 00000000 00000000 00000000 00000000 ................       0x00000010 a0000001 000102b0 a0000001 000102e0 ................       0x00000020 00000000 00000000 00000000 00000000 ................       0x00000030 00000000 00000263 00000000 00000000 ........c.......       0x00000040 20000000 018ea500 00000000 00000000 ...............       0x00000050 a0000001 000c2160 00005010 08da6010 .`...P..`!......       0x00000060 00000000 00000000 80000000 0000050d ................       [...]  The instruction pointer is a0000001000c2160. In crash:      crash> dis 0xa0000001000c2160     0xa0000001000c2160 <exit_robust_list+128>:      [MII]       ld8 r9=[r33]  (Also, the offending process is Xorg, according to crash.)  With addr2line:      [root@hp-rx2660-02 dump]# addr2line -ife \         /usr/lib/debug/lib/modules/2.6.18-300.el5/vmlinux <<< a0000001000c2160      fetch_robust_entry     /usr/src/debug/kernel-2.6.18/linux-2.6.18-300.el5.ia64/kernel/futex.c:1989     exit_robust_list     /usr/src/debug/kernel-2.6.18/linux-2.6.18-300.el5.ia64/kernel/futex.c:2016  So, the problem is triggered by the glibc commit linked in [bug 711531](show_bug.cgi?id=711531) comment 4: <http://repo.or.cz/w/glibc.git/commitdiff/6f8326ca>  Due to the patch, glibc calls sys_set_robust_list() in the child after fork(), if I understand correctly, which sets "robust_list" in the task_struct of the process. This will make the kernel walk the list of unlocked robust mutexen when the child dies (see "Documentation/robust-futex-ABI.txt").  This walk is implemented by exit_robust_list(), which is exactly the function where we die during the emulation on IA64 [kernel/kernel/futex.c]:      /*      * Walk curr->robust_list (very carefully, it's a userspace list!)      * and mark any locks found there dead, and notify any waiters.      *      * We silently return on any sign of list-walking problem.      */     void exit_robust_list(struct task_struct *curr)     {             struct robust_list_head __user *head = curr->robust_list;             struct robust_list __user *entry, *next_entry, *pending;             unsigned int limit = ROBUST_LIST_LIMIT, pi, next_pi, pip;             unsigned long futex_offset;             int rc;              /*              * Fetch the list head (which was registered earlier, via              * sys_set_robust_list()):              */ [2016]      if (fetch_robust_entry(&entry, &head->list.next, &pi))                     return;      /*      * Fetch a robust-list pointer. Bit 0 signals PI futexes:      */     static inline int fetch_robust_entry(struct robust_list __user **entry,                                          struct robust_list __user **head,                                          int *pi)     {             unsigned long uentry;  [1989]      if (get_user(uentry, (unsigned long *)head))                     return -EFAULT;  get_user() [include/asm-ia64/uaccess.h] -> __get_user_check()   -> __do_get_user()     -> __get_user_size()  __get_user_size() has two implementations, dependent on the macro ASM_SUPPORTED. The feature test macro is defined in [include/asm-ia64/gcc_intrin.h]. The corresponding __get_user_size() implementation seems to use r8 and r9; my eyes sting looking at it so I won't quote it. Anyway, refer back to the disassembly above:      crash> dis 0xa0000001000c2160     0xa0000001000c2160 <exit_robust_list+128>:      [MII]       ld8 r9=[r33]  qemu-dm crashes during get_user(), with a size arg of 8 bytes. Drew says it might be an address corruption problem -- the instruction could be decoded all fine, but the address is frobnicated so that the emulator thinks it's in MMIO range, and tries to translate it to port IO, and qemu-dm chokes on the 8-byte size.  r33 is a "strange" register, to say the least; the IA64 manual states that GR32 to GR127 is "IA-32 code execution space" and that "Convetion" is "undefined" -- "All registers in the current and prior registers frames are left in an undefined state after IA-32 execution. Software must preserve these values before entering the IA-32 instruction set".  OTOH I couldn't find anything above r31 in the "cpu_user_regs" structure in the hypervisor's "include/public/arch-ia64.h" source file. Grepping the hv tree further for "r33" yields hits in:  - arch/ia64/linux/memcpy_mck.S:   "Itanium 2-optimized version of memcpy and copy_user function"  - arch/ia64/linux/sn/kernel/pio_phys.S:   pio_phys_write_mmr, pio_atomic_phys_write_mmrs  - arch/ia64/xen/ivt.S:   "interruption vector table"  - include/asm-ia64/dom_fw.h:   "Xen domain firmware emulation"  We should figure out if this is a glibc-kernel problem (like not detecting invalid userspace data in the kernel), or a kernel-hypervisor problem (like misdecoding a valid kernel access in the hypervisor).  --- Additional comment from lersek on 2011-12-22 17:25:43 EST ---  I was intrigued how get_user() could blow up -- why does it trap to the hypervisor *at all*? Thankfully, "include/asm-ia64/uaccess.h" has an intro comment that explains __get_user_size():  /*  * This file defines various macros to transfer memory areas across  * the user/kernel boundary.  This needs to be done carefully because  * this code is executed in kernel mode and uses user-specified  * addresses.  Thus, we need to be careful not to let the user to  * trick us into accessing kernel memory that would normally be  * inaccessible.  This code is also fairly performance sensitive,  * so we want to spend as little time doing safety checks as  * possible.  *  * To make matters a bit more interesting, these macros sometimes also  * called from within the kernel itself, in which case the address  * validity check must be skipped.  The get_fs() macro tells us what  * to do: if get_fs()==USER_DS, checking is performed, if  * get_fs()==KERNEL_DS, checking is bypassed.  *  * Note that even if the memory area specified by the user is in a  * valid address range, it is still possible that we'll get a page  * fault while accessing it.  This is handled by filling out an  * exception handler fixup entry for each instruction that has the  * potential to fault.  When such a fault occurs, the page fault  * handler checks to see whether the faulting instruction has a fixup  * associated and, if so, sets r8 to -EFAULT and clears r9 to 0 and  * then resumes execution at the continuation point.  *  * Based on <asm-alpha/uaccess.h>.  *  * Copyright (C) 1998, 1999, 2001-2004 Hewlett-Packard Co  *	David Mosberger-Tang <davidm.com>  */  The page fault could trap to the hypervisor. Instead of giving it back to the domU fault handler, the hypervisor could try to translate it to MMIO.  Drew identified a hypervisor step -- emulate_io_inst() -- very close to qemu-dm in [comment 16](show_bug.cgi?id=771764#c16). It's called from the following function [arch/ia64/vmx/vmx_process.c]:      /* We came here because the H/W VHPT walker failed to find an entry */     IA64FAULT     vmx_hpw_miss(u64 vadr , u64 vec, REGS* regs)  This function has two call sites, looking like:                  [ conditions snipped ]                 emulate_io_inst(v,((vadr<<1)>>1),4);   //  UC                 return IA64_FAULT;  and                  if (data->pl >= ((regs->cr_ipsr >> IA64_PSR_CPL0_BIT) & 3))                     emulate_io_inst(v, gppa, data->ma);                 else {                     vcpu_set_isr(v, misr.val);                     data_access_rights(v, vadr);                 }                 return IA64_FAULT;  That is, whichever emulate_io_inst() call gets exercised, the vmx_hpw_miss() handler returns with IA64_FAULT. I'll make a big jump here, but if this returns the control to the domU kernel ultimately, then fetch_robust_entry() will return with -EFAULT, short-circuiting exit_robust_list(), and the domU simply won't care -- it's prepared for that.  This is consistent with Mirek's testing: when he removed the exit(-1) call from qemu-dm, everything worked okay. The emulated IO instruction should have turned into a NOP (because qemu-dm didn't do anything except complain), and the guest kernel happily processed the expected EFAULT in exit_robust_list().  I think this is a hypervisor (or qemu-dm problem). Either the hypervisor shouldn't interpret the access as MMIO, or qemu-dm should be able to handle it. Let's look at vmx_hpw_miss() in upstream.  --- Additional comment from lersek on 2011-12-22 19:04:51 EST ---  I believe we can get the address-to-be-fetched from the current core; the call in [comment 27](show_bug.cgi?id=771764#c27) should give us the starting point.      crash> struct -o robust_list_head     struct robust_list_head {        [0] struct robust_list list;        [8] long int futex_offset;       [16] struct robust_list *list_op_pending;     }     SIZE: 24      crash> struct -o robust_list     struct robust_list {       [0] struct robust_list *next;     }     SIZE: 8  So,   (char *)&(curr->robust_list->list.next) == (char *)curr->robust_list + 0 + 0      crash> set 1030         PID: 1030     COMMAND: "Xorg"        TASK: e00000000d618000  [THREAD_INFO: e00000000d619040]         CPU: 0       STATE: TASK_RUNNING (ACTIVE)      crash> struct task_struct.robust_list e00000000d618000       robust_list = 0x20000000018ea500  This is the (user) address we try to dereference. However:      crash> vtop -u 0x20000000018ea500     VIRTUAL           PHYSICAL             20000000018ea500  (not accessible)  (Just to be sure:      crash> vtop -k 0x20000000018ea500     VIRTUAL           PHYSICAL             20000000018ea500  (not a kernel virtual address) )  This could be the cause of the fault / trap.  Side note: referring back to the .xen_prstatus ELF section dump in [comment 27](show_bug.cgi?id=771764#c27), the above value is present in the dump at offset 0x40:        0x00000040 20000000 018ea500 00000000 00000000 ...............        This should correspond to r11. I tried to confirm it by disassembling exit_robust_list(), but it's greek to me.  --- Additional comment from lersek on 2011-12-23 07:46:32 EST ---  If the fault is indeed mistakenly classified as needing MMIO, then emulate_io_inst() shouldn't be called at all. Therefore the ldfp8 instruction is the result of a mis-parse. The disassembly from "crash" again (full bundle):  0xa0000001000c2160 <exit_robust_list+128>:      [MII]       ld8 r9=[r33] 0xa0000001000c2161 <exit_robust_list+129>:                  nop.i 0x0 0xa0000001000c2162 <exit_robust_list+130>:                  nop.i 0x0;;  crash> px  *(long unsigned *)0xa0000001000c2160 $3 = 0x101842004801  crash> px  *(long unsigned *)0xa0000001000c2168 $4 = 0x4000000000200  $4.$3 == 0040000000002000.0000101842004801  In binary, from left to right:  00000000000001000000000000000000000000000 -- 41 bits, slot 2 00000000000001000000000000000000000000000 -- 41 bits, slot 1 01000000011000010000100000000001001000000 -- 41 bits, slot 0 00001                                     -- 5 bits, template  The template value determines MII (M-Unit for slot 0, I unit for the others), plus there are no stops between the slots. Slot 1 and slot 2 have identical contents, corresponding to "nop.i". They probably only pad the bundle to three slots.  0000 0 000 000001 0 00000000000000000000 000000  I18 i  x3   x6   y        imm20a          qp  ("y" distinguishes between "nop.i" and "hint.i".)  slot 0:  0100 0 000011 00 0 0100001 0000000 0001001 000000 M1/2 m   x6   h. x    r3      r2     r1      qp  opcode: 4              --> M1 or M2 m     : 0 x6    : 0000.11 binary --> ld8 M2 hint  : 00 binary      --> no load hint x     : 0 r3    : 33 decimal r1    : 9 decimal  That is, the disassembler in "crash" does not lie.  --- Additional comment from lersek on 2011-12-23 13:17:06 EST ---  emulate_io_inst() does not misparse the ld8 instruction as ldfp8 actually -- it recognizes it correctly. Refer back to the previous comment ([comment 40](show_bug.cgi?id=771764#c40)) for data. The branch is not easy to find because the transfer size (8 bytes) is not specified in cleartext, it is expressed as "1 << (x6 & 0x03)".      // Integer Load/Store     if(inst.M1.major==4&&inst.M1.m==0&&inst.M1.x==0){         inst_type = SL_INTEGER;  //         size=(inst.M1.x6&0x3);         if((inst.M1.x6>>2)>0xb){      // write             dir=IOREQ_WRITE;     //write             vcpu_get_gr_nat(vcpu,inst.M4.r2,&data);         }else if((inst.M1.x6>>2)<0xb){   //  read             dir=IOREQ_READ;         }     }  [... a bunch of else-if branches, then ...]      size = 1 << size;     if(dir==IOREQ_WRITE){         mmio_access(vcpu, padr, &data, size, ma, dir);     }else{         mmio_access(vcpu, padr, &data, size, ma, dir);         if(inst_type==SL_INTEGER){       //gp             vcpu_set_gr(vcpu,inst.M1.r1,data,0);         }else{             panic_domain(NULL, "Don't support ldfd now !");         }     }     vcpu_increment_iip(vcpu);  --- Additional comment from lersek on 2011-12-23 15:31:51 EST ---  Created [attachment 549385](attachment.cgi?id=549385&action=diff) [[details]](attachment.cgi?id=549385&action=edit) add debug logging to ia64 fault handler and mmio insn decoder  The output of this patch seems to confirm the above. The last three hv dmesg lines before the hang are:  (XEN) mmio.c:458:d1 callsite=2 vadr=0x20000000018ea500                     ^                 ^                     |                 Xorg.robust_list, see [comment 36](show_bug.cgi?id=771764#c36)                     |                     2nd emulate_io_inst() call in vmx_hpw_miss()                     ([comment 32](show_bug.cgi?id=771764#c32), but see here too, with the debug patch:)  (XEN) mmio.c:463:d1 gppa=0xe0cea500 vec=2 d_ppn=0xe0ce8 d_ma=4 d_ps=14   313  /* We came here because the H/W VHPT walker failed to find an entry */  314  IA64FAULT  315  vmx_hpw_miss(u64 vadr , u64 vec, REGS* regs)  316  {   330    else if (vec == 2)  331      type = DSIDE_TLB;  vec == 2, data TLB.   351    if((data=vtlb_lookup(v, vadr,type))!=0){  vadr is found in the data TLB.   352      if (v->domain != dom0 && type == DSIDE_TLB) {  353        if (misr.sp) { /* Refer to SDM Vol2 Table 4-10,4-12 */  354          if ((data->ma == VA_MATTR_UC) || (data->ma == VA_MATTR_UCE))  355            return vmx_handle_lds(regs);  356        }  357        gppa = (vadr & ((1UL << data->ps) - 1)) +  358               (data->ppn >> (data->ps - 12) << data->ps);  "gppa" -- guest physical page address -- is computed as follows. The data TLB entry specifies a page size (d_ps == 14, 16KB). The lower 14 bits are taken from the virtual address (->0x2500). The low 2 bits in the physical page number (d_ppn == 0xe0ce8) are cleared, and then it is shifted 12 bits to the left (->0xe0ce8000). Finally they are combined to gppa == 0xe0cea500.   359        if (__gpfn_is_io(v->domain, gppa >> PAGE_SHIFT)) {  PAGE_SHIFT is 14 in our configuration, the guest page frame number is 0x3833A. It is found to be an IO mapped page. I'll have to see why. An interesting tidbit is that qemu-dm logs:      inp: bad size: 33a8 8 -- pausing  "33a8" looks awfully similar to 0x3833A -- keep the low 16 bits of the latter and do a 4-bit ROL in those 16 bits, and you end up with 33A8.   360          if (misr.sp)  361            panic_domain(NULL, "ld.s on I/O page not with UC attr."  362                         " pte=0x%lx\n", data->page_flags);  So misr.sp was false above too (at line 353).   363          if (data->pl >= ((regs->cr_ipsr >> IA64_PSR_CPL0_BIT) & 3)) {  This is a privilege level check.   364            scratch.callsite = 2;  365            scratch.vadr = vadr;  366            scratch.gppa = gppa;  367            scratch.vec = vec;  368            scratch.d_ppn = data->ppn;  369            scratch.d_ma = data->ma;  370            scratch.d_ps = data->ps;  371            emulate_io_inst(v, gppa, data->ma);  (XEN) mmio.c:467:d1 padr=0xe0cea500 ma=4 cr_iip=0xa0000001000c2160 slot=0                     ^                    ^                         ^                     gppa                 domU get_user(),          slot in                                          see [comment 27](show_bug.cgi?id=771764#c27)            bundle        bundle=0x00040000000002000000101842004801                ^                the insn bundle containing the ld8 and the two NOPs, see                [comment 40](show_bug.cgi?id=771764#c40).  "ma" is "memory attribute", 4 means VA_MATTR_UC, uncacheable (see table 4-11).  ----o----  "callsite == 1" was never hit. The guest hit "callsite == 2" 2201 times (including the fatal, last one). The first 2200 occasions (that succeeded) were all like this:  (XEN) mmio.c:458:d1 callsite=2 vadr=0xc0000000000b.... (XEN) mmio.c:463:d1 gppa=0xb.... vec=2 d_ppn=0xb8 d_ma=4 d_ps=24 (XEN) mmio.c:467:d1 padr=0xb.... ma=4 cr_iip=0xa0000001002e9... slot=0       bundle=[whatever]  cr_iip always points into __copy_user() in the domU, and the physical address / physical frame number suggests it's video RAM. Logging depends on the transfer size being 8, so it's interesting why qemu-dm satisfies the first 2200 read requests.  ... I believe because they have a different path already in the hypervisor --  mmio_access() special-cases GPFN_LOW_MMIO:  low_mmio_access() -> hvm_buffered_io_intercept()  static struct hvm_buffered_io_range buffered_stdvga_range = {0xA0000, 0x20000};  All 2200 successful requests fall into this buffered range.  ----o----  So, is the problem that "vadr" is found in the virtual data TLB? Or is it that the retrieved frame number qualifies as (high) MMIO?  The virtual address in Xorg's robust_list definitely shouldn't be recognized as MMIO. Again, gppa is 0xe0cea500, which is above 3596 MB (decimal). The HVM guest in question has 1 GB RAM, so I'm inclined to believe the hypervisor will consider such a physical address as MMIO. Therefore I suspect the data TLB has a bogus entry. We're doomed.  --- Additional comment from lersek on 2011-12-25 06:20:52 EST ---  Created [attachment 549475](attachment.cgi?id=549475&action=diff) [[details]](attachment.cgi?id=549475&action=edit) hv debug logging v2  ... in ia64 fault handler and mmio insn decoder, mmio_access(), lookup_domain_mpa()  (In reply to [comment #42](show_bug.cgi?id=771764#c42))  > the guest page frame number is 0x3833A. > It is found to be an IO mapped page. I'll have to see why. An interesting > tidbit is that qemu-dm logs: > >     inp: bad size: 33a8 8 -- pausing > > "33a8" looks awfully similar to 0x3833A -- keep the low 16 bits of the latter > and do a 4-bit ROL in those 16 bits, and you end up with 33A8.  (XEN) mmio.c:472:d1 callsite=2 vadr=0x20000000018ea500 (XEN) mmio.c:479:d1 gppa=0xe0cea500 vec=2 d_ppn=0xe0ce8 d_ma=4 d_ps=14       misr_rs=0 vpsr_dt=1 vpsr_rt=1 (XEN) mmio.c:483:d1 padr=0xe0cea500 ma=4 cr_iip=0xa0000001000c2160 slot=0       bundle=0x00040000000002000000101842004801 (XEN) mmio.c:242:d1 mmio_access(): entry (XEN) mm.c:712:d1 lookup_domain_mpa(): entry (XEN) mm.c:718:d1 lookup_domain_mpa(): ptep=f000000181c699d0 (XEN) mm.c:726:d1 lookup_domain_mpa(): pte=0x5010000000000761 (XEN) mm.c:731:d1 lookup_domain_mpa(): pte present (XEN) mmio.c:248:d1 mmio_access(): iot=0x5000000000000000  vmx_hpw_miss() -- non-phys mode call, [comment 42](show_bug.cgi?id=771764#c42) -> emulate_io_inst() -- for ld8, [comment 41](show_bug.cgi?id=771764#c41)   -> mmio_access()     -> __gpfn_is_io -- returns GPFN_LEGACY_IO == 0x5000000000000000     -> legacy_io_access()  legacy_io_access() is the one to turn 0xE0CEA500 into 0x33A8 when composing the ioreq for qemu-dm:      #define TO_LEGACY_IO(pa)  (((pa)>>12<<2)|((pa)&0x3))      p->addr = TO_LEGACY_IO(pa&0x3ffffffUL);  11100000110011101010010100000000 bin = 0xE0CEA500       ^^^^^^^^^^^^^^          ^^       00110011101010          00 bin = 0x33A8  --- Additional comment from lersek on 2011-12-26 06:17:44 EST ---  Created [attachment 549579](attachment.cgi?id=549579&action=diff) [[details]](attachment.cgi?id=549579&action=edit) hv debug logging v3  debug patch: - ia64 fault handler and mmio insn decoder - mmio_access(), lookup_domain_mpa() - vmx_vcpu_thash() -- log "vhpt_adr" output - guest_vhpt_lookup()  (In reply to [comment #42](show_bug.cgi?id=771764#c42))  >  351    if((data=vtlb_lookup(v, vadr,type))!=0){ > > vadr is found in the data TLB. > >  352      if (v->domain != dom0 && type == DSIDE_TLB) { >  353        if (misr.sp) { /* Refer to SDM Vol2 Table 4-10,4-12 */ >  354          if ((data->ma == VA_MATTR_UC) || (data->ma == VA_MATTR_UCE)) >  355            return vmx_handle_lds(regs); >  356        } >  357        gppa = (vadr & ((1UL << data->ps) - 1)) + >  358               (data->ppn >> (data->ps - 12) << data->ps); > > "gppa" -- guest physical page address -- is computed as follows. The data TLB > entry specifies a page size (d_ps == 14, 16KB). The lower 14 bits are taken > from the virtual address (->0x2500). The low 2 bits in the physical page > number (d_ppn == 0xe0ce8) are cleared, and then it is shifted 12 bits to the > left (->0xe0ce8000). Finally they are combined to gppa == 0xe0cea500.  (In reply to [comment #44](show_bug.cgi?id=771764#c44))  > I may have to catch all references to the faulting vaddr (Xorg's robust_list) > in the virtual TLB.  So, why does vtlb_lookup() return 0xe0ce8 for the PPN? This patch helps track that back a bit more.  There are three mentions of guest iip=0xa0000001000c2160 in the log (which is the problematic ld8 of *robust_list, virtual address 0x20000000018ea500). There's a big gap between the 1st and (2nd+3rd), the latter two are adjacent.  The first DTLB miss (translation failure):  (XEN) vtlb.c:275:d1 guest_vhpt_lookup(): data=f000000180274100 (XEN) vmx_process.c:444:d1 vmx_hpw_miss(): vhpt_adr=0x3ffe0000000031d0 (XEN) vtlb.c:555:d1 thash_purge_and_insert(): pte=0x1000000e3181a1       itir=0x3ab938 ifa=0x20000000018ea500 type=1 iip=0xa0000001000c2160       caller=vmx_hpw_miss  vmx_hpw_miss() is called for a DTLB miss. - We're not in physical mode, - the vadr is not found in the vtlb, - we advance through vmx_hpw_miss() until we reach the following:          vmx_vcpu_thash(v, vadr, &vhpt_adr);  The virtual address is hashed to vhpt_addr (= 0x3ffe0000000031d0).          if (!guest_vhpt_lookup(vhpt_adr, &pteval)) {  It is looked up in the guest VHPT, and found; a PTE is returned, containing a PPN (here 0xe318, corresponding to about 227 MB),              /* VHPT successfully read.  */             if (!(pteval & _PAGE_P)) {                 if (vpsr.ic) {                     vcpu_set_isr(v, misr.val);                     dtlb_fault(v, vadr);                     return IA64_FAULT;                 } else {                     nested_dtlb(v);                     return IA64_FAULT;                 }             } else if ((pteval & _PAGE_MA_MASK) != _PAGE_MA_ST) {                 vcpu_get_rr(v, vadr, &rr);                 itir = rr & (RR_RID_MASK | RR_PS_MASK);                  if (0x20000000018ea500 == vadr) {                     gdprintk(XENLOG_DEBUG, "vmx_hpw_miss(): vhpt_adr=0x%lx\n",                              vhpt_adr);                 }                  thash_purge_and_insert(v, pteval, itir, vadr, DSIDE_TLB,                                        __FUNCTION__);                 return IA64_NO_FAULT;  and then inserted in the vtlb.  I think, what happens is basically: translation fails at first, we copy it from the guest VHPT to the TLB, and then we make progress. All good.  The second & third misses are our problem -- actually I think the same guest instruction faults twice in quick succession. Of those, the first happens just like above:  (XEN) vtlb.c:275:d1 guest_vhpt_lookup(): data=f000000180276100 (XEN) vmx_process.c:444:d1 vmx_hpw_miss(): vhpt_adr=0x3ffe0000000031d0 (XEN) vtlb.c:555:d1 thash_purge_and_insert(): pte=0x100000e0ce85b1       itir=0x3bc138 ifa=0x20000000018ea500 type=1 iip=0xa0000001000c2160       caller=vmx_hpw_miss  The vadr that fails to translate is the same (0x20000000018ea500, contents of robust_list), at the same domU instruction. The vadr hashes to the same vhpt_adr (0x3ffe0000000031d0), and it is again found in the guest VHPT, but with different contents: the PTE returned this time specifies PPN 0xe0ce8, which is what we copy in the VTLB.  Then the fault kicks again immediately (... probably), we retrieve the PPN from the VTLB we just copied over from the guest VHPT:  (XEN) mmio.c:472:d1 callsite=2 vadr=0x20000000018ea500 (XEN) mmio.c:479:d1 gppa=0xe0cea500 vec=2 d_ppn=0xe0ce8 d_ma=4 d_ps=14       misr_rs=0 vpsr_dt=1 vpsr_rt=1 (XEN) mmio.c:483:d1 padr=0xe0cea500 ma=4 cr_iip=0xa0000001000c2160 slot=0       bundle=0x00040000000002000000101842004801 (XEN) mmio.c:242:d1 mmio_access(): entry (XEN) mm.c:712:d1 lookup_domain_mpa(): entry (XEN) mm.c:718:d1 lookup_domain_mpa(): ptep=f000000181c699d0 (XEN) mm.c:726:d1 lookup_domain_mpa(): pte=0x5010000000000761 (XEN) mm.c:731:d1 lookup_domain_mpa(): pte present (XEN) mmio.c:248:d1 mmio_access(): iot=0x5000000000000000  and we decide the PPN is IO-mapped.  In short, the source of the problematic PPN is the guest VHPT; it's there where we copy the PPN from, into the VTLB. We retrieve the PPN from the VTLB finally, and it causes us to compose a bogus ioreq for qemu-dm.  I believe this code implements (virtualizes) the algorithm described in chapter "4.1 Virtual Addressing" of the Itanium SDM vol2.  I backported the fixed assembly from c/s 17086 to guest_vhpt_lookup(), assuming guest_vhpt_lookup() returned a garbage PTE (and so PPN) because of the messed up gcc assembly template. Unfortunately, the backport didn't help at all, it seems the guest VHPT indeed specifies the bad PPN.  An interesting point is the difference in the VCPU's ITIR ("Interruption TLB Insertion Register"), which is basically an input param to the vmx_hpw_miss() handler.  first (valid) thash insertion case:    itir=0x3ab938  second (bad) thash insertion case:     itir=0x3bc138   The difference is in the subsequence called "key" (bits 8 to 31). "On an instruction or data translation fault, this field is set to the accessed Region Identifier (RR.rid)" (Table 3-8.)  Why on earth does the VCPU think it is accessing a different Region? The vadr is the same, so the Virtual Region Number (the most significant 3 bits in the vadr) is the same, selecting the same (0th) region register. So, the contents of that region register must have changed. In that case, however, the hash of the virtual address (vhpt_adr, computed by vmx_vcpu_thash(), see above) should have changed as well, because the region ID is an input to the hash as well. However, vhpt_adr is identical (0x3ffe0000000031d0).  --- Additional comment from lersek on 2011-12-26 14:30:23 EST ---  I'm stuck figuring out where the guest VHPT is populated.  This could be the data flow:  guest VHPT ---> vtlb ---> HVM domU mm_struct  ---> legacy MMIO             ^         ^   (GPFN to mach. PTE)             |         |            1st       2nd        translation transl.            fault    fault  The guest page frame number 0xe0ce8 comes from the guest VHPT. I'm unable to find what writes it there (ie. more to the left on the diagram).  --- Additional comment from lersek on 2011-12-26 16:12:01 EST ---  Re-reading [comment 36](show_bug.cgi?id=771764#c36) (the userspace virtual address is not even resolvable in the guest!) this could be a "stale guest VHPT" problem. If the 1st translation fault didn't find the virtual adress's hash in the guest VHPT, we wouldn't even reach the 2nd translation: vmx_hpw_miss() would return IA64_FAULT, and the get_user() call in the guest would complete.  I think when the virtual address 0x20000000018ea500 (= robust_list) is unmapped, the guest VHPT is not updated (flushed?) quickly enough. guest_vhpt_lookup() should return failure for the vadr's hashed value.  --- Additional comment from lersek on 2011-12-28 11:08:03 EST ---  I think we're making progress!  (1) I changed the guest kernel like this:  --------v-------- diff --git a/kernel/futex.c b/kernel/futex.c index e4aa3d5..3a7d52b 100644 --- a/kernel/futex.c +++ b/kernel/futex.c @@ -1992,7 +1992,8 @@ static inline int fetch_robust_entry(struct robust_list __user **entry,    #ifdef CONFIG_IA64         ia64_ptr(2, head, 3); -       ia64_srlz_d(); +       ia64_ptcga(head, 3 << 2); +       ia64_srlz_i();  #endif         if (get_user(uentry, (unsigned long *)head))                 return -EFAULT; --------^--------  Inserting ptc.ga (purge global translation cache) before attempting to fetch *robust_list had the desired effect I wrote about in [comment 49](show_bug.cgi?id=771764#c49):  (In reply to [comment #49](show_bug.cgi?id=771764#c49))  > If the 1st translation fault didn't find the virtual adress's hash in the > guest VHPT, we wouldn't even reach the 2nd translation: vmx_hpw_miss() would > return IA64_FAULT  ptc.ga is trapped by the hypervisor. It is emulated by:  vmx_emulate() [arch/ia64/vmx/vmx_virt.c] -> vmx_emul_ptc_ga()   -> vmx_vcpu_ptc_ga() [arch/ia64/vmx/vmmu.c]     -> vmx_vcpu_ptc_l()       -> thash_purge_entries() [arch/ia64/vmx/vtlb.c]         -> vhpt_purge()  which indeed kills off the virtual address from the guest VHPT: when the guest kernel tries to dereference the vaddr, the subsequent vmx_hpw_miss() in the HV fails to look it up in either the VTLB or the VHPT -- guest_vhpt_lookup():  (XEN) vtlb.c:275:d13 guest_vhpt_lookup(): data=0000000000000000 (XEN) vtlb.c:281:d13 guest_vhpt_lookup(): data2=0000000000000000  and vmx_hpw_miss() ends up calling dvhpt_fault() --> _vhpt_fault() in "arch/ia64/vmx/vmx_interrupt.c". The latter function sets up IFA (= faulting vadr), ITIR, IHA, and injects an IA64_VHPT_TRANS_VECTOR guest interruption:  Hypervisor: [include/asm-ia64/ia64_int.h]      #define	IA64_VHPT_TRANS_VECTOR			0x0000  domU kernel: [arch/ia64/kernel/ivt.S]      // 0x0000 Entry 0 (size 64 bundles) VHPT Translation (8,20,47)     ENTRY(vhpt_miss)  The vhpt_miss() assembly-language domU function executes an "itc.d r18" instruction -- "insert translation cache". This traps back to the hypervisor, and the hypervisor inserts the PTE (coming from the domU!) in the VTLB:  (XEN) mm.c:712:d13 lookup_domain_mpa(): entry (XEN) mm.c:718:d13 lookup_domain_mpa(): ptep=f000001368dc19d0 (XEN) mm.c:726:d13 lookup_domain_mpa(): pte=0x5010000000000761 (XEN) mm.c:731:d13 lookup_domain_mpa(): pte present (XEN) vtlb.c:555:d13 thash_purge_and_insert(): pte=0x10100000e0ce85b1       itir=0x3c7138 ifa=0x20000000018ea500 type=1 iip=0xa000000100000130       caller=vmx_vcpu_itc_d  (iip=0xa000000100000130 points to the itc.d in vhpt_miss() in my test kernel, I verified it with objdump -D).  vmx_emulate() [arch/ia64/vmx/vmx_virt.c] -> vmx_emul_itc_d()   -> vmx_vcpu_itc_d() [arch/ia64/vmx/vmmu.c]     -> thash_purge_and_insert() [arch/ia64/vmx/vtlb.c]  Then the *robust_list read is retried, and resolved from the VTLB as before.  (XEN) mm.c:712:d13 lookup_domain_mpa(): entry (XEN) mm.c:718:d13 lookup_domain_mpa(): ptep=f000001368dc19d0 (XEN) mm.c:726:d13 lookup_domain_mpa(): pte=0x5010000000000761 (XEN) mm.c:731:d13 lookup_domain_mpa(): pte present (XEN) mmio.c:472:d13 callsite=2 vadr=0x20000000018ea500 (XEN) mmio.c:479:d13 gppa=0xe0cea500 vec=2 d_ppn=0xe0ce8 d_ma=4 d_ps=14       misr_rs=0 vpsr_dt=1 vpsr_rt=1 (XEN) mmio.c:483:d13 padr=0xe0cea500 ma=4 cr_iip=0xa0000001000c21a0 slot=0       bundle=0x00040000000002000000101842004801 (XEN) mmio.c:242:d13 mmio_access(): entry (XEN) mm.c:712:d13 lookup_domain_mpa(): entry (XEN) mm.c:718:d13 lookup_domain_mpa(): ptep=f000001368dc19d0 (XEN) mm.c:726:d13 lookup_domain_mpa(): pte=0x5010000000000761 (XEN) mm.c:731:d13 lookup_domain_mpa(): pte present (XEN) mmio.c:248:d13 mmio_access(): iot=0x5000000000000000   Summary: --------  (0) the "robust_list" userspace address is *not* in the VTLB, in either case.  (1) normally, it is in the guest VHPT, and on access it is copied from the gVHPT to the VTLB, and resolved from there.  (2) when I force the vaddr out of the gVHPT, the miss goes "deeper", ie. back to the domU, and this time the guest kernel actively reinserts the same bogus  pseudo-physical page number into the VTLB, originating from the *domU PTE* for the virtual address. Then on access the address is resolved from the VTLB as before.  It very much seems like a guest kernel problem.  --- Additional comment from lersek on 2011-12-28 14:53:22 EST ---  Created [attachment 549849](attachment.cgi?id=549849&action=diff) [[details]](attachment.cgi?id=549849&action=edit) walk_vadr() -- walk robust_list thorugh the pagetable (domU kernel)  Getting close.  I scavenged mapped_kernel_page_is_present() [arch/ia64/mm/fault.c] and wrote walk_vadr(). Each time sys_set_robust_list() is called or fetch_robust_entry() is called, the patch walks the pagetables and prints the PTE. This can be correlated with the hypervisor debug log.  (Please excuse the stupid " %16s" format specifier, I meant "%.16s" -- I didn't want to specify the field width (padding) but the precision for %s: the precision puts a limit on the number of printed bytes. I wasn't sure if task_struct.comm is NUL-terminated or not. Thankfully it is.)  Reproducing the problem again, this is the end of the hv log (see [comment 52](show_bug.cgi?id=771764#c52) for more):  (XEN) mmio.c:472:d21 callsite=2 vadr=0x20000000018ea500 (XEN) mmio.c:479:d21 gppa=0xe0cea500 vec=2 d_ppn=0xe0ce8 d_ma=4 d_ps=14       misr_rs=0 vpsr_dt=1 vpsr_rt=1 (XEN) mmio.c:483:d21 padr=0xe0cea500 ma=4 cr_iip=0xa0000001000c2860 slot=0       bundle=0x00040000000002000000101848004801  vadr=0x20000000018ea500 is the usual contents of the robust_list pointer, gppa has the usual offender PPN (coming from the usual bad guest PTE). cr_iip=0xa0000001000c2860 corresponds to the get_user() call in fetch_robust_entry(), right after the walk_vadr() invocation this patch introduced there.  So, what does the guest kernel log? A bunch of sys_set_robust_list() and fetch_robust_entry() lines. The revelation comes when we  - grab the last line, printed right before the problematic get_user() call (see cr_iip above), and  - check all other lines for the same PID, in order to see the original sys_set_robust_list() for the same process:  walk_vadr(): rhgb[1084]: sys_set_robust_list(): vadr=0x20000000018ea500     pgdp=e00000000dd10800 pgd=0xd8d4000     pudp=e00000000dd10800 pud=0xd8d4000     pmdp=e00000000d8d4000 pmd=0x3ce2c000     ptep=e00000003ce2f1d0 pte=0x1000000e7485e1  walk_vadr(): Xorg[1084]: fetch_robust_entry(): vadr=0x20000000018ea500     pgdp=e00000003c40c800 pgd=0x1e5c000     pudp=e00000003c40c800 pud=0x1e5c000     pmdp=e000000001e5c000 pmd=0x3cbf4000     ptep=e00000003cbf71d0 pte=0x100000e0ce85b1  The task's name (task_struct.comm) has changed! Although PIDs are recycled, during such a short time it must have been an exec(). The vadr is the same (consistent with the hypervisor), and compare the guest PTE (at Xorg exit time) against the bad PPN in the hypervisor log:        pte=0x100000e0ce85b1     d_ppn=0x      e0ce8  So, rhgb[1084] is *forked* by something (let's call it "rhgb^"), then rhgb[1084] *executes* Xorg[1084], without resetting the "robust_list" pointer in the task struct. When Xorg (a completely independent process image) exits, the same userspace virtual address happens to be mapped in it, but the backing PTE is completely different.        rhgb^    -- sets robust_list          |         |       fork()   -- *used* to clear robust_list, but not after the glibc patch         |         for [bug 711531](show_bug.cgi?id=711531).         |         V      rhgb[1084]          |         |       exec()   -- *never* clears robust_list         |         |         V      Xorg[1084]  The patch for [bug 711531](show_bug.cgi?id=711531) completed the inheritance chain from rhgb^ to Xorg[1084]. It must be broken again by fixing exec(). Candidate patch should follow soon.  --- Additional comment from lersek on 2012-01-02 11:21:27 EST ---  Created [attachment 550268](attachment.cgi?id=550268&action=diff) [[details]](attachment.cgi?id=550268&action=edit) Move "exit_robust_list" into mm_release(); nullify lists after cleanup (v2)  This is a backport of upstream commits 8141c7f3 & fc6b177d:      We don't want to get rid of the futexes just at exit() time, we want     to drop them when doing an execve() too, since that gets rid of the     previous VM image too.      Doing it at mm_release() time means that we automatically always do it     when we disassociate a VM map from the task.      The robust list pointers of user space held futexes are kept intact     over an exec() call. When the exec'ed task exits exit_robust_list() is     called with the stale pointer. The risk of corruption is minimal, but     still it is incorrect to keep the pointers valid. Actually glibc     should uninstall the robust list before calling exec() but we have to     deal with it anyway.      Nullify the pointers after [compat_]exit_robust_list() has been     called.  The fault caused by the stale robust_list pointer was spuriously resolved to MMIO in Xen HVM guests on IA64.  Inclusion of <linux/compat.h> in kernel/fork.c depends on !__GENKSYMS__ in order to avoid kABI breakage.  ----o----  --- Additional comment from lersek on 2012-01-06 04:17:33 EST ---  (In reply to [comment #71](show_bug.cgi?id=771764#c71)) > (In reply to [comment #68](show_bug.cgi?id=771764#c68)) >> (In reply to [comment #63](show_bug.cgi?id=771764#c63)) >>> ... >>> Can you please also test the kernel as described in [bug 711531](show_bug.cgi?id=711531) >>> [comment 0](show_bug.cgi?id=771764#c0)? (It doesn't matter if it's a guest or the host, or even bare >>> metal.)  > Is this supposed to be tested with a privileged user?  It should make no difference.  I think the test program checks if robust mutexen are indeed robust <<http://www.opengroup.org/onlinepubs/9699919799/functions/pthread_mutexattr_getrobust.html>>. Basically, a mutex can be shared by threads in the same process, or by threads in different processes (process-shared mutex).  If the mutex is process shared and robust, and thread T1 in process P1 locks it, and then process P1 exits or executes another image, then the next thread T2 in process P2 trying to acquire the mutex will get EOWNERDEAD. (Other contenders will block on the mutex). Then T2 can clean up the shared state, mark the mutex consistent, and unlock the mutex. This way global progress can be made.  If it's not the entire process P1 to exit, just thread T1 (which also enables the single-process case, ie. threads T1 and T2 are in the same process P1), and T1 exits while holding the mutex (returns from the thread start function or calls pthread_exit()), then returning EOWNERDEAD to T2 in pthread_mutex_lock() is optional -- preventing the deadlock in this case is not mandatory for the system.  The test program checks four cases. There are two dimensions and all variations are tested. The first dimension is the above, ie. whether T1 and T2 share P1, or belong to different processes (via fork()). Linux seems to provide (otherwise not mandated, but allowed) EOWNERDEAD even for threads sharing the same process.  The second dimension is whether the test program tries to "patch up" glibc dynamically, ie. if it calls the set_robust_list() syscall manually right after fork(). The test program uses pthread_atfork() for this <<http://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_atfork.html>>, it copies the robust_list pointer from the parent to the child if glibc doesn't take care of that itself. The test program was originally a reproducer for the glibc bug -- when it says in case #4: "forks with NO post-fork set_robust_list -- hangs (no owner-death cleanup)", it demonstrates the missing set_robust_list() call after fork() in glibc.  With the glibc patch applied this dimension should make no difference, all four test cases and the entire test run should complete.  I also executed the test program (in the HVM Xen guest that I used to debug the bug), on the brew kernel from [comment 61](show_bug.cgi?id=771764#c61) (_gks2), after the guest booted successfully into runlevel 5. The test program exited successfully (which matches Qixiang's results in [comment 68](show_bug.cgi?id=771764#c68)), so I think we can consider this verified.   --- Additional comment from lersek on 2012-02-01 11:04:29 EST ---  We tracked down where gppa=0xe0cea500 comes from: why is that (pseudo-)physical page mapped into Xorg at all?  Xorg contains a bunch of ioperm() calls [hw/xfree86/os-support/linux/lnx_video.c]: - xf86EnableIO() - xf86DisableIO() - xf86DisableInterrupts() - xf86EnableInterrupts()  xf86EnableIO() is the most probable caller.  ioperm() is a libc function which depends on appropriate privileges (Petr tested its EPERM condition in the IA64 HVM guest). On IA64, ioperm() is implemented like this [sysdeps/unix/sysv/linux/ia64/ioperm.c]:  - "get I/O base physical address from ar.k0 as per PRM" --> phys_io_base, - open /dev/mem --> this gives access to (pseudo-)physical memory,   if the process has appropriate privileges, - get a length from "io_offset(MAX_PORT)" --> returns 64 MB (see also   chapter 10.7 "I/O Port Space Model" in the Itanium(R) SDM rev 2.3), - mmap offset range [phys_io_base, phys_io_base + len) from /dev/mem, - close the file descriptor.  (Should Xorg execute another image with such a mapping: memory mappings are dropped on execve(), and the fd is closed early enough. Xorg is not multi-threaded, so the "usual" FD_CLOEXEC (or close()) race against other threads shouldn't apply.)  The mappings of the Xorg process (from /proc/PID/maps, some fields omitted): - virtual address range: 2000000000c00000-2000000004c00000 - consequently, size: 64 MB - file: /dev/mem - start offset in file: e0000000  From /proc/iomem (in the guest):   e0000000-e033dcf7 : PCI Bus 0000:00 I/O Ports 00000000-00000cf7   e0340d00-e3ffffff : PCI Bus 0000:00 I/O Ports 00000d00-0000ffff  Also 64 MB (e0000000 .. e3ffffff). Plus, 0x400 bytes (= 1 KB) are allocated for each port.  Again, gppa=0xe0cea500, falling in the second iomem range. Xorg must have attempted to access the following port:       (gppa - iomem_range_base) / bytes_per_port + port_base   == (0xe0cea500 - 0xe0340d00) / 0x400 + 0xD00   == 0x9A9800 / 0x400 + 0xD00   == 0x26A6 + 0xD00   == 0x33A6  Which is quite close to the 0x33A8 described in [comment 45](show_bug.cgi?id=771764#c45). There's some "non-linearity" between the two port ranges above; if we rebase the formula onto the first range:       (0xe0cea500 - 0xe0000000) / 0x400 + 0x0 ~= 0x33A9  In summary, - itc.d and its dependencies are kernel-space only in the guest, - qemu-dm's reaction to an ill-sized MMIO request could be hardened perhaps,   but it needs more analysis, - Xorg had the gppa mapped because that's how ioperm() works on IA64.   ```  [Comment 5](show_bug.cgi?id=771764#c5)  errata-xmlrpc    2012-02-09 16:41:53 UTC  ``` This issue has been addressed in following products:    Red Hat Enterprise Linux 5  Via RHSA-2012:0107 <https://rhn.redhat.com/errata/RHSA-2012-0107.html>   ```  [Comment 7](show_bug.cgi?id=771764#c7)  Eugene Teo (Security Response)    2012-02-15 05:22:27 UTC  ``` Statement:  This issue did not affect the Linux kernel as shipped with Red Hat Enterprise Linux 4 as it did not have support for robust futexes. It did not affect Red Hat Enterprise Linux 6 and Red Hat Enterprise MRG as they have the backported fixes. This has been addressed in Red Hat Enterprise Linux 5 via <https://rhn.redhat.com/errata/RHSA-2012-0107.html>.   ```  [Comment 9](show_bug.cgi?id=771764#c9)  errata-xmlrpc    2012-03-06 17:44:00 UTC  ``` This issue has been addressed in following products:    Red Hat Enterprise Linux 5.6 EUS - Server Only  Via RHSA-2012:0358 <https://rhn.redhat.com/errata/RHSA-2012-0358.html>   ``` |  |
| --- | --- |

---

| Note You need to [log in](show_bug.cgi?id=771764&GoAheadAndLogIn=1) before you can comment on or make changes to this bug. |
| --- |

---

[Privacy](page.cgi?id=redhat/privacy.html)
[Contact](page.cgi?id=redhat/contact.html)
[FAQ](page.cgi?id=faq.html)
[Legal](page.cgi?id=terms-conditions.html)



=== Content from access.redhat.com_5f28fbb5_20250126_074316.html ===


[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

**We're sorry but cve-details doesn't work properly without JavaScript enabled. Please enable it to continue.**

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2025 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from www.openwall.com_bef0866a_20250125_090814.html ===


| [Openwall](/) * [Products](/)   + [Openwall GNU/\*/Linux   *server OS*](/Owl/)+ [Linux Kernel Runtime Guard](/lkrg/)+ [John the Ripper   *password cracker*](/john/)         - [Free & Open Source for any platform](/john/)- [in the cloud](/john/cloud/)- [Pro for Linux](/john/pro/linux/)- [Pro for macOS](/john/pro/macosx/)+ [Wordlists   *for password cracking*](/wordlists/)+ [passwdqc   *policy enforcement*](/passwdqc/)             - [Free & Open Source for Unix](/passwdqc/)- [Pro for Windows (Active Directory)](/passwdqc/windows/)+ [yescrypt   *KDF & password hashing*](/yescrypt/)+ [yespower   *Proof-of-Work (PoW)*](/yespower/)+ [crypt\_blowfish   *password hashing*](/crypt/)+ [phpass   *ditto in PHP*](/phpass/)+ [tcb   *better password shadowing*](/tcb/)+ [Pluggable Authentication Modules](/pam/)+ [scanlogd   *port scan detector*](/scanlogd/)+ [popa3d   *tiny POP3 daemon*](/popa3d/)+ [blists   *web interface to mailing lists*](/blists/)+ [msulogin   *single user mode login*](/msulogin/)+ [php\_mt\_seed   *mt\_rand() cracker*](/php_mt_seed/)* [Services](/services/)* Publications       + [Articles](/articles/)+ [Presentations](/presentations/)* Resources         + [Mailing lists](/lists/)+ [Community wiki](https://openwall.info/wiki/)+ [Source code repositories (GitHub)](https://github.com/openwall)+ [Source code repositories (CVSweb)](https://cvsweb.openwall.com)+ [File archive & mirrors](/mirrors/)+ [How to verify digital signatures](/signatures/)+ [OVE IDs](/ove/)* [What's new](/news) | |
| --- | --- |

| | [Follow @Openwall on Twitter for new release announcements and other news](https://twitter.com/openwall) | | --- | |
| --- | --- |

[[<prev]](../../../2012/05/07/14) [[next>]](2) [[<thread-prev]](../../../2012/01/05/8) [[thread-next>]](2) [[day]](.) [[month]](..) [[year]](../..) [[list]](../../..)
```

Message-ID: <20120508000817.GA13604@openwall.com>
Date: Tue, 8 May 2012 04:08:17 +0400
From: Solar Designer <solar@...nwall.com>
To: oss-security@...ts.openwall.com
Subject: Re: CVE Request -- kernel: futex: clear robust_list on execve

On Wed, Jan 04, 2012 at 11:10:59PM +0100, Petr Matousek wrote:
> Move "exit_robust_list" into mm_release() and clear them
>
> We don't want to get rid of the futexes just at exit() time, we want to
> drop them when doing an execve() too, since that gets rid of the
> previous VM image too.
>
> Doing it at mm_release() time means that we automatically always do it
> when we disassociate a VM map from the task.
>
> Upstream patches:
> 8141c7f3e7aee618312fa1c15109e1219de784a7
> fc6b177dee33365ccb29fe6d2092223cf8d679f9
>
> Reference:
> <https://bugzilla.redhat.com/show_bug.cgi?id=771764>

RHSA-2012:0107-1 summarizes this as:

"A flaw was found in the way the Linux kernel handled robust list pointers
of user-space held futexes across exec() calls. A local, unprivileged user
could use this flaw to cause a denial of service or, eventually, escalate
their privileges. (CVE-2012-0028, Important)"

Is there a known attack vector (for either/both of the impacts mentioned
above), and what is it?

Here's what I arrived at after looking at the code for a little while:

Indeed, execve() may make the new process relatively privileged (SUID,
SGID, fscaps), and thus being able to write into its memory is a
security issue.  However, it appears that robust_list (and its compat
counterpart) is only used for such writes when the process itself is
exiting (with the aim being to notify other threads sharing the same
mm).  If so, the question is whether and how writes into an exiting
process' memory may be exploited.  We're already in do_exit() at this
point, and it's just a few lines before we detach from and likely
destroy the mm.  Well, if that process itself is multi-threaded (and
other threads are not exiting yet), it possibly can be exploited
(through affecting those other threads).  Is this the only attack
scenario?  Do we know of any SUID/SGID/fscaps-privileged multi-threaded
programs?  OK, I suppose that some proprietary ones exist (likely with
plenty of vulnerabilities in them). ;-)

BTW, kernel/fork.c: copy_process() resets the new process' or thread's
robust_list pointers to NULL, but I think this does not prevent the
scenario above because the parent's robust_list pointers are not reset
and they're the ones that matter for attack against the new thread.
However, this may help prevent the attack when there's a privileged
wrapper around a multi-threaded program, if that wrapper does a fork()
before execve()'ing the program.

It is entirely possible that I have missed something crucial, and thus
any/all of the above reasoning may be wrong.

I'd appreciate any comments.

Alexander

```

[Powered by blists](https://www.openwall.com/blists/) - [more mailing lists](https://lists.openwall.net)

Please check out the
[Open Source Software Security Wiki](https://oss-security.openwall.org/wiki/), which is counterpart to this
[mailing list](https://oss-security.openwall.org/wiki/mailing-lists/oss-security).

Confused about [mailing lists](/lists/) and their use?
[Read about mailing lists on Wikipedia](https://en.wikipedia.org/wiki/Electronic_mailing_list)
and check out these
[guidelines on proper formatting of your messages](https://www.complang.tuwien.ac.at/anton/mail-news-errors.html).


