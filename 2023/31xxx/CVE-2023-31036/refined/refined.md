- **Root cause of vulnerability**: The vulnerability is due to a relative path traversal issue when loading models via the model load API in NVIDIA Triton Inference Server. This occurs when the server is launched with the non-default command line option `--model-control explicit`.

- **Weaknesses/vulnerabilities present**: The primary weakness is the failure to properly sanitize or validate file paths provided to the model loading API when the `--model-control explicit` option is used. This allows an attacker to use relative paths (e.g., `../`) to traverse directories outside the intended model directory.

- **Impact of exploitation**: Successful exploitation can lead to:
    - Code execution: By loading malicious models or libraries from arbitrary locations.
    - Denial of service: By loading models that cause the server to crash or become unresponsive.
    - Escalation of privileges: By loading models or libraries with elevated privileges.
    - Information disclosure: By reading sensitive files or directories from the server's file system.
    - Data tampering: By modifying files or data on the server.

- **Attack vectors**: The vulnerability is exploitable via the model load API. The attack vector involves sending crafted requests to this API with relative paths in the model loading parameters.

- **Required attacker capabilities/position**: An attacker needs to be able to access the model load API, which requires having at least low privileges. The attack is network-based and does not require any user interaction. The vulnerability exists only if the non-default command line option `--model-control explicit` is used.