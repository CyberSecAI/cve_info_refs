=== Content from lists.proxmox.com_eae732b0_20250115_125214.html ===

# [pbs-devel] [RFC backup 0/6] Two factor authentication

**Oguz Bektas**
o.bektas at proxmox.com

*Wed Dec 2 11:56:50 CET 2020*

* Previous message (by thread): [[pbs-devel] applied: [PATCH proxmox-backup] client/pull: log how many groups to pull were found](001653.html)
* Next message (by thread): [[pbs-devel] [RFC backup 0/6] Two factor authentication](001655.html)
* **Messages sorted by:**
  [[ date ]](date.html#1654)
  [[ thread ]](thread.html#1654)
  [[ subject ]](subject.html#1654)
  [[ author ]](author.html#1654)

---

```
hi,

we talked with wolfgang off-list about some issues, so here are
some recommendations for the next version:

1. increase the length of recovery codes for bruteforce mitigation

most websites use 12-16 characters for the length of recovery keys.

2. do not store recovery codes in cleartext (hash them instead, we thought
hmac-sha256 is fine). the reason being that recovery codes can bypass
other tfa methods so they shouldn't be visible

3. don't store all the tfa information in a single json file.

current version uses a single /etc/proxmox-backup/tfa.json file
which holds all the tfa info for all the users. this is a single point
of failure because:
- file can be corrupted, causing tfa to break for everyone (no more logins)
- file could get deleted, disabling/bypassing 2fa for everyone
- file could get leaked in a backup etc., giving everyone's tfa secrets
and/or recovery keys to attackers (bypass everything)

better is to at least create a file for each user:
/etc/proxmox-backup/tfa/<username>.json or similar

this way the damage is contained if for example the config breaks
because of incorrect deserialization etc.

4. html/js injection in the description field on gui (fixed on staff
repo already)

5. notify user if more than X failed tfa attempts (password is already
compromised at this point, so it's important to notify) and block IP
for certain amount of time (fail2ban?)

5.b also if recovery keys are available, limit amount of TOTP attempts
for that user

review still going on, but i figured it's good to have a feedback loop
:)

On Thu, Nov 19, 2020 at 03:56:02PM +0100, Wolfgang Bumiller wrote:
> This series is a first RFC for two factor authentication.
>
> Notes:
> * Backend contains support for TOTP, Webauthn, Recovery keys and U2F.
> * The webauthn-rs crate introduces new dependencies we need to package:
>   - `half`
>   - `serde-cbor`
>   For our internal rust packaging I pushed the current debcargo-conf
>   changes to my `staff/w.bumiller/debcargo-conf` repo, branch `webauthn-rs`.
>
>   some extra (already-packaged) deps will be pulled in along with them:
>     $ cargo update
>           Adding getrandom v0.1.14
>           Adding half v1.6.0
>           Adding nom v4.2.3
>           Adding ppv-lite86 v0.2.6
>           Adding rand v0.7.2
>           Adding rand_chacha v0.2.2
>           Adding rand_core v0.5.1
>           Adding rand_hc v0.2.0
>           Adding serde_bytes v0.11.5
>           Adding serde_cbor v0.11.1
>           Adding thiserror v1.0.15
>           Adding thiserror-impl v1.0.15
>           Adding webauthn-rs v0.2.5
>
> * I wrote u2f before webauthn and left it in there unused because:
>   * we may want to move the code out to be integrated to PVE and PBS as
>     well for webauthn
>   * if we do: the webauthn-rs crate doesn't seem to provide a way
>     forward to using existin u2f credentials, so to not break those
>     we'll need the u2f backend.
>
> * The GUI does not use U2F (see above). (I do have code for it if for
>   some reason we do want that).
>
> * The GUI code is probably super weird. Some windows might look clunky,
>   but for me they always do currently since I'm working with
>   non-standard dpi monitor settings... so I can't really tell :-P
>
> * I introduced some `async` code into the GUI because the webauthn api
>   uses Promises and extjs doesn't seem to have issues with that...
>
> * The TFA configuration is currently a single json file.
>
> * While writing this mail I realized I still want to change the way
>   webauthn credentials are being serialized, but that's not important
>   for a first draft to look through ;-)
>
> Wolfgang Bumiller (6):
>   add tools::serde_filter submodule
>   config: add tfa configuration
>   api: tfa management and login
>   depend on libjs-qrcodejs
>   proxy: expose qrcodejs
>   gui: tfa support
>
>  Cargo.toml                      |    1 +
>  debian/control.in               |    1 +
>  src/api2/access.rs              |  171 ++++--
>  src/api2/access/tfa.rs          |  567 +++++++++++++++++
>  src/bin/proxmox-backup-proxy.rs |    1 +
>  src/config.rs                   |    1 +
>  src/config/tfa.rs               | 1017 +++++++++++++++++++++++++++++++
>  src/server.rs                   |    2 +
>  src/server/rest.rs              |    5 +-
>  src/server/ticket.rs            |   77 +++
>  src/tools.rs                    |    1 +
>  src/tools/serde_filter.rs       |   97 +++
>  www/LoginView.js                |  323 +++++++++-
>  www/Makefile                    |    6 +
>  www/OnlineHelpInfo.js           |   36 --
>  www/Utils.js                    |   59 ++
>  www/config/TfaView.js           |  322 ++++++++++
>  www/index.hbs                   |    1 +
>  www/panel/AccessControl.js      |    6 +
>  www/window/AddTfaRecovery.js    |  211 +++++++
>  www/window/AddTotp.js           |  283 +++++++++
>  www/window/AddWebauthn.js       |  193 ++++++
>  www/window/TfaEdit.js           |   92 +++
>  23 files changed, 3357 insertions(+), 116 deletions(-)
>  create mode 100644 src/api2/access/tfa.rs
>  create mode 100644 src/config/tfa.rs
>  create mode 100644 src/server/ticket.rs
>  create mode 100644 src/tools/serde_filter.rs
>  create mode 100644 www/config/TfaView.js
>  create mode 100644 www/window/AddTfaRecovery.js
>  create mode 100644 www/window/AddTotp.js
>  create mode 100644 www/window/AddWebauthn.js
>  create mode 100644 www/window/TfaEdit.js
>
> --
> 2.20.1
>
>
>
> _______________________________________________
> pbs-devel mailing list
> [pbs-devel at lists.proxmox.com](https://lists.proxmox.com/cgi-bin/mailman/listinfo/pbs-devel)
> <https://lists.proxmox.com/cgi-bin/mailman/listinfo/pbs-devel>
>
>

```

---

* Previous message (by thread): [[pbs-devel] applied: [PATCH proxmox-backup] client/pull: log how many groups to pull were found](001653.html)
* Next message (by thread): [[pbs-devel] [RFC backup 0/6] Two factor authentication](001655.html)
* **Messages sorted by:**
  [[ date ]](date.html#1654)
  [[ thread ]](thread.html#1654)
  [[ subject ]](subject.html#1654)
  [[ author ]](author.html#1654)

---

[More information about the pbs-devel
mailing list](https://lists.proxmox.com/cgi-bin/mailman/listinfo/pbs-devel)



=== Content from bugzilla.proxmox.com_32b5d9b3_20250114_224632.html ===


Proxmox Bugzilla – Bug 4579
Improve resiliency against TOTP brute force if account credentials already leaked
Last modified: 2024-10-18 08:25:04 CEST

* [Home](./)
* | [New](enter_bug.cgi)
* | [Browse](describecomponents.cgi)
* | [Search](query.cgi)
* |

  [[?]](page.cgi?id=quicksearch.html "Quicksearch Help")
* | [Reports](report.cgi)
* |
  [Help](https://bugzilla.readthedocs.org/en/5.0/using/understanding.html)
* |
  [New Account](createaccount.cgi)
* |
  [Log In](show_bug.cgi?id=4579&GoAheadAndLogIn=1)

  [x]
* |
  [Forgot Password](show_bug.cgi?id=4579&GoAheadAndLogIn=1#forgot)
  Login:

  [x]

[**Bug 4579**](show_bug.cgi?id=4579)
- Improve resiliency against TOTP brute force if account credentials already leaked

[Summary:](page.cgi?id=fields.html#short_desc "The bug summary is a short sentence which succinctly describes what the bug is about.")
Improve resiliency against TOTP brute force if account credentials already le...

| | [Status](page.cgi?id=fields.html#bug_status): | NEW | | --- | --- | |  | | | [Alias:](page.cgi?id=fields.html#alias "A short, unique name assigned to a bug in order to assist with looking it up and referring to it in other places in Bugzilla.") | None | |  | | | [Product:](describecomponents.cgi "Bugs are categorised into Products and Components.") | common | | [Classification:](page.cgi?id=fields.html#classification "Bugs are categorised into Classifications, Products and Components. classifications is the top-level categorisation.") | Unclassified | | [Component:](describecomponents.cgi?product=common "Components are second-level categories; each belongs to a particular Product. Select a Product to narrow down this list.") | Backend/API ([show other bugs](buglist.cgi?component=Backend%2FAPI&product=common&bug_status=__open__)) | | [Version:](page.cgi?id=fields.html#version "The version field defines the version of the software the bug was found in.") | bullseye-based | | [Hardware:](page.cgi?id=fields.html#rep_platform "The hardware platform the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | PC Linux | |  | | | [Importance](page.cgi?id=fields.html#importance): | --- enhancement | | [Assignee:](page.cgi?id=fields.html#assigned_to "The person in charge of resolving the bug.") | Bugs | |  | | | [URL:](page.cgi?id=fields.html#bug_file_loc "Bugs can have a URL associated with them - for example, a pointer to a web site where the problem is seen.") |  | |  | | | [Depends on:](page.cgi?id=fields.html#dependson "The bugs listed here must be resolved before this bug can be resolved.") | [4581](show_bug.cgi?id=4581 "NEW - Notify user if second factor failed multiple times") [4584](show_bug.cgi?id=4584 "RESOLVED FIXED - restrict user after multiple failed TOTP second factor auth tries in a row") | | [Blocks:](page.cgi?id=fields.html#blocked "This bug must be resolved before the bugs listed in this field can be resolved.") |  | |  | Show dependency [tree](showdependencytree.cgi?id=4579&hide_resolved=1) | |  | | Reported: | 2023-03-08 18:19 CET by Cory Cline | | --- | --- | | Modified: | 2024-10-18 08:25 CEST ([History](show_activity.cgi?id=4579)) | | CC List: | 4 users (show)  cory esiy0676+proxmox neobin.mail t.lamprecht | |  | | | [See Also:](page.cgi?id=fields.html#see_also "This allows you to refer to bugs in other installations. You can enter a URL to a bug in the 'Add Bug URLs' field to note that that bug is related to this one. You can enter multiple URLs at once by separating them with whitespace. You should normally use this field to refer to bugs in other installations. For bugs in this installation, it is better to use the Depends on and Blocks fields.") |  | |  | | |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| --- | | |

| | Attachments | | | --- | --- | | [Add an attachment](attachment.cgi?bugid=4579&action=enter) (proposed patch, testcase, etc.) | |   | Note You need to [log in](show_bug.cgi?id=4579&GoAheadAndLogIn=1) before you can comment on or make changes to this bug. | | --- | |  |
| --- | --- | --- | --- | --- | --- | --- |

| [Description](show_bug.cgi?id=4579#c0)  Cory Cline    2023-03-08 18:19:25 CET  ``` Proxmox 7.3-4 allows users to utilize TOTP 2FA via an authenticator application of their choice. This method generates a new 6-digit PIN number every thirty seconds. An attacker with knowledge of a valid credential pair would be able to brute force this PIN. Due to a lack of rate-limiting, the probability of guessing this PIN rises to 99.9% chance of success after 23 days, but real-world testing has demonstrated successful attacks in as little as 12 hours and 23 minutes.  Per the email discussion with Thomas Lamprecht, these two fixes were recommended.  1) send out notification to the user email (fallback to system root@pam mail)    if user/password matches but second factor fails more than once on a single    system (that is, ignore PVE's clustering)  2) block TOTP per user if there where more than five bad entries in a row.  If    other TFA methods are configured they'd still work, so a user could login    with recovery code or WebAuthn token to change their compromised password.    The state could here be handled via either user.cfg or tfa.cfg (more    complex and added lock contention), or just ignore clustering again    (attacker would then get a few more tries (4 * node-count + 1), so not a    issue in practice) a use a node-local state file in /run or /var/ for    counting and only set a lock flag  if over the try amount on one node. ```  [Comment 1](show_bug.cgi?id=4579#c1)  Thomas Lamprecht    2023-03-09 13:39:19 CET  ``` Huh, that was a bit unexpected to see a request here get opened directly without any reply, especially as I suggested opening the requests (as they're unrelated to each other w.r.t. implementation and would need some fleshing out).  But well, here we are - I'll transform this into a more general tracking issue, open separate bugs for each of my proposals, adding some more info, and then refer to them here as "Depends on" (one I already wrote, the other follows shortly).  For context also more from our exchange, as it includes IMO noteworthy info about our (off-list) decision for not (immediately) implementing rate-limiting:  On 2023-03-08T10:43+01:00 Thomas Lamprecht wrote: > On 2023-03-07T21:58+01:00 Cory Cline wrote: >> Proxmox 7.3-4 does not implement rate-limiting when validating TOTP 2FA >> passcodes. An attacker who knows a valid username and password credential >> pair could automate a brute-force attempt of the TOTP token for that user. >> >  > This is known and was discussed [0] during initial addition of TFA to our > Proxmox Backup Server, which was then later used as base for a improved > implementation for Proxmox VE - where improved means mostly that multiple > factors could be added per user and that u2f got replaced by its successor, > WebAuthn. >  > [0]: <https://lists.proxmox.com/pipermail/pbs-devel/2020-December/001672.html> >  > What's missing from [0] is a discussion about how rate-limiting could work > without opening PVE, PBS, or PMG to a DOS attacks; i.e., where such a semi > compromised user could be prevent that user, or even others from executing a > valid log-in. Per IP rate-limiting would 1) be easily circumvented, > especially with cheap VPS or IPv6 address ranges and 2) allow locking out > others from behind the same (e.g., NAT'd) IP; and besides that is already > possible to set-up fail2ban for those that still wish something like that. >  > Per-User rate-limiting would fare better from that POV, as it would at least > only affected the semi-compromised user, but with our products often that > will be a target with a high-level of permissions, especially as quite some > running instances will have only a small count of admins managing the > hyper-visor, backup server or mail gateway, so the affected might be the one > that needs to fully log-in to change their password in the first place; but > still, lets just assume we want security at all cost, then just rate limiting > won't be an actual solution, as it just moves the time-target, and a lot of > attacker don't care if they have to run their automated tools for half a day > or a month. E.g., rate limiting to once every 5s gives you a 50% chance to > guess a right one in 40 days, for 90% change it would be 133 days - really > not out of a practical attack range. To get into real impractical ranges (say > 50% chance more than two years) one would need to rate limit these to once > every 90s - which is just impractical from a UX POV. A trade-off might be to > double the delay per failed request - that would not affect valid users that > just fat-fingered entering the code once or twice but slow down automated > tooling for good. >  > For PBS and PMG we might be able to implement this somewhat efficiently, for > our multi-master Proxmox VE it's definitively more complex, as all nodes can > be used as login target. >  > Notifying the user about a valid login via credentials but failed second > factor authentication seems like being an additional requirement, as > otherwise they got no idea about the need for changing the password. >  > In the end it was then decided to don't block the addition/rework of TFA on > that grounds, at it is still always a win (or at least never worse off than > without it), as without any TFA configured the compromised user/pw would > grant immediate access after all. >  > The fact that we recommend to not run the admin interfaces publicly > accessible, but use the in-house firewall, or tunnelling solutions like > wireguard, to limit access only to trusted networks plus the availability of > more secure second factors like WebAuthn may provide was then part of the > decision to move this to the back burner. >  >  > That all said, we definitively can and should improve this for TOTP without > impacting UX for valid logins. As this topic was already discussed publicly > on our mailing list over two years ago I'd just open/refresh enhancement > request over at our bugzilla, that is if you don't see any reason to object? >  > The tracking-requests I'd make would be: >  > 1) send out notification to the user email (fallback to system root@pam mail) >    if user/password matches but second factor fails more than once on a >    single system (that is, ignore PVE's clustering) >  > 2) block TOTP per user if there where more than five bad entries in a row. >    If other TFA methods are configured they'd still work, so a user could >    login with recovery code or WebAuthn token to change their compromised >    password.  The state could here be handled via either user.cfg or tfa.cfg >    (more complex and added lock contention), or just ignore clustering again >    (attacker would then get a few more tries (4 * node-count + 1), so not a >    issue in practice) a use a node-local state file in /run or /var/ for >    counting and only set a lock flag  if over the try amount on one node. >  > Those two should not be overly complex to implement and improve security for > this scenario enough for totp brute forcing to not be relevant any more. >  >  ... >  > btw. when adding TOTP originally to Proxmox VE 5.4 in 2019 we intended to use > a higher digit count by default and let the user override it, as e.g., 10^9 > fares naturally way better against brute forcing than 10^6 (at 100 tries/s > it's 2 hours vs 80 days for 50% chance). Note that the TOTP spec (from > Google) denotes this possibility of including the amount of digits to be > used. > But the most prominent authenticator apps do not adhere to the spec and > hard-code 6 digits, among the Google Authenticator - i.e., the one from the > same org that specified that digit count should be adaptable... ```  [Comment 2](show_bug.cgi?id=4579#c2)  Cory Cline    2023-09-22 19:00:34 CEST  ``` CVE-2023-43320 has been assigned to this issue. ```  [Comment 3](show_bug.cgi?id=4579#c3)  Thomas Lamprecht    2023-09-23 10:15:56 CEST  ``` Thanks for the info, but we do not use or relay CVE's due to the multitude of problems there are in that system [0], but I'm sure this will be classified high, or even critical..  [0]: just one example <https://lwn.net/Articles/944209/>  Oh, and I guess the CVE number is wrong, as this was initially found by Oguz Bektas in December 2020 [1] it should have been dated to that year. Also, I guess the CVE will only apply w.r.t. rate limiting [2].  [1]: <https://lists.proxmox.com/pipermail/pbs-devel/2020-December/001654.html> [2]: [https://bugzilla.proxmox.com/show_bug.cgi?id=4584](show_bug.cgi?id=4584 "RESOLVED FIXED - restrict user after multiple failed TOTP second factor auth tries in a row") ``` |  |
| --- | --- |

---

* [Format For Printing](show_bug.cgi?format=multiple&id=4579)
* - [XML](show_bug.cgi?ctype=xml&id=4579)
* - [Clone This Bug](enter_bug.cgi?cloned_bug_id=4579)
* - Top of page

* + [Home](./)
  + | [New](enter_bug.cgi)
  + | [Browse](describecomponents.cgi)
  + | [Search](query.cgi)
  + |

    [[?]](page.cgi?id=quicksearch.html "Quicksearch Help")
  + | [Reports](report.cgi)
  + |
    [Help](https://bugzilla.readthedocs.org/en/5.0/using/understanding.html)
  + |
    [New Account](createaccount.cgi)
  + |
    [Log In](show_bug.cgi?id=4579&GoAheadAndLogIn=1)

    [x]
  + |
    [Forgot Password](show_bug.cgi?id=4579&GoAheadAndLogIn=1#forgot)
    Login:

    [x]

+ Service provided by Proxmox Server Solutions GmbH+ | [Privacy](https://www.proxmox.com/en/privacy-policy)
  + | [Legal](https://www.proxmox.com/en/legal)



=== Content from github.com_50e15188_20250114_224634.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fproxmox%2Fproxmox-rs%2Fcommit%2F50b793db8d3421bbfe2bce060a486263f18a90cb)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fproxmox%2Fproxmox-rs%2Fcommit%2F50b793db8d3421bbfe2bce060a486263f18a90cb)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fcommit_fragments%2Frepo_layout&source=header-repo&source_repo=proxmox%2Fproxmox-rs)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[proxmox](/proxmox)
/
**[proxmox-rs](/proxmox/proxmox-rs)**
Public

* [Notifications](/login?return_to=%2Fproxmox%2Fproxmox-rs) You must be signed in to change notification settings
* [Fork
  10](/login?return_to=%2Fproxmox%2Fproxmox-rs)
* [Star
   27](/login?return_to=%2Fproxmox%2Fproxmox-rs)

* [Code](/proxmox/proxmox-rs)
* [Pull requests
  0](/proxmox/proxmox-rs/pulls)
* [Security](/proxmox/proxmox-rs/security)
* [Insights](/proxmox/proxmox-rs/pulse)

Additional navigation options

* [Code](/proxmox/proxmox-rs)
* [Pull requests](/proxmox/proxmox-rs/pulls)
* [Security](/proxmox/proxmox-rs/security)
* [Insights](/proxmox/proxmox-rs/pulse)

## Commit

[Permalink](/proxmox/proxmox-rs/commit/50b793db8d3421bbfe2bce060a486263f18a90cb)

This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.

tfa: add data for rate limiting and blocking

[Browse files](/proxmox/proxmox-rs/tree/50b793db8d3421bbfe2bce060a486263f18a90cb)
Browse the repository at this point in the history

```
TfaUserData uses `#[serde(deny_unknown_fields)]`, so we add
this now, but using it will require explicitly enabling it.

If the TOTP count is high, the user should be locked out of
TOTP entirely until they use a recovery key to reset the
count.

If a user's TFA try count is too high, they should get rate
limited.

In both cases they should receive some kind of notification.

Signed-off-by: Wolfgang Bumiller <w.bumiller@proxmox.com>
```

* Loading branch information

[![@Blub](https://avatars.githubusercontent.com/u/123893?s=40&v=4)](/Blub)

[Blub](/proxmox/proxmox-rs/commits?author=Blub "View all commits by Blub")
committed
May 10, 2023

1 parent
[8d96827](/proxmox/proxmox-rs/commit/8d968274f12f25b3e3cd1231b4a403e984a0a116)

commit 50b793d

Showing
**1 changed file**
with
**22 additions**
and
**0 deletions**.

* Whitespace
* Ignore whitespace

* Split
* Unified

## There are no files selected for viewing

22 changes: 22 additions & 0 deletions

22
[proxmox-tfa/src/api/mod.rs](#diff-4b9f27069f674032c94a20db51c414c02ba57c5257bfb490ec00826d0852a628 "proxmox-tfa/src/api/mod.rs")

Show comments

[View file](/proxmox/proxmox-rs/blob/50b793db8d3421bbfe2bce060a486263f18a90cb/proxmox-tfa/src/api/mod.rs)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -331,6 +331,15 @@ pub struct TfaUserData { |
|  |  | /// available for PVE, where the yubico API server configuration is part if the realm. |
|  |  | #[serde(skip\_serializing\_if = "Vec::is\_empty", default)] |
|  |  | pub yubico: Vec<TfaEntry<String>>, |
|  |  |  |
|  |  | /// Once a user runs into a TOTP limit they get locked out of TOTP until they successfully use |
|  |  | /// a recovery key. |
|  |  | #[serde(skip\_serializing\_if = "bool\_is\_false", default)] |
|  |  | pub totp\_locked: bool, |
|  |  |  |
|  |  | /// If a user hits too many 2nd factor failures, they get completely blocked for a while. |
|  |  | #[serde(skip\_serializing\_if = "Option::is\_none", default)] |
|  |  | pub tfa\_blocked\_until: Option<i64>, |
|  |  | } |
|  |  |  |
|  |  | impl TfaUserData { |
| Expand Down  Expand Up | | @@ -924,6 +933,19 @@ pub struct TfaUserChallenges { |
|  |  | #[serde(skip\_serializing\_if = "Vec::is\_empty", default)] |
|  |  | #[serde(deserialize\_with = "filter\_expired\_challenge")] |
|  |  | webauthn\_auths: Vec<WebauthnAuthChallenge>, |
|  |  |  |
|  |  | /// Number of consecutive TOTP failures. Too many of those will lock out a user. |
|  |  | #[serde(skip\_serializing\_if = "u32\_is\_zero", default)] |
|  |  | totp\_failures: u32, |
|  |  |  |
|  |  | /// Number of consecutive 2nd factor failures. When the limit is reached, the user is locked |
|  |  | /// out for 12 hours. |
|  |  | #[serde(skip\_serializing\_if = "u32\_is\_zero", default)] |
|  |  | tfa\_failures: u32, |
|  |  | } |
|  |  |  |
|  |  | fn u32\_is\_zero(n: &u32) -> bool { |
|  |  | \*n == 0 |
|  |  | } |
|  |  |  |
|  |  | /// Serde helper using our `FilteredVecVisitor` to filter out expired entries directly at load |
| Expand Down | |  |

Toggle all file notes
Toggle all file annotations

### 0 comments on commit `50b793d`

Please
[sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fproxmox%2Fproxmox-rs%2Fcommit%2F50b793db8d3421bbfe2bce060a486263f18a90cb) to comment.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from lwn.net_1e72c87e_20250115_125215.html ===


[![LWN.net Logo](https://static.lwn.net/images/logo/barepenguin-70.png)
LWN
.net
News from the source](/)
[![LWN](https://static.lwn.net/images/lcorner-ss.png)](/)

* [**Content**](#t)
  + [Weekly Edition](/current/)
  + [Archives](/Archives/)
  + [Search](/Search/)
  + [Kernel](/Kernel/)
  + [Security](/Security/)
  + [Events calendar](/Calendar/)
  + [Unread comments](/Comments/unread)
  + ---
  + [LWN FAQ](/op/FAQ.lwn)
  + [Write for us](/op/AuthorGuide.lwn)
* [**Edition**](#t)
  + [Return to the Front page](/Articles/943824/)

**User:**
**Password:**    |

 |

[**Subscribe**](/subscribe/) /
[**Log in**](/Login/) /
[**New account**](/Login/newaccount)

# The bogus CVE problem

> **This article brought to you by LWN subscribers**
>
> Subscribers to LWN.net made this article — and everything that
> surrounds it — possible. If you appreciate our content, please
> [buy a subscription](/Promo/nst-nag3/subscribe) and make the next
> set of articles possible.

By **Jake Edge**
September 13, 2023

The "[Common Vulnerabilities and
Exposures](https://cve.mitre.org/)" (CVE) system was launched late
in the previous century (September 1999) to track vulnerabilities in
software. Over the years since, it has had a [somewhat checkered
reputation](/Articles/679315/), along with some [some attempts to
replace it](/Articles/851849/), but CVE numbers are still the only effective way to track
vulnerabilities. While that can certainly be useful, the
CVE-assignment (and severity scoring) process is not without its problems.
The prominence of CVE numbers, and the consequent increase in
"reputation" for a reporter, have combined to create a system that can
be—and is—actively gamed. Meanwhile, the organizations that oversee the
system are ultimately not doing a particularly stellar job.

A recent incident highlights some of the problems inherent in the system. [CVE-2020-19909](https://nvd.nist.gov/vuln/detail/CVE-2020-19909),
which is an integer-overflow bug in
the [curl tool and library for URL-based data
transfers](https://curl.se/) that was only reported
to the project in 2023. In a [blog
post describing the mess](https://daniel.haxx.se/blog/2023/08/26/cve-2020-19909-is-everything-that-is-wrong-with-cves/), curl maintainer Daniel
Stenberg said that a [message to the
curl-library mailing list](https://curl.se/mail/lib-2023-08/0031.html) on August 25 alerted the project that the CVE
had become public the week before.

The year in the CVE number (2020 in this case) is meant to indicate when
the bug was
reported to one of the [more than 300 CVE
numbering authorities](https://www.cve.org/ProgramOrganization/CNAs) (CNAs) that hand out CVE numbers. Under normal
circumstances, a new bug showing up with a CVE number would have 2023 in
it, but sometimes CVEs are given out for older bugs that somehow
slipped through the cracks. That appears to be what happened in this case,
as Stenberg was able to track the problem back to a [bug report](https://hackerone.com/reports/661847) from Jason Lee
in mid-2019.

The report was for a legitimate bug, where the
‑‑retry‑delay option value was being multiplied
by 1000 (to milliseconds) without an overflow check. But what it was
*not* was a security
bug, Stenberg said; giving insanely large values for the
option might result in incorrect
delays—far shorter than requested—but it is not a security problem to make
multiple requests in a short time span. If it were, "then a browser
makes a DOS [denial of service] every time you visit a website — and curl
does it when you give it two URLs on the same command line", he said in
a [followup
post](https://daniel.haxx.se/blog/2023/09/05/bogus-cve-follow-ups/).

The problem was [duly
fixed](https://github.com/curl/curl/pull/4166), a test case was added, and Lee was credited with the report in
the commit message. In September 2019, curl 7.66.0 was [released](https://curl.se/mail/archive-2019-09/0002.html) with
fix, which was mentioned in the announcement; also notable are the two CVEs
mentioned at the top of the bug fixes listed. As Stenberg noted, the curl
project
works hard to ensure that it fully documents the (real) CVEs that get filed
for
it; his exasperation with CVE-2020-19909 coming out of the blue is evident:
> In the curl project we work hard and fierce on security and we always work
> with security researchers who report problems. We file our own CVEs, we
> document them and we make sure to tell the world about them. [We list over 140 of them](https://curl.se/docs/security.html) with every imaginable detail about them provided. We aim at
> providing gold-level documentation for *everything* and that includes our
> past security vulnerabilities.
>
> That someone else suddenly has submitted a CVE for curl is a surprise. We
> have not been told about this and we would *really* have liked to. [...]

The [National Vulnerability Database](https://nvd.nist.gov/)
(NVD) tracks CVEs and "scores" them using the [Common
Vulnerability Scoring System](https://en.wikipedia.org/wiki/Common_Vulnerability_Scoring_System) (CVSS), which is a ten-point scale that is
meant to give an indication of the severity of a vulnerability. For the
curl bug, which should probably not be scored at all, NVD initially came up
with a "9.8 critical", scoring an integer overflow in a delay parameter
as one of the most severe types of vulnerability possible. Stenberg, who
has tangled with NVD over scoring before, is even further exasperated:
> It was obvious already before that NVD really does not try very hard to
> actually understand or figure out the problem they grade. In this case it
> is quite impossible for me to understand how they could come up with this
> severity level. It's like they saw "integer overflow" and figure that *wow,
> yeah that is the most horrible flaw we can imagine*, but clearly nobody at
> NVD engaged their brains nor looked at the "vulnerable" code or the patch
> that fixed the bug. Anyone that looks can see that this is not a security
> problem.

In fact, the pull request for the fix was attached to the report, but that
apparently made little difference in the assessment from NVD. Back in
March,
Stenberg [decried](https://daniel.haxx.se/blog/2023/03/06/nvd-makes-up-vulnerability-severity-levels/)
the NVD scoring process and, in particular, the NVD practice of re-scoring
CVEs that have already had severity levels attached to them. NVD uses
CVSS, but the curl project long ago rejected that scoring system:
> In the curl project we decided to abandon CVSS years ago because of its
> inherent problems. Instead we use only the four severity names: **Low**,
> **Medium**, **High**, and **Critical** and we work out the
> severity together in the
> curl security team as we work on the vulnerability. We make sure we
> understand the problem, the risks, its prevalence and more. We take all
> factors into account and then we set a severity level we think helps the
> world understand it.

His example in that case is [a double-free in curl](https://curl.se/docs/CVE-2022-42915.html)
that the project determined had a "medium" severity, while NVD scored it as
"9.8 critical", as can be seen in the [GitHub advisory
database](https://github.com/advisories/GHSA-98w6-hw73-ph8m). Since then, NVD apparently had a change of heart after
Stenberg's complaint as the CVE is [now scored "8.1
high"](https://nvd.nist.gov/vuln/detail/CVE-2022-42915). In a [followup
on NVD "brokenness"](https://daniel.haxx.se/blog/2023/06/12/nvd-damage-continued/), Stenberg gave another example of a CVE that was
initially scored "9.8 critical", but eventually was reduced to "5.9 medium"
after complaints—though the curl project rates it as "low". He also noted
that there is a set of projects that never report low or medium CVEs that
they find, in order to avoid these kinds of scoring woes.

One could perhaps wonder if this is all just a problem for the curl project
and not more widespread, but there is a fair amount of evidence of a
variety of problems in CVE-land. For example, the PostgreSQL project had a
similar problem with a [CVE
"from" 2020](https://www.postgresql.org/about/news/cve-2020-21469-is-not-a-security-vulnerability-2701/) that appeared recently—and is not a security vulnerability
at all, according to the project. In June, the [KeePassXC](https://keepassxc.org/) password manager project
[had a bogus
CVE filed](https://keepassxc.org/blog/2023-06-20-cve-202335866/) for the tool; there are other examples as well.

Each of these bogus CVE filings, which can apparently be made anonymously and
without much in the way of backing information, require that the project
notice its existence, analyze the problem (or "problem"), and, if
necessary, dispute the existence or score of the CVE.
As noted, several curl CVEs have had their scores reduced rather
substantially due to requests from the project. The delay parameter
overflow that was initially scored 9.8 has been reduced to "3.3
low", marked as "disputed", and had a link to Stenberg's blog post
added to the NVD entry.

Keeping up with all of that is a lot of
work, which Stenberg said he is going to try to avoid in the future by
applying to become the CNA for curl. Several other open-source projects are
CNAs, which gives them some notification of a reported problem along with
ways to try to ensure that the problem is handled sanely. He mentioned
Apache, OpenSSL, and Python as some of the projects that are already
CNAs; Python was just [granted
CNA status](https://pyfound.blogspot.com/2023/08/psf-authorized-as-cna.html) at the end of August.

Meanwhile, though, CVEs are used in ways that elevate their importance well
beyond the level that makes sense given the amount of scrutiny that is
apparently applied to them.
Service-level contracts and governmental requirements mean that a critical
CVE needs to be addressed in short order, so non-critical bugs that get
marked that way can cause real problems. It does provide incentives for
companies and others to try to downplay the severity of bugs, as well, of
course, which makes for something of a "[Pushmi-Pullyu](https://en.wikipedia.org/wiki/List_of_Doctor_Dolittle_characters#Pushmi-Pullyu)"
in CVE-land.

As was alluded to in our mid-August [look at
kernel security reporting for distributions](/Articles/941745/), the CVE system is
generally included in the "security circus" that kernel developers
largely disdain. A [2019 talk by Greg
Kroah-Hartman](/Articles/801157/) described multiple problems that he sees with the
system as well.

All in all, the CVE system seems to be broken in various ways. It also
seems to be getting more and more entrenched into "cybersecurity" handling
at various levels. Given that it is effectively run by—and now
for—governmental agencies, the ability to replace it with something more
sensible has likely already passed us by. CVE, warts and all, will be with
us for a long time to come; FOSS projects and organizations are simply
going to have to figure out how to coexist with it.

| Index entries for this article | |
| --- | --- |
| [Security](/Security/Index/) | [Bug reporting/CVE](/Security/Index/#Bug_reporting-CVE) |

---

 to post comments

### The bogus CVE problem

Posted Sep 13, 2023 21:10 UTC (Wed)
by **geofft** (subscriber, #59789)
[[Link](/Articles/944399/)] (6 responses)

William Woodruff's post from last year [ReDoS "vulnerabilities" and misaligned incentives](https://blog.yossarian.net/2022/12/28/ReDoS-vulnerabilities-and-misaligned-incentives) is another good look at this problem focusing particularly on people's excitement with superlinear regular expressions, and points out a very practical issue: a lot of automated security tools will report issues if any of the dependencies you're using have unresolved CVEs. This is well-intentioned, but for things that aren't actually vulnerabilities, it leads to needless churn and panic, and for things that are so much not a vulnerability that they aren't fixed, or aren't fixed except in the current development release, or similar, it may even cause deploy tools to refuse to deploy. Or, worse, it may cause well-funded corporate users to make demands of open-source projects to backport a patch that has no need to be backported. When there's an actual bug to fix, we can just lament the open-source sustainability problem, but when there isn't, it's nothing other than rude.

I actually [think](https://twitter.com/geofft/status/1582898573439799300) that this is, essentially, a DoS vulnerability in the CVE process itself. Anyone can submit an entry into a database that gets insufficiently validated and causes other people to have to scramble and respond and maybe makes their automated systems break. That's unauthenticated input causing denial-of-service attacks!

Also it occurs to me that CVE + CVSS actually does kind of provide a solution here. The point of CVE is that it's *common*, i.e., if someone else discovers the same vulnerability, there's a way to ideally give them the same CVE identifier or at least mark their new one as a duplicate. It feels like we should be able to proactively mark things as CVSS score 0, and say, yes, this is an integer overflow or stack corruption or whatever, but exploiting it [rather involves being on the other side of this airtight hatchway](https://devblogs.microsoft.com/oldnewthing/20060508-22/?p=31283), and so we're going to mark the fact that it exists so people who find it know it was already analyzed. And in some cases it makes sense to "fix" it, as with CVE-2020-19909. It's always better to print a real error message instead of "double free or corruption (fasttop)". (But I do wonder about the incentive system, as Woodruff mentions, of having CVEs on your résumé, and whether the existence of CVEs with CVSS scores of 0 will make things better or worse.)

### The bogus CVE problem

Posted Sep 14, 2023 0:04 UTC (Thu)
by **wahern** (subscriber, #37304)
[[Link](/Articles/944408/)] (5 responses)

All this is true enough, but proving that a vulnerability is protected by an "airtight hatchway" (i.e. is unexploitable in practice) is difficult, often more difficult than identifying the vulnerability. Not only is it difficult, but implementations and vendors are highly incentivized to wave away vulnerabilities with claims that they're unexploitable. But in most cases claims are never proven systematically, rather averred. And such assertions often are merely failures of imagination--defenders don't think like attackers, even when they're being earnest and diligent.

The CVE system has flaws--serious flaws. But I'd argue that these flaws are less severe than the alternative where vendors can more easily waive off reports. Let's not forget from whence we came--a time when vendors didn't take these things seriously unless and until bugs were already being conspicuously exploited in the wild. And we still have problems with too many vendors not taking CVEs seriously. The current system is unfair to conscientious developers and maintainers whose time is wasted by self-aggrandizing bug reporters, but we would never have needed the current CVE system if such conscientious people were the majority of those shipping software.

\* There's a reason we can't have nice things. \* No good deed goes unpunished. \* Etc, etc.

### The bogus CVE problem

Posted Sep 14, 2023 7:14 UTC (Thu)
by **madhatter** (subscriber, #4665)
[[Link](/Articles/944416/)]

You do make a depressingly good point about software makers, particularly commercial ones, being incentivised to handwave vulnerabilities away. Bruce Schenier wrote this pithy response in last month's Crypto-Gram newsletter, in response to a vendor quote in a vice.com article about a vulnerability found in Tetra police radios:

*> Specifically on the researchers’ claims of a backdoor in TEA1, Boyer added “At this time, we would like to

> point out that the research findings do not relate to any backdoors. The TETRA security standards have

> been specified together with national security agencies and are designed for and subject to export

> control regulations which determine the strength of the encryption.”

And I would like to point out that that’s the very definition of a backdoor.*

### The bogus CVE problem

Posted Sep 15, 2023 3:01 UTC (Fri)
by **florianfainelli** (subscriber, #61952)
[[Link](/Articles/944529/)] (3 responses)

Unfortunately the CVE circus will continue to go on:

- EU CRA: <https://www.european-cyber-resilience-act.com/>

- US EO 14028: [https://www.nist.gov/itl/executive-order-14028-improving-...](https://www.nist.gov/itl/executive-order-14028-improving-nations-cybersecurity)

this will no doubt create an immense amount of work for projects, distributors, and so on, almost as if it was a jobs program.

### The bogus CVE problem

Posted Sep 15, 2023 11:42 UTC (Fri)
by **wtarreau** (subscriber, #51152)
[[Link](/Articles/944545/)] (1 responses)

> this will no doubt create an immense amount of work for projects, distributors, and so on, almost as if it was a jobs program.

... or this garbage will convince many of us that too much is too much and it's time to switch jobs, maybe become a european deputee of some other such dummy jobs where you can vote for random rules that morons will blindly apply. I mean, there's no reason we should be their slaves, we're still free to stop maintaining projects that take too much time under such stupid rules, and let the internet fall apart as well.

### The bogus CVE problem

Posted Sep 15, 2023 13:17 UTC (Fri)
by **pizza** (subscriber, #46)
[[Link](/Articles/944548/)]

> ... or this garbage will convince many of us that too much is too much and it's time to switch jobs,

This is the most likely outcome.

> we're still free to stop maintaining projects that take too much time under such stupid rules, and let the internet fall apart as well.

Ah yes, but if you stop maintaining it, you're engaging in willful gross negligence and will be on the hook for $very\_massive liabilities. And that's where things are heading.

Damned if you do, damned if you don't.

### The bogus CVE problem

Posted Sep 22, 2023 6:46 UTC (Fri)
by **kunitz** (subscriber, #3965)
[[Link](/Articles/945248/)]

I work in the financial industry and we live already in the regulated future. Basically if anything in your build has an unresolved high or critical rated CVE, you can't use it anymore. Right now we are in the process to move all our container images to Alpine, because it doesn't use all the user space tools. A normal Debian image has 70 to 100 high or critical rated CVEs.

Since there are so many software packages, nobody has the time to look at the detail of a CVE. If there is a CVE which is high or critical you have to make it disappear, regardless whether you actually use the functionality or expose the service in any way. The financial industry has the audit and governance structures to enforce such rules.

For me it looks like that dependency reduction will become very important in the industry. How open-source will deal with the requirements of the CRA will be interesting to see.

### The bogus CVE problem

Posted Sep 13, 2023 21:55 UTC (Wed)
by **flussence** (guest, #85566)
[[Link](/Articles/944407/)] (4 responses)

CVEs are exactly the same class of scam as Better Business Bureau ratings. Anyone can make them up, they have a false air of reputability, and nowadays they're more often used as a force-multiplying tool in cash shakedowns than their stated purpose.

If NVD/MITRE don't massively clean up their act following this, the next step is to start removing baked-in recognition of CVE numbers in the many tools that have it, and educating the general public that those organisations possess no legitimate authority. IMO this part of the industry is at least a decade overdue for a scorched-earth cleanup like what Let's Encrypt did to the CA aristocracy.

### The bogus CVE problem

Posted Sep 14, 2023 12:03 UTC (Thu)
by **hkario** (subscriber, #94864)
[[Link](/Articles/944431/)]

As much as I'd like that to happen, CVEs are baked into regulation, and government agencies and enterprises in regulated industries do spend a lot of money on software. So CVEs are here to stay.

### The bogus CVE problem

Posted Sep 14, 2023 17:50 UTC (Thu)
by **mcatanzaro** (subscriber, #93033)
[[Link](/Articles/944501/)] (2 responses)

Honestly the current system is better than the alternative. It wasn't too long ago that LWN was running articles about how it was too hard to get CVEs assigned to real bugs due to nonresponsiveness from MITRE. Now it's easier to get the CVEs, but of course this means there are going to be more invalid CVEs.

Most CVEs are valid. But invalid CVEs are certainly annoying. Another common problem is multiple CVEs being reported for the same issue. Recently somebody found one bug in WebKit and managed to get 6 different CVEs for it by asking MITRE instead of Apple to assign them. It was a serious vulnerability and the reporter otherwise did a good job, but 6 CVEs was unimpressive. (I think I requested these be marked as duplicate CVEs, but I don't think it actually happened.)

What's especially weird is that sometimes MITRE sides with the reporter rather than the project developer even when there is no dispute. E.g. a few years ago, somebody received two CVEs for what turned out to be one bug (I think it was also WebKit bug?) and when I requested that they be combined, MITRE decided that two CVEs was correct because there were two different test cases that trigger the bug. This was mind boggling to me.

### The bogus CVE problem

Posted Sep 18, 2023 11:20 UTC (Mon)
by **cpitrat** (subscriber, #116459)
[[Link](/Articles/944749/)]

But then you get to solve 2 CVEs with a single patch which is certainly something you can brag about.

### The bogus CVE problem

Posted Sep 18, 2023 12:14 UTC (Mon)
by **wtarreau** (subscriber, #51152)
[[Link](/Articles/944750/)]

> Most CVEs are valid.

Some ex-insiders such as Kurt Seifried and Josh Bressers in a recent talk disagreed with this suggesting that around 20% only were valid. See the link to their talk below in another comment.

### The bogus CVE problem

Posted Sep 14, 2023 7:03 UTC (Thu)
by **Trou.fr** (subscriber, #26289)
[[Link](/Articles/944415/)]

Nvd does not assign and rate vulnerabilities, this is done by any of the 300+ CNA, as long as the product that is vulnerable is not published by a CNA itself.

AFAIK, nvd is exactly what is says, a database.

That's not to say the CVE/CVSS is broken, but it is still the only tool that allows people and organisations to track which vulnerability they should patch or they have patched.

And BTW the CVSS 4.0 <https://www.first.org/cvss/v4-0/> is going to be published soon, it should fix some of the problems of v3 (including the impossibility to reach 10)

### The bogus CVE problem

Posted Sep 14, 2023 7:25 UTC (Thu)
by **wtarreau** (subscriber, #51152)
[[Link](/Articles/944417/)] (4 responses)

I also recommend the long but interesting talk from Kurt Seifried and Josh Bressers on this matter: [https://opensourcesecuritypodcast.libsyn.com/episode-392-...](https://opensourcesecuritypodcast.libsyn.com/episode-392-curl-and-the-calamity-of-cve). They've been part of this process in the past and quit it. They estimate that less than 20% of CVEs filed are relevant (I would have thought even less to be honest).

But yeah the process is totally broken and non-transparent. Other projects such as SQLite don't want to hear about CVE anymore for these reasons. In HAProxy we don't file them any more after an embargoed CVE was twitted with only the subject, but enough details to hurry up the process. Instead we now let distro package maintainers decide if it makes their life easier with or without one and leave it to them to file these. When they do, they fill them correctly because they're more accustomed to the process. In the end it's a clean and efficient sharing of the roles so it's not that bad.

One thing I've been tempted to do many times is to file one CVE per backported patch, at least to ensure that all backports land into distros, and not have to respond to questions about CVEs anymore. In our case it would cause a real burden to our package maintainers and since they're doing a great job I don't want to do that. It would have been different otherwise :-)

I tried to educate coworkers and other people about focusing on "bug fixes" and not "CVE" for backports, but it doesn't seem to take off. There's so heavy an industry hammering "CVE" all the day that they manage to make anyone believe this has anything to do with security, while it's just a business consisting in selling lists and automated tools checking for the presence of a tiny portion of bugs affecting software, and this business is so lucrative that it's almost hopeless to be able to open other people's eyes about what it really is. It's particularly annoying because real bugs are rarely fixed and CVE make lots of noise.

### The bogus CVE problem

Posted Sep 14, 2023 9:37 UTC (Thu)
by **ringerc** (subscriber, #3071)
[[Link](/Articles/944421/)] (3 responses)

The CVE noise is ridiculous. My org spends so much time and effort "fixing" these "vulnerabilities" that it has little left over for \*actual real security efforts\*.

They've decided it's too hard to classify the balance of supposed vulnerabilities, so they're just going to take the severities as fact, irrespective of where the component lives in our stack.

"Critical" vuln in a completely unrelated part of a golang executable that happens to share the same huge monorepo as a library we use? Everybody panic, rush to upgrade everything to the latest no matter what the breakage, even though we probably don't use it. Used by a 3rd pty component that didn't jump fast enough? Fork it and hack it.

Then we have all these mini forks of various 3rd party components sitting around rotting. Or they decide it's too hard to keep up with "security" for a perfectly good external component and rewrite it in-house, badly. No more CVEs because nobody's looking anymore! It's less secure, but we made the squeaky wheel go away. Go us.

They've also rolled out various mandatory and enforced static checkers and linters with centrally managed one-size-fits-all configs. The stupid things run on pull requests and they don't compare the pull request results to a scan of main with the same config and db version. So whenever the vendor or info-"security" management rolls out new config/dbs, totally unrelated changes become unmergeable. Sure you could raise a new separate PR to patch main then rebase your change. But you've got a gauntlet of Jira ticket workflow requirements, encorced pull request reviews from people who're often unavailable, slow unreliable GitHub workflows, etc. Who's got time for that? So we have PRs "fix off by one in A" that have 200 lines of completely irrelevant noise "fixing" meaningless non issues. They obscure the real changes and introduce new bugs.

Yay management of developers by non developers, and management of IT security by people who couldn't explain the difference between authentication and authorisation if you gave them a textbook first.

### The bogus CVE problem

Posted Sep 14, 2023 15:39 UTC (Thu)
by **wtarreau** (subscriber, #51152)
[[Link](/Articles/944492/)] (2 responses)

I feel sorry for you, really. It must be quite frustrating to work in your company :-(

### The bogus CVE problem

Posted Sep 20, 2023 14:21 UTC (Wed)
by **bearstech** (subscriber, #160755)
[[Link](/Articles/944987/)] (1 responses)

I work for companies who misconduct in that way, so the problem might spread to your company without your consent. At least I got to bill them for handling that nonsense bureaucracy.

The main flow of alerts/requests I've been handling for close to a year is composed of ... requests to add anti-XSS HTTP headers. By far. At the same time I got \_zero\_ status requests on the Zenbleed/Inception mayhem from this summer. The cultural gap is that wide.

In my case the problem is clearly companies who want to adopt security policies but are no trained on computer security. I can't blame them except their CTO which most of the time is totally missing the point while thinking that security is just another component that need dashboards and reports, and done.

CVE ranking is conceptually wrong, a security issue must be evaluated with context and is multi-faceted, there should never be a single figure in the first place. When talking with a dev or project manager I can educate about those issues and explain them how to handle a specific security issue in context, that's often satisfying for both parties. But then it won't bubble up to the top management and against the solidified bureaucracy they call security policy.

### The bogus CVE problem

Posted Sep 29, 2023 4:01 UTC (Fri)
by **wtarreau** (subscriber, #51152)
[[Link](/Articles/945901/)]

I totally agree with what was said above!

### The bogus CVE problem

Posted Sep 14, 2023 11:42 UTC (Thu)
by **smoogen** (subscriber, #97)
[[Link](/Articles/944430/)]

Some of the problems with CVE's is the scale of the software available now and how much is used in odd places all over the place. CVE's were designed and written around the idea that the amount of software was in the hundred's of thousands and you only had a couple million systems to alert and protect.

Some of the problems with CVE's is that the system was designed to replace at least 2 other systems which fell apart in the late 1990's where most software was closed source and unless you could prove undeniably that there was a true vulnerability (and could not be hand waived off with "you didn't do exactly what we said in this manual on Alpha Centauri protected by a cyberraptor ") it wasn't looked and or fixed.

Some of the problems is that everyone has a tendency to make anything they run into a game they can 'win' at. And when they can't win, look for ways to avoid playing anymore. This goes for core programmers, security researchers, software companies, etc. These are known problems which aren't solvable because they are 'human condition' issues (and every solution just becomes a new game to win or lose at).

Most of the issues are that the above are known, but because they are all hard to get N people to agree to even trying a solution, you end up punting the problem to the next year and maybe just add another number to the amount of possible CVE's for a year.

### The bogus CVE problem

Posted Sep 14, 2023 15:54 UTC (Thu)
by **MarcB** (subscriber, #101804)
[[Link](/Articles/944488/)]

Another example is a batch of four recent CVEs for Notepad++: [https://securitylab.github.com/advisories/GHSL-2023-092\_N...](https://securitylab.github.com/advisories/GHSL-2023-092_Notepad__/)

One of them might be a real vulnerability, but very likely not a 7.8.

The other three are scored 5.5, but look much more like zeroes. Read buffer-overflows that do not cross any confidentiality or other security boundaries and do not have any way to exfiltrate the data anywhere.

### The bogus CVE problem

Posted Sep 14, 2023 23:10 UTC (Thu)
by **nliadm** (subscriber, #94000)
[[Link](/Articles/944521/)]

As an author of a container static analyzer, this is one of the reasons we purposefully do not consume NVD data directly. The CVSS scores from NVD frequently conflict with vendors and authors own severity ratings, and so users would ask us to "just fix" the score in the report. We now only consume vendor and language-authority data, and it's completely eliminated this class of problem.

I think having a process to triage reported vulnerabilities easily is key to handling this at scale. Frameworks like SSVC are great, but there's an onus on reporting tools to be able to integrate those decisions back in and not show scary red marks to people that just want a "security" toggle.

### The bogus CVE problem

Posted Sep 15, 2023 1:22 UTC (Fri)
by **amworsley** (subscriber, #82049)
[[Link](/Articles/944527/)] (1 responses)

I think it would be good to see some better CVSS rules established.

e.g. no CVSS 10 (or > 8?) if there is no PoC exploit code. So much time is wasted trying to see

if a vaguely described fault is actually a significant problem. If there is a PoC it really spells out

what is required and what can be done very quickly and efficiently.

### The bogus CVE problem

Posted Sep 15, 2023 10:01 UTC (Fri)
by **farnz** (subscriber, #17727)
[[Link](/Articles/944544/)]

That sort of thing is already captured by the "Exploit Code Maturity (E)" component of the CVSS score; if the overall score was capped to 4 if E:U or E:X (i.e. no PoC available now), then people would focus on that.

Organisations that consume the CVSS metrics can do that today, of course.

### The bogus CVE problem

Posted Sep 15, 2023 4:29 UTC (Fri)
by **buck** (subscriber, #55985)
[[Link](/Articles/944530/)]

As a source of names for bugs it has served its purpose well, so not every vulnerability needs to get a vanity exploit name, and the ones that anybody cares about, you can generally remember them by number until they fade into obscurity (one hopes). The ones that are bogus or that don't merit attention? No inherent problem with them having names, just like one is free to name one's imaginary friends.

After all, remember the first of the 3 hardest problems in computer science.

As the key to databases (NVD, the CVE-named errata pages of RedHat, Debian security-tracker, etc.) with links to advisories and/or references, it's kinda useful to have them be content-addressable.

As long as one can ignore everything else, which I guess it's hard for somebody to do if a CVE is kind of like an unsealed indictment of your software product, ... hmm.

Maybe there needs to be a CVE-rank algorithm to score CVEs: If there are no vendor and/or distro and/or vulnerability-list and/or such links attached to, say, the NVD entry, then it should carry a low score and people should ignore it (should the score stay low). And if the score doesn't respond dynamically enough to reflect some really bad news? Well, if you're looking to track CVSS scores to tell you what advisories to pay attention to in your system, then I got nothing for you. But if you're only responding to some vulnerability scanner telling you which high-CVSS things you need to worry about, then it's the scanner's problem, not yours, and you can maybe go back to figuring out your most significant risks and how to balance them yourself.

Not sure if that would be very open to gaming (CVEO?) but also hard to see the point. I don't flatter myself that I'm very devious, though.

### The bogus CVE problem

Posted Sep 22, 2023 8:54 UTC (Fri)
by **j16sdiz** (guest, #57302)
[[Link](/Articles/945250/)]

> His example in that case is a double-free in curl that the project determined had a "medium" severity, while NVD scored it as "9.8 critical", as can be seen in the GitHub advisory database.

Is there anything special about this "double-free" making this just a medium?

Depends on the malloc implementation, double-free can corrupt data. In a library like curl, this can have very bad consequence.. A "high" score is well justified.

### The bogus CVE problem

Posted Sep 22, 2023 17:06 UTC (Fri)
by **fung1** (subscriber, #144307)
[[Link](/Articles/945334/)]

I mostly run the vulnerability management team for a large ecosystem of popular free/libre open source services. We request CVE assignments as a matter of course when we determine that we're going to issue a security advisory, and use them for the purpose they were intended (tracking). We purposefully do not make up CVSS scores because the heck if I can guess whether this specific problem is critical or benign in your deployment, it all depends on how you're using our software. At least for us, CVSS is entirely pointless.

We also do not bother to dispute CVE assignments others request for bugs in our software, because it's not worth our (limited) time to do so. It's our policy that if someone has requested a CVE for one of our bugs and notified us what number got assigned, then we'll reuse that \*if\* we issue an advisory (instead of requesting a conflicting CVE). It's been clear for a very long time that since anyone can request and receive a CVE assignment without even talking to the people maintaining the project it's about, the mere existence of a CVE does not imply there's any sort of vulnerability, nor is there any point in wasting time trying to get them rescinded.

### The bogus CVE problem

Posted Sep 23, 2023 7:31 UTC (Sat)
by **domdfcoding** (guest, #159754)
[[Link](/Articles/945367/)] (1 responses)

What do you expect? Both the CVE program and NVD are run by the US Government. That alone should tell you not to touch it with a barge pole.

### The bogus CVE problem

Posted Sep 23, 2023 21:16 UTC (Sat)
by **mathstuf** (subscriber, #69389)
[[Link](/Articles/945405/)]

My understanding is that it is run by a military industrial complex component (or is it more the NSA/CIA security analogue?) via MITRE, not the government itself.

Copyright © 2023, Eklektix, Inc.

This article may be redistributed under the terms of the
[Creative
Commons CC BY-SA 4.0](http://creativecommons.org/licenses/by-sa/4.0/) license

Comments and public postings are copyrighted by their creators.

Linux is a registered trademark of Linus Torvalds



=== Content from bugzilla.proxmox.com_87a54850_20250115_125217.html ===


Proxmox Bugzilla – Bug 4584
restrict user after multiple failed TOTP second factor auth tries in a row
Last modified: 2023-09-15 14:22:17 CEST

* [Home](./)
* | [New](enter_bug.cgi)
* | [Browse](describecomponents.cgi)
* | [Search](query.cgi)
* |

  [[?]](page.cgi?id=quicksearch.html "Quicksearch Help")
* | [Reports](report.cgi)
* |
  [Help](https://bugzilla.readthedocs.org/en/5.0/using/understanding.html)
* |
  [New Account](createaccount.cgi)
* |
  [Log In](show_bug.cgi?id=4584&GoAheadAndLogIn=1)

  [x]
* |
  [Forgot Password](show_bug.cgi?id=4584&GoAheadAndLogIn=1#forgot)
  Login:

  [x]

[**Bug 4584**](show_bug.cgi?id=4584)
- restrict user after multiple failed TOTP second factor auth tries in a row

[Summary:](page.cgi?id=fields.html#short_desc "The bug summary is a short sentence which succinctly describes what the bug is about.")
restrict user after multiple failed TOTP second factor auth tries in a row

| | [Status](page.cgi?id=fields.html#bug_status): | RESOLVED FIXED | | --- | --- | |  | | | [Alias:](page.cgi?id=fields.html#alias "A short, unique name assigned to a bug in order to assist with looking it up and referring to it in other places in Bugzilla.") | None | |  | | | [Product:](describecomponents.cgi "Bugs are categorised into Products and Components.") | common | | [Classification:](page.cgi?id=fields.html#classification "Bugs are categorised into Classifications, Products and Components. classifications is the top-level categorisation.") | Unclassified | | [Component:](describecomponents.cgi?product=common "Components are second-level categories; each belongs to a particular Product. Select a Product to narrow down this list.") | Backend/API ([show other bugs](buglist.cgi?component=Backend%2FAPI&product=common&bug_status=__open__)) | | [Version:](page.cgi?id=fields.html#version "The version field defines the version of the software the bug was found in.") | bullseye-based | | [Hardware:](page.cgi?id=fields.html#rep_platform "The hardware platform the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | PC Linux | |  | | | [Importance](page.cgi?id=fields.html#importance): | --- enhancement | | [Assignee:](page.cgi?id=fields.html#assigned_to "The person in charge of resolving the bug.") | Wolfgang Bumiller | |  | | | [URL:](page.cgi?id=fields.html#bug_file_loc "Bugs can have a URL associated with them - for example, a pointer to a web site where the problem is seen.") |  | |  | | | [Depends on:](page.cgi?id=fields.html#dependson "The bugs listed here must be resolved before this bug can be resolved.") |  | | [Blocks:](page.cgi?id=fields.html#blocked "This bug must be resolved before the bugs listed in this field can be resolved.") | [4579](show_bug.cgi?id=4579 "NEW - Improve resiliency against TOTP brute force if account credentials already leaked") | |  | Show dependency [tree](showdependencytree.cgi?id=4584&hide_resolved=1) | |  | | Reported: | 2023-03-09 18:24 CET by Thomas Lamprecht | | --- | --- | | Modified: | 2023-09-15 14:22 CEST ([History](show_activity.cgi?id=4584)) | | CC List: | 2 users (show)  cory neobin.mail | |  | | | [See Also:](page.cgi?id=fields.html#see_also "This allows you to refer to bugs in other installations. You can enter a URL to a bug in the 'Add Bug URLs' field to note that that bug is related to this one. You can enter multiple URLs at once by separating them with whitespace. You should normally use this field to refer to bugs in other installations. For bugs in this installation, it is better to use the Depends on and Blocks fields.") |  | |  | | |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| --- | | |

| | Attachments | | | --- | --- | | [Add an attachment](attachment.cgi?bugid=4584&action=enter) (proposed patch, testcase, etc.) | |   | Note You need to [log in](show_bug.cgi?id=4584&GoAheadAndLogIn=1) before you can comment on or make changes to this bug. | | --- | |  |
| --- | --- | --- | --- | --- | --- | --- |

| [Description](show_bug.cgi?id=4584#c0)  Thomas Lamprecht    2023-03-09 18:24:27 CET  ``` TOTP is in general susceptible to brute-forcing if tries are not limited or throttled.  Basically, one can always try a specific ranges of values, and sooner or later (depending on requests rate per second) an attacker gets lucky and hits one; the   In theory the chance `p` for getting a hit with `rate` (per seconds) of a standard 6 digit TOTP code is:  (ln(1 - p) / ln(1 - (30 * rate / 10^6))) / 2 / 60  So, for 100/s requests and a 99% chance you'd need about 12.8 hours, really not that much. For details see: <https://security.stackexchange.com/a/185917>  So the idea is that after a series of failed retries we block TOTP for a user. If other TFA methods are configured they'd still work, so a user could login with recovery code (96 bits of entropy) or WebAuthn token (challenge response) to change their compromised password.  The counting state should probably be handled via an inexpensive method, e.g., a use a host-local state file in /run or /var/, and then set a lock flag in the actual tfa.cfg once the counter gets over the try amount on one node. While this would allow doing some extra request on cluster (4 * node-count + 1 total), that needs 1) the attacker to know about all nodes from that cluster and b) should not matter with the hundred thousands to multiple millions of counts required to find a clash.  The state counting might be used from (or in, whichever of the two requests is implemented first) [Bug 4581](show_bug.cgi?id=4581 "NEW - Notify user if second factor failed multiple times").  For the amount of failed retries I'd propose at least 5 and probably below 10. Five allows for even two times of fat-fingered or even skewed clock unluckiness, that might happen to valid users, while then not be already in the "dead zone" of the last try available like the often used "max three" attempts has, as that then often makes one do mistakes more easily. ```  [Comment 1](show_bug.cgi?id=4584#c1)  Thomas Lamprecht    2023-09-15 14:22:17 CEST  ``` Since the Debian 12 Bookworm based releases (PVE 8, PMG 8, PBS 3) a user account will be locked if TFA fails to many times, protecting against brute force attack for the case where a user's credentials have leaked and TFA is the only barrier left. ``` |  |
| --- | --- |

---

* [Format For Printing](show_bug.cgi?format=multiple&id=4584)
* - [XML](show_bug.cgi?ctype=xml&id=4584)
* - [Clone This Bug](enter_bug.cgi?cloned_bug_id=4584)
* - Top of page

* + [Home](./)
  + | [New](enter_bug.cgi)
  + | [Browse](describecomponents.cgi)
  + | [Search](query.cgi)
  + |

    [[?]](page.cgi?id=quicksearch.html "Quicksearch Help")
  + | [Reports](report.cgi)
  + |
    [Help](https://bugzilla.readthedocs.org/en/5.0/using/understanding.html)
  + |
    [New Account](createaccount.cgi)
  + |
    [Log In](show_bug.cgi?id=4584&GoAheadAndLogIn=1)

    [x]
  + |
    [Forgot Password](show_bug.cgi?id=4584&GoAheadAndLogIn=1#forgot)
    Login:

    [x]

+ Service provided by Proxmox Server Solutions GmbH+ | [Privacy](https://www.proxmox.com/en/privacy-policy)
  + | [Legal](https://www.proxmox.com/en/legal)



=== Content from packetstormsecurity.com_bb6185e0_20250114_224631.html ===

[![](/logos/smalllogobeta.png)](/)

* files
* news
* users
* cve

[![](/logos/smalllogobeta.png)](/)

* files
* news
* users
* cve

![](/logos/linegray.png)

 [About](/help/view/4) |
[Terms](/tos/) |
[Copyright](/help/view/7) |
[Privacy](/help/view/6) |
[BlueSky](https://bsky.app/profile/packetstorm.bsky.social) |
[X](https://x.com/packet_storm) |
[Mastodon](https://infosec.exchange/%40packet_storm/)



=== Content from lists.proxmox.com_3e1c1edc_20250115_125217.html ===

# [pbs-devel] [RFC backup 0/6] Two factor authentication

**Oguz Bektas**
o.bektas at proxmox.com

*Wed Dec 2 15:21:07 CET 2020*

* Previous message (by thread): [[pbs-devel] [RFC backup 0/6] Two factor authentication](001670.html)
* Next message (by thread): [[pbs-devel] [RFC backup 0/6] Two factor authentication](001673.html)
* **Messages sorted by:**
  [[ date ]](date.html#1672)
  [[ thread ]](thread.html#1672)
  [[ subject ]](subject.html#1672)
  [[ author ]](author.html#1672)

---

```
On Wed, Dec 02, 2020 at 03:05:42PM +0100, Thomas Lamprecht wrote:
> On 02.12.20 14:35, Oguz Bektas wrote:
> > On Wed, Dec 02, 2020 at 02:07:25PM +0100, Thomas Lamprecht wrote:
> >> On 02.12.20 13:35, Oguz Bektas wrote:
> >>> On Wed, Dec 02, 2020 at 01:27:47PM +0100, Thomas Lamprecht wrote:
> >>>>> 3. don't store all the tfa information in a single json file.
> >>>>>
> >>>>
> >>>> makes no sense to me, any reason you mention below can happen to
> >>>> arbitrary files, so just adds complexity while not gaining
> >>>> anything.
> >>>>
> >>>>> current version uses a single /etc/proxmox-backup/tfa.json file
> >>>>> which holds all the tfa info for all the users. this is a single
> >>>>> point of failure because: - file can be corrupted, causing tfa
> >>>>> to break for everyone (no more logins) - file could get deleted,
> >>>>> disabling/bypassing 2fa for everyone - file could get leaked in
> >>>>> a backup etc., giving everyone's tfa secrets and/or recovery
> >>>>> keys to attackers (bypass everything)
> >>>>>
> >>>>> better is to at least create a file for each user:
> >>>>> /etc/proxmox-backup/tfa/<username>.json or similar
> >>>>>
> >>>>> this way the damage is contained if for example the config
> >>>>> breaks because of incorrect deserialization etc.
> >>>>
> >>>> Why would deserialisation be incorrect for one single file but
> >>>> magically works if multiple files? Makes no sense.
> >>>
> >>> of course this can happen on arbitrary files...  i don't see why
> >>> it would add any complexity to use multiple files though (actually
> >>> makes it simpler imo). the reasoning behind this was to avoid a
> >>> single point of failure like i explained:
> >>>
> >>> multiple files for users -> only that user is affected by broken
> >>> config, other users can log in single file for all users -> all
> >>> users affected if config breaks and nobody can log in
> >>
> >> See that almost as anti-feature, it's actually better if such a
> >> thing happens that it's broken for all, as then one gets admin
> >> attention and can actually look for the underlying root cause -
> >> which at that point is probably memory or disk corruption/failure -
> >> or where does wolfgangs serializer breaks for all in one but not
> >> for split??
> >>
> >>
> >>>
> >>> so the point wasn't to magically fix (potential) incorrect
> >>> deserialization but to reduce breakage in case something like that
> >>> happens.
> >>
> >>
> >> like "what" happens? There's no such thing as one serialization is
> >> fine and the other not - if you start assuming that transient error
> >> model you cannot do anything at all anymore!
> >
> > as i explained already, it's not about if one serialization is fine
> > and the other isnt; if we have one big mess of a json file holding
> > all the secrets of everyone's tfa config, and at any point there's
> > some bug in the serializer or any other component that interacts
> > with this, then this can lead to DOS of ALL accounts on the server
> > (or compromise of ALL secrets in that file). the model is different
> > than the normal authentication mechanism with pam/pbs realms, since
> > the 2fa configuration has (untrusted) user input that gets
> > serialized and added into a root-owned file during the setup.
> > letting any user on any realm do this is IMO bad practice.
>
> It's not a mess it's clearly structured. Serde does just a fine job
> serializing JSON, a simple format to escape, plus we define schemas
> with validation for that exact reason.
>
> >
> > furthermore we could easily add a check during auth to see if the
> > tfa.json parses to correct json, and if not pop up an error message
> > like "2FA configuration invalid, please contact administrator" etc.
> > and even automatically send an email to [root at pam](https://lists.proxmox.com/cgi-bin/mailman/listinfo/pbs-devel) ...
>
> That's what serde already does, it errors if not valid JSON, which
> then erros the login (did not looked at it, but would assume that a
> error there does not just defuses TFA completely...) ...
yes instead of erroring the login without any explanation we can do like
i suggested. that way we still get notified if something is wrong, and
without DOSing the whole server ;)
>
> >
> >>
> >> I rather have it corrupt for all files as then the admin needs to
> >> fix it and we get notified, as some "magic" bug that only happens
> >> if it's a Tuesday and full moon.
> >>
> >> So no I do *not* want to have user.cfg, token.cfg, shadow.json with
> >> all info in one file, and then start to split TFA for every user,
> >> because of an error model which just assumes whatever one wishes.
> >>
> >>>>
> >>>>> 5. notify user if more than X failed tfa attempts (password is
> >>>>> already compromised at this point, so it's important to notify)
> >>>>> and block IP for certain amount of time (fail2ban?)
> >>>>
> >>>> we do not setup fail2ban but any admin can already if wished.
> >>>> Notification can only work if the user has setup a mail in the
> >>>> first place - but yes, sou
> >>> yes, but imo 2fa is more sensitive to bruteforcing than regular
> >>> passwords so it would make sense to limit it by default
> >>
> >> why is it more sensitive? I need both, so it's the same? If I get
> >> leaked shadow and tfa, I need to break both, only one has no use -
> >> that's the idea of TFA...
> >
> > it's more sensitive to bruteforcing; because of limited keyspace, as
> > in it's easier to bruteforce a 6 digit numerical passcode than a
> > regular passphrase in most circumstances. if attacker cracks/steals
> > a password and is presented with a 2fa screen, it should be unlikely
> > for them to bypass/crack that.  if i get unlimited tries to crack a
> > 6-digit code you'll eventually get it right.
>
> You have about 2 time windows to get through all combinations of 10^6
> with a forced response delay of 3 seconds + network latency, so 20
> tries max before the time change so much that you need to start
> again...
>
> >
> > that's why i think attempts should be limited by default and not
> > reliant on fail2ban, because there's no use case where anyone tries
> > to enter a totp code a thousand times for any legitimate reason...
> > (however you could forget/lose your password easily so it's more
> > acceptable to let someone keep trying in the regular auth case)
>
> but fail2ban can cope with the difference between >3 tries per minute,
> so why exactly
>
> >>>>
> >>>>>
> >>>>> 5.b also if recovery keys are available, limit amount of TOTP
> >>>>> attempts for that user
> >>>>
> >>>> what?
> >>>>
> >>>
> >>> if a user sets up TOTP + recovery keys, then it would make sense
> >>> to lock account in case of a lot of auth attempts with TOTP, until
> >>> recovery key is entered (afaik this is a common mechanism). but
> >>> maybe just notifying the user is enough as well.
> >>
> >> and why do you place more trust onto the fixed recovery keys than
> >> another TFA option?
> > the same reason i explained above, this would only kick in when the
> > TOTP is disabled because of too many auth failures. if a user has
> > set up recovery keys then they can be already used instead of TOTP
> > (the option is there regardless). so it's not placing more trust on
> > the recovery keys.
>
> It sure is, because you say that recovery keys are still good when u2f
> is not anymore, that implies you trusting it more that u2f or other
> variants.

no... that's just how recovery keys work (they are usable at *any* time
until used once). the decision to set up recovery key or not is up to
the user. this lockout mechanism would be only with TOTP setup enabled +
recovery keys also enabled (in case it wasn't clear in the previous
mails).

>
> >
> > the flow could be something like this:
> > 1. user sets up 2fa, TOTP and recovery keys
> > 2. attacker login with stolen password
> > 3. attacker attempts to crack 2fa totp code
> > 4. fails after 3/5/X attempts, user gets notified and TOTP is disabled
> > 5. at this point user can only log in with password + recovery code. (which they
> > could anyway, even if TOTP is present)
> >
> >> Which services/programs/websites do that, can you name a few examples?
> >
> > afaik some "secure" email providers like protonmail/tutanota etc. use
>
> proton mail seems to use just 8 hex characters as recovery key and I see nowhere
> any description for the behaviour you suggest..
>
> <https://protonmail.com/support/knowledge-base/two-factor-authentication/>
my bad then
>
> > this kind of mechanism (account password + mailbox is encrypted with
> > password, and recovery keys in case all else is lost/locked).
> >
> > i'm sure there are other examples as well
>
> I'm then sure you can list them, for now we're at 0 examples with actual
> source ;-)

here one example: <https://docs.genesys.com/Documentation/GAAP/latest/iaHelp/2FA>
"If the result is successful (i.e. the code is valid), Intelligent
Automation grants access. If the result is unsuccessful (i.e. the code
is invalid), Intelligent Automation prompts the user to enter another
code, until the Maximum Attempts at Sending an Authentication Code value
is reached."

so it is definitely a thing...

here is some explanation for the mathematics behind it: <https://security.stackexchange.com/questions/185905/maximum-tries-for-2fa-code>

if lockout isn't preferred, another solution would be for example to
increase the delay in a linear fashion after every failed 2fa auth attempt
(gets longer to auth for that IP address each time TOTP code failed).
however this can also be easily bypassed by using proxies etc. during
bruteforce so i'd prefer a lockout policy instead.

>

```

---

* Previous message (by thread): [[pbs-devel] [RFC backup 0/6] Two factor authentication](001670.html)
* Next message (by thread): [[pbs-devel] [RFC backup 0/6] Two factor authentication](001673.html)
* **Messages sorted by:**
  [[ date ]](date.html#1672)
  [[ thread ]](thread.html#1672)
  [[ subject ]](subject.html#1672)
  [[ author ]](author.html#1672)

---

[More information about the pbs-devel
mailing list](https://lists.proxmox.com/cgi-bin/mailman/listinfo/pbs-devel)


