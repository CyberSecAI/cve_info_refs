=== Content from bugzilla.redhat.com_de5edfc1_20250114_233014.html ===


* Login
  + Log in using an SSO provider:- [Fedora Account System](saml2_login.cgi?idp=Fedora%20Account%20System&target=show_bug.cgi%3Fid%3D2147462)
    - [Red Hat Associate](saml2_login.cgi?idp=Red%20Hat%20Associate&target=show_bug.cgi%3Fid%3D2147462)
    - [Red Hat Customer](saml2_login.cgi?idp=Red%20Hat%20Customer&target=show_bug.cgi%3Fid%3D2147462)+ Login using a Red Hat Bugzilla account
  + Forgot Password
  + [Create an Account](createaccount.cgi)

Red Hat Bugzilla – Bug 2147462

* [Home](./)
* [New](enter_bug.cgi)
* Search
  + [Simple Search](query.cgi?format=specific)
  + [Advanced Search](query.cgi?format=advanced)
* My Links
  + [Browse](describecomponents.cgi)
  + [Requests](request.cgi)
  + Reports
  + Current State
    - [Search](query.cgi)
    - [Tabular reports](query.cgi?format=report-table)
    - [Graphical reports](query.cgi?format=report-graph)
    - [Duplicates](duplicates.cgi)
  + Other Reports
    - [User Changes](https://bugzilla.redhat.com/page.cgi?id=user_activity.html)
  + Plotly Reports
    - [Bug Status](https://bugzilla.redhat.com/page.cgi?id=bug_status.html)
    - [Bug Severity](https://bugzilla.redhat.com/page.cgi?id=bug_severity.html)
    - [Non-Defaults](https://bugzilla.redhat.com/page.cgi?id=non_defaults.html)
* [Product Dashboard](page.cgi?id=productdashboard.html)

- Help
  * [Page Help!](docs/en/html/using/understanding.html)
  * [Bug Writing Guidelines](page.cgi?id=bug-writing.html)
  * [What's new](page.cgi?id=whats-new.html)
  * [Browser Support Policy](https://access.redhat.com/help/browsers)
  * [5.0.4.rh103 Release notes](page.cgi?id=release-notes.html)
  * [FAQ](page.cgi?id=faq.html)
  * [Guides index](docs/en/html/index.html)
  * [User guide](docs/en/html/using/index.html)
  * [Web Services](docs/en/html/integrating/api/Bugzilla/WebService/Bug.html)
  * [Contact](page.cgi?id=redhat/contact.html)
  * [Legal](page.cgi?id=terms-conditions.html)
- [[?]](page.cgi?id=quicksearch.html "Quicksearch Help")

This site requires JavaScript to be enabled to function correctly, please enable it.

[**Bug 2147462**](show_bug.cgi?id=2147462)
(CVE-2022-4134)
- [CVE-2022-4134](https://access.redhat.com/security/cve/CVE-2022-4134) openstack: glance & ceph conflict which allows image tampering

[Summary:](page.cgi?id=fields.html#short_desc "The bug summary is a short sentence which succinctly describes what the bug is about.")
CVE-2022-4134 openstack: glance & ceph conflict which allows image tampering

| | [Keywords](describekeywords.cgi): | Security | | --- | --- | | [Status](page.cgi?id=fields.html#bug_status): | NEW | | [Alias:](page.cgi?id=fields.html#alias "A short, unique name assigned to a bug in order to assist with looking it up and referring to it in other places in Bugzilla.") | CVE-2022-4134 | | [Product:](describecomponents.cgi "Bugs are categorised into Products and Components. Select a Classification to narrow down this list.") | Security Response | | [Classification:](page.cgi?id=fields.html#classification "Bugs are categorised into Classifications, Products and Components. classifications is the top-level categorisation.") | Other | | [Component:](describecomponents.cgi?product=Security Response "Components are second-level categories; each belongs to a particular Product. Select a Product to narrow down this list.") | vulnerability | | [Sub Component:](page.cgi?id=fields.html#rh_sub_components "The sub component of a specific component") | --- | | [Version:](page.cgi?id=fields.html#version "The version field defines the version of the software the bug was found in.") | unspecified | | [Hardware:](page.cgi?id=fields.html#rep_platform "The hardware platform the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | All | | [OS:](page.cgi?id=fields.html#op_sys "The operating system the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | Linux | | [Priority:](page.cgi?id=fields.html#priority) | medium | | [Severity:](page.cgi?id=fields.html#bug_severity) | medium | | [Target Milestone:](page.cgi?id=fields.html#target_milestone "The Target Milestone field is used to define when the engineer the bug is assigned to expects to fix it.") | --- | | [Assignee:](page.cgi?id=fields.html#assigned_to "The person in charge of resolving the bug.") | Nobody | | [QA Contact:](page.cgi?id=fields.html#qa_contact "The person responsible for confirming this bug if it is unconfirmed, and for verifying the fix once the bug has been resolved.") |  | | [Docs Contact:](page.cgi?id=fields.html#docs_contact "The person responsible for documenting once the bug has been resolved.") |  | | [URL:](page.cgi?id=fields.html#bug_file_loc "Bugs can have a URL associated with them - for example, a pointer to a web site where the problem is seen.") |  | | [Whiteboard:](page.cgi?id=fields.html#status_whiteboard "Each bug has a free-form single line text entry box for adding tags and status information.") |  | | [Depends On:](page.cgi?id=fields.html#dependson "The bugs listed here must be resolved before this bug can be resolved.") | [2147463](show_bug.cgi?id=2147463 "NEW - CVE-2022-4134 openstack-glance: openstack: glance & ceph conflict which allows image tampering [openstack-rdo]") [2147467](show_bug.cgi?id=2147467) [2154114](show_bug.cgi?id=2154114) | | [Blocks:](page.cgi?id=fields.html#blocked "This bug must be resolved before the bugs listed in this field can be resolved.") | [2135069](show_bug.cgi?id=2135069) [2175301](show_bug.cgi?id=2175301) | | TreeView+ | [depends on](buglist.cgi?bug_id=2147462&bug_id_type=anddependson&format=tvp) / [blocked](buglist.cgi?bug_id=2147462&bug_id_type=andblocked&format=tvp&tvp_dir=blocked) |  | |  | | [Reported:](page.cgi?id=fields.html#reporter) | 2022-11-23 23:44 UTC by Nick Tait | | --- | --- | | [Modified:](page.cgi?id=fields.html#modified) | 2023-07-07 08:34 UTC ([History](show_activity.cgi?id=2147462)) | | [CC List:](page.cgi?id=fields.html#cclist) | 9 users (show)  athomas cyril eglynn jjoyce lhh mburns mgarciac msava spower | | Fixed In Version: |  | | | Doc Type: | If docs needed, set a value | | | Doc Text: | A flaw was found in openstack-glance. This issue could allow a remote, authenticated attacker to tamper with images, compromising the integrity of virtual machines created using these modified images. | | | Clone Of: |  | | | Environment: |  | | | Last Closed: |  | | | Embargoed: |  | | |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| --- | | |

| | Attachments | [(Terms of Use)](page.cgi?id=terms-conditions.html) | | | --- | --- | --- | |  | | | |  |
| --- | --- | --- | --- | --- | --- | --- | --- |

| [Description](show_bug.cgi?id=2147462#c0)  Nick Tait    2022-11-23 23:44:32 UTC  ``` <https://wiki.openstack.org/wiki/OSSN/OSSN-0090>   ```  [Comment 1](show_bug.cgi?id=2147462#c1)  Nick Tait    2022-11-23 23:46:01 UTC  ``` Created openstack-glance tracking bugs for this issue:  Affects: openstack-rdo [[bug 2147463](show_bug.cgi?id=2147463 "NEW - CVE-2022-4134 openstack-glance: openstack: glance & ceph conflict which allows image tampering [openstack-rdo]")]   ``` |  |
| --- | --- |

---

| Note You need to [log in](show_bug.cgi?id=2147462&GoAheadAndLogIn=1) before you can comment on or make changes to this bug. |
| --- |

---

[Privacy](page.cgi?id=redhat/privacy.html)
[Contact](page.cgi?id=redhat/contact.html)
[FAQ](page.cgi?id=faq.html)
[Legal](page.cgi?id=terms-conditions.html)



=== Content from access.redhat.com_ed37023d_20250115_205844.html ===


[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

**We're sorry but cve-details doesn't work properly without JavaScript enabled. Please enable it to continue.**

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2025 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from bugs.launchpad.net_a909552f_20250114_233008.html ===

[Log in / Register](https://bugs.launchpad.net/glance/%2Bbug/1990157/%2Blogin)

[![](https://launchpadlibrarian.net/355215744/glance-chipmunk-64.png)](https://launchpad.net/glance)

## [Glance](https://launchpad.net/glance)

* [Overview](https://launchpad.net/glance)
* [Code](https://code.launchpad.net/glance)
* [Bugs](https://bugs.launchpad.net/glance)
* [Blueprints](https://blueprints.launchpad.net/glance)
* [Translations](https://translations.launchpad.net/glance)
* [Answers](https://answers.launchpad.net/glance)

# OSSN-0090: Malicious image data modification can happen when using COW

Bug #1990157 reported by
[Erno Kuvaja](https://launchpad.net/~jokke)
on 2022-09-19

[268](/%2Bhelp-bugs/bug-heat.html)

This bug affects 1 person

| Affects | | Status | Importance | Assigned to | Milestone |
| --- | --- | --- | --- | --- | --- |
|  | [Glance](https://bugs.launchpad.net/glance) | Status tracked in Zed | | | | |
|  | [Wallaby](https://bugs.launchpad.net/glance/wallaby) | New | Undecided | Unassigned |  |
|  | [Xena](https://bugs.launchpad.net/glance/xena) | New | Undecided | Unassigned |  |
|  | [Yoga](https://bugs.launchpad.net/glance/yoga) | New | Undecided | Unassigned |  |
|  | [Zed](https://bugs.launchpad.net/glance/zed) | New | Critical | Unassigned |  |
|  | [OpenStack Security Notes](https://bugs.launchpad.net/ossn) | In Progress | Undecided | [Brian Rosmaita](https://launchpad.net/~brian-rosmaita) |  |

### Bug Description

The location fix manipulation mentioned in <https://security.openstack.org/ossa/OSSA-2016-006.html> of disallowing removal of last image location (and thus transition it back to queued) is only partial fix for the issue.

The fix at the time was able to ensure that the hash stayed in the image record causing validations to fail even if the image data itself had changed.

Different efforts to speed up booting and volume creation processes utilizing Copy On Write behaviour of Ceph or various Cinder backends is causing two different scenarios where malicious content can be sneaked into the image.

1) When Nova creates snapshot directly into the Ceph store and creates image through the API adding the location via locations API rather than uploading the data to Glance it omits 2 parts of metadata that would allow identifying alteration of the image data. The image does not have multihash (or checksum) associated with it making validation impossible. The image does not have size metadata either.

2) When image is consumed in COW manner even if it had multihash (checksum) registered in the metadata it does not get validated as the consumer does not read the whole image and calculate checksum of it.

All current implementations of COW handling of the image depends of the direct url and locations API being exposed. As the services are accessing the image with user credentials if Glance is deployed with single API configuration serving both OpenStack services and end users, the malicious end user will have all the tools needed to make this attack valid. Only real mitigation for this issue is to deploy External API endpoint (for user access) and Internal API endpoint (for Openstack services, note that this endpoint needs to be firewalled off from end user access as the credentials are the same). Additional hardening of creating the multihash metadata entries and validating them upon use should be implemented. The dual API deployment should be highlighted clearly in the documentation.

These two behavioural facts causes the image manipulation mentioned in the OSSA-2016-006 (CVE 2016-0757) still possible.

If the image has multihash (checksum) recorded for it, python-glanceclient will reject the image if the data does not match. But this requires manual verification (actually downloading the image) to find out or deep understanding of the technical implementation to match the location URI with the image ID (in Ceph case). The COW consumers will not flag it to anyone and will just happily consume the modified data.

In the case that there is no multihash recorded for the image the only indication for malicious activity would be through comparing the location URI with the image ID (in Ceph case) and there is no other validation channels.

Once the location of the modified image data has been added to the image locations table, Glance will allow deleting the original data as that is not the last location anymore.

Tags:

[security](/glance/%2Bbugs?field.tag=security)

## CVE References

* [2016-0757](/bugs/cve/2016-0757 "OpenStack Image Service (Glance) befo...")
* [2022-4134](/bugs/cve/2022-4134 "A flaw was found in openstack-glance....")

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Erno Kuvaja (jokke)](https://launchpad.net/~jokke) wrote on 2022-09-19: |  |  | [#1](/glance/%2Bbug/1990157/comments/1) |
| --- | --- | --- | --- |

I've added Pranali into the bug as new Glance PTL and she is aware of the issue.

I've added Pranali into the bug as new Glance PTL and she is aware of the issue.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jeremy Stanley (fungi)](https://launchpad.net/~fungi) wrote on 2022-09-19: |  |  | [#2](/glance/%2Bbug/1990157/comments/2) |
| --- | --- | --- | --- |

Since this report concerns a possible security risk, an incomplete

security advisory task has been added while the core security

reviewers for the affected project or projects confirm the bug and

discuss the scope of any vulnerability along with potential

solutions.

Since this report concerns a possible security risk, an incomplete
security advisory task has been added while the core security
reviewers for the affected project or projects confirm the bug and
discuss the scope of any vulnerability along with potential
solutions.

| **description**: | updated |
| --- | --- |
| Changed in ossa: | |
| **status**: | New → Incomplete |

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jeremy Stanley (fungi)](https://launchpad.net/~fungi) wrote on 2022-09-19: |  |  | [#3](/glance/%2Bbug/1990157/comments/3) |
| --- | --- | --- | --- |

Was this way of triggering the defective behavior present even at the time OSSA 2016-006 was published and nobody realized it, or did subsequent changes to Glance or other projects re-expose the vulnerability some time later?

Was this way of triggering the defective behavior present even at the time OSSA 2016-006 was published and nobody realized it, or did subsequent changes to Glance or other projects re-expose the vulnerability some time later?

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-09-19: |  |  | [#4](/glance/%2Bbug/1990157/comments/4) |
| --- | --- | --- | --- |

@Jeremy: I think it's fair to say that this issue was present at the time of OSSA 2016-006 but nobody realized it ... that's because after the initial bug was fixed, a subsequent bug was filed that did identify the issue. Here's the history of this problem:

1. "[OSSA 2016-006] Normal user can change image status if show\_multiple\_locations has been set to true (CVE-2016-0757)"

[https://bugs.launchpad.net/glance/+bug/1525915](https://bugs.launchpad.net/glance/%2Bbug/1525915)

what: create image, upload data (checksum is set), delete all locations, image goes to 'queued' status, can upload malicious data via the API in the normal way

- checksum can't be modified (although checksum is md5 until Rocky)

- can only do it with an image you own (or if you are admin)

- fix: don't allow the image location deletion if the result would be no locations

2. "Normal user can replace active image data if show\_multiple\_locations has been set to true"

[https://bugs.launchpad.net/ossn/+bug/1549483](https://bugs.launchpad.net/ossn/%2Bbug/1549483)

what: create image, upload data (checksum is set), add a new location pointing to malicious data, delete all non-malicious locations

- checksum can't be modified (although checksum is md5 until Rocky)

- can only do it with an image you own (or if you are admin)

- fix: OSSN-0065 recommends do not configure glance with show\_multiple\_locations=true

3. In Rocky (glance 17.0.0, Tagged on 2018-08-30 14:06:53 +0000)

- introduction of glance "multihash" ... like legacy "checksum", os\_hash\_algo/os\_hash\_value can't be modified, and the default algo is sha512

- if the "multihash" is checked on download, data substitution from [Bug #1549483](/bugs/1549483) will be revealed

4. In Rocky (glance 17.0.1, Tagged on 2020-03-19 12:26:00 +0000)

- <https://docs.openstack.org/releasenotes/glance/rocky.html#relnotes-17-0-1-stable-rocky>

- Known Issue: "The workaround is to continue to use the show\_multiple\_locations option in a dedicated “internal” Glance node that is not accessible to end users. We continue to recommend that image locations not be exposed to end users."

5. "Malicious image data modification can happen when using COW"

[https://bugs.launchpad.net/glance/+bug/1990157](https://bugs.launchpad.net/glance/%2Bbug/1990157) (this bug)

what: create an image, upload data ("multihash" is set), boot a server from the image, ask nova to create an image from the server. This image will not have "multihash" info set. Then do the attack from [Bug #1549483](/bugs/1549483), probably by uploading a malicious image to glance (to get the data into the backend); then add the location to the un-checksummed image and delete the original location from the un-checksummed image

- can't mitigate with a "multihash" check (because there isn't one)

- can only do it with an image you own (or if you are admin)

@Jeremy: I think it's fair to say that this issue was present at the time of OSSA 2016-006 but nobody realized it ... that's because after the initial bug was fixed, a subsequent bug was filed that did identify the issue. Here's the history of this problem:
1. "[OSSA 2016-006] Normal user can change image status if show\_multiple\_locations has been set to true (CVE-2016-0757)"
https://bugs.launchpad.net/glance/+bug/1525915
what: create image, upload data (checksum is set), delete all locations, image goes to 'queued' status, can upload malicious data via the API in the normal way
- checksum can't be modified (although checksum is md5 until Rocky)
- can only do it with an image you own (or if you are admin)
- fix: don't allow the image location deletion if the result would be no locations
2. "Normal user can replace active image data if show\_multiple\_locations has been set to true"
https://bugs.launchpad.net/ossn/+bug/1549483
what: create image, upload data (checksum is set), add a new location pointing to malicious data, delete all non-malicious locations
- checksum can't be modified (although checksum is md5 until Rocky)
- can only do it with an image you own (or if you are admin)
- fix: OSSN-0065 recommends do not configure glance with show\_multiple\_locations=true
3. In Rocky (glance 17.0.0, Tagged on 2018-08-30 14:06:53 +0000)
- introduction of glance "multihash" ... like legacy "checksum", os\_hash\_algo/os\_hash\_value can't be modified, and the default algo is sha512
- if the "multihash" is checked on download, data substitution from Bug #1549483 will be revealed
4. In Rocky (glance 17.0.1, Tagged on 2020-03-19 12:26:00 +0000)
- https://docs.openstack.org/releasenotes/glance/rocky.html#relnotes-17-0-1-stable-rocky
- Known Issue: "The workaround is to continue to use the show\_multiple\_locations option in a dedicated “internal” Glance node that is not accessible to end users. We continue to recommend that image locations not be exposed to end users."
5. "Malicious image data modification can happen when using COW"
https://bugs.launchpad.net/glance/+bug/1990157 (this bug)
what: create an image, upload data ("multihash" is set), boot a server from the image, ask nova to create an image from the server. This image will not have "multihash" info set. Then do the attack from Bug #1549483, probably by uploading a malicious image to glance (to get the data into the backend); then add the location to the un-checksummed image and delete the original location from the un-checksummed image
- can't mitigate with a "multihash" check (because there isn't one)
- can only do it with an image you own (or if you are admin)

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Erno Kuvaja (jokke)](https://launchpad.net/~jokke) wrote on 2022-09-20 (last edit on 2022-09-20): |  |  | [#5](/glance/%2Bbug/1990157/comments/5) |
| --- | --- | --- | --- |

@Jeremy & @Brian I'm not convinced, but can't say for sure, that this was existing when the original bug was handled in 2016. Lots of the vectors that were problematic at the time got plugged.

The problem really is that since that we've introduced "Community" visibility, at least Cinder COW paths, and I think the nova direct snapshotting, which of all are very much expanding the old exposure. Especially as the COW operations do require 'show\_multiple\_locations=true' & 'show\_image\_direct\_url=true' which were the majority of discussion during OSSA-0065 (Brian's #2) fixing and mitigating the issues.

Basically all deployments with Ceph are vulnerable and the users are shrugging the warnings off "as it's the default with Ceph" while these COW models never even tried to address the elephant in the room.

The multihash would help to identify the exploitation if it was present in all images, but like said that is not the case with direct snapshotting. (One of the reasons why I wanted to bring this up as a new bug). The other part which is very worrying is that the COW style consumers do not check the hash even if it was present like mentioned in my bug description, which might have been overlooked during the original OSSA-2016-006, but I'm not sure if that was even implemented yet at the time.

While the recommendation (Brian #4) landed in Rocky release notes, it never made it's way to any of the other documentation highlighting any of these issues actually being present if the separation of gapi nodes had not been done. Good indicator of this confusion is that at least TripleO, DevStack and I think OSA are all deploying only one set of gapi to serve both the user and internal services.

So lots of the attack vectors did not exists when the mechanism was identified in 2016 and was flagged as solved at the time.

@Jeremy & @Brian I'm not convinced, but can't say for sure, that this was existing when the original bug was handled in 2016. Lots of the vectors that were problematic at the time got plugged.
The problem really is that since that we've introduced "Community" visibility, at least Cinder COW paths, and I think the nova direct snapshotting, which of all are very much expanding the old exposure. Especially as the COW operations do require 'show\_multiple\_locations=true' & 'show\_image\_direct\_url=true' which were the majority of discussion during OSSA-0065 (Brian's #2) fixing and mitigating the issues.
Basically all deployments with Ceph are vulnerable and the users are shrugging the warnings off "as it's the default with Ceph" while these COW models never even tried to address the elephant in the room.
The multihash would help to identify the exploitation if it was present in all images, but like said that is not the case with direct snapshotting. (One of the reasons why I wanted to bring this up as a new bug). The other part which is very worrying is that the COW style consumers do not check the hash even if it was present like mentioned in my bug description, which might have been overlooked during the original OSSA-2016-006, but I'm not sure if that was even implemented yet at the time.
While the recommendation (Brian #4) landed in Rocky release notes, it never made it's way to any of the other documentation highlighting any of these issues actually being present if the separation of gapi nodes had not been done. Good indicator of this confusion is that at least TripleO, DevStack and I think OSA are all deploying only one set of gapi to serve both the user and internal services.
So lots of the attack vectors did not exists when the mechanism was identified in 2016 and was flagged as solved at the time.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Erno Kuvaja (jokke)](https://launchpad.net/~jokke) wrote on 2022-09-20: |  |  | [#6](/glance/%2Bbug/1990157/comments/6) |
| --- | --- | --- | --- |

There is fairly simple solution for this too.

We could kick off asynchronous task (all the piping is there so only the taskflow and triggering for it would need to be implemented) when ever there is location added to the image from locations API for Glance to go and read the data and calculate the multihash of it. If the image was new, like Nova direct snapshot or someone creating image with http-store, we would add the multihash to the metadata (unlike we do now). If the image was existing one, we could validate the hash against the existing metadata.

it would not help in the COW cases where the hash is not verified upon consumption, but it would plug any easy way to replace the existing data with new one. One would need to have access to the actual storage.

There is fairly simple solution for this too.
We could kick off asynchronous task (all the piping is there so only the taskflow and triggering for it would need to be implemented) when ever there is location added to the image from locations API for Glance to go and read the data and calculate the multihash of it. If the image was new, like Nova direct snapshot or someone creating image with http-store, we would add the multihash to the metadata (unlike we do now). If the image was existing one, we could validate the hash against the existing metadata.
it would not help in the COW cases where the hash is not verified upon consumption, but it would plug any easy way to replace the existing data with new one. One would need to have access to the actual storage.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-09-21: |  |  | [#7](/glance/%2Bbug/1990157/comments/7) |
| --- | --- | --- | --- |

The point of my comment #4 was that this exploit is a fairly obvious implication of items 1-4 in that comment. Thus, I think there's no point in keeping this embargoed as a private security bug, and we should go ahead and make it public.

The point of my comment #4 was that this exploit is a fairly obvious implication of items 1-4 in that comment. Thus, I think there's no point in keeping this embargoed as a private security bug, and we should go ahead and make it public.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jeremy Stanley (fungi)](https://launchpad.net/~fungi) wrote on 2022-09-21: |  |  | [#8](/glance/%2Bbug/1990157/comments/8) |
| --- | --- | --- | --- |

Thanks Brian. The other things to consider are:

1. If the bug is impractical for an attacker to successfully exploit, we should work on this in public.

2. If the solutions to the bug are not safely backportable to maintained stable branches, we should work on this in public.

3. If solutions to the bug are very likely to take longer than three months (our maximum embargo duration) to implement and/or would be very hard to develop in secret, we should work on this in public.

Thanks Brian. The other things to consider are:
1. If the bug is impractical for an attacker to successfully exploit, we should work on this in public.
2. If the solutions to the bug are not safely backportable to maintained stable branches, we should work on this in public.
3. If solutions to the bug are very likely to take longer than three months (our maximum embargo duration) to implement and/or would be very hard to develop in secret, we should work on this in public.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Dan Smith (danms)](https://launchpad.net/~danms) wrote on 2022-09-21: |  |  | [#9](/glance/%2Bbug/1990157/comments/9) |
| --- | --- | --- | --- |

Erno, that's a good idea to re-hash the image when we add the location, but:

1. We'd probably want some way to not expose that location until it's verified, otherwise we've just shrunk the window. I don't think we have a "state" for each location today, do we?

2. It would probably be difficult to expose the result of a failure. Accidental tripping of the hash failure would result in locations just disappearing (I assume) which could be confusing.

3. We'd need some way to recover the process if we're interrupted in the middle of reading a very large image. If we had #1, then perhaps the location would never become usable, but we'd need to cover that case.

4. We'd end up with a very large additional load on glance-api that isn't there today, as all the (currently very lightweight) snapshotting of nova instances would cause a lot of additional CPU and network load to glance. Right now, you can snapshot your instances very frequently on ceph because it's so lightweight, and people do. On an edge deployment where you've got a local glance, that could end up overwhelming what is actually just a very lightweight set of glance workers for the (current) purpose of just finding images in RBD.

So, it might be worth doing this anyway, but I think we'd want to hide that behind a "verify\_additional\_locations=(True|False)" flag for the security-conscious. For people that don't want that level of additional work, deploying glance internal and public would be a lot better I think as it closes the hole and avoids a bunch of additional work on each snapshot.

Erno, that's a good idea to re-hash the image when we add the location, but:
1. We'd probably want some way to not expose that location until it's verified, otherwise we've just shrunk the window. I don't think we have a "state" for each location today, do we?
2. It would probably be difficult to expose the result of a failure. Accidental tripping of the hash failure would result in locations just disappearing (I assume) which could be confusing.
3. We'd need some way to recover the process if we're interrupted in the middle of reading a very large image. If we had #1, then perhaps the location would never become usable, but we'd need to cover that case.
4. We'd end up with a very large additional load on glance-api that isn't there today, as all the (currently very lightweight) snapshotting of nova instances would cause a lot of additional CPU and network load to glance. Right now, you can snapshot your instances very frequently on ceph because it's so lightweight, and people do. On an edge deployment where you've got a local glance, that could end up overwhelming what is actually just a very lightweight set of glance workers for the (current) purpose of just finding images in RBD.
So, it might be worth doing this anyway, but I think we'd want to hide that behind a "verify\_additional\_locations=(True|False)" flag for the security-conscious. For people that don't want that level of additional work, deploying glance internal and public would be a lot better I think as it closes the hole and avoids a bunch of additional work on each snapshot.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Dan Smith (danms)](https://launchpad.net/~danms) wrote on 2022-09-21: |  |  | [#10](/glance/%2Bbug/1990157/comments/10) |
| --- | --- | --- | --- |

Jeremy, the other thing to consider is that the real (current, immediate) fix to this is one of deployment and not so much a change to glance itself. So, OSA might want to make a change, which I guess could be covered under the embargo period, but I don't think we should expect a glance change to be released as a result of this.

Thus, publicizing it would let operators change their deployments (which many of them can probably do right away) to eliminate the concern sooner than later.

Jeremy, the other thing to consider is that the real (current, immediate) fix to this is one of deployment and not so much a change to glance itself. So, OSA might want to make a change, which I guess could be covered under the embargo period, but I don't think we should expect a glance change to be released as a result of this.
Thus, publicizing it would let operators change their deployments (which many of them can probably do right away) to eliminate the concern sooner than later.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-09-22: |  |  | [#11](/glance/%2Bbug/1990157/comments/11) |
| --- | --- | --- | --- |

The glance team discussed this extensively at a PTG a few years ago, and rejected background computation of the hash largely because the time/load are exactly what operators are trying to avoid by using a common ceph to back nova and glance (Dan's point 4).

Plus, if the hash isn't going to be checked by nova when the image is consumed, recomputing it for each location seems kind of pointless (all we would know is that the data at location L had hash H at the time glance checked and allowed L to be added to the image, but if someone changes the data at L later (not the location uri, changes the actual data ... doesn't have to be malicious, could just be some kind of failure in the backend), there's no way to know without downloading and hashing the image. So I don't think that a verify\_additional\_locations option would actually increase security.

What could increase security would be to allow images that have the img\_signature\* properties on them to \*always\* go through the validation path. However, last time I looked, image signature verification is only available for the libvirt compute driver (not sure that's a big deal) and when NOT using the rbd image backend (which is the backend we're using here). But I think forcing the "normal" data path for signed images would not increase load too much (it's a PITA for users to set up an image that can be verified), and you would have the check done at the point of consumption, which is really where you want it. (This is the case for cinder, too; when using the cinder glance\_store, the image-volume is cloned directly in the backend.)

Or, now that we have glance multi-store, an operator could use a second (non-rbd, non-cinder) store and tell end users to put all signed images into that store. (I think this would still require code changes in nova ... last I looked, if you turn verify\_glance\_signatures on for nova, if the img\_signature\* properties are incomplete or missing, nova puts the instance into an error state. I think we should look into changing this, though, so that there is some way to do image verification when nova and glance are using the same rbd backend. Cinder doesn't have the all-or-nothing signature verification setting, so I think this dedicated store for signed images plan could work for cinder with no code change.)

In any case, I think we should offer some way to guarantee (for the users who want it) that a consumed image is verified at the point of use. But that's not directly related to this bug.

For this bug right now, I think the situation is:

- If you don't expose locations on any end-user-facing glance-api, end users cannot modify locations via the Images API.

- If you do expose locations to end users, end users can modify them, but only on their own images. So if you set the policies for publicize\_image, communitize\_image, and add\_member to be admin-only, an end user cannot spread a malicious image outside of their own project.

The glance team discussed this extensively at a PTG a few years ago, and rejected background computation of the hash largely because the time/load are exactly what operators are trying to avoid by using a common ceph to back nova and glance (Dan's point 4).
Plus, if the hash isn't going to be checked by nova when the image is consumed, recomputing it for each location seems kind of pointless (all we would know is that the data at location L had hash H at the time glance checked and allowed L to be added to the image, but if someone changes the data at L later (not the location uri, changes the actual data ... doesn't have to be malicious, could just be some kind of failure in the backend), there's no way to know without downloading and hashing the image. So I don't think that a verify\_additional\_locations option would actually increase security.
What could increase security would be to allow images that have the img\_signature\* properties on them to \*always\* go through the validation path. However, last time I looked, image signature verification is only available for the libvirt compute driver (not sure that's a big deal) and when NOT using the rbd image backend (which is the backend we're using here). But I think forcing the "normal" data path for signed images would not increase load too much (it's a PITA for users to set up an image that can be verified), and you would have the check done at the point of consumption, which is really where you want it. (This is the case for cinder, too; when using the cinder glance\_store, the image-volume is cloned directly in the backend.)
Or, now that we have glance multi-store, an operator could use a second (non-rbd, non-cinder) store and tell end users to put all signed images into that store. (I think this would still require code changes in nova ... last I looked, if you turn verify\_glance\_signatures on for nova, if the img\_signature\* properties are incomplete or missing, nova puts the instance into an error state. I think we should look into changing this, though, so that there is some way to do image verification when nova and glance are using the same rbd backend. Cinder doesn't have the all-or-nothing signature verification setting, so I think this dedicated store for signed images plan could work for cinder with no code change.)
In any case, I think we should offer some way to guarantee (for the users who want it) that a consumed image is verified at the point of use. But that's not directly related to this bug.
For this bug right now, I think the situation is:
- If you don't expose locations on any end-user-facing glance-api, end users cannot modify locations via the Images API.
- If you do expose locations to end users, end users can modify them, but only on their own images. So if you set the policies for publicize\_image, communitize\_image, and add\_member to be admin-only, an end user cannot spread a malicious image outside of their own project.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Erno Kuvaja (jokke)](https://launchpad.net/~jokke) wrote on 2022-09-22: |  |  | [#12](/glance/%2Bbug/1990157/comments/12) |
| --- | --- | --- | --- |

@Dan we do have status on the locations table and we do update it. I don't think we consume it anywhere currently but it's there. Don't we also have the error metadata key where we already report errors from the import tasks, maybe we can reuse that?

Honestly I have not looked into the performance of the current hashing functions. So I cannot say yei or nei if the load would be significant on some snapshotting interval.

@Brian just to make clear, so we don't give wrong exposure assumption here. I'm taking you are referring to the PTG discussion within Glance Security core at the time which resulted to that release note that we still advice the dual deployment model. This was not discussed in depth with any wider audience at the time.

IIRC the hashing operation at the time was expected to be synchronous and we did not want to hold the client hostage on location call while we do it.

In hindsight our decision around (I think it was) OSSA-0065 when we decided on the blanket principle of "This covers all the future iterations of this location swap vulnerability" was wrong. It has became clear over the years that the releasenote gets ignored, we do not have the approach properly documented anywhere in the deployment guide and there's been clearly rather expansion of the issue than more limited situation in the field. And we get on frequent intervals people asking why this issue is still not plugged (like his time our RH Leadership Team).

I tend to agree with you that making yet another config option will not increase the security of the service. When the very first "We've fixed this by not allowing deletion of the last image location" was released we had no such scenario that we wouldn't have image hash in place and that was supposed to catch it. And we cannot blame any consumer not verifying it before we make sure we have that metadata available. I think it is key requirement for our promise of immutable images, being the change malicious act or accidental corruption etc.

I do think it being unreasonable expectation for clouds to policy out community images because of this when it was promoted as the user friendly solution for not allowing everyone publicize images. Just like it would be to turn of image sharing as well. Just because we can't be arsed to fix the underlying issues in our code.

@All Especially as any backend detail leakage is frowned upon the community, I think we still need to reiterate the importance of deploying public and internal gapi services. But clearly that is not the right solution to the fact that it's fairly trivial to change the image payload and the hashless images makes it impossible to detect. And past has proven that deployments don't do it anyways. When the Ceph deployments are North of 60% of all of the OpenStack deployments, the hashless images are by no means a corner case. If we plug that hole, then the decision is anymore "Do we care exposing what backend stores are in use or not" not if that risks the integrity of the images too.

@Dan we do have status on the locations table and we do update it. I don't think we consume it anywhere currently but it's there. Don't we also have the error metadata key where we already report errors from the import tasks, maybe we can reuse that?
Honestly I have not looked into the performance of the current hashing functions. So I cannot say yei or nei if the load would be significant on some snapshotting interval.
@Brian just to make clear, so we don't give wrong exposure assumption here. I'm taking you are referring to the PTG discussion within Glance Security core at the time which resulted to that release note that we still advice the dual deployment model. This was not discussed in depth with any wider audience at the time.
IIRC the hashing operation at the time was expected to be synchronous and we did not want to hold the client hostage on location call while we do it.
In hindsight our decision around (I think it was) OSSA-0065 when we decided on the blanket principle of "This covers all the future iterations of this location swap vulnerability" was wrong. It has became clear over the years that the releasenote gets ignored, we do not have the approach properly documented anywhere in the deployment guide and there's been clearly rather expansion of the issue than more limited situation in the field. And we get on frequent intervals people asking why this issue is still not plugged (like his time our RH Leadership Team).
I tend to agree with you that making yet another config option will not increase the security of the service. When the very first "We've fixed this by not allowing deletion of the last image location" was released we had no such scenario that we wouldn't have image hash in place and that was supposed to catch it. And we cannot blame any consumer not verifying it before we make sure we have that metadata available. I think it is key requirement for our promise of immutable images, being the change malicious act or accidental corruption etc.
I do think it being unreasonable expectation for clouds to policy out community images because of this when it was promoted as the user friendly solution for not allowing everyone publicize images. Just like it would be to turn of image sharing as well. Just because we can't be arsed to fix the underlying issues in our code.
@All Especially as any backend detail leakage is frowned upon the community, I think we still need to reiterate the importance of deploying public and internal gapi services. But clearly that is not the right solution to the fact that it's fairly trivial to change the image payload and the hashless images makes it impossible to detect. And past has proven that deployments don't do it anyways. When the Ceph deployments are North of 60% of all of the OpenStack deployments, the hashless images are by no means a corner case. If we plug that hole, then the decision is anymore "Do we care exposing what backend stores are in use or not" not if that risks the integrity of the images too.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-09-22: |  |  | [#13](/glance/%2Bbug/1990157/comments/13) |
| --- | --- | --- | --- |

[Download full text](https://bugs.launchpad.net/glance/%2Bbug/1990157/comments/13/%2Bdownload) (5.0 KiB)

I guess that I'm not being clear about my position here. What I'm saying is:

1. This exploit is a straightforward implication of knowledge that has been discussed publicly (even if not a lot of people paid attention to it; my point is that it's "out there"). So I think it's important to publish an OSS{AN} (whatever the VMT thinks is appropriate) to clue in/remind operators that there is a known vulnerability that they can take action about immediately, to wit:

- deploy separate internal/external glance-api so that multiple locations are not shown to end users

- or, if that looks too destabilizing to do instantly in a deployment, restrict the methods of image broadcast (publicize, communitize, share) until ^^ is done

2. Soon as we get the OSS{AN} published (which I think could happen next week), open this bug and use the PTG to discuss a long-term solution in public with any operators who care to attend. Since Red Hat in particular has an interest in OpenStack + Ceph configurations, we can reach out to some RH product managers who can attend and provide input, or will be able to get the word out to some large operators, who will hopefully provide direct input. There are some big tradeoffs here that we can't assess on our own. Right now, everything is aimed toward speed, and we heed help assessing how much of a slowdown people are willing to accept (if any), and under what circumstances.

3. I personally have never liked this non-checksummed image creation and consumption, but it's what operators have been willing to accept for performance. What I particularly don't like is that the current situation makes it \*impossible\* under some configurations of nova/glance/cinder to guarantee a verification chain for an image. If you don't use Ceph or the cinder glance\_store, you are guaranteed a hash check of sha512 (or stronger, if the operator has configured it) at the point when the image is consumed. (IMO, this is just as strong as image signature verification [0], with none of the hassle for end users.) But this isn't available for some configurations, and maybe that's OK; it's an operator (and their customers, who can vote with their feet) choice. But maybe not everyone is aware of this choice (which will hopefully be addressed by item 1 above). Note that this is independent of the exploit discussed by this bug, which is malicious image provision via manipulation of glance's location record. Even if we re-do locations so that only nova can set them, there's still the issue of image data substitution in the backend without modifying the location uri recorded in glance.

4. I think an acceptable compromise would be to rely on image signature verification for deployment configurations that allow non-checksummed images. This is not an immediate solution because signature verification is not supported in those configurations where it would be really useful. It imposes a speed penalty, but it's also right in your face that you are making a speed/security tradeoff, because you (the end user) are adding a bunch of image metadata specifically for this purpose.

  Additionally, the image-signature-verification implementation is inconsistent be...

[Read more...](/glance/%2Bbug/1990157/comments/13)

I guess that I'm not being clear about my position here. What I'm saying is:
1. This exploit is a straightforward implication of knowledge that has been discussed publicly (even if not a lot of people paid attention to it; my point is that it's "out there"). So I think it's important to publish an OSS{AN} (whatever the VMT thinks is appropriate) to clue in/remind operators that there is a known vulnerability that they can take action about immediately, to wit:
- deploy separate internal/external glance-api so that multiple locations are not shown to end users
- or, if that looks too destabilizing to do instantly in a deployment, restrict the methods of image broadcast (publicize, communitize, share) until ^^ is done
2. Soon as we get the OSS{AN} published (which I think could happen next week), open this bug and use the PTG to discuss a long-term solution in public with any operators who care to attend. Since Red Hat in particular has an interest in OpenStack + Ceph configurations, we can reach out to some RH product managers who can attend and provide input, or will be able to get the word out to some large operators, who will hopefully provide direct input. There are some big tradeoffs here that we can't assess on our own. Right now, everything is aimed toward speed, and we heed help assessing how much of a slowdown people are willing to accept (if any), and under what circumstances.
3. I personally have never liked this non-checksummed image creation and consumption, but it's what operators have been willing to accept for performance. What I particularly don't like is that the current situation makes it \*impossible\* under some configurations of nova/glance/cinder to guarantee a verification chain for an image. If you don't use Ceph or the cinder glance\_store, you are guaranteed a hash check of sha512 (or stronger, if the operator has configured it) at the point when the image is consumed. (IMO, this is just as strong as image signature verification [0], with none of the hassle for end users.) But this isn't available for some configurations, and maybe that's OK; it's an operator (and their customers, who can vote with their feet) choice. But maybe not everyone is aware of this choice (which will hopefully be addressed by item 1 above). Note that this is independent of the exploit discussed by this bug, which is malicious image provision via manipulation of glance's location record. Even if we re-do locations so that only nova can set them, there's still the issue of image data substitution in the backend without modifying the location uri recorded in glance.
4. I think an acceptable compromise would be to rely on image signature verification for deployment configurations that allow non-checksummed images. This is not an immediate solution because signature verification is not supported in those configurations where it would be really useful. It imposes a speed penalty, but it's also right in your face that you are making a speed/security tradeoff, because you (the end user) are adding a bunch of image metadata specifically for this purpose.
Additionally, the image-signature-verification implementation is inconsistent between glance, nova, and cinder [1]. This would be a good opportunity to get it sorted out to make it really useful.
Or there may be another way to solve this. But I think at this point we should get the OSS{AN} out right away so we can work on the solution in public with the community.
[0] Current glance multihash validation is just as good as image signature verification, because if you don't trust the infrastructure to perform the hash check correctly, it would also be pointless to trust the infrastructure to handle the signature verification correctly. At least that's my opinion. I think the only way to have surety about this in a public cloud would be to upload your own small image that is used to boot a vm, checks itself for integrity, then downloads a signed payload from some external location and verifies the payload, then rewrites the boot disk and reboots itself. There's probably already a service that does this somewhere.
[1] roughly:
- In glance, if you have all the img\_signature\* properties set before the data is uploaded, glance will verify the signature. If any are missing, glance doesn't do the verification. This is an intentional design so that you can sign images created by Nova or uploaded by Cinder (you download, compute the signature, and then set all the properties).
- In nova, if you turn the verify\_glance\_signatures option on, if the img\_signature\* properties are incomplete or not available, the instance goes to an error state. Nova also has an option to check for the validity of the images's signing cert; glance and cinder don't to this
- In cinder, if verify\_glance\_signatures is enabled, cinder looks for the img\_signature\* properties; if they any of them are there, it uses them to verify the image download (volume goes to error state if verification fails); but unlike nova, if no img\_signature\* properties are present, cinder allows the volume creation.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jeremy Stanley (fungi)](https://launchpad.net/~fungi) wrote on 2022-09-22: |  |  | [#14](/glance/%2Bbug/1990157/comments/14) |
| --- | --- | --- | --- |

If there won't be any patches accompanying the publication, then it would be an OSSN, but yes that plan sounds fine to me.

My grasp of the topic is, unfortunately, not solid enough to draft the explanation and operator guidance, so I'd be looking to someone with that background to write the relevant bits of prose. It can just be pasted into a comment on this bug initially, if folks are worried about this topic becoming more public before they have a chance to review it for accuracy.

If there won't be any patches accompanying the publication, then it would be an OSSN, but yes that plan sounds fine to me.
My grasp of the topic is, unfortunately, not solid enough to draft the explanation and operator guidance, so I'd be looking to someone with that background to write the relevant bits of prose. It can just be pasted into a comment on this bug initially, if folks are worried about this topic becoming more public before they have a chance to review it for accuracy.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Dan Smith (danms)](https://launchpad.net/~danms) wrote on 2022-09-22: |  |  | [#15](/glance/%2Bbug/1990157/comments/15) |
| --- | --- | --- | --- |

> @Dan we do have status on the locations table and we do update it. I don't think we consume it

> anywhere currently but it's there.

Okay fair enough. I guess we could make nova look at that, but I'm not sure what we'd do really. Maybe only consider the non-hashing ones and potentially download the image and duplicate it in RBD on boots that complete before a new location is available. Could work, but also probably confusing for people that wonder why some of their instances aren't doing COW from the base image. Some thinking on how best to handle that is probably required.

> Don't we also have the error metadata key where we already report errors from the import tasks,

> maybe we can reuse that?

Yup, and I suppose we could, or another similar one for locations specifically. But if we've got status on a location, that it is probably enough.

> Plus, if the hash isn't going to be checked by nova when the image is consumed, recomputing it

> for each location seems kind of pointless

Making nova check the hash before the boot is definitely counterproductive to the goal of fast COW boots. However, I think (one of) the benefit(s) of what Erno is proposing is that glance checks it once for the benefit of everyone and then we can trust it going forward. I think it would generate an intolerable amount of glance CPU and network traffic, but it would certainly be less than every nova checking it every time.

I agree with Brian's #4 and Erno's @All above. The most important thing is getting the tribal knowledge of how glance should be deployed out to the wider audience. Other things we can do between glance, nova and cinder to make this better in the future will take time, and likely have drawbacks that make them undesirable and/or hard to backport. Even if we implement some better hashing and verification, I suspect a lot of people would prefer to deploy two glance APIs, rely on host-level security for who can add locations, and trust that images created from behind the firewall are what they say they are.

> @Dan we do have status on the locations table and we do update it. I don't think we consume it
> anywhere currently but it's there.
Okay fair enough. I guess we could make nova look at that, but I'm not sure what we'd do really. Maybe only consider the non-hashing ones and potentially download the image and duplicate it in RBD on boots that complete before a new location is available. Could work, but also probably confusing for people that wonder why some of their instances aren't doing COW from the base image. Some thinking on how best to handle that is probably required.
> Don't we also have the error metadata key where we already report errors from the import tasks,
> maybe we can reuse that?
Yup, and I suppose we could, or another similar one for locations specifically. But if we've got status on a location, that it is probably enough.
> Plus, if the hash isn't going to be checked by nova when the image is consumed, recomputing it
> for each location seems kind of pointless
Making nova check the hash before the boot is definitely counterproductive to the goal of fast COW boots. However, I think (one of) the benefit(s) of what Erno is proposing is that glance checks it once for the benefit of everyone and then we can trust it going forward. I think it would generate an intolerable amount of glance CPU and network traffic, but it would certainly be less than every nova checking it every time.
I agree with Brian's #4 and Erno's @All above. The most important thing is getting the tribal knowledge of how glance should be deployed out to the wider audience. Other things we can do between glance, nova and cinder to make this better in the future will take time, and likely have drawbacks that make them undesirable and/or hard to backport. Even if we implement some better hashing and verification, I suspect a lot of people would prefer to deploy two glance APIs, rely on host-level security for who can add locations, and trust that images created from behind the firewall are what they say they are.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Erno Kuvaja (jokke)](https://launchpad.net/~jokke) wrote on 2022-09-22: |  |  | [#16](/glance/%2Bbug/1990157/comments/16) |
| --- | --- | --- | --- |

I think the asynchronous hash calculation can be approached 2 ways:

1) We don't let the image go to "active" before the multihash has been calculated. This would indeed break anything that currently depends on snapshot being immediately available and slow thing down significantly.

2) We let the new image behave just like it does now, but we also kick off the task to calculate the checksum and populate that to the image once it's done.

Then any additional location added via the API would be deferred until it's checksum has been verified. This is no extra work when the 'copy-image' import method is used as it's doing this already and at least I do not know any current usage where additional locations would be added to the image record "manually" apart from the said malicious activity.

As the COW consumers are not interested to check the hash anyways, I'd be n favour of #2 that would not be blocking the current legitimate usage patterns but would provide both user and Glance way to verify that the data is intact. Should consumers ever change their attitude on this, they could just have a logic that starts calculating their own hash and does the comparison once Glance has updated the record in it's database.

I think the asynchronous hash calculation can be approached 2 ways:
1) We don't let the image go to "active" before the multihash has been calculated. This would indeed break anything that currently depends on snapshot being immediately available and slow thing down significantly.
2) We let the new image behave just like it does now, but we also kick off the task to calculate the checksum and populate that to the image once it's done.
Then any additional location added via the API would be deferred until it's checksum has been verified. This is no extra work when the 'copy-image' import method is used as it's doing this already and at least I do not know any current usage where additional locations would be added to the image record "manually" apart from the said malicious activity.
As the COW consumers are not interested to check the hash anyways, I'd be n favour of #2 that would not be blocking the current legitimate usage patterns but would provide both user and Glance way to verify that the data is intact. Should consumers ever change their attitude on this, they could just have a logic that starts calculating their own hash and does the comparison once Glance has updated the record in it's database.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-09-22: |  |  | [#17](/glance/%2Bbug/1990157/comments/17) |
| --- | --- | --- | --- |

@Jeremy: I'll post a draft OSSN later today as a comment in this bug.

@Jeremy: I'll post a draft OSSN later today as a comment in this bug.

[Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita)
on 2022-09-22

| **affects**: | ossa → ossn |
| --- | --- |

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-09-23: |  |  | [#18](/glance/%2Bbug/1990157/comments/18) |
| --- | --- | --- | --- |

[Download full text](https://bugs.launchpad.net/glance/%2Bbug/1990157/comments/18/%2Bdownload) (3.2 KiB)

Still working on the draft. In the meantime, found one more place documenting this issue (leaving it here so we remember to revise it later):

The help text for 'show\_multiple\_locations' in the sample config file says:

# DEPRECATED:

# Show all image locations when returning an image.

#

# This configuration option indicates whether to show all the image

# locations when returning image details to the user. When multiple

# image locations exist for an image, the locations are ordered based

# on the location strategy indicated by the configuration opt

# ``location\_strategy``. The image locations are shown under the

# image property ``locations``.

#

# NOTES:

# \* Revealing image locations can present a GRAVE SECURITY RISK as

# image locations can sometimes include credentials. Hence, this

# is set to ``False`` by default. Set this to ``True`` with

# EXTREME CAUTION and ONLY IF you know what you are doing!

# \* See <https://wiki.openstack.org/wiki/OSSN/OSSN-0065> for more

# information.

# \* If an operator wishes to avoid showing any image location(s)

# to the user, then both this option and

# ``show\_image\_direct\_url`` MUST be set to ``False``.

#

# Possible values:

# \* True

# \* False

#

# Related options:

# \* show\_image\_direct\_url

# \* location\_strategy

#

# (boolean value)

# This option is deprecated for removal since Newton.

# Its value may be silently ignored in the future.

# Reason: Use of this option, deprecated since Newton, is a security risk and

# will be removed once we figure out a way to satisfy those use cases that

# currently require it. An earlier announcement that the same functionality can

# be achieved with greater granularity by using policies is incorrect. You

# cannot work around this option via policy configuration at the present time,

# though that is the direction we believe the fix will take. Please keep an eye

# on the Glance release notes to stay up to date on progress in addressing this

# issue.

#show\_multiple\_locations = false

Also, here's the text for 'show\_image\_direct\_url':

#

# Show direct image location when returning an image.

#

# This configuration option indicates whether to show the direct image

# location when returning image details to the user. The direct image

# location is where the image data is stored in backend storage. This

# image location is shown under the image property ``direct\_url``.

#

# When multiple image locations exist for an image, the best location

# is displayed based on the location strategy indicated by the

# configuration option ``location\_strategy``.

#

# NOTES:

# \* Revealing image locations can present a GRAVE SECURITY RISK as

# image locations can sometimes include credentials. Hence, this

# is set to ``False`` by default. Set this to ``True`` with

# EXTREME CAUTION and ONLY IF you know what you are doing!

# \* If an operator wishes to avoid showing any image location(s)

# to the user, then both this option and

# ``show\_multiple\_locations`` MUST be set to ``False``.

#

# Possible values:

# \* True

# \* False

#

# Related options:

# \* show\_multiple\_locations

# \* location\_stra...

[Read more...](/glance/%2Bbug/1990157/comments/18)

Still working on the draft. In the meantime, found one more place documenting this issue (leaving it here so we remember to revise it later):
The help text for 'show\_multiple\_locations' in the sample config file says:
# DEPRECATED:
# Show all image locations when returning an image.
#
# This configuration option indicates whether to show all the image
# locations when returning image details to the user. When multiple
# image locations exist for an image, the locations are ordered based
# on the location strategy indicated by the configuration opt
# ``location\_strategy``. The image locations are shown under the
# image property ``locations``.
#
# NOTES:
# \* Revealing image locations can present a GRAVE SECURITY RISK as
# image locations can sometimes include credentials. Hence, this
# is set to ``False`` by default. Set this to ``True`` with
# EXTREME CAUTION and ONLY IF you know what you are doing!
# \* See https://wiki.openstack.org/wiki/OSSN/OSSN-0065 for more
# information.
# \* If an operator wishes to avoid showing any image location(s)
# to the user, then both this option and
# ``show\_image\_direct\_url`` MUST be set to ``False``.
#
# Possible values:
# \* True
# \* False
#
# Related options:
# \* show\_image\_direct\_url
# \* location\_strategy
#
# (boolean value)
# This option is deprecated for removal since Newton.
# Its value may be silently ignored in the future.
# Reason: Use of this option, deprecated since Newton, is a security risk and
# will be removed once we figure out a way to satisfy those use cases that
# currently require it. An earlier announcement that the same functionality can
# be achieved with greater granularity by using policies is incorrect. You
# cannot work around this option via policy configuration at the present time,
# though that is the direction we believe the fix will take. Please keep an eye
# on the Glance release notes to stay up to date on progress in addressing this
# issue.
#show\_multiple\_locations = false
Also, here's the text for 'show\_image\_direct\_url':
#
# Show direct image location when returning an image.
#
# This configuration option indicates whether to show the direct image
# location when returning image details to the user. The direct image
# location is where the image data is stored in backend storage. This
# image location is shown under the image property ``direct\_url``.
#
# When multiple image locations exist for an image, the best location
# is displayed based on the location strategy indicated by the
# configuration option ``location\_strategy``.
#
# NOTES:
# \* Revealing image locations can present a GRAVE SECURITY RISK as
# image locations can sometimes include credentials. Hence, this
# is set to ``False`` by default. Set this to ``True`` with
# EXTREME CAUTION and ONLY IF you know what you are doing!
# \* If an operator wishes to avoid showing any image location(s)
# to the user, then both this option and
# ``show\_multiple\_locations`` MUST be set to ``False``.
#
# Possible values:
# \* True
# \* False
#
# Related options:
# \* show\_multiple\_locations
# \* location\_strategy
#
# (boolean value)
#show\_image\_direct\_url = false

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-09-23: |  |  | [#19](/glance/%2Bbug/1990157/comments/19) |
| --- | --- | --- | --- |

[Download full text](https://bugs.launchpad.net/glance/%2Bbug/1990157/comments/19/%2Bdownload) (6.5 KiB)

Here's a draft OSSN:

Best practices when configuring Glance with COW backends

---

### Summary ###

When deploying Glance in a popular configuration where Glance shares a common

storage backend with Nova and/or Cinder, it is possible to open some known

attack vectors by which malicious data modification can occur. This note

reviews the known issues and suggests a Glance deployment configuration that

can mitigate such attacks.

### Affected Services / Software ###

Glance, all releases

Nova, all releases

Cinder, all releases

### Discussion ###

This note applies to you if you are operating an end-user-facing

glance-api service with the 'show\_multiple\_locations' option set to True

(the default value is False) or if your end-user-facing glance-api has

the 'show\_image\_direct\_url' option set to True (default value is False).

Your exposure is less if you have \*only\* 'show\_image\_direct\_url=True',

but the deployment configuration suggested below is recommended for your

case as well.

The attack vector was originally outlined in OSSN-0065 [0], though that

note was not clear about the attack surface or mitigation, and contained

some forward-looking statements that were not fulfilled. (Though it

does contain a useful discussion of image visibility and its associated

policy settings.)

The subject of OSSN-0065 is "Users of Glance may be able to replace

active image data", but it suggests that this is only an issue when

users do not checksum their image data. It neglects the fact that in

some popular deployment configurations in which Nova creates a root disk

snapshot, data is never uploaded to Glance, but instead a snapshot is

created directly in the backend and Nova creates a Glance image record

with size 0 and no os\_hash\_value [1], making it impossible to compare

the hash of downloaded image data to the value maintained by Glance.

Further, when Nova is so configured, Nova efficiently creates a root

disk directly in the backend without checksumming the image data (which

is not necessarily a flaw, it's the whole point of this configuration).

Similarly, when using a shared backend, or a cinder glance\_store, Cinder

will efficiently clone a volume created from an image directly in the

backend without checksumming the image data.

The attack vector is the one outlined by OSSN-0065, namely:

[A] malicious user could create an image in Glance, set an additional

   location on that image pointing to an altered image, then delete the

   original location, so that consumers of the original image would

   unwittingly be using the malicious image. Note, however, that this

   attack vector cannot change the original image's checksum, and it is

   limited to images that are owned by the attacker.

OSSN-0065 suggested that this attack vector could be addressed by using

policies, but that turned out not to be the case. The only way currently

to close this vector is to deploy an internal-only-facing glance-api

used by Nova and Cinder, with show\_multiple\_locations enabled, and an

end-user-facing glance-api with show\_multiple\_locations disabled.

This was suggested in "Known Issues" in Glance release notes in the

Rocky [2] through Ussuri releases, but it seems tha...

[Read more...](/glance/%2Bbug/1990157/comments/19)

Here's a draft OSSN:
Best practices when configuring Glance with COW backends
---
### Summary ###
When deploying Glance in a popular configuration where Glance shares a common
storage backend with Nova and/or Cinder, it is possible to open some known
attack vectors by which malicious data modification can occur. This note
reviews the known issues and suggests a Glance deployment configuration that
can mitigate such attacks.
### Affected Services / Software ###
Glance, all releases
Nova, all releases
Cinder, all releases
### Discussion ###
This note applies to you if you are operating an end-user-facing
glance-api service with the 'show\_multiple\_locations' option set to True
(the default value is False) or if your end-user-facing glance-api has
the 'show\_image\_direct\_url' option set to True (default value is False).
Your exposure is less if you have \*only\* 'show\_image\_direct\_url=True',
but the deployment configuration suggested below is recommended for your
case as well.
The attack vector was originally outlined in OSSN-0065 [0], though that
note was not clear about the attack surface or mitigation, and contained
some forward-looking statements that were not fulfilled. (Though it
does contain a useful discussion of image visibility and its associated
policy settings.)
The subject of OSSN-0065 is "Users of Glance may be able to replace
active image data", but it suggests that this is only an issue when
users do not checksum their image data. It neglects the fact that in
some popular deployment configurations in which Nova creates a root disk
snapshot, data is never uploaded to Glance, but instead a snapshot is
created directly in the backend and Nova creates a Glance image record
with size 0 and no os\_hash\_value [1], making it impossible to compare
the hash of downloaded image data to the value maintained by Glance.
Further, when Nova is so configured, Nova efficiently creates a root
disk directly in the backend without checksumming the image data (which
is not necessarily a flaw, it's the whole point of this configuration).
Similarly, when using a shared backend, or a cinder glance\_store, Cinder
will efficiently clone a volume created from an image directly in the
backend without checksumming the image data.
The attack vector is the one outlined by OSSN-0065, namely:
[A] malicious user could create an image in Glance, set an additional
location on that image pointing to an altered image, then delete the
original location, so that consumers of the original image would
unwittingly be using the malicious image. Note, however, that this
attack vector cannot change the original image's checksum, and it is
limited to images that are owned by the attacker.
OSSN-0065 suggested that this attack vector could be addressed by using
policies, but that turned out not to be the case. The only way currently
to close this vector is to deploy an internal-only-facing glance-api
used by Nova and Cinder, with show\_multiple\_locations enabled, and an
end-user-facing glance-api with show\_multiple\_locations disabled.
This was suggested in "Known Issues" in Glance release notes in the
Rocky [2] through Ussuri releases, but it seems that they have not
received sufficient attention. Hence this security note.
So far the focus has been on show\_multiple\_locations. When that setting
is disabled in Glance, it is not possible to manipulate the locations
via the OpenStack Images API. It is worth mentioning, however, that
enabling 'show\_image\_direct\_url' (which can be used by various OpenStack
services to consume images directly from the storage backend) leaks
information about the backend to end users, which is never a good thing
from a security point of view. We therefore recommend that OpenStack
services that require exposure of the 'direct\_url' image property
be similarly configured to use an internal-only-facing glance-api.
(End users who wish to download an image do not require access to the
direct\_url image property because they can simply use the image data
download API call [3].)
### Recommended Actions ###
A glance-api service with 'show\_multiple\_locations' enabled should
\*never\* be exposed directly to end users. This setting should only
be enabled on an internal-only-facing glance-api that is used by
OpenStack services that require access to image locations.
Similarly, enabling 'show\_image\_direct\_url' exposes information about
the storage backend that could be of use to malicious actors in as yet
unknown exploits, so it should likewise only be enabled on an
internal-only-facing glance-api.
As this addresses a known issue, it is not an embargoed note concerning
a zero-day exploit. If, however, you are learning about this for the
first time, and you are exposing image locations to end users, it is
possible to limit the scope of the exploit described herein immediately
by restricting Glance policies related to image sharing:
- "publicize\_image" governs the ability to make an image available
to all users in a cloud, and such images appear in the default
image-list response for all users. It is restricted by default
to be admin-only.
- "communitize\_image" governs the ability to make an image available
to all users, though it does not appear in the default image-list
response for all users. The default configuration allows any
image owner to do this.
- "add\_member" governs the ability to share an image with particular
other projects. The default configuration allows any image owner
to do this.
Restricting these to admin-only would limit the exploit to a single
project, but given that it still allows for a disgruntled user to
maliciously modify images within that project, it is not recommended
as a long term solution.
### Notes / References ###
[0] OSSN-0065: https://wiki.openstack.org/wiki/OSSN/OSSN-0065
[1] The Glance "multihash" metadata pair of 'os\_hash\_algo' and 'os\_hash\_value'
were introduced in Rocky to replace the legacy md5 'checksum' field.
The python-glanceclient has used multihash checksumming for download
verification since version 2.13.0.
[2] https://docs.openstack.org/releasenotes/glance/rocky.html#known-issues
[3] https://docs.openstack.org/api-ref/image/v2/index.html?#download-binary-image-data
### Contacts / References ###
Author: Brian Rosmaita, Red Hat
This OSSN : https://wiki.openstack.org/wiki/OSSN/OSSN-0090
Original LaunchPad Bug : https://bugs.launchpad.net/ossn/+bug/1990157
Mailing List : [Security] tag on openstack-discuss@lists.openstack.org
OpenStack Security Project : https://launchpad.net/~openstack-ossg
CVE: none

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Dan Smith (danms)](https://launchpad.net/~danms) wrote on 2022-09-23: |  |  | [#20](/glance/%2Bbug/1990157/comments/20) |
| --- | --- | --- | --- |

> but instead a snapshot is

> created directly in the backend and Nova creates a Glance image record

> with size 0 and no os\_hash\_value [1

I think it's important to call out that even if you have an image that was uploaded and a hash was calculated, someone could \*later\* change the data in the backend. Since nova doesn't (and can't really without a lot of extra work) know that the hash doesn't match the image it's about to fast clone, the hash might look like it's there, you know it \*was\* correct, but nova will not check it to see that it no longer matches.

> A glance-api service with 'show\_multiple\_locations' enabled should

> \*never\* be exposed directly to end users. This setting should only

> be enabled on an internal-only-facing glance-api that is used by

> OpenStack services that require access to image locations.

I wonder if we should be more specific about "run two glance-apis with different config and use the public/internal endpoint types in keystone to differentiate. Also make sure the internal one is not accessible to the users (i.e. firewalled). You imply it with "never exposed to users" but...

> but instead a snapshot is
> created directly in the backend and Nova creates a Glance image record
> with size 0 and no os\_hash\_value [1
I think it's important to call out that even if you have an image that was uploaded and a hash was calculated, someone could \*later\* change the data in the backend. Since nova doesn't (and can't really without a lot of extra work) know that the hash doesn't match the image it's about to fast clone, the hash might look like it's there, you know it \*was\* correct, but nova will not check it to see that it no longer matches.
> A glance-api service with 'show\_multiple\_locations' enabled should
> \*never\* be exposed directly to end users. This setting should only
> be enabled on an internal-only-facing glance-api that is used by
> OpenStack services that require access to image locations.
I wonder if we should be more specific about "run two glance-apis with different config and use the public/internal endpoint types in keystone to differentiate. Also make sure the internal one is not accessible to the users (i.e. firewalled). You imply it with "never exposed to users" but...

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-09-26: |  |  | [#21](/glance/%2Bbug/1990157/comments/21) |
| --- | --- | --- | --- |

Revisions to comment #19:

### Affected Services / Software ###

-Glance, all releases

-Nova, all releases

-Cinder, all releases

+Glance, all supported and extended-maintenance releases (Queens through Zed)

### Discussion ###

 This note applies to you if you are operating an end-user-facing

@@ -67,19 +67,35 @@ is disabled in Glance, it is not possible to manipulate the locations

 via the OpenStack Images API. It is worth mentioning, however, that

 enabling 'show\_image\_direct\_url' (which can be used by various OpenStack

 services to consume images directly from the storage backend) leaks

-information about the backend to end users, which is never a good thing

-from a security point of view. We therefore recommend that OpenStack

-services that require exposure of the 'direct\_url' image property

-be similarly configured to use an internal-only-facing glance-api.

-(End users who wish to download an image do not require access to the

-direct\_url image property because they can simply use the image data

-download API call [3].)

+information about the backend to end users. What exactly that

+information consists of depends upon the backend in use and how it is

+configured, but in general, the safest course of action is not to expose

+it at all. Keep in mind that in any Glance/Nova/Cinder configuration

+where Nova and/or Cinder do copy-on-write directly in the image store,

+image data transfer takes place outside Glance's image data download

+path, and hence the os\_hash\_value is \*not\* checked. Thus, if the

+backend store is compromised, and image data is replaced directly in the

+backend, the substitution will \*not\* be detected. That's why it is

+important not to give malicious actors unnecessary hints about the image

+storage backend.

+

+We therefore recommend that OpenStack services that require exposure of

+the 'direct\_url' image property be similarly configured to use an

+internal-only-facing glance-api. (End users who wish to download an

+image do not require access to the direct\_url image property because

+they can simply use the image-data-download API call [3].)

### Recommended Actions ###

 A glance-api service with 'show\_multiple\_locations' enabled should

-\*never\* be exposed directly to end users. This setting should only

-be enabled on an internal-only-facing glance-api that is used by

-OpenStack services that require access to image locations.

+\*never\* be exposed directly to end users. This setting should only be

+enabled on an internal-only-facing glance-api that is used by OpenStack

+services that require access to image locations. This could be done,

+for example, by running two glance-api services with different

+configuration files and using the appropriate configuration options for

+each service to specify the Image API endpoint to access, and making

+sure the special internal endpoint is firewalled in such a way that only

+the appropriate OpenStack services can contact it.

Revisions to comment #19:
### Affected Services / Software ###
-Glance, all releases
-Nova, all releases
-Cinder, all releases
+Glance, all supported and extended-maintenance releases (Queens through Zed)
### Discussion ###
This note applies to you if you are operating an end-user-facing
@@ -67,19 +67,35 @@ is disabled in Glance, it is not possible to manipulate the locations
via the OpenStack Images API. It is worth mentioning, however, that
enabling 'show\_image\_direct\_url' (which can be used by various OpenStack
services to consume images directly from the storage backend) leaks
-information about the backend to end users, which is never a good thing
-from a security point of view. We therefore recommend that OpenStack
-services that require exposure of the 'direct\_url' image property
-be similarly configured to use an internal-only-facing glance-api.
-(End users who wish to download an image do not require access to the
-direct\_url image property because they can simply use the image data
-download API call [3].)
+information about the backend to end users. What exactly that
+information consists of depends upon the backend in use and how it is
+configured, but in general, the safest course of action is not to expose
+it at all. Keep in mind that in any Glance/Nova/Cinder configuration
+where Nova and/or Cinder do copy-on-write directly in the image store,
+image data transfer takes place outside Glance's image data download
+path, and hence the os\_hash\_value is \*not\* checked. Thus, if the
+backend store is compromised, and image data is replaced directly in the
+backend, the substitution will \*not\* be detected. That's why it is
+important not to give malicious actors unnecessary hints about the image
+storage backend.
+
+We therefore recommend that OpenStack services that require exposure of
+the 'direct\_url' image property be similarly configured to use an
+internal-only-facing glance-api. (End users who wish to download an
+image do not require access to the direct\_url image property because
+they can simply use the image-data-download API call [3].)
### Recommended Actions ###
A glance-api service with 'show\_multiple\_locations' enabled should
-\*never\* be exposed directly to end users. This setting should only
-be enabled on an internal-only-facing glance-api that is used by
-OpenStack services that require access to image locations.
+\*never\* be exposed directly to end users. This setting should only be
+enabled on an internal-only-facing glance-api that is used by OpenStack
+services that require access to image locations. This could be done,
+for example, by running two glance-api services with different
+configuration files and using the appropriate configuration options for
+each service to specify the Image API endpoint to access, and making
+sure the special internal endpoint is firewalled in such a way that only
+the appropriate OpenStack services can contact it.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-09-26: |  |  | [#22](/glance/%2Bbug/1990157/comments/22) |
| --- | --- | --- | --- |

About the Recommended Actions change: It's a bit more specific, but doesn't mention using the Keystone public/internal endpoint type for this purpose because the keystone docs [0] describe the 'internal' type as accessible to end users, and operators may already be using it in that way. I think the way to go is to use the Nova [glance]/endpoint\_override setting to point directly to the "internal-only" API; the corresponding cinder config would be glance\_api\_servers (Nova also has that option, but it's been deprecated since Queens). So I just said "use the appropriate configuration options for each service", which operators can find in the config help for each service.

[0] <https://docs.openstack.org/keystone/latest/contributor/service-catalog.html#endpoints>

About the Recommended Actions change: It's a bit more specific, but doesn't mention using the Keystone public/internal endpoint type for this purpose because the keystone docs [0] describe the 'internal' type as accessible to end users, and operators may already be using it in that way. I think the way to go is to use the Nova [glance]/endpoint\_override setting to point directly to the "internal-only" API; the corresponding cinder config would be glance\_api\_servers (Nova also has that option, but it's been deprecated since Queens). So I just said "use the appropriate configuration options for each service", which operators can find in the config help for each service.
[0] https://docs.openstack.org/keystone/latest/contributor/service-catalog.html#endpoints

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Erno Kuvaja (jokke)](https://launchpad.net/~jokke) wrote on 2022-09-27: |  |  | [#23](/glance/%2Bbug/1990157/comments/23) |
| --- | --- | --- | --- |

@Brian ok, let me make my stance on this very clear so it's on file and we can agree to disagree. I do think we have possibility to mitigate the issue from Glance side as well as the deployment front. And thus I do not agree with your rushed exposure of the details on this.

Obviously should you keep discussing this outside of the embargo and "agitate" it to public like you put it we probably will be on the wrong side of that. If we decide to ignore this issue from Glance side, we should at least give the courtecy of heads up to TripleO and OSA (are there other deplyoment projects under the umbrella?) before throwing them and all their users under the bus.

@Brian ok, let me make my stance on this very clear so it's on file and we can agree to disagree. I do think we have possibility to mitigate the issue from Glance side as well as the deployment front. And thus I do not agree with your rushed exposure of the details on this.
Obviously should you keep discussing this outside of the embargo and "agitate" it to public like you put it we probably will be on the wrong side of that. If we decide to ignore this issue from Glance side, we should at least give the courtecy of heads up to TripleO and OSA (are there other deplyoment projects under the umbrella?) before throwing them and all their users under the bus.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-09-27: |  |  | [#24](/glance/%2Bbug/1990157/comments/24) |
| --- | --- | --- | --- |

@Erno: I am fine with holding this if you think we can have a resolution before 19 December, I guess. My concern is that this is an obvious attack vector -- all the code is available, and anyone scanning the config file sees "GRAVE SECURITY RISK" associated with the settings for show\_multiple\_locations and show\_image\_direct\_url, and would be inclined to investigate and see what damage you can do with those. We've already mentioned in release notes the desirability of only exposing locations on an internal-only-facing glance-api, so the contents of this bug are pretty much already "out there", and it would be good to make sure operators are as aware of it as malicious actors are.

I'm not clear on what holding this gets us. The COW glance configuration is popular for space and time optimization, and I'm not sure what operators will accept. I really don't see the point of computing missing hash values if they're not being checked at the point of image data consumption, and that's exactly what operators don't want.

Anyway, let's continue to discuss this, being specific about the glance-side changes that would mitigate this. If we can fix and backport a good solution, I'm all for keeping this private while we get that done, though I really don't see the point of the privacy, because I think the exploit is already known.

@Erno: I am fine with holding this if you think we can have a resolution before 19 December, I guess. My concern is that this is an obvious attack vector -- all the code is available, and anyone scanning the config file sees "GRAVE SECURITY RISK" associated with the settings for show\_multiple\_locations and show\_image\_direct\_url, and would be inclined to investigate and see what damage you can do with those. We've already mentioned in release notes the desirability of only exposing locations on an internal-only-facing glance-api, so the contents of this bug are pretty much already "out there", and it would be good to make sure operators are as aware of it as malicious actors are.
I'm not clear on what holding this gets us. The COW glance configuration is popular for space and time optimization, and I'm not sure what operators will accept. I really don't see the point of computing missing hash values if they're not being checked at the point of image data consumption, and that's exactly what operators don't want.
Anyway, let's continue to discuss this, being specific about the glance-side changes that would mitigate this. If we can fix and backport a good solution, I'm all for keeping this private while we get that done, though I really don't see the point of the privacy, because I think the exploit is already known.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Erno Kuvaja (jokke)](https://launchpad.net/~jokke) wrote on 2022-09-27: |  |  | [#25](/glance/%2Bbug/1990157/comments/25) |
| --- | --- | --- | --- |

Like I explained before in my comments, it would provide us 2 things:

No-one (say even someone with OpenStack admin role who has access to the internal endpoint) could swap the data through the locations API. They would need write access to the actual storage to do so. With Ceph which is clearly our biggest worry here, the location points to a snapshot that is read-only and would require again location update on the image to be modified closing even that vector.

The users would have mechanism to verify the image data (by downloading it, for example with glanceclient). Regardless if their preferred consumption method does that as part of the deployment workflow. This would be available for all images available to them; being it public, community or shared.

Like I said earlier, we made very poor assumptions when we expected this issue to just go away by deployment model advice during OSSN-0065 and lots of those assumptions were relying on the image having checksum and it being verified. We could at least make sure to have the hash calculated and verify it during all of our own operations and we can do that without breaking the current legitimate use cases.

My main concern is that we effectively reissue OSSN-0065, nothing changes as we sweep the security holes under the carpet again because it's convenient to push the responsibility to the operators.

Like I explained before in my comments, it would provide us 2 things:
No-one (say even someone with OpenStack admin role who has access to the internal endpoint) could swap the data through the locations API. They would need write access to the actual storage to do so. With Ceph which is clearly our biggest worry here, the location points to a snapshot that is read-only and would require again location update on the image to be modified closing even that vector.
The users would have mechanism to verify the image data (by downloading it, for example with glanceclient). Regardless if their preferred consumption method does that as part of the deployment workflow. This would be available for all images available to them; being it public, community or shared.
Like I said earlier, we made very poor assumptions when we expected this issue to just go away by deployment model advice during OSSN-0065 and lots of those assumptions were relying on the image having checksum and it being verified. We could at least make sure to have the hash calculated and verify it during all of our own operations and we can do that without breaking the current legitimate use cases.
My main concern is that we effectively reissue OSSN-0065, nothing changes as we sweep the security holes under the carpet again because it's convenient to push the responsibility to the operators.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Erno Kuvaja (jokke)](https://launchpad.net/~jokke) wrote on 2022-09-27: |  |  | [#26](/glance/%2Bbug/1990157/comments/26) |
| --- | --- | --- | --- |

Oh and just to be clear, I reported this as private as it's trivial to turn the discussion public once we are sure the discussion is not exposing vulnerabilities/attack vectors that has not been acknowledged before. The reality that we know the code intimately and something feels obvious knowledge of working that way to us does not mean that it's publicly obvious or known.

So I'm all up for making this public if we are 100% sure there is nothing publicly new in this. Which I'm not at least convinced yet.

Oh and just to be clear, I reported this as private as it's trivial to turn the discussion public once we are sure the discussion is not exposing vulnerabilities/attack vectors that has not been acknowledged before. The reality that we know the code intimately and something feels obvious knowledge of working that way to us does not mean that it's publicly obvious or known.
So I'm all up for making this public if we are 100% sure there is nothing publicly new in this. Which I'm not at least convinced yet.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-09-27: |  |  | [#27](/glance/%2Bbug/1990157/comments/27) |
| --- | --- | --- | --- |

OK, I think I am confusing two issues here:

1. The image-location-substitution-via-Image-API exploit. That can be prevented solely on the glance side by Erno's suggestion -- not allowing a location to be visible on an image until the data it points to has been hashed, and the result either equals the os\_hash\_value (if present), or sets the os\_hash\_value (if it's empty).

2. Backend-data-substitution exploit. Even with #1 closed, we still have the situation where:

  time t: end user requests nova createImage action

  time t+1: glance posts os\_hash\_value

  time t+2: end user downloads image and computes hash, OK

  time t+3: end user requests nova to boot an instance from the image

If nova doesn't check the hash before booting the image, which it doesn't in the COW configuration, then how does the end user know that the image data hasn't been modified between t+2 and t+3? This exploit is facilitated by exposing the direct\_url or locations on images to end users, so having an internal-facing-only glance is still good to have, at least until a single Glance can handle only exposing the direct\_url and locations to other services.

  But it doesn't solve the larger issue of backend-data-substitution. However, if Glance is doing #1, then it would now at least be \*possible\* for consuming services to verify image data, and it would be up to nova and cinder to decide how to handle this. And since this requires the malicious actor to independently compromise the storage backend, it's not as critical as #1.

So, if we can get #1 done quickly in a way that doesn't kill the performance of hyperconverged infrastructure, then I am OK with keeping this private. I think that #2 is a real problem, however, that could use some discussion at the PTG. My question is whether we think the backend-data-substitution exploit can be discussed without revealing #1. Of course, if we can get #1 completed and new glance releases out before 17 October, then that's not an issue.

OK, I think I am confusing two issues here:
1. The image-location-substitution-via-Image-API exploit. That can be prevented solely on the glance side by Erno's suggestion -- not allowing a location to be visible on an image until the data it points to has been hashed, and the result either equals the os\_hash\_value (if present), or sets the os\_hash\_value (if it's empty).
2. Backend-data-substitution exploit. Even with #1 closed, we still have the situation where:
time t: end user requests nova createImage action
time t+1: glance posts os\_hash\_value
time t+2: end user downloads image and computes hash, OK
time t+3: end user requests nova to boot an instance from the image
If nova doesn't check the hash before booting the image, which it doesn't in the COW configuration, then how does the end user know that the image data hasn't been modified between t+2 and t+3? This exploit is facilitated by exposing the direct\_url or locations on images to end users, so having an internal-facing-only glance is still good to have, at least until a single Glance can handle only exposing the direct\_url and locations to other services.
But it doesn't solve the larger issue of backend-data-substitution. However, if Glance is doing #1, then it would now at least be \*possible\* for consuming services to verify image data, and it would be up to nova and cinder to decide how to handle this. And since this requires the malicious actor to independently compromise the storage backend, it's not as critical as #1.
So, if we can get #1 done quickly in a way that doesn't kill the performance of hyperconverged infrastructure, then I am OK with keeping this private. I think that #2 is a real problem, however, that could use some discussion at the PTG. My question is whether we think the backend-data-substitution exploit can be discussed without revealing #1. Of course, if we can get #1 completed and new glance releases out before 17 October, then that's not an issue.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Erno Kuvaja (jokke)](https://launchpad.net/~jokke) wrote on 2022-09-28: |  |  | [#28](/glance/%2Bbug/1990157/comments/28) |
| --- | --- | --- | --- |

@Brian for your #2 I think cinder is still an issue. The image data in Ceph consists of the image "object/file", if you wish, named as Image-ID and read-only snapshot of it called snap. The location of RBD image in glance points to that snap of the object. So malicious user would need to replace that snap of the image to be able to change the image data, which is not possible if there is other references for that snap (say already running COW VM of it). One can modify the image data object and create new snapshot of it, but that would require update into the database which solving #1 would prevent.

Not bullet proof for every corner case, but heavily resistant compared to our present situation.

@Brian for your #2 I think cinder is still an issue. The image data in Ceph consists of the image "object/file", if you wish, named as Image-ID and read-only snapshot of it called snap. The location of RBD image in glance points to that snap of the object. So malicious user would need to replace that snap of the image to be able to change the image data, which is not possible if there is other references for that snap (say already running COW VM of it). One can modify the image data object and create new snapshot of it, but that would require update into the database which solving #1 would prevent.
Not bullet proof for every corner case, but heavily resistant compared to our present situation.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Dan Smith (danms)](https://launchpad.net/~danms) wrote on 2022-10-03: |  |  | [#29](/glance/%2Bbug/1990157/comments/29) |
| --- | --- | --- | --- |

I think we really need to have anything like #1 available for all the supported branches if we're going to hold this up for that. I share Brian's concern on that being available in a timely manner. But I also think that it's not a reasonable resolution to the core problem because people using COW boots and snapshots are doing so specifically to \*avoid\* the need to do long and expensive operations there.

I think that the original OSSN did not clearly prescribe the way out of the box for this and as such we shouldn't use the lack of deployments using two endpoints as a gauge for whether or not people or deployment tools are aware of it. This originally got raised downstream when we were talking to deployment people and specifically asking about a split API horizon for this reason. They had no idea it was needed.

So again I'd say I think the far greater good is getting the information on how to mitigate this for all deployments out to the people. Changes to allow for tighter hashing controls in glance are good, but they're not going to be an acceptable solution for most of the affected users, I think. Deploying a second set of glance workers trades a little memory, which is a lot less expensive than the time and CPU load required for the hashing option.

Just MHO!

I think we really need to have anything like #1 available for all the supported branches if we're going to hold this up for that. I share Brian's concern on that being available in a timely manner. But I also think that it's not a reasonable resolution to the core problem because people using COW boots and snapshots are doing so specifically to \*avoid\* the need to do long and expensive operations there.
I think that the original OSSN did not clearly prescribe the way out of the box for this and as such we shouldn't use the lack of deployments using two endpoints as a gauge for whether or not people or deployment tools are aware of it. This originally got raised downstream when we were talking to deployment people and specifically asking about a split API horizon for this reason. They had no idea it was needed.
So again I'd say I think the far greater good is getting the information on how to mitigate this for all deployments out to the people. Changes to allow for tighter hashing controls in glance are good, but they're not going to be an acceptable solution for most of the affected users, I think. Deploying a second set of glance workers trades a little memory, which is a lot less expensive than the time and CPU load required for the hashing option.
Just MHO!

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Pranali Deore (pranali-deore)](https://launchpad.net/~pranali-deore) wrote on 2022-10-07: |  |  | [#30](/glance/%2Bbug/1990157/comments/30) |
| --- | --- | --- | --- |

Let's have a call to discuss this in terms of when to make it public and what to cover in the OSSN.

I'm adding some time slots options below, please let me know your availability,

Monday, 10th OCT - 14:00 UTC - 14:45 UTC?

                    15:00 UTC - 15:45 UTC?

Tuesday, 11th OCT - 14:00 UTC - 14:45 UTC?

                    15:00 UTC - 15:45 UTC?

I think 45 mins would be enough but we can stretch it if required or we can conclude early as well.

Let's have a call to discuss this in terms of when to make it public and what to cover in the OSSN.
I'm adding some time slots options below, please let me know your availability,
Monday, 10th OCT - 14:00 UTC - 14:45 UTC?
15:00 UTC - 15:45 UTC?
Tuesday, 11th OCT - 14:00 UTC - 14:45 UTC?
15:00 UTC - 15:45 UTC?
I think 45 mins would be enough but we can stretch it if required or we can conclude early as well.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jeremy Stanley (fungi)](https://launchpad.net/~fungi) wrote on 2022-10-07: |  |  | [#31](/glance/%2Bbug/1990157/comments/31) |
| --- | --- | --- | --- |

I'm free for all of those except 15z on Tuesday, thanks!

I'm free for all of those except 15z on Tuesday, thanks!

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Dan Smith (danms)](https://launchpad.net/~danms) wrote on 2022-10-07: |  |  | [#32](/glance/%2Bbug/1990157/comments/32) |
| --- | --- | --- | --- |

I can make any of those work.

I can make any of those work.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Abhishek Kekane (abhishek-kekane)](https://launchpad.net/~abhishek-kekane) wrote on 2022-10-07: |  |  | [#33](/glance/%2Bbug/1990157/comments/33) |
| --- | --- | --- | --- |

Monday 10th will be good for me, incase I can adjust on 11th if required. Thanks!

Monday 10th will be good for me, incase I can adjust on 11th if required. Thanks!

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-10-07: |  |  | [#34](/glance/%2Bbug/1990157/comments/34) |
| --- | --- | --- | --- |

Monday is best for me.

Monday is best for me.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Pranali Deore (pranali-deore)](https://launchpad.net/~pranali-deore) wrote on 2022-10-10: |  |  | [#35](/glance/%2Bbug/1990157/comments/35) |
| --- | --- | --- | --- |

Thanks everyone !! I've scheduled the meeting today, 10th OCT at 1400 UTC.

Gmeet : <https://meet.google.com/ymb-ksep-nhv>

Thanks everyone !! I've scheduled the meeting today, 10th OCT at 1400 UTC.
Gmeet : https://meet.google.com/ymb-ksep-nhv

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Erno Kuvaja (jokke)](https://launchpad.net/~jokke) wrote on 2022-10-10: |  |  | [#36](/glance/%2Bbug/1990157/comments/36) |
| --- | --- | --- | --- |

* [WIP patch for the meeting](https://bugs.launchpad.net/glance/%2Bbug/1990157/%2Battachment/5622726/%2Bfiles/0001-SEC-WIP-async-hashing-on-location-add.patch)
  [Edit](/glance/%2Bbug/1990157/%2Battachment/5622726)
  (12.3 KiB,
  text/plain)

Added WIP patch prior the meeting.

Added WIP patch prior the meeting.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jeremy Stanley (fungi)](https://launchpad.net/~fungi) wrote on 2022-10-10: |  |  | [#37](/glance/%2Bbug/1990157/comments/37) |
| --- | --- | --- | --- |

To summarize my takeaway from the call, the risk of exploit in basically all cases boils down to some trusted account "going rogue" and substituting a malicious image (perhaps after validation by the consumer), with their actions going entirely unnoticed. The currently proposed patch represents a new feature in Glance of the level that would normally require a formal specification and trigger broad discussion around API behavior changes and potential performance regressions. I don't think the risks presented outweigh the need for public design process around the proposed feature, so I'm recommending we switch this bug to public once the participants here are comfortable with the drafted guidance to operators, and then proceed with the code changes in public review where it can be better scrutinized and more thoroughly tested.

To summarize my takeaway from the call, the risk of exploit in basically all cases boils down to some trusted account "going rogue" and substituting a malicious image (perhaps after validation by the consumer), with their actions going entirely unnoticed. The currently proposed patch represents a new feature in Glance of the level that would normally require a formal specification and trigger broad discussion around API behavior changes and potential performance regressions. I don't think the risks presented outweigh the need for public design process around the proposed feature, so I'm recommending we switch this bug to public once the participants here are comfortable with the drafted guidance to operators, and then proceed with the code changes in public review where it can be better scrutinized and more thoroughly tested.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-10-10: |  |  | [#38](/glance/%2Bbug/1990157/comments/38) |
| --- | --- | --- | --- |

* [Latest version of the OSSN (6 Oct 2022)](https://bugs.launchpad.net/glance/%2Bbug/1990157/%2Battachment/5622747/%2Bfiles/0001-Add-OSSN-0090.patch)
  [Edit](/glance/%2Bbug/1990157/%2Battachment/5622747)
  (8.2 KiB,
  text/plain)

Latest version of the OSSN (6 Oct 2022)

Latest version of the OSSN (6 Oct 2022)

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Erno Kuvaja (jokke)](https://launchpad.net/~jokke) wrote on 2022-10-10: |  |  | [#39](/glance/%2Bbug/1990157/comments/39) |
| --- | --- | --- | --- |

As this addresses a known issue, it is not an embargoed note concerning

+a zero-day exploit. If, however, you are learning about this for the

+first time, and you are exposing image locations to end users, it is

+possible to limit the scope of the exploit described herein immediately

+by restricting Glance policies related to image sharing:

+

+- "publicize\_image" governs the ability to make an image available

+ to all users in a cloud, and such images appear in the default

+ image-list response for all users. It is restricted by default

+ to be admin-only.

+

+- "communitize\_image" governs the ability to make an image available

+ to all users, though it does not appear in the default image-list

+ response for all users. The default configuration allows any

+ image owner to do this.

+

+- "add\_member" governs the ability to share an image with particular

+ other projects. The default configuration allows any image owner

+ to do this.

+

+Restricting these to admin-only would limit the exploit to a single

+project, but given that it still allows for a disgruntled user to

+maliciously modify images within that project, it is not recommended

+as a long term solution.

I would not include this section. It gives false sign of security while it does not prevent using already shared, community or public images through the vector.

As this addresses a known issue, it is not an embargoed note concerning
+a zero-day exploit. If, however, you are learning about this for the
+first time, and you are exposing image locations to end users, it is
+possible to limit the scope of the exploit described herein immediately
+by restricting Glance policies related to image sharing:
+
+- "publicize\_image" governs the ability to make an image available
+ to all users in a cloud, and such images appear in the default
+ image-list response for all users. It is restricted by default
+ to be admin-only.
+
+- "communitize\_image" governs the ability to make an image available
+ to all users, though it does not appear in the default image-list
+ response for all users. The default configuration allows any
+ image owner to do this.
+
+- "add\_member" governs the ability to share an image with particular
+ other projects. The default configuration allows any image owner
+ to do this.
+
+Restricting these to admin-only would limit the exploit to a single
+project, but given that it still allows for a disgruntled user to
+maliciously modify images within that project, it is not recommended
+as a long term solution.
I would not include this section. It gives false sign of security while it does not prevent using already shared, community or public images through the vector.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Erno Kuvaja (jokke)](https://launchpad.net/~jokke) wrote on 2022-10-10: |  |  | [#40](/glance/%2Bbug/1990157/comments/40) |
| --- | --- | --- | --- |

+OSSN-0065 suggested that this attack vector could be addressed by using

+policies, but that turned out not to be the case. The only way currently

+to close this vector is to deploy an internal-only-facing glance-api

+used by Nova and Cinder, with show\_multiple\_locations enabled, and an

+end-user-facing glance-api with show\_multiple\_locations disabled.

"The only way currently mitigate this vector is to deploy" The dual deployment does not close the attack vector, just limits it from external users. Without patching the gapi service code the only way to close this vector is to not enable "show\_image\_direct\_url" nor "show\_multiple\_locations" and that way disable the locations API.

+OSSN-0065 suggested that this attack vector could be addressed by using
+policies, but that turned out not to be the case. The only way currently
+to close this vector is to deploy an internal-only-facing glance-api
+used by Nova and Cinder, with show\_multiple\_locations enabled, and an
+end-user-facing glance-api with show\_multiple\_locations disabled.
"The only way currently mitigate this vector is to deploy" The dual deployment does not close the attack vector, just limits it from external users. Without patching the gapi service code the only way to close this vector is to not enable "show\_image\_direct\_url" nor "show\_multiple\_locations" and that way disable the locations API.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-10-10: |  |  | [#41](/glance/%2Bbug/1990157/comments/41) |
| --- | --- | --- | --- |

@Erno #39:

I see how this could be misleading. Instead of removing completely, since this is a "best practices" doc, how about I rephrase as a reminder about how malicious images can be spread to other users (independently of this exploit) ... or do you think that's already clear from our current documentation? (I don't have a problem with removing it completely.)

Also, is it worth reminding operators about image deactivation?

@Erno #39:
I see how this could be misleading. Instead of removing completely, since this is a "best practices" doc, how about I rephrase as a reminder about how malicious images can be spread to other users (independently of this exploit) ... or do you think that's already clear from our current documentation? (I don't have a problem with removing it completely.)
Also, is it worth reminding operators about image deactivation?

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-10-10: |  |  | [#42](/glance/%2Bbug/1990157/comments/42) |
| --- | --- | --- | --- |

@Erno #40:

I have no problem rephrasing as you suggest.

@Erno #40:
I have no problem rephrasing as you suggest.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Erno Kuvaja (jokke)](https://launchpad.net/~jokke) wrote on 2022-10-11: |  |  | [#43](/glance/%2Bbug/1990157/comments/43) |
| --- | --- | --- | --- |

@Brian

I think repeating the same info/mistakes we did with OSSN-0065 is not beneficial. Thus I'd like to avoid go that route and just refer to OSSN-0065 for previous conversation. Thus my take to just remove the section copied from there.

Also realized that the Start of Discussion limits gives impression that this is vulnerable only when the nodes that has show multiple locations enable are public, but that's not the case. Fixin the deployments does not fix the issue, just limits it's accessibility from public.

+This note applies to you if you are operating an end-user-facing

+glance-api service with the 'show\_multiple\_locations' option set to True

+(the default value is False) or if your end-user-facing glance-api has

+the 'show\_image\_direct\_url' option set to True (default value is False).

+Your exposure is less if you have \*only\* 'show\_image\_direct\_url=True',

+but the deployment configuration suggested below is recommended for your

+case as well.

I'd change the first paragraph to something like:

This note applies to you if you are operating a glance-api service with the 'show\_multiple\_locations' option set to True

(the default value is False) or if your end-user-facing glance-api has

the 'show\_image\_direct\_url' option set to True (default value is False).

Your exposure is less if you have \*only\* 'show\_image\_direct\_url=True' or

your glance-api that has 'show\_multiple\_locations=True' is deployed internal

service facing only, but the deployment configuration suggested below is

recommended for your case as well.

@Brian
I think repeating the same info/mistakes we did with OSSN-0065 is not beneficial. Thus I'd like to avoid go that route and just refer to OSSN-0065 for previous conversation. Thus my take to just remove the section copied from there.
Also realized that the Start of Discussion limits gives impression that this is vulnerable only when the nodes that has show multiple locations enable are public, but that's not the case. Fixin the deployments does not fix the issue, just limits it's accessibility from public.
+This note applies to you if you are operating an end-user-facing
+glance-api service with the 'show\_multiple\_locations' option set to True
+(the default value is False) or if your end-user-facing glance-api has
+the 'show\_image\_direct\_url' option set to True (default value is False).
+Your exposure is less if you have \*only\* 'show\_image\_direct\_url=True',
+but the deployment configuration suggested below is recommended for your
+case as well.
I'd change the first paragraph to something like:
This note applies to you if you are operating a glance-api service with the 'show\_multiple\_locations' option set to True
(the default value is False) or if your end-user-facing glance-api has
the 'show\_image\_direct\_url' option set to True (default value is False).
Your exposure is less if you have \*only\* 'show\_image\_direct\_url=True' or
your glance-api that has 'show\_multiple\_locations=True' is deployed internal
service facing only, but the deployment configuration suggested below is
recommended for your case as well.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-10-11: |  |  | [#44](/glance/%2Bbug/1990157/comments/44) |
| --- | --- | --- | --- |

@Erno #43

I agree that the visibility stuff just confuses the issue. Based on your comments, I think I should restructure the entire note along these lines:

1. If you're using a COW backend configuration, you should deploy dual glances (probably won't use that term, but you know what i mean).

2. The COW backend efficiency/security tradeoff.

3. What we mean by "dual glances" <-- with reference to the nova/cinder config options.

4. Why: show\_multiple\_locations=True -> image data manipulation via the Image API

5. Why: show\_image\_direct\_url -> backend info leak which could be used by a malicious actor to independently access the backend storage and modify image data directly in the backend

@Everyone:

I won't get started on this until around 1800 UTC today, so if you have comments before then, please leave them!

@Erno #43
I agree that the visibility stuff just confuses the issue. Based on your comments, I think I should restructure the entire note along these lines:
1. If you're using a COW backend configuration, you should deploy dual glances (probably won't use that term, but you know what i mean).
2. The COW backend efficiency/security tradeoff.
3. What we mean by "dual glances" <-- with reference to the nova/cinder config options.
4. Why: show\_multiple\_locations=True -> image data manipulation via the Image API
5. Why: show\_image\_direct\_url -> backend info leak which could be used by a malicious actor to independently access the backend storage and modify image data directly in the backend
@Everyone:
I won't get started on this until around 1800 UTC today, so if you have comments before then, please leave them!

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Erno Kuvaja (jokke)](https://launchpad.net/~jokke) wrote on 2022-10-11: |  |  | [#45](/glance/%2Bbug/1990157/comments/45) |
| --- | --- | --- | --- |

@Brian ref #44

That sounds like a plan.

@Brian ref #44
That sounds like a plan.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-10-12: |  |  | [#46](/glance/%2Bbug/1990157/comments/46) |
| --- | --- | --- | --- |

* [Rewritten version of the OSSN (12 Oct 2022)](https://bugs.launchpad.net/glance/%2Bbug/1990157/%2Battachment/5623275/%2Bfiles/0002-Add-OSSN-0090.patch)
  [Edit](/glance/%2Bbug/1990157/%2Battachment/5623275)
  (8.6 KiB,
  text/plain)

Rewritten version of the OSSN (12 Oct 2022)

Rewritten version of the OSSN (12 Oct 2022)

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-10-12: |  |  | [#47](/glance/%2Bbug/1990157/comments/47) |
| --- | --- | --- | --- |

Added Jay and Julia to the bug since we've already decided it should be worked on in public, and just in case there's any ironic-specific info that should be added to the OSSN.

Added Jay and Julia to the bug since we've already decided it should be worked on in public, and just in case there's any ironic-specific info that should be added to the OSSN.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Dan Smith (danms)](https://launchpad.net/~danms) wrote on 2022-10-12: |  |  | [#48](/glance/%2Bbug/1990157/comments/48) |
| --- | --- | --- | --- |

Brian, the latest version (12 Oct 2022) looks great to me, thanks!

Brian, the latest version (12 Oct 2022) looks great to me, thanks!

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Julia Kreger (juliaashleykreger)](https://launchpad.net/~juliaashleykreger) wrote on 2022-10-12: |  |  | [#49](/glance/%2Bbug/1990157/comments/49) |
| --- | --- | --- | --- |

The latest also looks good to me. Thanks!

The latest also looks good to me. Thanks!

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jay Faulkner (jason-oldos)](https://launchpad.net/~jason-oldos) wrote on 2022-10-12: |  |  | [#50](/glance/%2Bbug/1990157/comments/50) |
| --- | --- | --- | --- |

+1 to the doc, thanks Brian!

+1 to the doc, thanks Brian!

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Abhishek Kekane (abhishek-kekane)](https://launchpad.net/~abhishek-kekane) wrote on 2022-10-14: |  |  | [#51](/glance/%2Bbug/1990157/comments/51) |
| --- | --- | --- | --- |

+1 from me as well, thank you Brian!!

+1 from me as well, thank you Brian!!

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Pranali Deore (pranali-deore)](https://launchpad.net/~pranali-deore) wrote on 2022-10-14: |  |  | [#52](/glance/%2Bbug/1990157/comments/52) |
| --- | --- | --- | --- |

+1 to the doc from me as well, Thanks !

I think we should go ahead and make it public as everyone agrees.

+1 to the doc from me as well, Thanks !
I think we should go ahead and make it public as everyone agrees.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jeremy Stanley (fungi)](https://launchpad.net/~fungi) wrote on 2022-10-14: |  |  | [#53](/glance/%2Bbug/1990157/comments/53) |
| --- | --- | --- | --- |

It looks like the revision attached to comment #46 addresses the points Erno raised, and has received consensus among other reviewers subscribed. In order not to further delay publication and make discussion of forward progress at the PTG harder, let's proceed with publication (even though I wouldn't normally recommend that on a Friday, the impact for this shouldn't pose a significant problem for our community).

Brian: Please push the final draft to <https://opendev.org/openstack/security-doc/src/branch/master/security-notes> and <https://wiki.openstack.org/wiki/OSSN/OSSN-0090> referencing this bug number, which I am switching to public now.

It looks like the revision attached to comment #46 addresses the points Erno raised, and has received consensus among other reviewers subscribed. In order not to further delay publication and make discussion of forward progress at the PTG harder, let's proceed with publication (even though I wouldn't normally recommend that on a Friday, the impact for this shouldn't pose a significant problem for our community).
Brian: Please push the final draft to https://opendev.org/openstack/security-doc/src/branch/master/security-notes and https://wiki.openstack.org/wiki/OSSN/OSSN-0090 referencing this bug number, which I am switching to public now.

| **description**: | updated |
| --- | --- |
| Changed in ossn: | |
| **status**: | Incomplete → In Progress |
| **assignee**: | nobody → Brian Rosmaita (brian-rosmaita) |
| **information type**: | Private Security → Public |
| **tags**: | added: security |
| **summary**: | - Malicious image data modification can happen when using COW+ OSSN-090: Malicious image data modification can happen when using COW |
| **summary**: | - OSSN-090: Malicious image data modification can happen when using COW+ OSSN-0090: Malicious image data modification can happen when using COW |

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-10-14: |  |  | [#54](/glance/%2Bbug/1990157/comments/54) |
| --- | --- | --- | --- |

Pushed the OSSN as:

[https://review.opendev.org/c/openstack/security-doc/+/861399](https://review.opendev.org/c/openstack/security-doc/%2B/861399)

Pushed the OSSN as:
https://review.opendev.org/c/openstack/security-doc/+/861399

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jeremy Stanley (fungi)](https://launchpad.net/~fungi) wrote on 2022-10-14: |  |  | [#55](/glance/%2Bbug/1990157/comments/55) |
| --- | --- | --- | --- |

Please also remember to send an OpenPGP-signed copy to the openstack-discuss and openstack-announce mailing lists (I'll expedite moderator approval through the latter).

Please also remember to send an OpenPGP-signed copy to the openstack-discuss and openstack-announce mailing lists (I'll expedite moderator approval through the latter).

[Erno Kuvaja (jokke)](https://launchpad.net/~jokke)
on 2022-10-19

| **information type**: | Public → Public Security |
| --- | --- |

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Nick Tait (nickthetait)](https://launchpad.net/~nickthetait) wrote on 2022-10-20: |  |  | [#56](/glance/%2Bbug/1990157/comments/56) |
| --- | --- | --- | --- |

I have a usability improvement idea: as OSSNs are designed for operators (as opposed to OpenStack developers) I would recommend replacing the acronym COW with the full name "Copy On Write." But I am not sure if such a tweak would be possible since it has already been released.

I have a usability improvement idea: as OSSNs are designed for operators (as opposed to OpenStack developers) I would recommend replacing the acronym COW with the full name "Copy On Write." But I am not sure if such a tweak would be possible since it has already been released.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jeremy Stanley (fungi)](https://launchpad.net/~fungi) wrote on 2022-10-21: |  |  | [#57](/glance/%2Bbug/1990157/comments/57) |
| --- | --- | --- | --- |

It's already been revised once since publication by <https://review.opendev.org/861878> and I don't mind reviewing another minor clarification (just make sure to keep the wiki version in sync with it if you do). It's not a significant enough change that we should send out a broad announcement with the clarification though, in my opinion.

It's already been revised once since publication by https://review.opendev.org/861878 and I don't mind reviewing another minor clarification (just make sure to keep the wiki version in sync with it if you do). It's not a significant enough change that we should send out a broad announcement with the clarification though, in my opinion.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Nick Tait (nickthetait)](https://launchpad.net/~nickthetait) wrote on 2022-11-02: |  |  | [#58](/glance/%2Bbug/1990157/comments/58) |
| --- | --- | --- | --- |

I agree a re-announcement is not needed. Got a local commit ready to publish, but its been ages since I've submitted a change to opendev... could someone point me toward some docs that tell me what my next step is?

I agree a re-announcement is not needed. Got a local commit ready to publish, but its been ages since I've submitted a change to opendev... could someone point me toward some docs that tell me what my next step is?

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Brian Rosmaita (brian-rosmaita)](https://launchpad.net/~brian-rosmaita) wrote on 2022-11-03: |  |  | [#59](/glance/%2Bbug/1990157/comments/59) |
| --- | --- | --- | --- |

@Nick: this is probably more basic than you need, but it contains some links that may be helpful:

<https://docs.openstack.org/contributors/code-and-documentation/quick-start.html>

@Nick: this is probably more basic than you need, but it contains some links that may be helpful:
https://docs.openstack.org/contributors/code-and-documentation/quick-start.html

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Nick Tait (nickthetait)](https://launchpad.net/~nickthetait) wrote on 2022-11-24: |  |  | [#60](/glance/%2Bbug/1990157/comments/60) |
| --- | --- | --- | --- |

Brian, that was a useful reminder but I ultimately gave up on trying to submit it. Anyway, I did reserve CVE-2022-4134 to track this issue.

Brian, that was a useful reminder but I ultimately gave up on trying to submit it. Anyway, I did reserve CVE-2022-4134 to track this issue.

[See full activity log](https://bugs.launchpad.net/glance/%2Bbug/1990157/%2Bactivity)

To post a comment you must [log in](%2Blogin?comments=all).

* [Report a bug](/glance/%2Bfilebug)

This report contains
**Public Security**
information

Everyone can see this security related information.

You are
[not directly subscribed to this bug's notifications.](/glance/%2Bbug/1990157/%2Bsubscribe)

Subscribing...

* [Edit bug mail](https://bugs.launchpad.net/glance/%2Bbug/1990157/%2Bsubscriptions "View and change your subscriptions to this bug")

## Other bug subscribers

[Subscribe someone else](https://bugs.launchpad.net/glance/%2Bbug/1990157/%2Baddsubscriber "Launchpad will email that person whenever this bugs changes")

## Patches

* [WIP patch for the meeting](https://bugs.launchpad.net/glance/%2Bbug/1990157/%2Battachment/5622726/%2Bfiles/0001-SEC-WIP-async-hashing-on-location-add.patch)
  [Edit](/glance/%2Bbug/1990157/%2Battachment/5622726 "Change patch details")
* [Latest version of the OSSN (6 Oct 2022)](https://bugs.launchpad.net/glance/%2Bbug/1990157/%2Battachment/5622747/%2Bfiles/0001-Add-OSSN-0090.patch)
  [Edit](/glance/%2Bbug/1990157/%2Battachment/5622747 "Change patch details")
* [Rewritten version of the OSSN (12 Oct 2022)](https://bugs.launchpad.net/glance/%2Bbug/1990157/%2Battachment/5623275/%2Bfiles/0002-Add-OSSN-0090.patch)
  [Edit](/glance/%2Bbug/1990157/%2Battachment/5623275 "Change patch details")

* [Add patch](/glance/%2Bbug/1990157/%2Baddcomment?field.patch=on)

## Remote bug watches

Bug watches keep track of this bug in other bug trackers.

[![Launchpad](/@@/launchpad-footer-logo.svg)](https://launchpad.net/)
 •
[Take the tour](https://launchpad.net/%2Btour)
 •
[Read the guide](https://help.launchpad.net/)

© 2004
[Canonical Ltd.](http://canonical.com/)
 •
[Terms of use](https://launchpad.net/legal)
 •
[Data privacy](https://www.ubuntu.com/legal/dataprivacy)
 •
[Contact Launchpad Support](/feedback)
 •
[Blog](http://blog.launchpad.net/)
 •
[Careers](https://canonical.com/careers)
 •
[System status](https://ubuntu.social/%40launchpadstatus)
 •
6394e03
([Get the code!](https://dev.launchpad.net/))



=== Content from wiki.openstack.org_ea60e2e8_20250115_130733.html ===


* [![OpenStack](https://wiki.openstack.org/w/images/thumb/c/c4/OpenStack_Logo_-_notext.png/30px-OpenStack_Logo_-_notext.png)](/wiki/Main_Page "Visit the main page")

* Page
  + [Page](/wiki/OSSN/OSSN-0090 "View the content page [c]")
  + [Discussion](/w/index.php?title=Talk:OSSN/OSSN-0090&action=edit&redlink=1 "Discussion about the content page [t]")
  + [View source](/w/index.php?title=OSSN/OSSN-0090&action=edit "This page is protected.
    You can view its source [e]")
  + [History](/w/index.php?title=OSSN/OSSN-0090&action=history "Past revisions of this page [h]")

* Print/export
  + [Create a book](/w/index.php?title=Special:Book&bookcmd=book_creator&referer=OSSN%2FOSSN-0090)
  + [Download as PDF](/w/index.php?title=Special:Book&bookcmd=render_article&arttitle=OSSN%2FOSSN-0090&returnto=OSSN%2FOSSN-0090&oldid=182066&writer=rl)
  + [Printable version](/w/index.php?title=OSSN/OSSN-0090&printable=yes "Printable version of this page [p]")

* Tools
  + [Page information](/w/index.php?title=OSSN/OSSN-0090&action=info "More information about this page")
  + [Permanent link](/w/index.php?title=OSSN/OSSN-0090&oldid=182066 "Permanent link to this revision of the page")
  + [Special pages](/wiki/Special%3ASpecialPages "A list of all special pages [q]")
  + [Related changes](/wiki/Special%3ARecentChangesLinked/OSSN/OSSN-0090 "Recent changes in pages linked from this page [k]")
  + [What links here](/wiki/Special%3AWhatLinksHere/OSSN/OSSN-0090 "A list of all wiki pages that link here [j]")

* * [Create account](/w/index.php?title=Special:CreateAccount&returnto=OSSN%2FOSSN-0090 "You are encouraged to create an account and log in; however, it is not mandatory")
* * [Log in](/w/index.php?title=Special:UserLogin&returnto=OSSN%2FOSSN-0090 "You are encouraged to log in; however, it is not mandatory [o]")
* * [Log in / create account with OpenID](/w/index.php?title=Special:OpenIDLogin&returnto=OSSN/OSSN-0090)
* + English

* [Home](http://www.openstack.org)
* [Software](http://www.openstack.org/software)
* [User Stories](http://www.openstack.org/user-stories)
* [Community](http://www.openstack.org/community)
* [Profile](http://www.openstack.org/profile)
* [Blog](http://www.openstack.org/blog)
* [Wiki](http://wiki.openstack.org)
* [Documentation](http://docs.openstack.org)

Jump to: [navigation](#mw-head),
[search](#p-search)

# OSSN/OSSN-0090

< [OSSN](/wiki/OSSN "OSSN")

## Contents

* [1 Best practices when configuring Glance with COW backends](#Best_practices_when_configuring_Glance_with_COW_backends)
  + [1.1 Summary](#Summary)
  + [1.2 Affected Services / Software](#Affected_Services_.2F_Software)
  + [1.3 Discussion](#Discussion)
  + [1.4 Recommended Actions](#Recommended_Actions)
  + [1.5 Notes / References](#Notes_.2F_References)
  + [1.6 Contacts / References](#Contacts_.2F_References)
# Best practices when configuring Glance with COW backends

## Summary

When deploying Glance in a popular configuration where Glance shares a
common storage backend with Nova and/or Cinder, it is possible to open
some known attack vectors by which malicious data modification can
occur. This note reviews the known issues and suggests a Glance
deployment configuration that can mitigate such attacks.

## Affected Services / Software

Glance, all supported releases (Queens through Zed)

## Discussion

This note applies to you if you are operating a
glance-api service with the 'show\_multiple\_locations' option set to True
(the default value is False) or if your end-user-facing glance-api has
the 'show\_image\_direct\_url' option set to True (default value is False).

Our recommendation is that the image "locations" and "direct\_url"
fields [0] \*never\* be displayed to end users in a cloud. This can be
accomplished by running two glance-api services:

* A "user-facing" glance-api that is accessible to end users and which appears in users' service catalogs.

* An "internal-only-facing" glance-api that is accessible only to those services that require access to the 'direct\_url' or image location fields, and which is protected by firewalls from access by end users. (Nova, Cinder, and Ironic all have configuration options to specify the Glance API endpoint each service uses [1].)

This dual glance-api deployment was suggested in "Known Issues" in Glance
release notes in the Rocky [2] through Ussuri releases, but it seems that
the idea has not received sufficient attention. Hence this security note.

The attack vector that becomes available when image locations are exposed to
users was originally outlined in OSSN-0065 [3], though that note was not
clear about the attack surface or mitigation, and contained some
forward-looking statements that were not fulfilled. The attack vector is:

> [A] malicious user could create an image in Glance, set an additional
> location on that image pointing to an altered image, then delete the
> original location, so that consumers of the original image would
> unwittingly be using the malicious image. Note, however, that this
> attack vector cannot change the original image's checksum, and it is
> limited to images that are owned by the attacker.

OSSN-0065 suggests that this is only an issue when users do not checksum
their image data. It neglects the fact that in some popular deployment
configurations in which Nova creates a root disk snapshot, data is never
uploaded to Glance, but instead a snapshot is created directly in the
backend and Nova creates a Glance image record with "size" 0 and an
empty "os\_hash\_value" [4], making it impossible to compare the hash of
downloaded image data to the value maintained by Glance.

Further, when Nova is configured to use the same storage for ephemeral disks
that is used as a Glance image store, Nova efficiently creates a server root
disk directly in the backend without checksumming the image data. This is
an intentional design choice to optimize storage space and host resources,
but an implication is that even if the image record has a recorded hash, it
is not being checked at the point of image consumption.

Similarly, when using a shared backend, or a cinder glance\_store, Cinder
will efficiently clone a volume created from an image directly in the
backend without checksumming the image data. Again, this is done
intentionally in order to optimize resources, but it is important to be
aware of the security tradeoff being made by this configuration. In other
words, if the image data is not going to be checked at the point of image
consumption, then extra care needs to be taken to ensure the integrity of
the data path.

OSSN-0065 suggested that the attack vector of substituting image data by
modifying the image locations could be addressed by using policies, but that
has turned out not to be the case. The only way currently to mitigate this
vector is to deploy glance-api in a dual configuration as described above,
namely with an internal-only-facing glance-api used by Nova and Cinder (that
has show\_multiple\_locations enabled), and an end-user-facing glance-api (that
has show\_multiple\_locations disabled).

So far the focus has been on 'show\_multiple\_locations'. When that setting
is disabled in Glance, it is not possible to manipulate the locations
via the OpenStack Images API. Keep in mind, however, that in any
Glance/Nova/Cinder configuration where Nova and/or Cinder do copy-on-write
directly in the image store, image data transfer takes place outside Glance's
image data download path, and the os\_hash\_value is \*not\* checked. Thus,
if the backend store is itself compromised and image data is replaced
directly in the backend, the substitution will \*not\* be detected.

This brings us to the 'show\_image\_direct\_url' option, which includes a
"direct\_url" field in the image-show response that can be used by various
OpenStack services to consume images directly from the storage backend.
Exposing the 'direct\_url' to end users leaks information about the storage
backend. What exactly that information consists of depends upon the backend
in use and how it is configured, but in general, it is not a good idea to
provide hints that could be useful to malicious actors in their attempts to
compromise the backend storage by some type of independent exploit. The
'direct\_url', being read-only, may appear innocuous, but its use by services
is usually to perform some kind of optimized image data access that most
likely does not include computing a hash of the image data.

We therefore recommend that OpenStack services that require exposure of
the 'direct\_url' image property be similarly configured to use an
internal-only-facing glance-api. It is worth nothing that end users who
wish to download an image do not require access to the 'direct\_url' image
property because they can simply use the image-data-download API call [5].

## Recommended Actions

A glance-api service with 'show\_multiple\_locations' enabled should
**never** be exposed directly to end users. This setting should only be
enabled on an internal-only-facing glance-api that is used by OpenStack
services that require access to image locations. This could be done,
for example, by running two glance-api services with different
configuration files and using the appropriate configuration options for
each service to specify the Image API endpoint to access, and making
sure the special internal endpoint is firewalled in such a way that only
the appropriate OpenStack services can contact it.

Similarly, enabling 'show\_image\_direct\_url' exposes information about
the storage backend that could be of use to malicious actors in as yet
unknown exploits, so it should likewise only be enabled on an
internal-only-facing glance-api.

## Notes / References

[0] <https://docs.openstack.org/api-ref/image/v2/index.html#show-image-schema>

[1] Nova and Ironic use 'endpoint\_override' in the '[glance]' section of the configuration file; Cinder uses 'glance\_api\_servers' in the '[DEFAULT]' section.

[2] OSSN-0065: <https://wiki.openstack.org/wiki/OSSN/OSSN-0065>

[3] The Glance "multihash" metadata pair of 'os\_hash\_algo' and 'os\_hash\_value' were introduced in Rocky to replace the legacy md5 'checksum' field. The python-glanceclient has used multihash checksumming for download verification since version 2.13.0.

[4] <https://docs.openstack.org/releasenotes/glance/rocky.html#known-issues>

[5] [https://docs.openstack.org/api-ref/image/v2/index.html?#download-binary-image-data](https://docs.openstack.org/api-ref/image/v2/index.html#download-binary-image-data)

## Contacts / References

Author: Brian Rosmaita, Red Hat

This OSSN : <https://wiki.openstack.org/wiki/OSSN/OSSN-0090>

Original LaunchPad Bug : [https://bugs.launchpad.net/ossn/+bug/1990157](https://bugs.launchpad.net/ossn/%2Bbug/1990157)

Mailing List : [Security] tag on openstack-discuss@lists.openstack.org

OpenStack Security Project : <https://launchpad.net/~openstack-ossg>

CVE: none

Retrieved from "<https://wiki.openstack.org/w/index.php?title=OSSN/OSSN-0090&oldid=182066>"

* [Privacy policy](/wiki/OpenStack%3APrivacy_policy "OpenStack:Privacy policy")
* [About OpenStack](/wiki/OpenStack%3AAbout "OpenStack:About")
* [Disclaimers](/wiki/OpenStack%3AGeneral_disclaimer "OpenStack:General disclaimer")

* [![Attribution 3.0 Unported (CC BY 3.0)](/w/resources/assets/licenses/cc-by.png)](http://creativecommons.org/licenses/by/3.0/)
* [![Powered by MediaWiki](/w/resources/assets/poweredby_mediawiki_88x31.png)](//www.mediawiki.org/)



=== Content from bugs.launchpad.net_9595cc38_20250115_205844.html ===

[Log in / Register](https://bugs.launchpad.net/glance/%2Bbug/1990157/%2Bactivity/%2Blogin)

[![](https://launchpadlibrarian.net/355215744/glance-chipmunk-64.png)](https://launchpad.net/glance)

## [Glance](https://launchpad.net/glance)

* [Overview](https://launchpad.net/glance)
* [Code](https://code.launchpad.net/glance)
* [Bugs](https://bugs.launchpad.net/glance)
* [Blueprints](https://blueprints.launchpad.net/glance)
* [Translations](https://translations.launchpad.net/glance)
* [Answers](https://answers.launchpad.net/glance)

1. [Bug #1990157](https://bugs.launchpad.net/glance/%2Bbug/1990157)
2. Activity log

# Activity log for bug #1990157

| Date | Who | What changed | Old value | New value | Message |
| --- | --- | --- | --- | --- | --- |
| 2022-09-19 14:33:14 | [Erno Kuvaja](https://launchpad.net/~jokke) | bug |  |  | added bug |
| 2022-09-19 14:33:49 | [Erno Kuvaja](https://launchpad.net/~jokke) | bug |  |  | added subscriber Pranali Deore |
| 2022-09-19 17:43:39 | [Jeremy Stanley](https://launchpad.net/~fungi) | description | The location fix manipulation mentioned in https://security.openstack.org/ossa/OSSA-2016-006.html of disallowing removal of last image location (and thus transition it back to queued) is only partial fix for the issue. The fix at the time was able to ensure that the hash stayed in the image record causing validations to fail even if the image data itself had changed. Different efforts to speed up booting and volume creation processes utilizing Copy On Write behaviour of Ceph or various Cinder backends is causing two different scenarios where malicious content can be sneaked into the image. 1) When Nova creates snapshot directly into the Ceph store and creates image through the API adding the location via locations API rather than uploading the data to Glance it omits 2 parts of metadata that would allow identifying alteration of the image data. The image does not have multihash (or checksum) associated with it making validation impossible. The image does not have size metadata either. 2) When image is consumed in COW manner even if it had multihash (checksum) registered in the metadata it does not get validated as the consumer does not read the whole image and calculate checksum of it. All current implementations of COW handling of the image depends of the direct url and locations API being exposed. As the services are accessing the image with user credentials if Glance is deployed with single API configuration serving both OpenStack services and end users, the malicious end user will have all the tools needed to make this attack valid. Only real mitigation for this issue is to deploy External API endpoint (for user access) and Internal API endpoint (for Openstack services, note that this endpoint needs to be firewalled off from end user access as the credentials are the same). Additional hardening of creating the multihash metadata entries and validating them upon use should be implemented. The dual API deployment should be highlighted clearly in the documentation. These two behavioural facts causes the image manipulation mentioned in the OSSA-2016-006 (CVE 2016-0757) still possible. If the image has multihash (checksum) recorded for it, python-glanceclient will reject the image if the data does not match. But this requires manual verification (actually downloading the image) to find out or deep understanding of the technical implementation to match the location URI with the image ID (in Ceph case). The COW consumers will not flag it to anyone and will just happily consume the modified data. In the case that there is no multihash recorded for the image the only indication for malicious activity would be through comparing the location URI with the image ID (in Ceph case) and there is no other validation channels. Once the location of the modified image data has been added to the image locations table, Glance will allow deleting the original data as that is not the last location anymore. | This issue is being treated as a potential security risk under embargo. Please do not make any public mention of embargoed (private) security vulnerabilities before their coordinated publication by the OpenStack Vulnerability Management Team in the form of an official OpenStack Security Advisory. This includes discussion of the bug or associated fixes in public forums such as mailing lists, code review systems and bug trackers. Please also avoid private disclosure to other individuals not already approved for access to this information, and provide this same reminder to those who are made aware of the issue prior to publication. All discussion should remain confined to this private bug report, and any proposed fixes should be added to the bug as attachments. This embargo shall not extend past 2022-12-18 and will be made public by or on that date even if no fix is identified. The location fix manipulation mentioned in https://security.openstack.org/ossa/OSSA-2016-006.html of disallowing removal of last image location (and thus transition it back to queued) is only partial fix for the issue. The fix at the time was able to ensure that the hash stayed in the image record causing validations to fail even if the image data itself had changed. Different efforts to speed up booting and volume creation processes utilizing Copy On Write behaviour of Ceph or various Cinder backends is causing two different scenarios where malicious content can be sneaked into the image. 1) When Nova creates snapshot directly into the Ceph store and creates image through the API adding the location via locations API rather than uploading the data to Glance it omits 2 parts of metadata that would allow identifying alteration of the image data. The image does not have multihash (or checksum) associated with it making validation impossible. The image does not have size metadata either. 2) When image is consumed in COW manner even if it had multihash (checksum) registered in the metadata it does not get validated as the consumer does not read the whole image and calculate checksum of it. All current implementations of COW handling of the image depends of the direct url and locations API being exposed. As the services are accessing the image with user credentials if Glance is deployed with single API configuration serving both OpenStack services and end users, the malicious end user will have all the tools needed to make this attack valid. Only real mitigation for this issue is to deploy External API endpoint (for user access) and Internal API endpoint (for Openstack services, note that this endpoint needs to be firewalled off from end user access as the credentials are the same). Additional hardening of creating the multihash metadata entries and validating them upon use should be implemented. The dual API deployment should be highlighted clearly in the documentation. These two behavioural facts causes the image manipulation mentioned in the OSSA-2016-006 (CVE 2016-0757) still possible. If the image has multihash (checksum) recorded for it, python-glanceclient will reject the image if the data does not match. But this requires manual verification (actually downloading the image) to find out or deep understanding of the technical implementation to match the location URI with the image ID (in Ceph case). The COW consumers will not flag it to anyone and will just happily consume the modified data. In the case that there is no multihash recorded for the image the only indication for malicious activity would be through comparing the location URI with the image ID (in Ceph case) and there is no other validation channels. Once the location of the modified image data has been added to the image locations table, Glance will allow deleting the original data as that is not the last location anymore. |  |
| 2022-09-19 17:43:48 | [Jeremy Stanley](https://launchpad.net/~fungi) | bug task added |  | ossa |  |
| 2022-09-19 17:43:55 | [Jeremy Stanley](https://launchpad.net/~fungi) | ossa: status | New | Incomplete |  |
| 2022-09-19 17:44:11 | [Jeremy Stanley](https://launchpad.net/~fungi) | bug |  |  | added subscriber Glance Core security contacts |
| 2022-09-19 21:42:45 | [Brian Rosmaita](https://launchpad.net/~brian-rosmaita) | cve linked |  | 2016-0757 |  |
| 2022-09-20 10:43:51 | [Erno Kuvaja](https://launchpad.net/~jokke) | nominated for series |  | glance/wallaby |  |
| 2022-09-20 10:43:51 | [Erno Kuvaja](https://launchpad.net/~jokke) | bug task added |  | glance/wallaby |  |
| 2022-09-20 10:43:51 | [Erno Kuvaja](https://launchpad.net/~jokke) | nominated for series |  | glance/yoga |  |
| 2022-09-20 10:43:51 | [Erno Kuvaja](https://launchpad.net/~jokke) | bug task added |  | glance/yoga |  |
| 2022-09-20 10:43:51 | [Erno Kuvaja](https://launchpad.net/~jokke) | nominated for series |  | glance/xena |  |
| 2022-09-20 10:43:51 | [Erno Kuvaja](https://launchpad.net/~jokke) | bug task added |  | glance/xena |  |
| 2022-09-20 10:43:51 | [Erno Kuvaja](https://launchpad.net/~jokke) | nominated for series |  | glance/zed |  |
| 2022-09-20 10:43:51 | [Erno Kuvaja](https://launchpad.net/~jokke) | bug task added |  | glance/zed |  |
| 2022-09-21 13:26:18 | [Brian Rosmaita](https://launchpad.net/~brian-rosmaita) | bug |  |  | added subscriber Dan Smith |
| 2022-09-22 20:56:44 | [Brian Rosmaita](https://launchpad.net/~brian-rosmaita) | affects | ossa | ossn |  |
| 2022-10-10 13:59:54 | [Erno Kuvaja](https://launchpad.net/~jokke) | attachment added |  | WIP patch for the meeting https://bugs.launchpad.net/glance/+bug/1990157/+attachment/5622726/+files/0001-SEC-WIP-async-hashing-on-location-add.patch |  |
| 2022-10-10 15:10:56 | [Brian Rosmaita](https://launchpad.net/~brian-rosmaita) | attachment added |  | Latest version of the OSSN (6 Oct 2022) https://bugs.launchpad.net/glance/+bug/1990157/+attachment/5622747/+files/0001-Add-OSSN-0090.patch |  |
| 2022-10-12 06:20:44 | [Brian Rosmaita](https://launchpad.net/~brian-rosmaita) | attachment added |  | Rewritten version of the OSSN (12 Oct 2022) https://bugs.launchpad.net/glance/+bug/1990157/+attachment/5623275/+files/0002-Add-OSSN-0090.patch |  |
| 2022-10-12 14:19:01 | [Brian Rosmaita](https://launchpad.net/~brian-rosmaita) | bug |  |  | added subscriber Jay Faulkner |
| 2022-10-12 14:20:42 | [Brian Rosmaita](https://launchpad.net/~brian-rosmaita) | bug |  |  | added subscriber Julia Kreger |
| 2022-10-13 12:49:00 | [Erno Kuvaja](https://launchpad.net/~jokke) | bug |  |  | added subscriber unmesh desale |
| 2022-10-13 12:51:10 | [Erno Kuvaja](https://launchpad.net/~jokke) | removed subscriber unmesh desale |  |  |  |
| 2022-10-13 12:51:29 | [Erno Kuvaja](https://launchpad.net/~jokke) | bug |  |  | added subscriber unmesh desale |
| 2022-10-14 14:05:51 | [Jeremy Stanley](https://launchpad.net/~fungi) | description | This issue is being treated as a potential security risk under embargo. Please do not make any public mention of embargoed (private) security vulnerabilities before their coordinated publication by the OpenStack Vulnerability Management Team in the form of an official OpenStack Security Advisory. This includes discussion of the bug or associated fixes in public forums such as mailing lists, code review systems and bug trackers. Please also avoid private disclosure to other individuals not already approved for access to this information, and provide this same reminder to those who are made aware of the issue prior to publication. All discussion should remain confined to this private bug report, and any proposed fixes should be added to the bug as attachments. This embargo shall not extend past 2022-12-18 and will be made public by or on that date even if no fix is identified. The location fix manipulation mentioned in https://security.openstack.org/ossa/OSSA-2016-006.html of disallowing removal of last image location (and thus transition it back to queued) is only partial fix for the issue. The fix at the time was able to ensure that the hash stayed in the image record causing validations to fail even if the image data itself had changed. Different efforts to speed up booting and volume creation processes utilizing Copy On Write behaviour of Ceph or various Cinder backends is causing two different scenarios where malicious content can be sneaked into the image. 1) When Nova creates snapshot directly into the Ceph store and creates image through the API adding the location via locations API rather than uploading the data to Glance it omits 2 parts of metadata that would allow identifying alteration of the image data. The image does not have multihash (or checksum) associated with it making validation impossible. The image does not have size metadata either. 2) When image is consumed in COW manner even if it had multihash (checksum) registered in the metadata it does not get validated as the consumer does not read the whole image and calculate checksum of it. All current implementations of COW handling of the image depends of the direct url and locations API being exposed. As the services are accessing the image with user credentials if Glance is deployed with single API configuration serving both OpenStack services and end users, the malicious end user will have all the tools needed to make this attack valid. Only real mitigation for this issue is to deploy External API endpoint (for user access) and Internal API endpoint (for Openstack services, note that this endpoint needs to be firewalled off from end user access as the credentials are the same). Additional hardening of creating the multihash metadata entries and validating them upon use should be implemented. The dual API deployment should be highlighted clearly in the documentation. These two behavioural facts causes the image manipulation mentioned in the OSSA-2016-006 (CVE 2016-0757) still possible. If the image has multihash (checksum) recorded for it, python-glanceclient will reject the image if the data does not match. But this requires manual verification (actually downloading the image) to find out or deep understanding of the technical implementation to match the location URI with the image ID (in Ceph case). The COW consumers will not flag it to anyone and will just happily consume the modified data. In the case that there is no multihash recorded for the image the only indication for malicious activity would be through comparing the location URI with the image ID (in Ceph case) and there is no other validation channels. Once the location of the modified image data has been added to the image locations table, Glance will allow deleting the original data as that is not the last location anymore. | The location fix manipulation mentioned in https://security.openstack.org/ossa/OSSA-2016-006.html of disallowing removal of last image location (and thus transition it back to queued) is only partial fix for the issue. The fix at the time was able to ensure that the hash stayed in the image record causing validations to fail even if the image data itself had changed. Different efforts to speed up booting and volume creation processes utilizing Copy On Write behaviour of Ceph or various Cinder backends is causing two different scenarios where malicious content can be sneaked into the image. 1) When Nova creates snapshot directly into the Ceph store and creates image through the API adding the location via locations API rather than uploading the data to Glance it omits 2 parts of metadata that would allow identifying alteration of the image data. The image does not have multihash (or checksum) associated with it making validation impossible. The image does not have size metadata either. 2) When image is consumed in COW manner even if it had multihash (checksum) registered in the metadata it does not get validated as the consumer does not read the whole image and calculate checksum of it. All current implementations of COW handling of the image depends of the direct url and locations API being exposed. As the services are accessing the image with user credentials if Glance is deployed with single API configuration serving both OpenStack services and end users, the malicious end user will have all the tools needed to make this attack valid. Only real mitigation for this issue is to deploy External API endpoint (for user access) and Internal API endpoint (for Openstack services, note that this endpoint needs to be firewalled off from end user access as the credentials are the same). Additional hardening of creating the multihash metadata entries and validating them upon use should be implemented. The dual API deployment should be highlighted clearly in the documentation. These two behavioural facts causes the image manipulation mentioned in the OSSA-2016-006 (CVE 2016-0757) still possible. If the image has multihash (checksum) recorded for it, python-glanceclient will reject the image if the data does not match. But this requires manual verification (actually downloading the image) to find out or deep understanding of the technical implementation to match the location URI with the image ID (in Ceph case). The COW consumers will not flag it to anyone and will just happily consume the modified data. In the case that there is no multihash recorded for the image the only indication for malicious activity would be through comparing the location URI with the image ID (in Ceph case) and there is no other validation channels. Once the location of the modified image data has been added to the image locations table, Glance will allow deleting the original data as that is not the last location anymore. |  |
| 2022-10-14 14:05:59 | [Jeremy Stanley](https://launchpad.net/~fungi) | ossn: status | Incomplete | In Progress |  |
| 2022-10-14 14:06:17 | [Jeremy Stanley](https://launchpad.net/~fungi) | ossn: assignee |  | Brian Rosmaita (brian-rosmaita) |  |
| 2022-10-14 14:06:24 | [Jeremy Stanley](https://launchpad.net/~fungi) | information type | Private Security | Public |  |
| 2022-10-14 14:06:33 | [Jeremy Stanley](https://launchpad.net/~fungi) | tags |  | security |  |
| 2022-10-14 14:07:00 | [Jeremy Stanley](https://launchpad.net/~fungi) | summary | Malicious image data modification can happen when using COW | OSSN-090: Malicious image data modification can happen when using COW |  |
| 2022-10-14 14:07:16 | [Jeremy Stanley](https://launchpad.net/~fungi) | summary | OSSN-090: Malicious image data modification can happen when using COW | OSSN-0090: Malicious image data modification can happen when using COW |  |
| 2022-10-19 11:18:04 | [Erno Kuvaja](https://launchpad.net/~jokke) | information type | Public | Public Security |  |
| 2022-11-24 00:35:46 | [Nick Tait](https://launchpad.net/~nickthetait) | cve linked |  | 2022-4134 |  |

[![Launchpad](/@@/launchpad-footer-logo.svg)](https://launchpad.net/)
 •
[Take the tour](https://launchpad.net/%2Btour)
 •
[Read the guide](https://help.launchpad.net/)

© 2004
[Canonical Ltd.](http://canonical.com/)
 •
[Terms of use](https://launchpad.net/legal)
 •
[Data privacy](https://www.ubuntu.com/legal/dataprivacy)
 •
[Contact Launchpad Support](/feedback)
 •
[Blog](http://blog.launchpad.net/)
 •
[Careers](https://canonical.com/careers)
 •
[System status](https://ubuntu.social/%40launchpadstatus)
 •
6394e03
([Get the code!](https://dev.launchpad.net/))


