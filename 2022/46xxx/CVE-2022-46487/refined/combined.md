=== Content from jovanbulck.github.io_899982a3_20250114_195803.html ===
Faulty Point Unit: ABI Poisoning Attacks on
Intel SGX

Fritz Alder
imec-DistriNet, KU Leuven, Belgium
fritz.alder@acm.org

David Oswald
University of Birmingham, UK
d.f.oswald@bham.ac.uk

Jo Van Bulck
imec-DistriNet, KU Leuven, Belgium
jo.vanbulck@cs.kuleuven.be

Frank Piessens
imec-DistriNet, KU Leuven, Belgium
frank.piessens@cs.kuleuven.be

ABSTRACT
This paper analyzes a previously overlooked attack surface that al-
lows unprivileged adversaries to impact supposedly secure floating-
point computations in Intel SGX enclaves through the Application
Binary Interface (ABI). In a comprehensive study across 7 widely
used industry-standard and research enclave shielding runtimes, we
show that control and state registers of the x87 Floating-Point Unit
(FPU) and Intel Streaming SIMD Extensions (SSE) are not always
properly sanitized on enclave entry. First, we abuse the adversary‚Äôs
control over precision and rounding modes as a novel ‚ÄúABI-level
fault injection‚Äù primitive to silently corrupt enclaved floating-point
operations, enabling a new class of stealthy, integrity-only attacks
that disturb the result of SGX enclave computations. Our analysis
reveals that this threat is especially relevant for applications that
use the older x87 FPU, which is still being used under certain con-
ditions for high-precision operations by modern compilers like gcc.
We exemplify the potential impact of ABI-level quality-degradation
attacks in a case study of an enclaved machine learning service
and in a larger analysis on the SPEC benchmark programs. Second,
we explore the impact on enclave confidentiality by showing that
the adversary‚Äôs control over floating-point exception masks can be
abused as an innovative controlled channel to detect FPU usage and
to recover enclaved multiplication operands in certain scenarios.
Our findings, affecting 5 out of the 7 studied runtimes, demonstrate
the fallacy and challenges of implementing high-assurance trusted
execution environments on contemporary x86 hardware. We re-
sponsibly disclosed our findings to the vendors and were assigned
two CVEs, leading to patches in the Intel SGX-SDK, Microsoft
OpenEnclave, the Rust compiler‚Äôs SGX target, and Go-TEE.

CCS CONCEPTS
‚Ä¢ Security and privacy ‚Üí Systems security; Operating sys-
tems security; Side-channel analysis and countermeasures.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
ACSAC 2020, December 7‚Äì11, 2020, Austin, USA
¬© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-8858-0/20/12. . . $15.00
https://doi.org/10.1145/3427228.3427270

1

KEYWORDS
Trusted execution, Intel SGX, FPU, ABI, side channels

ACM Reference Format:
Fritz Alder, Jo Van Bulck, David Oswald, and Frank Piessens. 2020. Faulty
Point Unit: ABI Poisoning Attacks on Intel SGX. In Annual Computer Security
Applications Conference (ACSAC 2020), December 7‚Äì11, 2020, Austin, USA.
ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/3427228.3427270

1 INTRODUCTION
In recent years, several Trusted Execution Environments (TEEs) [28]
have been developed as a new security paradigm to provide a
hardware-backed approach of securing software. Their promise
is that applications can be run in so called enclaves to be isolated
and protected from the surrounding, potentially untrusted Oper-
ating System (OS). This allows to radically reduce the size of the
Trusted Computing Base (TCB) to the point where only the enclave
application itself and the underlying processor need to be trusted.
TEEs hence offer the compelling potential of securely offloading
sensitive computations to untrusted remote platforms [2, 18, 29].
However, the isolation guarantees provided by any TEE only hold
in so far as the trusted in-enclave software properly scrutinizes
the untrusted interface that is exposed to the potentially hostile
environment. In the context of Intel SGX [10], a state-of-the-art
TEE widely available on recent Intel processors, the last years have
seen a considerable effort by academia and industry to develop
shielding runtimes that aid secure enclave development by trans-
parently protecting application binaries inside the TEE. Besides the
canonical open-source SGX-SDK [9] reference implementation by
Intel, several other mature enclave runtimes have been developed,
including Microsoft‚Äôs OpenEnclave [30], Fortanix‚Äôs Rust-EDP [13],
Graphene-SGX [38], and SGX-LKL [35].

Attacks on enclave shielding runtimes. A recent systematic
vulnerability assessment [43] of enclave runtimes has shown that
shielding requirements are not sufficiently understood in today‚Äôs
TEE runtimes. Particularly, it was shown that popular SGX shielding
systems suffered from a wide range of often subtle, yet crucial inter-
face sanitization oversights. From this analysis, we conclude that
the complex enclave shielding responsibility can be broken down
into two successive tiers of interface sanitizations, as illustrated
in Figure 1. In a first tier, immediately after entering the enclave
protection domain, the trusted runtime should sanitize low-level
machine state and establish a trustworthy ABI. This bootstrapping
phase is typically implemented in a minimal assembly stub that

ACSAC 2020, December 7‚Äì11, 2020, Austin, USA

Alder et al.

Figure 1: Enclaved application binaries are transparently
shielded by sanitizing untrusted ABI and API-level state.

sets up a trusted stack and initializes selected CPU registers before
calling second-stage code written in a higher-level language. At
this point, the trusted shielding runtime is responsible to provide
a secure Application Programming Interface (API) abstraction by
sanitizing untrusted arguments, such as pointers, before finally
handing over control to the shielded application binary written by
the enclave developer. Any sanitization oversight in either of the
phases of the trusted runtime, or in the application tier itself, may
nullify all of the enclave‚Äôs pursued security objectives.

This is especially apparent for a long line of confused-deputy
enclave attacks [5, 22, 34, 43] that abuse untrusted pointer pass-
ing in the shared address space to trick a victim enclave program
into inadvertently dereferencing secure memory locations chosen
by the attacker. Such API-level pointer sanitization vulnerabilities
have been traditionally widely studied, both in the context of con-
ventional user-to-kernel exploits [7] and more recently also TEE
scenarios [5, 22, 27, 34, 43]. However, as these vulnerabilities fully
manifest at the programmer-visible API level, principled solutions
have been developed to thwart this category of pointer poisoning
attacks, e.g., by means of developer annotations and automatic
code generation as in Intel‚Äôs edger8r [9], a secure type system as
in Fortanix‚Äôs Rust-EDP [13], or by automatically scrutinizing the
enclave API through symbolic execution [22] and even formal in-
terface verification efforts [45, 46]. Furthermore, prior work exists
to analyze enclave code via symbolic execution in order to reason
about API-level attack surfaces [8]. Another example for insuffi-
cient API-level sanitization is the lack of scrubbing of uninitialized
structure padding reported by [24], causing leakage of confidental
data from enclave memory.

ABI-level attacks. We argue that ABI-level vulnerabilities, on
the other hand, are generally more subtle and harder to reason
about as they do not manifest at the program level, but instead
exploit implicit assumptions made by the compiler regarding the
integrity of the low-level machine state, which may not always
hold in the enclave‚Äôs hostile environment. Due to their low-level
nature, this class of ABI-level vulnerabilities hence falls explicitly
out of the scope of established language-level security mechanisms
like memory-safe type systems. Prior work [11, 43] has for instance
exploited improper stack pointer initialization or insufficient sani-
tization of x86 flags to induce severe memory-safety issues in oth-
erwise perfectly secure applications. It remains unclear, however,
whether other ABI-level attack surfaces exist, to what extent they
endanger the enclave protection model, and if they are limited to
triggering evident memory-safety misbehavior or could also induce
more indirect and stealthier errors in enclaved computations.

2

In this paper, we analyze a subtle and previously overlooked
ABI-level attack surface arising from enclave interactions with
the processor‚Äôs underlying x87 FPU and SSE vector extensions.
Specifically, we show that insufficient FPU and SSE control reg-
ister initialization at the enclave boundary allows to adversely
impact the integrity, and to a certain extend even the confiden-
tiality, of enclaved floating-point operations executing under the
protection of a TEE. Our analysis of this attack surface in popular
Intel SGX shielding runtimes revealed re-occurring ABI-level saniti-
zation oversights in 5 different runtimes, including widely deployed
production-quality implementations such as Intel‚Äôs SGX-SDK [9],
Microsoft‚Äôs OpenEnclave [30], and Fortanix‚Äôs Rust-EDP [13]. This
lack of secure FPU initialization allows unprivileged adversaries to
influence the rounding and possibly even the precision of enclaved
floating-point operations, introduce indefinite values, and mask
or unmask selected floating-point exception types. Interestingly,
in contrast to prior research [11, 43] on ABI-level attacks which
induce direct memory corruptions in the victim program, uninitial-
ized FPU and SSE configuration registers pose a significantly less
straightforward threat and necessitate more insightful exploitation
methodologies. Our work therefore contributes novel attack tech-
niques that abuse the adversary‚Äôs control over FPU state from two
complementary angles.

First, we explore the use of rounding and precision control poi-
soning as an ‚ÄúABI-level fault-injection‚Äù primitive to silently corrupt
supposedly secure enclaved floating-point operations. In several
case studies, we show that such subtle floating-point corruptions
can break the overall security objective of enclaved applications
that operate as a service in an untrusted cloud environment, with-
out ever breaking confidentiality. This threat is especially relevant
for legacy applications that employ the x87 FPU, which can be
maliciously downgraded from 64-bit double-extended precision
to a mere 24-bit single precision mode. We illustrate that such at-
tacks on the x87 FPU can lead to persistent misclassification in
an exemplary enclaved image recognition neural network, as well
as subtle, yet visible quality-degradation artifacts in 3D rendering
algorithms. To the best of our knowledge, these case studies for
the first time explore a new and stealthy class of integrity-only
attacks that purposefully disturb the end result of outsourced en-
clave computations without ever breaching confidentiality, thus
potentially defeating even severely reduced ‚Äútransparent enclave
execution‚Äù paradigms [37]. This perspective represents a notable
change in direction compared to prior TEE attack research, which
has so far only focused on abusing enclaved execution integrity
flaws as a stepping stone to ultimately breach confidentiality, e.g.,
through memory-safety misbehavior [3, 23, 43], undervolting [33],
or incorrect transient-execution paths [6, 41, 42]. By contrast, our
work shows that, even when the processed data is not considered
secretive and the enclave binary is free from any application-level
vulnerabilities, current widely used shielding systems cannot al-
ways safeguard the correctness of outsourced computation results.

Controlled-channel attacks. In a second and complementary
angle, we explore the impact of ABI poisoning on the confidentiality
of enclaved floating-point operations by showing that attacker-
induced FPU or SSE exceptions can be abused as an innovative
new type of controlled-channel attack [48]. Using this technique,

enclave shielding runtimeEENTERTier 3APPTier 2APITier 1ABIFaulty Point Unit: ABI Poisoning Attacks on Intel SGX

ACSAC 2020, December 7‚Äì11, 2020, Austin, USA

we show that attackers can deterministically detect the occurrence
of x87 instructions in secret-dependent code paths and may even
partially reconstruct SSE operand values in straight-line code.

Specifically, in cases where an enclave multiplies a user-controlled
input with a secret learned parameter, such as the weights in a
neural network, attackers may partially reconstruct the secret mul-
tiplier by forcefully enabling floating-point exceptions before enter-
ing the victim enclave and abusing the mere occurrence or absence
of a subsequent ‚Äúdenormal operand‚Äù exception for a carefully cho-
sen input as an unconventional side channel. This technique is
closely related to a powerful class of controlled-channel attacks
that have previously abused side-channel leakage from x86 CPU
exception events to spy on memory addresses accessed by a victim
Intel SGX enclave through either page faults [48], segmentation
faults [17], or alignment-check exceptions [43]. Our ABI-level at-
tacks, on the other hand, directly reconstruct full data operand
values for selected floating-point operations, and, hence, for the
first time extend the threat of controlled-channel attacks beyond
leaking address-related metadata for memory operations.

Our contributions. In summary, we make the following main

contributions:

‚Ä¢ A novel ABI-level fault-injection attack that allows unprivileged
adversaries to influence the precision, rounding, and exception
behavior of x87 or SSE floating-point operations in at least 5
popular Intel SGX enclave shielding runtimes.

‚Ä¢ An innovative controlled channel that abuses floating-point ex-

ceptions to recover enclaved multiplication operands.

‚Ä¢ An exploration of a new class of quality-degradation attacks
that stealthily compromise the integrity of supposedly secure
outsourced enclave computation results.

‚Ä¢ A demonstration of practical FPU attacks in an end-to-end ma-
chine learning case study enclave and a larger analysis of attacker-
induced floating-point errors on the SPEC suite.

Finally, we formulate recommendations for principled ABI san-
itization and we argue that this attack surface is non-trivial to
patch. Specifically, our analysis revealed insufficient FPU sanitiza-
tion patches in two production-quality runtimes [13, 30] that were
explicitly aware of this attack surface. We show that, despite the
initial patches for these runtimes, it was still possible for ABI-level
unprivileged attackers to silently override the outcome of trusted
in-enclave x87 computations with indefinite NaN outcomes.

Responsible disclosure. The main security vulnerabilities ex-
ploited in this work have been assigned CVE-2020-0561 by Intel,
for the sanitization oversight in the Intel SGX-SDK, and CVE-2020-
15107 by Microsoft, for the remaining attack surface after the initial
mitigation attempt in OpenEnclave. While the initial mitigation
attempt in OpenEnclave served as inspiration for our work, both
the issue in the Intel SGX-SDK and the remediation of insufficient
patches were then responsibly disclosed through the proper chan-
nels for the affected production runtimes. Intel, Microsoft, Fortanix,
and Go-TEE acknowledged the issue and applied our recommended
patches in the enclave entry code for the SGX-SDK v2.8, Open-
Enclave v0.10.0, and the Rust compiler v1.46.0, respectively. We

provide our case studies and proof-of-concept exploits as open-
source artifact for other researchers to independently evaluate and
build upon our findings1.

2 BACKGROUND
This section introduces the necessary background on SGX enclaves
and Intel processor support for floating-point computations through
the x87 FPU and SSE vector extensions, respectively.

2.1 Intel SGX
Intel Software Guard Extensions (SGX) [10, 20], are a set of hard-
ware instructions that allow to create trusted regions of code called
enclaves that are shielded from the surrounding, potentially un-
trusted Operating System (OS). The SGX promise is that enclave
applications can access almost all capabilities of the user-mode x86
instruction set, while at the same time being provided with strong
hardware-backed memory isolation and the capability of attesting
code to remote parties. SGX protects enclave memory from outside
access and provides instructions to enter and exit enclave mode.
When encountering exceptions or interrupts during enclaved exe-
cution, the CPU securely saves and scrubs the full extended register
set inside the enclave, to be later restored when the enclave is re-
sumed. However on initial enclave entry into registered call gates,
named ecalls, the cleansing and sanitization of registers is the
responsibility of the software. Due to this challenge, multiple en-
clave shielding runtimes (cf. Figure 1) have emerged that take over
this sanitization on enclave entry, bring the processor into a clean
state, and then forward execution to the intended application bi-
nary inside the enclave. This not only lowers application developer
effort to adopt enclaved execution but also streamlines the miti-
gation of vulnerabilities on ABI-level. While a 64-bit operation is
the norm for SGX enclaves, a 32-bit compatibility mode is officially
supported.

2.2 x87 FPU
The x87 FPU [20] provides an environment to perform floating-
point and other math operations. For this, the x87 FPU has eight
80-bit data registers that are used internally as a register stack
during computation of FPU instructions. The 80 bits in the registers
are designed to ensure a high precision inside the FPU to minimize
floating-point errors of data that is returned back from the data
registers to memory. With 1 bit used for the sign and 14 bits used
for the exponent, one 80-bit register utilizes 64 bits to store the
significand of a floating-point variable which Intel calls double-
extended precision. The internal data registers of the x87 FPU by
default utilize the full 64 bits of the significand during computations.
In addition, the x87 FPU also contains a control register that can be
set with the FPU Control Word as shown in Figure 2. This control
register allows to specify two additional precision formats, namely
double precision with 53 bits used for the significand and single
precision with only 24 bits for the significand. These additional
precision modes enable compatibility with the IEEE Standard 754
and legacy programs or older programming languages.

Besides limited precision, another important aspect of floating-
point operations is the rounding mode. Whenever a floating-point

1https://github.com/fritzalder/faulty-point-unit

3

ACSAC 2020, December 7‚Äì11, 2020, Austin, USA

Alder et al.

Figure 2: Layout of the x87 FPU control word.

number can not be represented exactly with the given precision, the
FPU needs to make a decision whether to choose the next higher
or next lower possible representation. By default the x87 FPU will
round to the nearest value, but developers can choose to override
this in the control word and enforce rounding up, rounding down,
or rounding toward zero. Naturally, the impact of the rounding
mode is greater for computations in single-precision mode than
for computations in double-extended precision as rounding errors
accumulate faster and the distance between two floating-point
numbers that can be represented with the given precision is larger.
Figure 2 shows those fields of the FPU control word that con-
trol the behavior of FPU operations in red. These are the Precision
Control (PC) bits 8 and 9, and the Rounding Control (RC) bits 10
and 11. Fields that control the masking of floating-point exceptions
are shown in orange in the figure. Bits 0 to 5 can be used to mask
any of the 6 floating-point exceptions that may be triggered by the
x87 FPU. Notable examples of exceptions the FPU might encounter
include underflow when a result becomes subnormal, also referred
to as ‚Äúdenormal‚Äù, and overflow when the result can no longer be
represented in the respective floating-point type. Exceptions are
masked by default, instructing the FPU to continue with some safe
default values. However, in case programmers want to be notified
about these events, individual exception types can be unmasked by
clearing the respective bits in the FPU control word, e.g., through
the C library function feenableexcept(). When encountering an
unmasked exception, the FPU will stop operation and program-
mers can register a custom SIGFPE signal handler through the OS.
Lastly, the remaining non-relevant bits in the FPU control word are
marked gray. These are bits 6,7, and 13-15 which are reserved and
bit 12 which exists for compatibility reasons and is not meaningful
anymore for current versions of the x87 FPU.

Importantly, since the x87 FPU control word defines global pro-
gram behavior, it is expected by the ABI to be initialized to a pre-
defined sane state 0x37f that should be preserved across function
calls, except for procedures that have the explicit intention of glob-
ally changing the FPU configuration [12, 26]. Furthermore, on Intel
processors supporting MMX technology [20], the eight x87 floating-
point registers can also be utilized as general-purpose MMX vector
registers. However, since the MMX registers are internally aliased to
the x87 FPU register stack, care should be taken when mixing MMX
and x87 instructions. Specifically, any MMX instruction marks the
entire x87 stack as in-use and developers are required to issue a
special emms instruction to clear the register stack before executing
any subsequent x87 operation. Failure to do so may produce un-
expected results, and compiler ABIs hence demand that ‚Äúthe CPU
shall be in x87 mode upon entry to a function‚Äù [26].

4

Figure 3: Layout of the MXCSR control/status register.

2.3 Streaming SIMD Extensions (SSE)
In order to further speed up floating-point arithmetics, recent Intel
processors include vector extensions that operate independently of
the x87 FPU and allow for high performance of parallelized calcula-
tions. The line of Streaming SIMD Extensions (SSE) [20] supports
parallel floating-point operations on 128-bit vector registers holding
either four 32-bit single-precision or two 64-bit extended-precision
floating-point numbers. In contrast to the x87 FPU which calcu-
lates intermediate results with 80 bits of precision, SSE processes
a vector of operands in parallel with a fixed (but lower) precision
that cannot anymore be dynamically degraded by the developer.

Similar to the x87 control word, SSE offers a global MXCSR control
register to configure the rounding mode and exception behavior,
as shown in Figure 3. The SSE rounding control bits 13-14 (red)
and floating-point exception mask bits 7-12 (orange) work identi-
cal to those described earlier for the x87 FPU. In addition, MXCSR
provides status flags 0-5 (green) that indicate whether one of the
six floating-point exceptions occurred and configuration bits to
specify the behavior when encountering subnormal numbers and
underflow conditions. Specifically, bit 15 is called the Flush-To-Zero
bit and can be used to enter a mode that flushes the result to zero
whenever an underflow is encountered which slightly reduces pre-
cision of the calculations for the benefit of increased performance.
Bit 6 can be used to enter the Denormals-Are-Zeroes mode that
treats all subnormal numbers as zeroes. Neither of these two modes
is compatible with the IEEE Standard 754 and both of them are
disabled by default [20]. Again similar to the x87 control word, the
configuration bits in the global MXCSR register are expected by the
ABI to be initialized to a predefined state 0x3f80 and preserved
across function calls [12, 26].

The performance gain of parallelized SSE vector floating-point
operations is leveraged by most modern compilers. For example gcc,
the GNU Compiler Collection, defaults to the SSE when compiling
for 64-bit targets [14]. Similarly, Microsoft Visual C++ defaults to
the SSE for modern 64-bit applications [31]. For compatibility with
32-bit and legacy systems, both compilers also provide options to
compile applications without the SSE and with all math operations
purely executed by the x87 FPU. In gcc, this compiler option is
called -mfpmath=387. At the same time, the x87 FPU remains fully
supported also for modern 64-bit applications and default compila-
tion options. One notable example is the C data type long double
which is defined as ‚Äúat least as large as the float type, and it may be
larger‚Äù [14]. Some compilers as such aim to use the maximum avail-
able precision for this data type, which means utilizing the full 80-bit
precision of the x87 FPU instead of the 64-bit precision provided by
the SSE. For example, gcc will default to x87 instructions whenever
a long double variable is involved and will regularly switch data
between the FPU and SSE data register stacks if the SSE was utilized
by a support library such as libm. Furthermore, gcc provides an
experimental compilation option called -mfpmath=both to utilize a

Precision Control00b = Single prec (24 bits)01b = Reserved10b = Double prec (53 bits)11b = Extended prec (64 bits)Rounding Control00b = To nearest01b = Down10b = Up11b = Toward ZeroRCPC09101513123exceptionmasks45671211148RCexceptionmasks09101513123exceptionÔ¨Çags456712111481631Rounding ControlFaulty Point Unit: ABI Poisoning Attacks on Intel SGX

ACSAC 2020, December 7‚Äì11, 2020, Austin, USA

combination of SSE and x87 FPU for increased performance beyond
just using it for long double variables [14]. Overall, the x87 FPU,
while not being the default compilation target for all platforms any-
more, is still relevant for calculations that require the high precision
of long double variables or for legacy applications.

3 POISONING FPU STATE REGISTERS
This section first elaborates on the assumed attacker capabilities and
system model. Thereafter, we analyze the different attack avenues
that may arise in case of insufficient ABI-level sanitization, and we
provide a toy example that illustrates their impact on the integrity
of exemplary enclave computations. Finally, we conclude with a
systematic vulnerability assessment of this attack surface across 7
widely used SGX shielding runtimes.

3.1 Attacker and system model
We assume the standard Intel SGX threat model [10] where only
the processor and the software executing inside the enclave are
to be trusted. Notably, while Intel SGX explicitly excludes the OS
from the trusted computing base and aims to protect even against
adversaries who have gained root access to the target platform [44],
we demonstrate our exploits with a considerably weaker attacker
model. Particularly, we only assume user-space code execution in
the untrusted host application so as to invoke the enclave with
custom ABI-level register settings and to optionally install signal
handlers via the OS interface. This falls within the capabilities of
any unprivileged user who has access to the enclave binary.

Following widespread industry practice [2, 4, 13, 15, 19, 30, 35,
39], we assume the use of a shielding runtime that intervenes on
enclave entry and exit to transparently protect the enclaved ap-
plication binary from its untrusted environment. Specifically, we
consider the explicit security objective of the shielding runtime to
be to (i) make sure that an enclaved application behaves exactly
like on a trusted OS, and (ii) prevent any avoidable information
leakage beyond what is allowed through explicit interaction with
the application. As an example of the first requirement, previous
research has shown that the shielding runtime should clear the
direction flag in the x86 status register on enclave entry to avoid
unexpected memory corruption for string operations [43]. As an
example of the second requirement, runtimes should scrub low-
level CPU registers that do not form part of the calling convention
before exiting the enclave to avoid leaking intermediary state [43].
We assume that the Intel SGX TEE is properly patched against
microarchitectural vulnerabilities [6, 41, 42], such that the shielding
system can provide enclaved computation results to remote parties
as if they were executed on a trusted OS. In this respect, we con-
sider it to be the objective of the shielding runtime to transparently
protect any ABI-compliant x86 application binary. The latter can
include legacy libraries and can be generated by an arbitrary com-
piler, as long as ABI-level calling conventions [12] are respected,
that can hence make use of the full power of the x86 instruction
set permitted inside SGX enclaves. In some of our case studies,
only when explicitly mentioned, we may emphasize this point by
instrumenting the compiler to make increased use of the x87 FPU in-
stead of more modern SSE features by means of the -mfpmath=387

5

gcc compiler flag. It should be stressed, however, that the result-
ing application binaries remain fully legit ABI-compliant x86 code
that may for instance also have been generated by older or more
specialized compilers [14].

3.2 ABI poisoning attacks
While trusted code can be relied on to respect ABI calling con-
ventions [12, 26], this does not hold anymore for ecall functions
exposed to the untrusted world. The shielding runtime hence has
the crucial responsibility to bridge this trust semantics gap by sani-
tizing the ABI on enclave entry. Before showing in Section 3.3 that
this requirement is not sufficiently understood in today‚Äôs widely
used SGX shielding runtimes, we first elaborate below on what are
the exact security implications of insufficient initialization of x87
and SSE registers, respectively.

Poisoning x87 FPU state. When the shielding system does not
cleanse the x87 control word, attackers may execute the unprivi-
leged fldcw instruction before entering the enclave to control all
bits described in Section 2.2 and Figure 2. In fact, executing this
instruction at any point before entering the enclave suffices to suc-
cessfully implement the attack as long as the x87 control word
does not get modified in-between. Since programs rarely modify
the x87 control word as long as they are not performing floating
point operations, the attack may often be performed in advance
instead of right before the actual ecall. In the following, we assume
however that the attacker loads the desired x87 control word as the
last instruction before switching into the enclave which ensures
that the x87 control register is in the desired state. The immediately
obvious impactful fields the attacker can target are bits 8-9 to de-
grade the precision and bits 10-11 to alter the rounding mode for
enclaved x87 floating-point operations. We will show in Sections 5
and 6 that the impact of a maliciously downgraded x87 precision
can be especially devastating in larger applications. Additionally,
by selectively unmasking floating-point exceptions and registering
a signal handler, attackers may be informed of certain, possibly
secret-dependent, FPU events that would otherwise pass unnoticed.
Furthermore, when the shielding runtime does not explicitly
initialize the x87 register stack, it may be incorrectly left in MMX
mode. For this, it suffices that the attacker executes any MMX oper-
ation that is not followed by an emms instruction before entering the
enclave. Since an ABI-compliant enclave application expects the
CPU to be in x87 mode with all registers available, any following
attempt to load data into an x87 register will cause an unexpected
FPU register stack overflow event, as the CPU still is incorrectly in
MMX mode with all eight floating-point registers marked as in-use.
The exact behavior in this case will depend on the corresponding
exception mask bit in the FPU control word. In the default case
where exceptions are masked, the processor will silently replace
the intended x87 destination register with an indefinite value (NaN)
and continue execution. We experimentally confirmed that such
attacker-injected unintended NaN values are silently propagated
further, which is a clear violation of computational integrity and
may further cause unexpected or incorrect behavior depending on
the victim application.

Alternatively, in the case where exception bits in the x87 control
word are craftily unmasked before enclave entry, the attacker will

ACSAC 2020, December 7‚Äì11, 2020, Austin, USA

Alder et al.

be notified by means of an FPU exception signal whenever the
enclave loads an x87 register. This technique is somewhat similar to
prior controlled-channel attacks on Intel SGX, which have abused
memory contention through page-fault exceptions [48] to spy on
enclave-private page accesses. Essentially, by adversely filling the
FPU register stack with MMX instructions before enclave entry,
the attacker causes unexpected contention that can be used as side
channel to learn subsequent use of the FPU by the enclave. We
experimentally verified that this technique can be abused as an
innovative controlled channel to deterministically recognize x87
instructions in a secret-dependent code path. We note that privi-
leged attackers could further improve the temporal resolution of
this novel FPU controlled channel by relying on the SGX-Step [44]
enclave execution control framework to exactly pinpoint on which
instruction the exception has been raised. SGX-Step leverages care-
fully scheduled timer device interrupts and has been shown to de-
terministically advance production enclaves exactly one instruction
at a time [32, 44]. FPU poisoning adversaries can, hence, precisely
establish the relative instruction offset of enclaved x87 operations
by merely counting the number of SGX-Step interrupts before de-
tecting the FPU exception signal.

We finally note that the above x87 FPU poisoning attacks can
even impact programs that were never explicitly compiled as x87
FPU programs. Section 2.3 indeed explained that some compilers,
including gcc, still utilize the x87 FPU in certain scenarios such as
for long double data types.

Poisoning SSE state. Compared to the x87 FPU, the more recent
SSE floating-point extensions include less configuration bits and
hence also expose a smaller ABI-level attack surface. However, we
found that when the shielding system does not sanitize the control
bits in the MXCSR register, attackers may execute the unprivileged
ldmxcsr instruction before entering the enclave to control all bits
described in Section 2.3 and Figure 3. Similar to the FPU attacks
described above, this allows the attacker to maliciously alter the
in-enclave rounding mode through bits 13-14 and to arbitrarily
unmask floating-point exceptions through bits 7-12. Unlike the x87
FPU, the precision of SSE floating-point operations is fixed and can
hence not be overridden by the attacker.

We demonstrate below that poisoning the SSE rounding mode
may adversely impact the integrity (i.e., the expected outcome) of
certain in-enclave floating-point computations. Section 4 further-
more introduces a case study which exploits the adversary‚Äôs control
over the denormal-operand SSE exception mask as an innovative
controlled channel to reconstruct secret in-enclave multiplication
operands.

A toy example. We exemplify the threat of ABI-level poisoning
attacks on the integrity of enclaved floating-point computations by
means of two types of math operations: one complex operation that
relies on the standard math library included in the Intel SGX-SDK,
and one example of a simple multiplication of two floating-point
numbers. The complex example is an approximation of the number
œÄ by calculating arccos(-1) with the acosl function provided by
math.h and the second example is a calculation of 2.1‚àó3.4. To
achieve a maximum precision, the code utilizes variables of the
long double type, which the compiler translates to predominantly
x87 FPU instructions. For completeness, both the minimal C code

Table 1: Proof-of-concept attack executed inside an enclave.

and the resulting assembly instructions can be viewed in Section A.
The enclave was compiled with a recent gcc v7.4.0 with standard
compilation flags under Ubuntu 18.04.1 and with the Intel SGX-SDK
v2.7.1. All evaluations were performed on an Intel i5-1035G1.

Table 1 shows the attack in practice by listing the results of an
executed enclave with attacker-primed FPU registers before the
ecall into the enclave. For all depicted values, the FPU CW and the
MXCSR were set to the desired value via the fldcw and the ldmxcsr
instruction respectively right before the enclave was entered. Illus-
trated are four FPU groups of possible attack modes available to an
ABI poisoning adversary, with the expected (unpoisoned) default
mode highlighted. In the first three FPU groups, the attacker sets the
x87 FPU control word to operate in either single-precision, double-
precision, or extended-precision mode. These precision modes are
then combined with each of the four available rounding modes set
in both the FPU control word and the MXCSR register to affect the
operation of the x87 FPU as well as SSE instructions. The last FPU
group targets the MMX mode by marking all x87 registers as in-use,
as described above, which always yields NaN independent of the
rounding mode. For readability, all computation results are listed
with a precision of 10‚àí30 and cut off after the last digit.

As a first interesting observation, the results of the calculation
of œÄ listed in the middle column remain unaffected by the choice
of the x87 precision mode. Up to the order of 10‚àí19, the calculated
approximation is identical with the actual value of œÄ across all
possible x87 precision modes. Only the rounding mode can degrade
the precision of this single math library calculation in the order of
10‚àí19. Specifically, the rounding modes to nearest and upward both
achieve the baseline precision while the rounding modes down-
ward and towards zero have a degraded performance. This example
shows that even when relying on standard math libraries, the at-
tacker can partly degrade the quality of calculations. At the same
time, it is evident that although the compiler relied on the x87 FPU
to satisfy the precision requirements of the long double data type,
the results remain unaffected by the modified precision mode. The
reason for this is the fact that the acosl library function is inter-
nally implemented using SSE instructions, and hence the actual
computation is not performed by the x87 FPU in this case. Listing 3
in Section A shows that the compiler-generated code transfers the
x87 data into the SSE registers and similarly retrieves the data after

6

ACSAC2020,December7‚Äì11,2020,Austin,USAAlderetal.benotifiedbymeansofanFPUexceptionsignalwhenevertheenclaveloadsanx87register.Thistechniqueissomewhatsimilartopriorcontrolled-channelattacksonIntelSGX,whichhaveabusedmemorycontentionthroughpage-faultexceptions[48]tospyonenclave-privatepageaccesses.Essentially,byadverselyfillingtheFPUregisterstackwithMMXinstructionsbeforeenclaveentry,theattackercausesunexpectedcontentionthatcanbeusedassidechanneltolearnsubsequentuseoftheFPUbytheenclave.Weexperimentallyverifiedthatthistechniquecanbeabusedasaninnovativecontrolledchanneltodeterministicallyrecognizex87instructionsinasecret-dependentcodepath.Wenotethatprivi-legedattackerscouldfurtherimprovethetemporalresolutionofthisnovelFPUcontrolledchannelbyrelyingontheSGX-Step[44]enclaveexecutioncontrolframeworktoexactlypinpointonwhichinstructiontheexceptionhasbeenraised.SGX-Stepleveragescare-fullyscheduledtimerdeviceinterruptsandhasbeenshowntode-terministicallyadvanceproductionenclavesexactlyoneinstructionatatime[32,44].FPUpoisoningadversariescan,hence,preciselyestablishtherelativeinstructionoffsetofenclavedx87operationsbymerelycountingthenumberofSGX-Stepinterruptsbeforede-tectingtheFPUexceptionsignal.Wefinallynotethattheabovex87FPUpoisoningattackscanevenimpactprogramsthatwereneverexplicitlycompiledasx87FPUprograms.Section2.3indeedexplainedthatsomecompilers,includinggcc,stillutilizethex87FPUincertainscenariossuchasforlongdoubledatatypes.PoisoningSSEstate.Comparedtothex87FPU,themorere-centSSEfloating-pointextensionsincludelessconfigurationbitsandhencealsoexposeasmallerABI-levelattacksurface.How-ever,wefoundthatwhentheshieldingsystemdoesnotsanitizethecontrolbitsintheMXCSRregister,attackersmayexecutetheunprivilegedldmxcsrinstructionbeforeenteringtheenclavetocontrolallbitsdescribedinSection2.3andFig.3.SimilartotheFPUattacksdescribedabove,thisallowstheattackertomaliciouslyalterthein-enclaveroundingmodethroughbits13-14andtoarbitrarilyunmaskfloating-pointexceptionsthroughbits7-12.Unlikethex87FPU,theprecisionofSSEfloating-pointoperationsisfixedandcanhencenotbeoverriddenbytheattacker.WedemonstratebelowthatpoisoningtheSSEroundingmodemayadverselyimpacttheintegrity(i.e.,theexpectedoutcome)ofcertainin-enclavefloating-pointcomputations.Section4further-moreintroducesacasestudywhichexploitstheadversary‚Äôscontroloverthedenormal-operandSSEexceptionmaskasaninnovativecontrolledchanneltoreconstructsecretin-enclavemultiplicationoperands.Atoyexample.WeexemplifythethreatofABI-levelpoisoningattacksontheintegrityofenclavedfloating-pointcomputationsbymeansoftwotypesofmathoperations:onecomplexoperationthatreliesonthestandardmathlibraryincludedintheIntelSGX-SDK,andoneexampleofasimplemultiplicationoftwofloating-pointnumbers.Thecomplexexampleisanapproximationofthenumberùúãbycalculatingarccos(-1)withtheacoslfunctionprovidedbymath.handthesecondexampleisacalculationof2.1‚àó3.4.Toachieveamaximumprecision,thecodeutilizesvariablesofthelongdoubletype,whichthecompilertranslatestopredominantlyx87FPUinstructions.Forcompleteness,boththeminimalCcodeandTable1:Proof-of-conceptattackexecutedinsideanenclave.FPURoundingarccos(-1)=ùúã2.1‚àó3.4=7.14SingleprecisionTonearest3.14159265358979323851280897.1399998664855957031250000Downward3.14159265358979323829596857.1399998664855957031250000Upward3.14159265358979323851280897.1400003433227539062500000Tozero3.14159265358979323829596857.1399998664855957031250000DoubleprecisionTonearest3.14159265358979323851280897.1399999999999996802557689Downward3.14159265358979323829596857.1399999999999996802557689Upward3.14159265358979323851280897.1400000000000005684341886Tozero3.14159265358979323829596857.1399999999999996802557689ExtendedprecisionTonearest3.14159265358979323851280897.1400000000000001156713613Downward3.14159265358979323829596857.1400000000000001152376805Upward3.14159265358979323851280897.1400000000000001156713613Tozero3.14159265358979323829596857.1400000000000001152376805MMXAny-NaN-NaNtheresultingassemblyinstructionscanbeviewedinAppendixA.Theenclavewascompiledwitharecentgccv7.4.0withstandardcompilationflagsunderUbuntu18.04.1andwiththeIntelSGX-SDKv2.7.1.AllevaluationswereperformedonanInteli5-1035G1.Table1showstheattackinpracticebylistingtheresultsofanexecutedenclavewithattacker-primedFPUregistersbeforetheecallintotheenclave.Foralldepictedvalues,theFPUCWandtheMXCSRweresettothedesiredvalueviathefldcwandtheldmxcsrinstructionrespectivelyrightbeforetheenclavewasentered.Illus-tratedarefourFPUgroupsofpossibleattackmodesavailabletoanABIpoisoningadversary,withtheexpected(unpoisoned)defaultmodehighlighted.InthefirstthreeFPUgroups,theattackersetsthex87FPUcontrolwordtooperateineithersingle-precision,double-precision,orextended-precisionmode.TheseprecisionmodesarethencombinedwitheachofthefouravailableroundingmodessetinboththeFPUcontrolwordandtheMXCSRregistertoaffecttheoperationofthex87FPUaswellasSSEinstructions.ThelastFPUgrouptargetstheMMXmodebymarkingallx87registersasin-use,asdescribedabove,whichalwaysyieldsNaNindependentoftheroundingmode.Forreadability,allcomputationresultsarelistedwithaprecisionof10‚àí30andcutoffafterthelastdigit.Asafirstinterestingobservation,theresultsofthecalculationofùúãlistedinthemiddlecolumnremainunaffectedbythechoiceofthex87precisionmode.Uptotheorderof10‚àí19,thecalculatedapproximationisidenticalwiththeactualvalueofùúãacrossallpossiblex87precisionmodes.Onlytheroundingmodecandegradetheprecisionofthissinglemathlibrarycalculationintheorderof10‚àí19.Specifically,theroundingmodestonearestandupwardbothachievethebaselineprecisionwhiletheroundingmodesdown-wardandtowardszerohaveadegradedperformance.Thisexampleshowsthatevenwhenrelyingonstandardmathlibraries,theat-tackercanpartlydegradethequalityofcalculations.Atthesametime,itisevidentthatalthoughthecompilerreliedonthex87FPUtosatisfytheprecisionrequirementsofthelongdoubledatatype,theresultsremainunaffectedbythemodifiedprecisionmode.Thereasonforthisisthefactthattheacosllibraryfunctionisinter-nallyimplementedusingSSEinstructions,andhencetheactualcomputationisnotperformedbythex87FPUinthiscase.Listing3inAppendixAshowsthatthecompiler-generatedcodetransfersthex87dataintotheSSEregistersandsimilarlyretrievesthedata6Faulty Point Unit: ABI Poisoning Attacks on Intel SGX

ACSAC 2020, December 7‚Äì11, 2020, Austin, USA

acosl has returned. In summary, the attack surface is somewhat
limited whenever the victim code utilizes library functions that are
not compiled to x87 instructions.

The capabilities of an attacker that targets victim code which
solely relies on x87 calculations, however, can be seen in the right
column of Table 1. The right column of the table lists the results of
the calculation 2.1 ‚àó 3.4 which is performed without any external
libraries and is, as such, by default compiled into pure x87 instruc-
tions due to its long double data type. Notice that this simple
multiplication already experiences a floating-point representation
error in the highlighted base mode, which is an inherent conse-
quence of limited-precision numerical representations. However,
the table clearly shows that ABI attackers can significantly magnify
the error with several orders of magnitude. While in the default
extended-precision mode, the error for our exemplary multipli-
cation lies in the order of 10‚àí19, this error increases to the order
of 10‚àí16 in double-precision mode and lastly to the order of 10‚àí7
in single-precision mode. Observe that for each precision mode,
rounding upward yields the next higher floating-point number that
can be represented in the given precision, whereas the other three
rounding modes yield identical results for this particular example.
It is important to note that any successive calculation on the cor-
rupted result in larger applications would be exposed to an ever
increasing floating-point error. In this respect, our example also
highlights a remarkable discrepancy: while attentive enclave devel-
opers would aim to utilize the maximum available precision and
minimize the effects of inherent floating-point imprecisions, the
usage of the long double data type for this purpose also exposes
the enclave to increased attack surface for x87 ABI attackers.

The last row finally shows the impact of the MMX attack that
always silently replaces the expected outcome with an incorrect
-NaN result. As discussed previously, this error results from the x87
FPU not being able to determine a usable floating-point register on
the register stack and aborting the calculation.

3.3 TEE runtime vulnerability assessment
In order to methodologically assess the prevalence of ABI-level
FPU poisoning attack surface in real-world SGX shielding runtimes,
we performed a comprehensive vulnerability assessment of the 7
open-source projects summarized in Table 2. Our selection was
motivated by a recent extensive study [43] of popular Intel SGX
shielding runtimes, which we extended with two newer runtimes [4,
15] that were not analyzed before. Particularly, we examined all
predominant SGX shielding solutions in use by industry, namely
Intel‚Äôs SGX-SDK [19], Microsoft‚Äôs OpenEnclave [30], Fortanix‚Äôs
Rust-EDP [13], and RedHat‚Äôs Enarx [4], as well as three relevant
runtimes that were, at least initially, developed as research projects,
namely Graphene-SGX [38], SGX-LKL [35], and Go-TEE [15]. This
wide selection highlights that our ABI-level vulnerabilities apply
to both research and production code, emerging safe languages
like Rust and Go as well as traditional unsafe languages like C or
C++, and SDK-based secure function interfaces as well as library
OS-based system call shielding systems.

A first conclusion from Table 2 is that prior to October 2019, i.e.,
before the initial Patch by Microsoft OpenEnclave, all 7 runtimes
were originally vulnerable to the ABI poisoning attacks described

Table 2: Marked runtimes were demonstrated to not (‚ãÜ) or
only partially (‚ãÜ) sanitize FPU/SSE state, whereas empty
symbols (
) indicate that the runtime was not vulnerable at
the time of our initial analysis (Nov 2019). When applicable,
applied and potentially remediated Patches are provided.

(cid:35)

S D K ‚àó

X -

G

S

n

E

n

e

O p

e

v

c l a

e

n

e

h

p

a

G r

G

S

‚ãÜ

Exploit
Patch 1 xrstor ldmxcsr/cw fxrstor
Patch 2

xrstor

(cid:35)

‚ãÜ

L

X -

‚ãÜ
‚Äì

L

K

E D P

s t -

u

R

E

E

T

-

o

G

x

r

a

n

E

‚ãÜ

‚ãÜ

ldmxcsr/cw xrstor xrstor

(cid:35)

xrstor

‚àó Includes derived runtimes such as Apache Teaclave‚Äôs Rust SGX SDK [36] (formerly
Baidu Rust-SGX [46]) and Google‚Äôs Asylo [16].

in this work. Indeed, our initial analysis was motivated by a par-
tial ABI hardening patch in OpenEnclave in October 2019, which
subsequently appears to have been picked up by Graphene-SGX
developers as well. For the remaining runtimes, we then performed
our initial analysis in November 2019 where we experimentally
demonstrated that the SGX-SDK, Rust-EDP, SGX-LKL, and Go-TEE
all similarly lacked any form of FPU or SSE register sanitization.
We reported these issues and in the case of the SGX-SDK, this can
be tracked via CVE-2020-0561/Intel-SA-00336, which also affects
derived runtimes, such as Apache Teaclave‚Äôs Rust SGX SDK [36]
(formerly Baidu Rust-SGX [46]) and Google‚Äôs Asylo [16], that build
on top of the SGX-SDK.

A second tendency in Table 2 relates to the mitigation strate-
gies applied in the different runtimes. Particularly, following our
recommendations for more principled ABI sanitization, Intel re-
sponded to our disclosure by patching the shielding runtime with an
explicit xrstor instruction that fully initializes the entire processor-
extended state on every enclave entry. This is also the mitigation
applied by Enarx2 and Go-TEE. Note that SGX-LKL is depicted
in Table 2 as not to sanitize the FPU/SSE state because of their
unmaintained assembly entry code into the shielding enclave. How-
ever, SGX-LKL has been in a migration process in order to utilize
the code base of Microsoft OpenEnclave in favor of self-written
assembly stubs. As such, once SGX-LKL is fully migrated to utilize
OpenEnclave, it will inherit the mitigations implemented there.

In response to our disclosure, Rust-EDP adopted the original
mitigation strategy of OpenEnclave, which merely sanitizes the
SSE configuration register and the x87 control word through the
ldmxcsr and fldcw instructions respectively. While this approach
appears sufficient at first sight, and avoiding a full xrstor may
indeed be motivated from a performance perspective, we make
the crucial observation that fldcw does not clear the x87 regis-
ter stack and hence cannot protect the enclave against the MMX
poisoning attack variants described above. Specifically, we experi-
mentally demonstrated that on the initially patched Rust-EDP and
OpenEnclave runtimes, we can still forcibly put the processor in
MMX mode before entering the enclave and cause the outcome of
trusted in-enclave x87 FPU operations to be incorrectly replaced
with NaN values, which are further propagated silently and may
cause application-specific misbehavior. Hence, while the initial

2Enarx is an ongoing project, still under active development, which is only included
for completeness here. The specific runtime entry sanitization code was committed in
March 2020, in completion of a longer-standing documented issue.

7

ACSAC 2020, December 7‚Äì11, 2020, Austin, USA

Alder et al.

patches in these runtimes do severely reduce the attack surface
by cleansing MXCSR and the FPU control word, they fail to fully
shield the enclave application binary from our attacks. To fully rule
out MMX attack variants as well, the runtime should minimally
execute an additional emms instruction to place the FPU in the ex-
pected x87 mode. The mitigation implemented by the Graphene
developers who used an fxrstor instruction is sufficient to also
rule out this followup MMX attack as it cleanses all state related
to the FPU, MMX, XMM, and MXCSR registers. However, in light
of our findings, we explicitly recommend that shielding runtimes
adopt the more principled and future-proof strategy of cleansing the
entire processor-extended state through xrstor on every enclave
entry. Both OpenEnclave and Rust-EDP acknowledged the remain-
ing attack surface of an insufficient ldmxcsr/cw mitigation, and
our recommended full xrstor approach was integrated into their
respective projects. Microsoft additionally assigned this followup
issue CVE-2020-15107.

4 CASE STUDY: FLOATING-POINT

EXCEPTIONS AS A SIDE CHANNEL

Background. Apart from allowing to compromise computa-
tions, an adversary can also use the FPU state registers to obtain
side-channel information about floating-point computations inside
SGX enclaves. Notably, this side channel also applies to floating-
point operations carried out using the SSE extensions, i.e., with
standard compiler settings and without the special requirement to
use the x87 FPU. The base for this side channel are the exception
mask bits that can be set in the MXCSR register right before entering
the enclave and the fact that an attacker can register a custom signal
handler for floating-point exceptions (SIGFPE) to be notified about
the exceptions. Crucially, for SGX enclaves, the signal handler is
untrusted code. This is similar to other controlled-channel attacks,
e.g., attacks based on page faults [48], segmentation faults [17],
or alignment-check exceptions [43]. Note that in contrast to user-
space code, the exact reason for the exception (e.g., underflow or
overflow) is not passed on to the signal handler when triggered
from within SGX. However, we show that this can be overcome by
only unmasking one exception at a time and executing the enclave
multiple times with the same input operands.

In this section, for the sake of simplicity, we focus on double
operands, i.e., the 8-byte IEEE 754 double-precision binary floating-
point format [47]. In this case, the smallest normal number is
nmin ‚âà 2.2250738585072014 ¬∑ 10‚àí308 (hex 0x0010000000000000),
while the largest subnormal is dmax ‚âà 2.2250738585072009 ¬∑ 10‚àí308
(hex 0x000FFFFFFFFFFFFF). Whenever the result of a computation
is ‚â§ dmax , an underflow exception will be triggered. As described
in the following, this can be used as a side channel to infer one
possibly secret operand of an enclaved floating-point computation,
in this particular example a multiplication, if the other operand is
attacker-controlled.

Attack scenario. For example, consider a neural network im-
plementation, where the weights of the network are secrets stored
securely inside an SGX enclave. The input layer of the network
involves multiplications of the attacker-controlled inputs and the
secret weights. For simplicity, we focus on a single multiplication
of two floats secret * input in the following, but note that the

method can be extended to multiple such multiplications by recov-
ering the secret operand one-by-one. Furthermore, for SGX, the
enclave code can be single-stepped [44] which allows to exactly
pinpoint on which instruction an exception has been raised.

For our proof-of-concept, we created an ecall on Intel SGX-
SDK v2.7.1 which multiplies a secret value with an input. The gcc
compiler by defaults generates the SSE instruction mulsd for the
multiplication in Listing 1. Note that the enclave API does not
expose the internal result value to the attacker and we merely focus
on the side-channel signal whether an exception was raised or not.

Secret recovery. To recover secret, in the first step, we deter-
mine if its magnitude is ‚â§ 1. This can be achieved by passing nmin
as input: if an underflow exception is raised, |secret| < 1, because
the result of the multiplication is less than nmin . In the follow-
ing, we describe an attack for the case that |secret| < 1, but we
verified that a similar procedure can be used for the other case
where |secret| ‚â• 1 by leveraging the overflow exception (cf. Al-
gorithm 2 in Section B). Next, knowing that |secret| < 1, we use
binary search to gradually approximate the secret. More precisely,
the attack proceeds as in Algorithm 1: the input is set to 0.5, and
if no underflow occurred, the search continues in the lower half
[0, 0.5] and otherwise in the upper half [0.5, 1]. This process is re-
peated until the difference between the upper and lower bound is
below an attacker-chosen minimal value epsilon.

Algorithm 1: Binary search algorithm to recover a secret
value based on underflow exceptions for operands < 1

Result: recovered_secret
low = 0;
high = 1;
while abs(high - low) >= epsilon do

mid = (low + high) / 2;
secret_mul(mid);
recovered_secret = nmin / mid;
if underflow exception raised then

// continue search in upper half
low = mid;

else

// continue search in lower half
high = mid;

end

end

For our experiments, we set epsilon = 0.00001 ¬∑ 10‚àí308. For this
bound, Algorithm 1 requires a fixed number of 1040 invocations
of the ecall to recover a secret operand. We ran this algorithm for
1000 random, uniformly distributed secrets in the interval [0, 1[,
and computed the difference between the actual and the recov-
ered secret. The histogram of the error is shown in Figure 4. The

8

ACSAC2020,December7‚Äì11,2020,Austin,USAAlderetal.patchesintheseruntimesdoseverelyreducetheattacksurfacebycleansingMXCSRandtheFPUcontrolword,theyfailtofullyshieldtheenclaveapplicationbinaryfromourattacks.TofullyruleoutMMXattackvariantsaswell,theruntimeshouldminimallyexecuteanadditionalemmsinstructiontoplacetheFPUintheex-pectedx87mode.ThemitigationimplementedbytheGraphenedeveloperswhousedanfxrstorinstructionissufficienttoalsoruleoutthisfollowupMMXattackasitcleansesallstaterelatedtotheFPU,MMX,XMM,andMXCSRregisters.However,inlightofourfindings,weexplicitlyrecommendthatshieldingruntimesadoptthemoreprincipledandfuture-proofstrategyofcleansingtheentireprocessor-extendedstatethroughxrstoroneveryenclaveentry.BothOpenEnclaveandRust-EDPacknowledgedtheremain-ingattacksurfaceofaninsufficientldmxcsr/cwmitigation,andourrecommendedfullxrstorapproachwasintegratedintotheirrespectiveprojects.MicrosoftadditionallyassignedthisfollowupissueCVE-2020-15107.4CASESTUDY:FLOATING-POINTEXCEPTIONSASASIDECHANNELBackground.Apartfromallowingtocompromisecomputa-tions,anadversarycanalsousetheFPUstateregisterstoobtainside-channelinformationaboutfloating-pointcomputationsinsideSGXenclaves.Notably,thissidechannelalsoappliestofloating-pointoperationscarriedoutusingtheSSEextensions,i.e.,withstandardcompilersettingsandwithoutthespecialrequirementtousethex87FPU.ThebaseforthissidechannelaretheexceptionmaskbitsthatcanbesetintheMXCSRregisterrightbeforeenteringtheenclaveandthefactthatanattackercanregisteracustomsignalhandlerforfloating-pointexceptions(SIGFPE)tobenotifiedabouttheexceptions.Crucially,forSGXenclaves,thesignalhandlerisuntrustedcode.Thisissimilartoothercontrolled-channelattacks,e.g.,attacksbasedonpagefaults[48],segmentationfaults[17],oralignment-checkexceptions[43].Notethatincontrasttouser-spacecode,theexactreasonfortheexception(e.g.,underfloworoverflow)isnotpassedontothesignalhandlerwhentriggeredfromwithinSGX.However,weshowthatthiscanbeovercomebyonlyunmaskingoneexceptionatatimeandexecutingtheenclavemultipletimeswiththesameinputoperands.Inthissection,forthesakeofsimplicity,wefocusondoubleoperands,i.e.,the8-byteIEEE754double-precisionbinaryfloating-pointformat[47].Inthiscase,thesmallestnormalnumberisùëõùëöùëñùëõ‚âà2.2250738585072014¬∑10‚àí308(hex0x0010000000000000),whilethelargestsubnormalisùëëùëöùëéùë•‚âà2.2250738585072009¬∑10‚àí308(hex0x000FFFFFFFFFFFFF).Whenevertheresultofacomputationis‚â§ùëëùëöùëéùë•,anunderflowexceptionwillbetriggered.Asdescribedinthefollowing,thiscanbeusedasasidechanneltoinferonepossiblysecretoperandofanenclavedfloating-pointcomputation,inthisparticularexampleamultiplication,iftheotheroperandisattacker-controlled.Attackscenario.Forexample,consideraneuralnetworkim-plementation,wheretheweightsofthenetworkaresecretsstoredsecurelyinsideanSGXenclave.Theinputlayerofthenetworkinvolvesmultiplicationsoftheattacker-controlledinputsandthesecretweights.Forsimplicity,wefocusonasinglemultiplicationoftwofloatssecret*inputinthefollowing,butnotethatthe1voidsecret_mul(doubleinput){2doubleinternal=secret*input;3//furthercomputationsoninternalvalue...4}Listing1:Exampleenclavecodevulnerabletosecretextractionthroughafloating-pointexceptionsidechannel.methodcanbeextendedtomultiplesuchmultiplicationsbyrecov-eringthesecretoperandone-by-one.Furthermore,forSGX,theenclavecodecanbesingle-stepped[44]whichallowstoexactlypinpointonwhichinstructionanexceptionhasbeenraised.Forourproof-of-concept,wecreatedanecallonIntelSGX-SDKv2.7.1whichmultipliesasecretvaluewithaninput.ThegcccompilerbydefaultsgeneratestheSSEinstructionmulsdforthemultiplicationinListing1.NotethattheenclaveAPIdoesnotexposetheinternalresultvaluetotheattackerandwemerelyfocusontheside-channelsignalwhetheranexceptionwasraisedornot.Secretrecovery.Torecoversecret,inthefirststep,wedeter-mineifitsmagnitudeis‚â§1.Thiscanbeachievedbypassingùëõùëöùëñùëõasinput:ifanunderflowexceptionisraised,|secret|<1,becausetheresultofthemultiplicationislessthanùëõùëöùëñùëõ.Inthefollowing,wedescribeanattackforthecasethat|secret|<1,butweveri-fiedthatasimilarprocedurecanbeusedfortheothercasewhere|secret|‚â•1byleveragingtheoverflowexception(cf.Algorithm2inAppendixB).Next,knowingthat|secret|<1,weusebinarysearchtograduallyapproximatethesecret.Moreprecisely,theattackproceedsasinAlgorithm1:theinputissetto0.5,andifnounderflowoccurred,thesearchcontinuesinthelowerhalf[0,0.5]andotherwiseintheupperhalf[0.5,1].Thisprocessisrepeateduntilthedifferencebetweentheupperandlowerboundisbelowanattacker-chosenminimalvalueepsilon.Algorithm1:Binarysearchalgorithmtorecoverasecretvaluebasedonunderflowexceptionsforoperands<1Result:recovered_secretlow=0;high=1;whileabs(high-low)>=epsilondomid=(low+high)/2;secret_mul(mid);recovered_secret=ùëõùëöùëñùëõ/mid;ifunderflowexceptionraisedthen//continuesearchinupperhalflow=mid;else//continuesearchinlowerhalfhigh=mid;endendForourexperiments,wesetepsilon=0.00001¬∑10‚àí308.Forthisbound,Algorithm1requiresafixednumberof1040invocationsoftheecalltorecoverasecretoperand.Weranthisalgorithmfor1000random,uniformlydistributedsecretsintheinterval[0,1[,andcomputedthedifferencebetweentheactualandtherecov-eredsecret.ThehistogramoftheerrorisshowninFigure4.The8Faulty Point Unit: ABI Poisoning Attacks on Intel SGX

ACSAC 2020, December 7‚Äì11, 2020, Austin, USA

Experimental evaluation. We base our case study on earlier
work from Alder et al. [1] who placed the Duktape Javascript en-
gine [40] in an Intel SGX enclave and utilized it to provide Machine
Learning with the ConvNetJS Javascript library [21]. This setup
allows to provide machine learning predictions from Javascript
code executed inside an Intel SGX enclave. We adjust this system
to prototype a simple service where a user requests evaluations of
her input from a machine learning model inside the enclave. As a
platform for this service, we utilize a standard exemplary convo-
lutional neural network from the ConvNetJS library that classifies
images of handwritten digits from the MNIST dataset into their
machine counterpart of 0 to 9. We utilize the demo example to
perform the training of a neural network on a trusted machine
outside of the enclave and export the trained classifier to be used
by our MLaaS enclave to classify future inputs. Such a training step
is equivalent to a model provider training the neural network in a
trusted environment, as it has not been subject to ABI-level fault
injection by our attack yet. With the exported neural network and
the ConvNetJS library, the enclave aims to evaluate customer inputs
in a trusted environment. Finally, we simulate the customer with
repeated requests with MNIST input digits to the enclave and mea-
sure the reported class and the reported confidence of the neural
network associated with each class. Again, we perform the attack
by modifying the FPU CW and the MXCSR directly before entering
the enclave. To showcase the potential worst-case impacts of our
attack, we consider two distinct scenarios with different victim en-
clave binaries created using Intel SGX-SDK v2.7.1: one binary was
generated with default compilation flags and hence uses primarily
SSE instructions, whereas the other binary was generated by ad-
ditionally passing the -mfpmath=387 compilation flag to explicitly
instruct gcc to use the x87 FPU for floating-point computations.

Table 3 shows the results of 100 input evaluations for all rounding
modes when using the SSE, or the x87 FPU in extended or single-
precision mode. Evaluations with the x87 double-precision mode
are not shown as we found these results to be identical to runs with
the x87 extended-precision mode. All depicted configurations were
executed on the same set of inputs to ensure repeatability. For the
highlighted baseline scenario, i.e., SSE and the default rounding
mode of rounding to the nearest value, the trained model expectedly
predicts 100% of the provided digits correctly. When adversely
changing rounding modes through the untrusted ABI, small errors
in the order of 10‚àí16 are clearly introduced. Importantly, however,
the results indicate that such small perturbations are insufficient to
affect the predicted digit class and the model still holds the same
overall accuracy. This observation also holds for the x87 victim
enclave binary when utilizing the x87 FPU in extended-precision
mode. However, when ABI-level attackers maliciously reduce the
FPU to a single-precision mode, the x87 victim enclave binary can
interestingly be coerced into one of two roles. When rounding to
nearest or rounding up, the trained model will simply have a gravely
decreased accuracy with only 4% of the given input classified with
the correct digit. Alternatively, when forced to round down or
towards zero, the trained model will predict every given input as
the digit 2, regardless of the actual input. The average error in single-
precision mode lies in the range of 10‚àí1, which easily scrambles
and rearranges the prediction percentages of each input evaluation.

Figure 4: Histogram over the error of the recovered secret
for 1000 samples (x-axis in log scale).

Figure 5: MLaaS system model with enclaves

maximum observed error was 3.667689888908754 ¬∑ 10‚àí6, with the
average error being 6.2648851729085662 ¬∑ 10‚àí7.

5 CASE STUDY: ATTACKING MACHINE

LEARNING PREDICTIONS

Background and system model. The core attributes of TEEs
are ideally suited for offloading sensitive computations into the
cloud. With conventional systems, a sensitive workload needed
to either be self-hosted or entrusted to an external cloud provider
that is bound by contracts and confidentiality clauses. Both solu-
tions require extensive (legal) planning and are attributed with
an increased cost compared to the benefit of conventional cloud
computing. When utilizing TEEs on the other hand, a customer can
place her sensitive computation inside an enclave that is executed
on the cloud provider‚Äôs premises. The TEE will guarantee the confi-
dentiality and integrity of the performed workload while the cloud
provider will do his due diligence to achieve a high availability of
the paid service to preserve his reputation. Additionally, customers
that utilize the service can be ensured that the cloud provider will
not learn the potentially confidential inputs or outputs.

Figure 5 illustrates such a TEE-based cloud computing service: A
Machine Learning as a Service (MLaaS) example of a model provider
who gives paid access to his model to customers. In this case study,
we assume that the model provider has spent enough resources
on the training of the model to make a direct access of customers
to the model undesirable. The model provider is assumed to train
the model in a trusted setting and then pushes the trained model
directly into the enclave that provides the service to customers.
Customers then communicate with the enclave and perform evalu-
ations and predictions of their input without learning the machine
learning model. Additionally, the enclave can guarantee privacy
such that neither the model provider nor the cloud provider learn
the customer‚Äôs input.

We assume that the cloud provider can behave maliciously as
long as his actions stay hidden from the model provider and the
customer.

9

10‚àí1210‚àí1010‚àí810‚àí6Error02550Countreceive predictionModel providerEnclaveDuktape JavascriptEnginepush modelCustomerpush inputPoison FPU registerACSAC 2020, December 7‚Äì11, 2020, Austin, USA

Alder et al.

Table 3: MNIST data set predictions with the x87 FPU and with SSE for different rounding modes and precisions.

Discussion. While the overall effectiveness of this attack was
shown to heavily depend on the way in which the enclave appli-
cation was compiled, which may not always be under the control
of the attacker, the case study clearly highlights the fallacy of the
shielding runtime to protect an ABI-compliant enclaved applica-
tion binary from its untrusted environment. The results especially
underline the threat for larger legacy 32-bit [17] or specialized ap-
plications that heavily rely on the x87 FPU, or even just require high
precision via the long double data type that might get compiled to
utilize the x87 FPU. Our example MNIST attack illustrates that, for
certain enclaved application binaries, an ABI-level adversary has
the potential to inject faults that purposefully and stealthily disrupt
the overall security objective of the outsourced application, with-
out needing to break any confidentiality or availability guarantees.
Furthermore, this attack can stealthily target specific customers to
allow a malicious cloud provider to degrade the neural network per-
formance for specific victims. Such a degradation in performance
may for instance allow the adversary to shift the customer‚Äôs favor
greatly towards a competing product or drive away customers from
the model provider while the adversary at the same time would
have little to no risk of being detected.

6 CASE STUDY: SPEC BENCHMARKS
To evaluate the theoretical impact of our ABI-level fault-injection
attacks on larger and more varied applications, we perform a larger-
scale synthetic attack evaluation on the SPEC CPU 2017 benchmark
programs outside of Intel SGX. While it is not straightforwardly pos-
sible to run the SPEC benchmark programs inside an SGX enclave,
we argue that the induced faults into floating-point computations
are independent of the surrounding execution environment and
a common benchmark will help to better understand the possible
impact of our attacks on an objective baseline computation.

Experimental evaluation. Our experimental setup runs out-
side Intel SGX and compiles the SPEC suite twice with gcc v6.2.0,
one time with default settings and one time with an additional
-mfpmath=387 flag to enforce the usage of the x87 FPU for a maxi-
mum demonstration of the attack‚Äôs impact. We then run the refer-
ence workload of the fprate class to generate meaningful evalua-
tion results. The fprate class of benchmarks is explicitly designed

10

around floating-point calculations and as such forms a relevant can-
didate to evaluate the impacts of our attack. It is important to note,
that the SPEC benchmark evaluation scripts already account for
floating-point errors by allowing a workload-specific error margin
before a benchmark is marked as failed. Similar to the previous case
studies, we perform the attack by executing fldcw and ldmxcsr
instructions before executing the SPEC benchmarks. As such, the
attacker performs the same steps as when attacking enclave code
as the execution of the SPEC benchmark can be seen as equivalent
to entering the enclave in this respect.

Table 4 shows the benchmarks in the fprate class and a marker
indicating whether the benchmark succeeded or failed for both the
default SSE binary, as well as for the x87 binary in single-precision
mode. In the highlighted baseline mode of to-nearest rounding with
the SSE, all SPEC benchmarks succeed. When maliciously changing
the rounding mode before execution of the SPEC benchmark, how-
ever, multiple tests already fail due to a too high accumulation of
floating-point errors. Furthermore, when considering a simulated
maximum-impact attack on an x87 binary in single-precision mode,
the attacker can, depending on the rounding mode, further degrade
floating-point computations and cause even more benchmarks to
fail. Under this attack, only 4 benchmarks in to-nearest rounding
mode or one benchmark in to-zero rounding mode still succeed.

Discussion. To better understand the nature of the induced
floating-point errors, we performed an additional manual analy-
sis of the 526.blender_r image rendering benchmark. While the
blender benchmark is designed to be resilient against expected
floating-point perturbations that do not exceed the internal error
threshold, we found that the x87 binary in single-precision mode
and with rounding towards zero can lead to subtle-yet-visible qual-
ity degradations in the rendered 3D images.

Figure 6 shows an example rendering with the difference be-
tween the expected original and an attacked scene marked in shades
of red. While most of the scene is colored in a light shade of red
that already stands for a small difference between the expected
and calculated output, some parts of the screenshot are marked
more clearly such as the framed mountain scenery or the hills to its
left. In the zoomed in portion of the framed scenery, it can be seen
that the expected baseline image (left) shows a tree shadow and

ACSAC2020,December7‚Äì11,2020,Austin,USAAlderetal.Table3:MNISTdatasetpredictionswiththex87FPUandwithSSEfordifferentroundingmodesandprecisions.Predictionclasscount(predicteddigit)AverageerrorcomparedtobaselineRoundingmodeAccuracy0123456789(SSE,roundingtonearest)x87SingleprecisionRoundtonearest4%0121421032030000.176046466527088413256407761764Roundingdown8%0010000000000.167963971736379585886211884826Roundingup4%0121421032030000.176046434092910736302073360093Roundtozero8%0010000000000.167963875521444400140680386357x87ExtendedprecisionRoundtonearest100%9148101489143110.000000000000000000554406357383Roundingdown100%9148101489143110.000000000000000330733402271493Roundingup100%9148101489143110.000000000000000314522247559579Roundtozero100%9148101489143110.000000000000000524157807065445SSERoundtonearest100%9148101489143110.0Roundingdown100%9148101489143110.000000000000000330733402271493Roundingup100%9148101489143110.000000000000000314522247559579Roundtozero100%9148101489143110.000000000000000524157807065445Discussion.Whiletheoveralleffectivenessofthisattackwasshowntoheavilydependonthewayinwhichtheenclaveappli-cationwascompiled,whichmaynotalwaysbeunderthecontroloftheattacker,thecasestudyclearlyhighlightsthefallacyoftheshieldingruntimetoprotectanABI-compliantenclavedapplica-tionbinaryfromitsuntrustedenvironment.Theresultsespeciallyunderlinethethreatforlargerlegacy32-bit[17]orspecializedap-plicationsthatheavilyrelyonthex87FPU,orevenjustrequirehighprecisionviathelongdoubledatatypethatmightgetcompiledtoutilizethex87FPU.OurexampleMNISTattackillustratesthat,forcertainenclavedapplicationbinaries,anABI-leveladversaryhasthepotentialtoinjectfaultsthatpurposefullyandstealthilydisrupttheoverallsecurityobjectiveoftheoutsourcedapplication,with-outneedingtobreakanyconfidentialityoravailabilityguarantees.Furthermore,thisattackcanstealthilytargetspecificcustomerstoallowamaliciouscloudprovidertodegradetheneuralnetworkper-formanceforspecificvictims.Suchadegradationinperformancemayforinstanceallowtheadversarytoshiftthecustomer‚Äôsfavorgreatlytowardsacompetingproductordriveawaycustomersfromthemodelproviderwhiletheadversaryatthesametimewouldhavelittletonoriskofbeingdetected.6CASESTUDY:SPECBENCHMARKSToevaluatethetheoreticalimpactofourABI-levelfault-injectionattacksonlargerandmorevariedapplications,weperformalarger-scalesyntheticattackevaluationontheSPECCPU2017benchmarkprogramsoutsideofIntelSGX.Whileitisnotstraightforwardlypos-sibletoruntheSPECbenchmarkprogramsinsideanSGXenclave,wearguethattheinducedfaultsintofloating-pointcomputationsareindependentofthesurroundingexecutionenvironmentandacommonbenchmarkwillhelptobetterunderstandthepossibleimpactofourattacksonanobjectivebaselinecomputation.Experimentalevaluation.Ourexperimentalsetuprunsout-sideIntelSGXandcompilestheSPECsuitetwicewithgccv6.2.0,onetimewithdefaultsettingsandonetimewithanadditional-mfpmath=387flagtoenforcetheusageofthex87FPUforamaxi-mumdemonstrationoftheattack‚Äôsimpact.Wethenruntherefer-enceworkloadofthefprateclasstogeneratemeaningfulevalua-tionresults.Thefprateclassofbenchmarksisexplicitlydesignedaroundfloating-pointcalculationsandassuchformsarelevantcan-didatetoevaluatetheimpactsofourattack.Itisimportanttonote,thattheSPECbenchmarkevaluationscriptsalreadyaccountforfloating-pointerrorsbyallowingaworkload-specificerrormarginbeforeabenchmarkismarkedasfailed.Similartothepreviouscasestudies,weperformtheattackbyexecutingfldcwandldmxcsrinstructionsbeforeexecutingtheSPECbenchmarks.Assuch,theattackerperformsthesamestepsaswhenattackingenclavecodeastheexecutionoftheSPECbenchmarkcanbeseenasequivalenttoenteringtheenclaveinthisrespect.Table4showsthebenchmarksinthefprateclassandamarkerindicatingwhetherthebenchmarksucceededorfailedforboththedefaultSSEbinary,aswellasforthex87binaryinsingle-precisionmode.Inthehighlightedbaselinemodeofto-nearestroundingwiththeSSE,allSPECbenchmarkssucceed.WhenmaliciouslychangingtheroundingmodebeforeexecutionoftheSPECbenchmark,how-ever,multipletestsalreadyfailduetoatoohighaccumulationoffloating-pointerrors.Furthermore,whenconsideringasimulatedmaximum-impactattackonanx87binaryinsingle-precisionmode,theattackercan,dependingontheroundingmode,furtherdegradefloating-pointcomputationsandcauseevenmorebenchmarkstofail.Underthisattack,only4benchmarksinto-nearestroundingmodeoronebenchmarkinto-zeroroundingmodestillsucceed.Discussion.Tobetterunderstandthenatureoftheinducedfloating-pointerrors,weperformedanadditionalmanualanaly-sisofthe526.blender_rimagerenderingbenchmark.Whiletheblenderbenchmarkisdesignedtoberesilientagainstexpectedfloating-pointperturbationsthatdonotexceedtheinternalerrorthreshold,wefoundthatthex87binaryinsingle-precisionmodeandwithroundingtowardszerocanleadtosubtle-yet-visiblequal-itydegradationsintherendered3Dimages.Figure6showsanexamplerenderingwiththedifferencebe-tweentheexpectedoriginalandanattackedscenemarkedinshadesofred.Whilemostofthesceneiscoloredinalightshadeofredthatalreadystandsforasmalldifferencebetweentheexpected10Faulty Point Unit: ABI Poisoning Attacks on Intel SGX

ACSAC 2020, December 7‚Äì11, 2020, Austin, USA

Table 4: Benchmarks with SPEC CPU 2017 under compilation with the x87 FPU and with the SSE, both shown for different
rounding modes. Listed are all workloads in the fprate test class and their result in the given configuration.

Rounding mode

bwaves

cactuBSSN namd

parest

povray

lbm wrf

blender

cam4

imagick

nab

fotonik3d

roms

specrand

e
l
g
n
i
S

n To nearest
Downward
Upward
To zero

o
i
s
i
c
e
r
p

E
S
S

To nearest
Downward
Upward
To zero

¬∏
√ò
√ò
√ò

¬∏
¬∏
¬∏
¬∏

√ò
√ò
√ò
√ò

¬∏
√ò
√ò
√ò

√ò
√ò
√ò
√ò

¬∏
√ò
√ò
√ò

√ò
√ò
√ò
√ò

¬∏
¬∏
√ò
¬∏

√ò
√ò
√ò
√ò

¬∏
¬∏
√ò
¬∏

√ò
√ò
√ò
√ò

¬∏
√ò
√ò
√ò

¬∏ ¬∏
√ò
¬∏
√ò
¬∏
√ò
¬∏

¬∏
¬∏
¬∏
√ò

¬∏
√ò
¬∏
√ò

√ò
√ò
√ò
√ò

¬∏
¬∏
¬∏
¬∏

¬∏
¬∏
¬∏
¬∏

¬∏
¬∏
¬∏
¬∏

√ò
√ò
√ò
√ò

¬∏
¬∏
¬∏
¬∏

√ò
√ò
√ò
√ò

¬∏
√ò
√ò
√ò

√ò
√ò
√ò
√ò

¬∏
¬∏
¬∏
¬∏

√ò
√ò
√ò
√ò

¬∏
√ò
√ò
√ò

to pose a threat to the promise of transparently shielding enclave
applications [22, 43].

In this work, we presented novel ABI-level attacks on the largely
overlooked x87 FPU and SSE state that allow an unprivileged adver-
sary to impact the integrity of enclaved floating-point operations, in
terms of the rounding mode, precision, and silently introduced NaN
values. We furthermore explored an innovative controlled-channel
attack variant that abuses attacker-induced floating-point excep-
tions to partially breach the confidentiality of otherwise private
enclaved floating-point operations. In a comprehensive analysis of
this vulnerability space in 7 popular runtimes, developed by both
academia and industry, we were able to provide a proof-of-concept
attack for 5 of them. Moreover, our analysis revealed that 2 pre-
viously patched production runtimes remained vulnerable to NaN
injection, further highlighting the intricacy of fully mitigating this
ABI-level attack surface. While the eventual impact of our FPU
poisoning attacks remains intrinsically application-dependent, we
have presented several case studies that illustrate the potential
exploitability in selected application binaries.

The fundamental issue can be mitigated by simply setting the
x87 FPU control word as well as the SSE MXCSR register into known
states when entering enclaved execution. Mitigating the followup
MMX issue requires an additional emms instruction to place the
FPU in the expected x87 mode. Regarding more principled mitiga-
tion strategies however, we explicitly recommend that shielding
runtimes perform a full xrstor to initialize the complete processor-
extended state whenever the enclave is entered. Although this may
come with a slightly increased cost in performance, we believe that
our findings underscore the need for shielding runtimes to move
away from selective register cleansing on an ad-hoc case-by-case
basis, in order to more systematically prevent any orthogonal ABI-
level issues that may arise in current or future processor extensions.
Six of the seven investigated enclave shielding runtimes have now
opted to perform such a full xrstor or in the case of Graphene
perform an equivalent fxrstor while SGX-LKL will inherit the
xrstor mitigation from Microsoft OpenEnclave in the future.

In the wider perspective, our work highlights the fallacy and chal-
lenges of implementing a high-assurance TEE on top of a complex
instruction set architecture like x86, with arguably too many ne-
glected legacy features and strict backwards compatibility. We argue
that, in an era where the research community is increasingly look-
ing into subtle microarchitectural CPU vulnerabilities [6, 25, 41, 42],
the strictly architectural attack surface of today‚Äôs complex x86 pro-
cessor features remains not sufficiently understood. As such, an

Figure 6: Composite image of the Blender benchmark in
Spec CPU 2017 under attack by our FPU attacker in x87 sin-
gle precision mode when rounding towards zero. Areas in
red differ from the expected render image with the zoomed-
in area showing differences visible to the human eye.

a snow cover on the mountains. With the attack (right), however,
the shadow is missing and the contours of the mountains are lower,
making the snow cover to appear to float. It is evident that the
visual perturbations between the baseline and attacked rendering
are small, yet the fact that they are visible even for human observers
clearly illustrates the potential impact of insufficient ABI shield-
ing on the integrity of an outsourced enclave rendering service.
Such an attack may for instance be relevant when an untrusted
cloud provider has an economical incentive to stealthily degrade
the quality of refined 3D movie stills from a competitor.

From the SPEC analysis, we conclude that common applications
may widely fail when unexpectedly interfaced with a malicious ABI
and that attacker-induced floating-point errors in larger applica-
tions may propagate into subtle corruptions of the expected result.
The exact impact of such attacks will always be application-specific,
however, and require careful analysis by the attacker depending on
the x87 or SSE processor features used in the victim application.

7 CONCLUSIONS AND LESSONS LEARNED
With the wide availability of SGX in mainstream Intel processors,
an emerging software ecosystem of enclave shielding runtimes
has developed in recent years to ease the adoption process and
enable developers to largely transparently enjoy SGX protection
guarantees. But despite the considerable advances and developer
efforts behind these runtimes, API and ABI-level issues continue

11

ACSAC 2020, December 7‚Äì11, 2020, Austin, USA

Alder et al.

interesting focus of future work could be to extend vulnerability as-
sessment tools such as TEEREX [8] that are predominantly focused
on API-level attack surfaces thus far, to ABI-level vulnerabilities.
Our analysis reveals that the high level of complexity and the large
amount of interconnected instructions in modern x86 architectures
make it particularly challenging to evaluate, investigate, and finally
mitigate ABI-level attacks. We urge the research community and
industry players to deepen their efforts of exploring TEE solutions
for alternative processor architectures, such as RISC-V, that are not
unnecessarily complex for historic reasons.

ACKNOWLEDGMENTS
This research was partially funded by the Engineering and Physical
Sciences Research Council (EPSRC) under grants EP/R012598/1,
EP/S030867/1, by the European Union‚Äôs Horizon 2020 research
and innovation programme under grant agreement No. 779391
(FutureTPM), by the Research Fund KU Leuven, and by a gift from
Intel Corporation. Fritz Alder and Jo Van Bulck are supported by a
grant of the Research Foundation ‚Äì Flanders (FWO).

REFERENCES
[1] Fritz Alder, N Asokan, Arseny Kurnikov, Andrew Paverd, and Michael Steiner.
2019. S-faas: Trustworthy and accountable function-as-a-service using Intel SGX.
In Proceedings of the 2019 ACM SIGSAC Conference on Cloud Computing Security
Workshop. 185‚Äì199.

[2] Andrew Baumann, Marcus Peinado, and Galen Hunt. 2014. Shielding applications
from an untrusted cloud with Haven. In Proceedings of the 11th USENIX conference
on Operating Systems Design and Implementation. USENIX Association, 267‚Äì283.
[3] Andrea Biondo, Mauro Conti, Lucas Davi, Tommaso Frassetto, and Ahmad-Reza
Sadeghi. 2018. The Guard‚Äôs Dilemma: Efficient Code-Reuse Attacks Against Intel
SGX. In Proceedings of the 27th USENIX Security Symposium. 1213‚Äì1227.
[4] Mike Bursell. 2019. Trust No One, Run Everywhere‚ÄîIntroducing Enarx.
[5] S. Checkoway and H. Shacham. 2013. Iago attacks: Why the system call API is a
bad untrusted RPC interface. In International Conference on Architectural Support
for Programming Languages and Operating Systems (ASPLOS). 253‚Äì264.

[6] Guoxing Chen, Sanchuan Chen, Yuan Xiao, Yinqian Zhang, Zhiqiang Lin, and
Ten H Lai. 2019. SgxPectre Attacks: Stealing Intel Secrets from SGX Enclaves via
Speculative Execution. In 4th IEEE European Symposium on Security and Privacy
(Euro S&P). IEEE.

[7] Haogang Chen, Yandong Mao, Xi Wang, Dong Zhou, Nickolai Zeldovich, and
M. Frans Kaashoek. 2011. Linux kernel vulnerabilities: State-of-the-art defenses
and open problems. In Proceedings of the Second Asia-Pacific Workshop on Systems.
ACM, 5:1‚Äì5:5.

[8] Tobias Cloosters, Michael Rodler, and Lucas Davi. 2020. TeeRex: Discovery
and Exploitation of Memory Corruption Vulnerabilities in SGX Enclaves. In
Proceedings of the 29th USENIX Security Symposium. 841‚Äì858.

[9] Intel Corporation. 2017. Intel software guard extensions SDK for Linux OS: Devel-

oper reference.

[10] V. Costan and S. Devadas. 2016. Intel SGX explained. IACR Cryptology ePrint

Archive 2016, 086 (2016), 1‚Äì118.

[19] Intel Corporation. 2019. Intel Software Guard Extensions ‚Äì Get Started with the

SDK. https://software.intel.com/en-us/sgx/sdk.

[20] Intel Corporation. 2020. Intel 64 and IA-32 architectures software developer‚Äôs man-

ual ‚Äì Combined volumes. Reference no. 325462-062US.

[21] Andrej Karpathy. 2014. Convnetjs: Deep learning in your browser (2014). URL

http:// cs.stanford.edu/ people/ karpathy/ convnetjs (2014).

[22] Mustakimur Rahman Khandaker, Yueqiang Cheng, Zhi Wang, and Tao Wei.
2020. COIN Attacks: On Insecurity of Enclave Untrusted Interfaces in SGX. In
Proceedings of the Twenty-Fifth International Conference on Architectural Support
for Programming Languages and Operating Systems. 971‚Äì985.

[23] J. Lee, J. Jang, Y. Jang, N. Kwak, Y. Choi, C. Choi, T. Kim, M. Peinado, and
B. Byunghoon Kang. 2017. Hacking in darkness: Return-oriented programming
against secure enclaves. In Proceedings of the 26th USENIX Security Symposium.
523‚Äì539.

[24] S. Lee and T. Kim. 2017. Leaking uninitialized secure enclave memory via structure

padding. arXiv preprint arXiv:1710.09061 (2017).

[25] Sangho Lee, Ming-Wei Shih, Prasun Gera, Taesoo Kim, Hyesoon Kim, and Marcus
Peinado. 2017.
Inferring fine-grained control flow inside SGX enclaves with
branch shadowing. In Proceedings of the 26th USENIX Security Symposium. 557‚Äì
574.

[26] H.J. Lu, David L Kreitzer, Milind Girkar, and Zia Ansari. 2015. System V appli-
cation binary interface. Intel386 Architecture Processor Supplement, Version 1.1 (7
December 2015).

[27] A. Machiry, E. Gustafson, C. Spensky, C. Salls, N. Stephens, R. Wang, A. Bianchi,
Y. Ryn Choe, C. Kruegel, and G. Vigna. 2017. BOOMERANG: Exploiting the
semantic gap in trusted execution environments. In NDSS 2017.

[28] P. Maene, J. G√∂tzfried, R. de Clercq, T. M√ºller, F. Freiling, and I. Verbauwhede. 2017.
Hardware-based trusted computing architectures for isolation and attestation.
IEEE Trans. Comput. 99 (2017).

[29] Microsoft. [n.d.]. https://azure.microsoft.com/en-us/blog/introducing-azure-

confidential-computing/.

[30] Microsoft. 2019. Open Enclave SDK. https://openenclave.io/sdk/.
[31] Microsoft Corporation. 2020. Microsoft Visual C++. https://docs.microsoft.com/

en-us/cpp/.

[32] Daniel Moghimi, Jo Van Bulck, Nadia Heninger, Frank Piessens, and Berk Sunar.
2020. CopyCat: Controlled Instruction-Level Attacks on Enclaves. In Proceedings
of the 29th USENIX Security Symposium. USENIX Association, 469‚Äì486.

[33] Kit Murdock, David Oswald, Flavio D. Garcia, Jo Van Bulck, Daniel Gruss, and
Frank Piessens. 2020. Plundervolt: Software-based fault injection attacks against
Intel SGX. In Proceedings of the 41th IEEE Symposium on Security and Privacy
(S&P‚Äô20).

[34] S. Pinto and N. Santos. 2019. Demystifying ARM TrustZone: A Comprehensive

Survey. ACM Computing Surveys (CSUR) 51, 6 (2019), 130.

[35] Christian Priebe, Divya Muthukumaran, Joshua Lind, Huanzhou Zhu, Shujie Cui,
Vasily A Sartakov, and Peter Pietzuch. 2019. SGX-LKL: Securing the Host OS
Interface for Trusted Execution. arXiv preprint arXiv:1908.11143 (2019).

[36] The Apache Software Foundation. 2020. Apache Teaclave (Incubating). https:

//teaclave.incubator.apache.org/.

[37] Florian Tramer, Fan Zhang, Huang Lin, Jean-Pierre Hubaux, Ari Juels, and Elaine
Shi. 2017. Sealed-glass proofs: Using transparent enclaves to prove and sell
knowledge. In 2nd IEEE European Symposium on Security and Privacy (Euro S&P).
IEEE.

[38] Chia-Che Tsai, Donald Porter, et al. 2017. Graphene-SGX library OS ‚Äî A library
OS for Linux multi-process applications with Intel SGX support. https://github.
com/oscarlab/graphene.

[39] Chia-Che Tsai, Donald E Porter, and Mona Vij. 2017. Graphene-SGX: A practical
library OS for unmodified applications on SGX. In 2017 USENIX Annual Technical
Conference (USENIX ATC). USENIX Association.

[11] J. Edge. 2008. CVE-2008-1367: Kernel doesn‚Äôt clear DF for signal handlers.

[40] Sami Vaarala. 2020. Duktape embeddable Javascript engine. URL https:// duktape.

https://bugzilla.redhat.com/show_bug.cgi?id=437312.

org/ (2020).

[12] A. Fog. 2018. Calling conventions for different C++ compilers and operating

systems. http://www.agner.org/optimize/calling_conventions.pdf.

[13] Fortanix. 2019. Fortanix Enclave Development Platform ‚Äî Rust EDP. https:

//edp.fortanix.com/.

[14] Free Software Foundation. 2020. GCC, the GNU Compiler Collection. https:

//gcc.gnu.org/.

[15] Adrien Ghosn, James R Larus, and Edouard Bugnion. 2019. Secured routines:
language-based construction of trusted execution environments. In 2019 USENIX
Annual Technical Conference (USENIX ATC 19). 571‚Äì586.

[16] Google. 2019. Asylo: An open and flexible framework for enclave applications.

https://asylo.dev/.

[17] Jago Gyselinck, Jo Van Bulck, Frank Piessens, and Raoul Strackx. 2018. Off-limits:
Abusing legacy x86 memory segmentation to spy on enclaved execution. In
International Symposium on Engineering Secure Software and Systems (ESSoS ‚Äô18).
Springer, 44‚Äì60.

[18] IBM. [n.d.]. Data-in-use protection on IBM cloud. https://www.ibm.com/blogs/
bluemix/2017/12/data-use-protection-ibm-cloud-ibm-intel-fortanix-partner-
keep-enterprises-secure-core/.

[41] J. Van Bulck, M. Minkin, O. Weisse, D. Genkin, B. Kasikci, F. Piessens, M. Sil-
berstein, T. F. Wenisch, Y. Yarom, and R. Strackx. 2018. Foreshadow: Extracting
the keys to the Intel SGX kingdom with transient out-of-order execution. In
Proceedings of the 27th USENIX Security Symposium.

[42] Jo Van Bulck, Daniel Moghimi, Michael Schwarz, Moritz Lipp, Marina Minkin,
Daniel Genkin, Yarom Yuval, Berk Sunar, Daniel Gruss, and Frank Piessens.
2020. LVI: Hijacking transient execution through microarchitectural load value
injection. In 41st IEEE Symposium on Security and Privacy (S&P‚Äô20).

[43] Jo Van Bulck, David Oswald, Eduard Marin, Abdulla Aldoseri, Flavio D. Garcia,
and Frank Piessens. 2019. A tale of two worlds: Assessing the vulnerability
of enclave shielding runtimes. In Proceedings of the 26th ACM Conference on
Computer and Communications Security (CCS‚Äô19). ACM.

[44] Jo Van Bulck, Frank Piessens, and Raoul Strackx. 2017. SGX-Step: A practical
attack framework for precise enclave execution control. In 2nd Workshop on
System Software for Trusted Execution (SysTEX 2017). ACM, 4:1‚Äì4:6.

[45] N. van Ginkel, R. Strackx, and F. Piessens. 2017. Automatically generating
secure wrappers for SGX enclaves from separation logic specifications. In Asian
Symposium on Programming Languages and Systems. 105‚Äì123.

12

Faulty Point Unit: ABI Poisoning Attacks on Intel SGX

ACSAC 2020, December 7‚Äì11, 2020, Austin, USA

[46] Huibo Wang, Pei Wang, Yu Ding, Mingshen Sun, Yiming Jing, Ran Duan, Long Li,
Yulong Zhang, Tao Wei, and Zhiqiang Lin. 2019. Towards Memory Safe Enclave
Programming with Rust-SGX. In Proceedings of the 2019 ACM SIGSAC Conference
on Computer and Communications Security. 2333‚Äì2350.

[47] Wikipedia contributors. 2020. Double-precision floating-point format ‚Äî
Wikipedia, The Free Encyclopedia. https://en.wikipedia.org/w/index.php?title=
Double-precision_floating-point_format&oldid=960696001 [Online; accessed
16-June-2020].

[48] Yuanzhong Xu, Weidong Cui, and Marcus Peinado. 2015. Controlled-channel
attacks: Deterministic side channels for untrusted operating systems. In 2015
IEEE Symposium on Security and Privacy. IEEE, 640‚Äì656.

A PROOF-OF-CONCEPT ENCLAVE CODE
This appendix lists the C source code (Listing 2) and compiled as-
sembly (Listing 3) for the benchmark toy example enclave discussed
in Section 3.2 and Table 1. The assembly code in Listing 3 was out-
put by gcc v7.4.0 under Ubuntu 18.04.1 and the Intel SGX-SDK
v2.7.1 using the default compilation flags.

However, if desired, these algorithm could be likely re-written (al-
though in a less clear manner) using the binary representation of
the double operands instead.

Algorithm 2: Binary search algorithm to recover a secret
value based on overflow exceptions for operands > 1

Result: recovered_secret
// Maximum representable double
max_double = 1.7976931348623157e308;
low = 1;
high = max_double;
cnt = 0;
while cnt < 100 do

mid = low / 2 + high / 2;
secret_mul(mid);
recovered_secret = max_double / mid;
cnt++;
if overflow exception raised then

// continue search in lower half
high = mid;

else

// continue search in upper half
low = mid;

end

end

B SEARCH ALGORITHM BASED ON

OVERFLOW EXCEPTIONS

This appendix lists the additional Algorithm 2 to recover secrets
for operands > 1. It functions analogous to Algorithm 1 described
in Section 4. We note that for brevity, both Algorithm 1 and Algo-
rithm 2 use standard floating-point variables for secret recovery.

13

FaultyPointUnit:ABIPoisoningAttacksonIntelSGXACSAC2020,December7‚Äì11,2020,Austin,USAComputerandCommunicationsSecurity(CCS‚Äô19).ACM.[44]JoVanBulck,FrankPiessens,andRaoulStrackx.2017.SGX-Step:Apracticalattackframeworkforpreciseenclaveexecutioncontrol.In2ndWorkshoponSystemSoftwareforTrustedExecution(SysTEX2017).ACM,4:1‚Äì4:6.[45]N.vanGinkel,R.Strackx,andF.Piessens.2017.AutomaticallygeneratingsecurewrappersforSGXenclavesfromseparationlogicspecifications.InAsianSymposiumonProgrammingLanguagesandSystems.105‚Äì123.[46]HuiboWang,PeiWang,YuDing,MingshenSun,YimingJing,RanDuan,LongLi,YulongZhang,TaoWei,andZhiqiangLin.2019.TowardsMemorySafeEnclaveProgrammingwithRust-SGX.InProceedingsofthe2019ACMSIGSACConferenceonComputerandCommunicationsSecurity.2333‚Äì2350.[47]Wikipediacontributors.2020.Double-precisionfloating-pointformat‚ÄîWikipedia,TheFreeEncyclopedia.https://en.wikipedia.org/w/index.php?title=Double-precision_floating-point_format&oldid=960696001[Online;accessed16-June-2020].[48]YuanzhongXu,WeidongCui,andMarcusPeinado.2015.Controlled-channelattacks:Deterministicsidechannelsforuntrustedoperatingsystems.In2015IEEESymposiumonSecurityandPrivacy.IEEE,640‚Äì656.APROOF-OF-CONCEPTENCLAVECODEThisappendixliststheCsourcecode(Listing2)andcompiledas-sembly(Listing3)forthebenchmarktoyexampleenclavediscussedinSection3.2andTable1.TheassemblycodeinListing3wasout-putbygccv7.4.0underUbuntu18.04.1andtheIntelSGX-SDKv2.7.1usingthedefaultcompilationflags.1#include<stdint.h>2#include<math.h>34longdoubleecall_acosf(inta){5returnacosl(a);6}7longdoubleecall_mul(longdoublea,longdoubleb){8returna*b;9}Listing2:Codetoperformbasicfloating-pointoperationsinsidetheenclave.1<ecall_acosf>:2push%rbp3mov%rsp,%rbp4sub$0x20,%rsp5mov%edi,-0x4(%rbp)6fildl-0x4(%rbp)7lea-0x10(%rsp),%rsp8fstpt(%rsp)9callq4450<acosl>10add$0x10,%rsp11fstpt-0x20(%rbp)12mov-0x20(%rbp),%rax13mov-0x18(%rbp),%edx14mov%rax,-0x20(%rbp)15mov%edx,-0x18(%rbp)16fldt-0x20(%rbp)17leaveq18retq1920<ecall_mul>:21push%rbp22mov%rsp,%rbp23fldt0x10(%rbp)24fldt0x20(%rbp)25fmulp%st,%st(1)26pop%rbp27retqListing3:CompiledassemblyofListing2.BSEARCHALGORITHMBASEDONOVERFLOWEXCEPTIONSThisappendixliststheadditionalAlgorithm2torecoversecretsforoperands>1.ItfunctionsanalogoustoAlgorithm1describedinSection4.Wenotethatforbrevity,bothAlgorithm1andAlgo-rithm2usestandardfloating-pointvariablesforsecretrecovery.However,ifdesired,thesealgorithmcouldbelikelyre-written(al-thoughinalessclearmanner)usingthebinaryrepresentationofthedoubleoperandsinstead.Algorithm2:Binarysearchalgorithmtorecoverasecretvaluebasedonoverflowexceptionsforoperands>1Result:recovered_secret//Maximumrepresentabledoublemax_double=1.7976931348623157e308;low=1;high=max_double;cnt=0;whilecnt<100domid=low/2+high/2;secret_mul(mid);recovered_secret=max_double/mid;cnt++;ifoverflowexceptionraisedthen//continuesearchinlowerhalfhigh=mid;else//continuesearchinupperhalflow=mid;endend13FaultyPointUnit:ABIPoisoningAttacksonIntelSGXACSAC2020,December7‚Äì11,2020,Austin,USAComputerandCommunicationsSecurity(CCS‚Äô19).ACM.[44]JoVanBulck,FrankPiessens,andRaoulStrackx.2017.SGX-Step:Apracticalattackframeworkforpreciseenclaveexecutioncontrol.In2ndWorkshoponSystemSoftwareforTrustedExecution(SysTEX2017).ACM,4:1‚Äì4:6.[45]N.vanGinkel,R.Strackx,andF.Piessens.2017.AutomaticallygeneratingsecurewrappersforSGXenclavesfromseparationlogicspecifications.InAsianSymposiumonProgrammingLanguagesandSystems.105‚Äì123.[46]HuiboWang,PeiWang,YuDing,MingshenSun,YimingJing,RanDuan,LongLi,YulongZhang,TaoWei,andZhiqiangLin.2019.TowardsMemorySafeEnclaveProgrammingwithRust-SGX.InProceedingsofthe2019ACMSIGSACConferenceonComputerandCommunicationsSecurity.2333‚Äì2350.[47]Wikipediacontributors.2020.Double-precisionfloating-pointformat‚ÄîWikipedia,TheFreeEncyclopedia.https://en.wikipedia.org/w/index.php?title=Double-precision_floating-point_format&oldid=960696001[Online;accessed16-June-2020].[48]YuanzhongXu,WeidongCui,andMarcusPeinado.2015.Controlled-channelattacks:Deterministicsidechannelsforuntrustedoperatingsystems.In2015IEEESymposiumonSecurityandPrivacy.IEEE,640‚Äì656.APROOF-OF-CONCEPTENCLAVECODEThisappendixliststheCsourcecode(Listing2)andcompiledas-sembly(Listing3)forthebenchmarktoyexampleenclavediscussedinSection3.2andTable1.TheassemblycodeinListing3wasout-putbygccv7.4.0underUbuntu18.04.1andtheIntelSGX-SDKv2.7.1usingthedefaultcompilationflags.1#include<stdint.h>2#include<math.h>34longdoubleecall_acosf(inta){5returnacosl(a);6}7longdoubleecall_mul(longdoublea,longdoubleb){8returna*b;9}Listing2:Codetoperformbasicfloating-pointoperationsinsidetheenclave.1<ecall_acosf>:2push%rbp3mov%rsp,%rbp4sub$0x20,%rsp5mov%edi,-0x4(%rbp)6fildl-0x4(%rbp)7lea-0x10(%rsp),%rsp8fstpt(%rsp)9callq4450<acosl>10add$0x10,%rsp11fstpt-0x20(%rbp)12mov-0x20(%rbp),%rax13mov-0x18(%rbp),%edx14mov%rax,-0x20(%rbp)15mov%edx,-0x18(%rbp)16fldt-0x20(%rbp)17leaveq18retq1920<ecall_mul>:21push%rbp22mov%rsp,%rbp23fldt0x10(%rbp)24fldt0x20(%rbp)25fmulp%st,%st(1)26pop%rbp27retqListing3:CompiledassemblyofListing2.BSEARCHALGORITHMBASEDONOVERFLOWEXCEPTIONSThisappendixliststheadditionalAlgorithm2torecoversecretsforoperands>1.ItfunctionsanalogoustoAlgorithm1describedinSection4.Wenotethatforbrevity,bothAlgorithm1andAlgo-rithm2usestandardfloating-pointvariablesforsecretrecovery.However,ifdesired,thesealgorithmcouldbelikelyre-written(al-thoughinalessclearmanner)usingthebinaryrepresentationofthedoubleoperandsinstead.Algorithm2:Binarysearchalgorithmtorecoverasecretvaluebasedonoverflowexceptionsforoperands>1Result:recovered_secret//Maximumrepresentabledoublemax_double=1.7976931348623157e308;low=1;high=max_double;cnt=0;whilecnt<100domid=low/2+high/2;secret_mul(mid);recovered_secret=max_double/mid;cnt++;ifoverflowexceptionraisedthen//continuesearchinlowerhalfhigh=mid;else//continuesearchinupperhalflow=mid;endend13

=== Content from www.intel.com_2e0a7d10_20250114_195808.html ===

[Skip To Main Content](#primary-content)

[![Intel logo - Return to the home page](/content/dam/logos/intel-header-logo.svg)](/content/www/us/en/homepage.html)

Toggle Navigation

Sign In

My Intel

My Tools

* ?

Sign Out

English

## Select Your Language

* [Bahasa Indonesia](https://www.intel.co.id/content/www/id/id/homepage.html)
* [Deutsch](https://www.intel.de/content/www/de/de/homepage.html)
* [English](https://www.intel.com/content/www/us/en/homepage.html)
* [Espa√±ol](https://www.intel.la/content/www/xl/es/homepage.html)
* [Fran√ßais](https://www.intel.fr/content/www/fr/fr/homepage.html)
* [Portugu√™s](https://www.intel.com.br/content/www/br/pt/homepage.html)

* [Ti√™ÃÅng Vi√™Ã£t](https://www.intel.vn/content/www/vn/vi/homepage.html)
* [‡πÑ‡∏ó‡∏¢](https://www.thailand.intel.com/content/www/th/th/homepage.html)
* [ÌïúÍµ≠Ïñ¥](https://www.intel.co.kr/content/www/kr/ko/homepage.html)
* [Êó•Êú¨Ë™û](https://www.intel.co.jp/content/www/jp/ja/homepage.html)
* [ÁÆÄ‰Ωì‰∏≠Êñá](https://www.intel.cn/content/www/cn/zh/developer/articles/technical/software-security-guidance/best-practices/data-operand-independent-timing-isa-guidance.html)
* [ÁπÅÈ´î‰∏≠Êñá](https://www.intel.com.tw/content/www/tw/zh/homepage.html)

Toggle Search

Search

<

Close Search Panel

Advanced Search

close

Sign In to access restricted content

### Using Intel.com Search

You can easily search the entire Intel.com site in several ways.

* Brand Name:
  **Core i9**
* Document Number:
  **123456**
* Code Name:
  **Emerald Rapids**
* Special Operators:
  **‚ÄúIce Lake‚Äù, Ice AND Lake, Ice OR Lake, Ice\***

### Quick Links

You can also try the quick links below to see results for most popular searches.

* [Product Information](https://www.intel.com/content/www/us/en/products/overview.html?wapkw=quicklink:products)
* [Support](https://www.intel.com/content/www/us/en/support.html?wapkw=quicklink:support)
* [Drivers & Software](https://downloadcenter.intel.com?wapkw=quicklink:download-center)

### Recent Searches

Sign In to access restricted content

### Advanced Search

All of these terms
Any of these terms
Exact term only

Find results with

All Results

Product Information

Support

Drivers & Software

Documentation & Resources

Partners

Communities

Corporate

Show results from

### Only search in

Title

Description
Content ID

Search

Sign in to access
restricted content.

The browser version you are using is not recommended for this site.
Please consider upgrading to the latest version of your browser by clicking one of the following links.

* [Safari](https://support.apple.com/downloads/safari)
* [Chrome](https://support.google.com/chrome/answer/95346?hl=en)
* [Edge](https://www.microsoft.com/en-us/edge)
* [Firefox](https://www.mozilla.org/en-US/firefox/new/)

# Data Operand Independent Timing Instruction Set Architecture (ISA) Guidance

 ID
768873

 Updated
2/13/2023

 Version
Latest

Public

![author-image]()

By

This document describes a new feature supported by some recent Intel processors, adding a data operand independent timing mode which can be used to ensure ‚Äúconstant time‚Äù execution for a specific subset of instructions. Although not relevant for the majority of code, data operand independent timing (DOIT) is a useful property for code which has specifically been written to execute in constant time such as cryptographic algorithms. This mode allows constant time code to inform the processor that data operand independent timing is needed.

DOIT requires disabling hardware optimizations and/or performance features on some processors; for example, enabling data operand independent timing might disable data-dependent prefetching. This means that the DOIT mode may have a performance impact, and Intel expects the performance impact of this mode may be significantly higher on future processors.

This functionality is intended for use by software which has already applied other techniques to mitigate software timing side channels, such as those documented in [Intel's Guidelines for Mitigating Timing Side Channels Against Cryptographic Implementations](/content/www/us/en/developer/articles/technical/software-security-guidance/secure-coding/mitigate-timing-side-channel-crypto-implementation.html). Such software is typically limited to cryptographic implementations. This mode is not intended to provide any additional security benefit for software that is not already applying these software techniques. Due to its potential performance impact, Intel does not recommend enabling this mode globally. Instead, the mode should be enabled only for software that is specifically designed to benefit from the additional properties provided by the DOIT mode. In order to allow this mode to be enabled for the subset of an application that is constant time, Intel plans to add new capabilities in future processors to allow applications to dynamically enabled/disabled when system software permits.

The¬†[data operand independent timing instructions](/content/www/us/en/developer/articles/technical/software-security-guidance/resources/data-operand-independent-timing-instructions.html)¬†section provides a list of the instructions that have data-independent timing that can be used in conjunction with the previous guidelines. Software using these instructions for ‚Äúconstant time‚Äù code can enable the DOIT mode for data operand independent timing on a per-thread or per-process basis. Future enhancements may allow more fine-grain user mode control inside an application or library.

## Instructions with Data Operand Independent Timing (DOIT)

Refer to the [list of documented data operand independent timing instructions](/content/www/us/en/developer/articles/technical/software-security-guidance/resources/data-operand-independent-timing-instructions.html)¬†for a list of instructions with data operand independent timing.¬†Note that these data operand independent timing instructions may have variable latency for reasons unrelated to the data values (for example, loading data from memory or the encoding of the instruction). Furthermore, an instruction being included on this list does not mean that its usage is resistant to power, thermal, or frequency-based side channels. Refer to the [frequency-throttling side channel guidance](/content/www/us/en/developer/articles/technical/software-security-guidance/best-practices/frequency-throttling-side-channel-guidance.html) for more information.

### Data Values vs. Address Values

The latency of a data operand independent timing instruction does not depend on the data values on which it operates. However, the latency of these instructions that fetch data from memory may vary based on the memory address that the load accesses to get that data, as discussed in [Intel's Guidelines for Mitigating Timing Side Channels Against Cryptographic Implementations](/content/www/us/en/developer/articles/technical/software-security-guidance/secure-coding/mitigate-timing-side-channel-crypto-implementation.html).

### Instruction Encodings and Immediate Values

Anything that changes the code bytes of an instruction may impact the latency of that instruction. For example, an instruction may have different latency if:

* It has a different immediate value.
* It uses a different memory addressing mode (for example, just a base register instead of having both a base and index register) even when the address being accessed is the same.
* It uses different registers (for example, RAX vs. AX vs. RBX) or different condition code (such as CF vs. ZF).

### Masked Operations

Masked operations have mask registers as inputs to the instruction. For example, certain Intel¬Æ Advanced Vector Extensions 512 (Intel¬Æ AVX-512) operations take a K mask register input. Some non-Intel AVX-512 operations (such as VMASKMOV, MASKMOVDQU, Gather, among others) have a mask register that is not a K mask register. For masked operations that do not access memory, the instruction latency will be invariant with respect to the mask register value.

For masked operations that access memory, the mask register (whether a K mask register or a separate register) may affect which memory addresses are accessed. Therefore, data operand independent timing instructions that read or write to memory may have different timing depending on mask register values.

## Data Operand Independent Timing Mode (DOITM)

To support use cases such as constant time code, a new model specific register (MSR) control enables data operand independent timing for the listed data operand independent timing instructions.

Specifically, when data operand independent timing mode is enabled, instructions within the data operand independent timing subset execute with timing (in terms of processor cycles) that is independent of the data values in the sources of the instruction, except for potential timing differences due to power or thermal variations. Moreover, while in data operand independent timing mode, the data values operated on by these data independent instructions will not impact the timing of other instructions. This property is true regardless of the status of data operand independent timing mode when the other instructions are executed.

When an instruction outside of the data operand independent timing subset or outside of the data operand independent timing mode is executed (either speculatively or non-speculatively), the data values operated on could potentially affect the timing both of the instruction operating on the data and of other instructions. Additionally, power consumed, CPU frequency, and telemetry recorded (such as performance monitoring events or running average power limit (RAPL) power measurements[1](#footnotes)) may differ based on the data values operated on within data operand independent timing mode. It is also possible that subsystems outside the core may implement data operand dependent features that may impact the timing in a data-dependent manner for data independent instructions.

Developers handling secret data that should only ever be processed in a data operand independent timing manner may need to consider speculative execution vulnerabilities. These vulnerabilities may cause the secret data to be handled in a data operand dependent manner and developers may need to apply additional mitigations. Refer to [Mitigating Timing Side Channels Against Cryptographic Implementations](/content/www/us/en/developer/articles/technical/software-security-guidance/secure-coding/mitigate-timing-side-channel-crypto-implementation.html).

### Data Operand Independent Timing Mode Controls

IA32\_UARCH\_MISC\_CTL[DOITM] is a data operand independent timing mode control mechanism that restricts non-data operand independent timing behavior for the [listed instructions](/content/www/us/en/developer/articles/technical/software-security-guidance/resources/data-operand-independent-timing-instructions.html). A processor supports IA32\_UARCH\_MISC\_CTL[DOITM]¬†if IA32\_ARCH\_CAPABILITIES[12]¬†is 1.¬†WRMSR to IA32\_UARCH\_MISC\_CTL (MSR index 1B01H) is not defined as a serializing instruction.

Table 1: Enumeration of Data Operand Independent Timing Mode on IA32\_ARCH\_CAPABILITIES
| Register Address Hex | Register Address Dec | Register Name / Bit Fields | Bit Description | Comment |
| --- | --- | --- | --- | --- |
| 10AH | 266 | IA32\_ARCH\_CAPABILITIES | Enumeration of Architectural Features (RO) | If CPUID.(EAX-07H, ECX=0):EDX[29]=1 |
| 10AH | 266 | 12 | DOITM: The processor supports data operand independent timing mode. |  |

For Intel¬Æ Core‚Ñ¢ family processors based on microarchitectures before Ice Lake and Intel Atom¬Æ family processors based on microarchitectures before Gracemont that do not enumerate IA32\_UARCH\_MISC\_CTL, developers may assume that the instructions listed here operate as if DOITM is enabled.

Intel Core family processors based on Ice Lake and later, such as Tiger Lake, Lakefield, and Rocket Lake will enumerate DOITM. Intel Atom family processors based on Gracemont and later will also enumerate DOITM. Refer to the [Enumeration and Architectural MSRs](#enumeration) section for more information.

### Software Enabling

On certain processors, microcode updates may need to be loaded for IA32\_UARCH\_MISC\_CTL to be enumerated.

Software can enable data operand independent timing operation on a logical processor by setting IA32\_UARCH\_MISC\_CTL[DOITM] to 1. Setting DOITM to 1 may impact performance, and that impact may increase in future processor generations.

Users should evaluate their threat model to decide whether this is a significant threat to their applications and then ask the operating system to only deploy DOIT mode to applications that they deem necessary. Note that DOIT mode is not expected to significantly improve resistance to side channel attacks unless the software was carefully written to avoid such attacks (specifically, following the guidance in [Intel‚Äôs Guidelines for Mitigating Timing Side Channels Against Cryptographic Implementations](/content/www/us/en/developer/articles/technical/software-security-guidance/secure-coding/mitigate-timing-side-channel-crypto-implementation.html)).

Operating systems may wish to support IA32\_UARCH\_MISC\_CTL in a manner similar to [speculative store bypass disable](/content/www/us/en/developer/articles/technical/software-security-guidance/advisory-guidance/speculative-store-bypass.html).

## Interactions with Other Modes of Operation

### Interactions with¬†Intel¬Æ Software Guard Extensions (Intel¬Æ SGX)

While executing inside enclave mode, processors that enumerate support for DOITM will enable data operand independent timing mode irrespective of the settings that control the mode.

The existing Intel SGX architecture cannot manipulate DOITM and cannot trust the OS to manipulate DOITM.

To mitigate attacks on constant time code running in enclave mode, processors that enumerate support for DOITM will always enable data operand independent timing mode. This behavior is independent from the setting of DOITM itself.

This design choice considers both the complexity of extending the Intel SGX architecture to allow more dynamic control of mitigations and the existing reduced performance within enclave mode.

**Note**: Software with similar complexity concerns and which can tolerate reduced performance may also converge on a design that opts to leave DOITM always enabled.

### Interactions with Intel¬Æ Trust Domain Extension (Intel¬Æ TDX)

There are no special interactions or interactions between data operand independent timing mode and Secure Arbitration Mode-Virtual Machines Extensions (SEAM VMX) operation. In particular, the enabling of data operand independent timing mode is not impacted while operating in SEAM VMX mode.

The DOIT mode control will be made visible to trust domains (TDs) and the Intel TDX module will context switch the control between TDs. Unlike Intel SGX enclaves, TDs can decide to set this based on their threat model.

## Enumeration and Architectural MSRs

### DOIT Enumeration

IA32\_ARCH\_CAPABILITIES[12] enumerates support for the IA32\_UARCH\_MISC\_CTL MSR (addr 0x1B01) and bit 0 of that MSR (DOITM). This bit implements a data operand independent timing mode. This enumeration bit is called Data Operand Independent Timing Mode (DOITM).

Processors that do not enumerate IA32\_ARCH\_CAPABILITIES[DOITM] when the latest microcode is applied do not need to set IA32\_UARCH\_MISC\_CTL [DOITM] in order to have the behavior described in this document.¬†On certain processors, MXCSR may also need to be configured to avoid data-dependent behavior for the instructions listed in¬†[Data Operand Independent Timing Instructions with MXCSR Configuration Dependent Timing](/content/www/us/en/developer/articles/technical/software-security-guidance/resources/mcdt-data-operand-independent-timing-instructions.html). For additional information on MXCSR configuration, refer to¬†[MXCSR Configuration Dependent Timing](/content/www/us/en/developer/articles/technical/software-security-guidance/best-practices/mxcsr-configuration-dependent-timing.html).

### IA32\_UARCH\_MISC\_CTL MSR Definition

Table 2: IA32\_UARCH\_MISC\_CTL
| Register Address Hex | Register Name / Bit Fields | Permission | Bit Description | Comment |
| --- | --- | --- | --- | --- |
| 1B01H | IA32\_UARCH\_MISC\_CTL |  |  | If IA32\_ARCH\_CAPABILITIES[DOITM]=1 |
| 1B01H | 0 | R/W | Data Operand Independent Timing Mode (DOITM) | If IA32\_ARCH\_CAPABILITIES[DOITM]=1 |
| 1B01H | 63:1 | RO | Reserved |  |

This MSR is logical processor scoped and has a reset value of 0.

## Documented Data Operand Independent Timing Instructions

Refer to the list of¬†[documented Data Operand Independent Timing instructions](/content/www/us/en/developer/articles/technical/software-security-guidance/resources/data-operand-independent-timing-instructions.html).

## Footnotes

1. Refer to [Running Average Power Limit Energy Reporting](/content/www/us/en/developer/articles/technical/software-security-guidance/advisory-guidance/running-average-power-limit-energy-reporting.html).
2. MCDT\_NO is CPUID.(EAX=7H,ECX=2):EDX[5].

1

#### Product and Performance Information

1

Performance varies by use, configuration and other factors. Learn more at¬†[www.Intel.com/PerformanceIndex](http://www.intel.com/PerformanceIndex "Follow link").

Get Help

* [Company Overview](/content/www/us/en/company-overview/company-overview.html)
* [Contact Intel](/content/www/us/en/support/contact-us.html)
* [Newsroom](/content/www/us/en/newsroom/home.html)
* [Investors](https://www.intc.com/)
* [Careers](/content/www/us/en/jobs/life-at-intel.html)
* [Corporate Responsibility](/content/www/us/en/corporate-responsibility/corporate-responsibility.html)
* [Diversity & Inclusion](/content/www/us/en/diversity/diversity-at-intel.html)
* [Public Policy](/content/www/us/en/company-overview/public-policy.html)

* ¬© Intel Corporation
* [Terms of Use](/content/www/us/en/legal/terms-of-use.html)
* [\*Trademarks](/content/www/us/en/legal/trademarks.html)
* [Cookies](/content/www/us/en/privacy/intel-cookie-notice.html)
* [Privacy](/content/www/us/en/privacy/intel-privacy-notice.html)
* [Supply Chain Transparency](/content/www/us/en/corporate-responsibility/statement-combating-modern-slavery.html)
* [Site Map](/content/www/us/en/siteindex.html)
* [Recycling](/content/www/us/en/support/articles/000098122/services.html)
* [Your Privacy Choices
  California Consumer Privacy Act (CCPA) Opt-Out Icon](/)
* [Notice at Collection](/content/www/us/en/privacy/privacy-residents-certain-states.html)

Intel technologies may require enabled hardware, software or service activation. // No product or component can be absolutely secure. // Your costs and results may vary. // Performance varies by use, configuration and other factors. // See our complete legal [Notices and Disclaimers](https://edc.intel.com/content/www/us/en/products/performance/benchmarks/overview/#GUID-26B0C71C-25E9-477D-9007-52FCA56EE18C). //¬†Intel is committed to respecting human rights and avoiding causing or contributing to adverse impacts on human rights. See Intel‚Äôs [Global Human Rights Principles](/content/www/us/en/policy/policy-human-rights.html). Intel‚Äôs products and software are intended only to be used in applications that do not cause or contribute to adverse impacts on human rights.

[![Intel Footer Logo](/content/dam/logos/intel-footer-logo.svg "Intel Footer Logo")](/content/www/us/en/homepage.html "Intel Footer Logo")

![](https://www.intel.com/akam/13/pixel_76c5835b?a=dD0wZjE0MzM1MmIxZGVlMWM1ZDgxMWEyOTYwNTVhMWI2MDExY2E1Njg2JmpzPW9mZg==)

=== Content from jovanbulck.github.io_43fb3aa6_20250114_195806.html ===
Pandora: Principled Symbolic Validation of Intel SGX Enclave Runtimes

Fritz Alder1, Lesly-Ann Daniel1, David Oswald2, Frank Piessens1, and Jo Van Bulck1

1DistriNet, KU Leuven, Belgium, 2University of Birmingham, UK

Abstract‚ÄîThe popularity of Intel SGX technology in recent
years has given rise to a wide range of shielding runtimes to
transparently safeguard secure enclave applications against a
hostile operating system. Adequate validation of the crucial and
numerous shielding runtimes is, however, a multi-faceted and
fast-changing challenge, as new attack techniques against SGX
enclaves are discovered regularly and commonly necessitate
extensive software patches throughout the SGX ecosystem.

This paper proposes Pandora, a practical, enclave-aware
symbolic execution tool designed to address this challenge.
In contrast to existing tools, Pandora‚Äôs truthful and runtime-
agnostic symbolic execution of the exact attested enclave binary
for the first time allows to validate the critical enclave shield-
ing runtime itself. Furthermore, Pandora provides principled
foundations to deal with the moving-target nature of enclave
software security by implementing accurate taint tracking of
attacker inputs, a precise symbolic enclave memory model, and
support for pluggable vulnerability detectors.

We extensively evaluate Pandora on 11 different SGX
shielding runtimes with 4 detection plugins for a diverse set
of vulnerability types. Our experiments show that Pandora
can autonomously discover 200 new and 69 known vulnerable
code locations. Notably, Pandora is the first tool that allows a
wide-scale ecosystem investigation of recent pointer-alignment
software mitigations in real-world SGX enclave runtimes.

1. Introduction

Recent years have seen the rise of trusted execution
environments (TEEs) that provide strong, hardware-rooted
protection of small software components, called enclaves,
against hostile, possibly attacker-controlled system soft-
ware. With the release of the Software Guard Extensions
(SGX) [1], [2], included in selected Intel processors from
2015 onwards, TEE protection is readily available in today‚Äôs
mainstream computing platforms, and even more recent
technology, like the Trust Domain Extensions (TDX) [3] for
upcoming Intel server processors, continues to rely critically
on SGX enclaves. Thus, the widespread availability of SGX
has boosted ongoing interest in enclave applications and
limitations from both industry and academia.

While SGX hardware enforces that enclave memory can-
not be accessed from the outside, enclave software remains
ultimately responsible to be bug-free and should properly
sanitize registers and pointer arguments in the shared ad-
dress space. This non-trivial requirement has given rise to

a sizable ecosystem of SGX shielding runtimes that sup-
port diverse enclave applications. Modern SGX development
paradigms nowadays include (i) custom C/C++ software de-
velopment kits (SDKs) [4], [5] that directly expose a secure
function call abstraction; (ii) numerous SGX-tailored library
operating systems (libOSs) [6]‚Äì[10] to support lift-and-shift
protection of existing legacy applications; and (iii) enclaved
memory-safe language runtimes [11]‚Äì[14].

The popularity of Intel SGX has, furthermore, triggered
a long and ongoing line of attacks exploring limitations of
this technology [15]. In this respect, a clear trend has been
that, while some of the earlier SGX attacks [16]‚Äì[20] could
still be mitigated fully transparently at the hardware level
by means of CPU microcode patches, progressively more
stringent demands have been placed on enclave software
behavior to mitigate evermore specific vulnerabilities [20]‚Äì
[27] when interacting with the untrusted environment. This
has increasingly made secure enclave software development,
and especially the sanitization responsibilities for the numer-
ous SGX shielding runtimes, a moving target (cf. Section 2).
While software mitigations for transient-execution and
side-channel attacks have been widely studied for Intel
SGX, and presently various compiler-based solutions [24],
[28]‚Äì[33] exist, the crucial aspect of validating the security
of the enclave interface has received much less attention.
Researchers have only recently started to explore more sys-
tematic analyses through fuzzing [34]‚Äì[36] or symbolic exe-
cution [37]‚Äì[39]. However, existing approaches fall short in
that they focus on validating enclave application logic only,
without considering vulnerabilities in the crucial shielding
runtime, or even being compatible with diverse runtimes
beyond Intel‚Äôs SGX SDK. Furthermore, existing approaches
focus mainly on detecting memory-safety issues, without
considering more subtle types of shielding responsibilities,
such as untrusted pointer alignments [25], [26] and CPU
register sanitizations [21], [22], [27]. These approaches,
hence, are not fitted for the diverse and fast-changing SGX
software ecosystem, where a subtle sanitization oversight in
a shielding runtime may be the equivalent of a zero-day
rootkit vulnerability in a commodity OS kernel.

To address these challenges, the main objective of our
work is the development of a principled, tool-supported
approach to validate the security of enclave software binaries
using symbolic execution. We propose Pandora, an exten-
sible, enclave-aware symbolic execution tool that is built
upon the popular angr framework and extends it with several
technical contributions. Particularly, we accurately
novel

implement missing, SGX-specific x86 semantics, conceive a
proficient, enclave-aware symbolic memory model, and de-
velop a generic enclave memory extractor. Thus, Pandora for
the first time enables truthful and runtime-agnostic symbolic
exploration of full enclave binaries, identical to the attested
initial memory layout and including the crucial shielding
runtime itself. Furthermore, to deal with the moving-target
nature of secure enclave software development, we propose
pluggable vulnerability detectors, extending the notion of
angr breakpoints with SGX-specific memory-access and
control-flow events that allow rapid scripting of powerful
Pandora plugins.

Our extensive experimental evaluation on 11 different
shielding runtimes from research and industry, with 4 plu-
gins validating diverse sanitizations, highlights the delicacy
and complexity of present SGX software responsibilities.
We demonstrate the power of Pandora‚Äôs truthful symbolic
execution semantics by identifying several subtle vulnera-
bilities in commonly overlooked low-level enclave initializa-
tion and relocation code that cannot be analyzed with state-
of-the-art enclave symbolic-execution tools. We, further-
more, are the first to construct an automated tool for wide-
scale validation of intricate untrusted pointer-alignment soft-
ware mitigations [26], [40] recently deployed throughout the
SGX ecosystem in response to √ÜPIC [25] attacks.

In the wider research landscape, we envision our open-
source tool as a solid foundation to enable future science on
validating the security of enclaved software, including low-
level and fast-changing SGX software shielding runtimes.

Contributions. In summary, our contributions are:

‚Ä¢ We propose Pandora, an extensible, enclave-aware
symbolic execution framework for truthful and prin-
cipled validation of SGX binaries.

‚Ä¢ Responding to the heterogeneity of the emerging SGX
software landscape, we propose a universal enclave
memory extractor and corresponding angr loader.

‚Ä¢ Responding to the volatile and elusive SGX software
responsibilities, we propose pluggable detectors for
diverse vulnerabilities, from validating CPU register
cleansing over untrusted pointer sanitization and align-
ment constraints to control-flow transitions.

‚Ä¢ In an extensive experimental evaluation on 11 different
SGX runtimes, Pandora autonomously confirmed 69
known and 200 new vulnerable code locations.

Disclosure and Artifacts. We responsibly disclosed all
findings to the respective vendors (tracked via 7 CVEs), pro-
viding them with comprehensive reports from our tool. We,
furthermore, included recommendations for software miti-
gations and assisted in validating the applied fixes, which
has uncovered remaining issues in at least one runtime.

In the spirit of open science, we provide a comprehen-
sive open-source artifact1 with self-contained HTML reports
of all vulnerabilities from Table 2, multiple runtimes to test
out Pandora, and documentation of how to reproduce our

1. Available at https://github.com/pandora-tee.

Figure 1. A shielding runtime transparently protects enclave applications
by 1 cleansing CPU registers upon entry or exit events; 2 finalizing
the initial memory layout, including any in-enclave relocations, upon first
entry; and 3 sanitizing pointer arguments before handing control over to
the application, which can call back via trusted standard library functions.

results. The artifact also includes the binaries of analyzed
shielding runtime versions (where allowed by licensing)
to provide a representative public data set of vulnerable
enclaves that can serve as a baseline for future research.

2. Background and Related Work

Enclave Shielding. Due to its strong attacker model, en-
clave software faces several additional security challenges
compared to traditional user-space software. In current prac-
tice, these additional challenges are primarily handled by a
shielding runtime that transparently intervenes on interac-
tions with the untrusted environment, as shown in Fig. 1.

Intel SGX enclaves are embedded as a contiguous vir-
tual address region within an untrusted, surrounding host
application. As in-enclave software is allowed to freely
dereference outside memory locations, the host application
can efficiently communicate through the enclave‚Äôs applica-
tion programming interface (API) by passing pointers to
arguments and return values in the shared virtual address
space. However, this also opens the door to an especially
powerful class of confused-deputy attacks, necessitating
that the enclave shielding runtime adequately sanitizes any
attacker-provided API pointers prior to dereference. Despite
this requirement being well-known and the availability of
automated methods‚Äîsuch as the edger8r tool to automat-
ically generate interface sanitization code from developer
annotations in the Intel SGX-SDK [4] and Open Enclave [5],
or the Rust type system leveraged in EDP [11]‚Äîa continu-
ous stream of vulnerabilities [21], [34], [37]‚Äì[39] has proven
SGX pointer sanitization vulnerabilities to be particularly
elusive and widespread in practice. As an example, Listing 1
illustrates how adequately sanitizing an elementary pointer-
to-pointer argument can be non-trivial in practice.

to the

Moreover,

in response

recently disclosed
√ÜPIC [25] and related memory-mapped I/O (MMIO) [26]
stale data vulnerabilities in Intel processors, enclave soft-
ware requirements for sanitizing untrusted pointer arguments
have been considerably complicated. That is, not only does
enclave software nowadays need to ensure that attacker-
provided pointers properly fall entirely outside the protected
enclave range, but any subsequent pointer dereferences also
need to proceed at a certain alignment and size or need to be
preceded and followed by fragile x86 instruction sequences

EnclaveBoundaryEnclave RuntimeEntryExitApplicationRuntimelibraryInitEENTERvoid encl_get_from_addr(struct user_arg *op) {

assert(is_outside_enclave(op, sizeof(*op)));
// Copy op->addr to avoid TOCTOU attacks
volatile char* ptr = (char*) op->addr;
assert(is_outside_enclave(ptr, 1));
g_state = *ptr; }

Listing 1. Example of API sanitization: the highlighted lines enforce that
all attacker-controlled pointers lie outside the enclave prior to dereference.

the CPU
to cleanse microarchitectural buffers and stall
pipeline. These successive refinements of software respon-
sibilities hence necessitated extensive and ongoing changes
throughout the heterogeneous SGX software ecosystem.

A parallel moving-target evolution can be observed at
the level of the application binary interface (ABI). An
initial comprehensive study [21] has shown that secure
initialization was widely overlooked for certain crucial CPU
configuration flags, such as the x86 direction flag that
may introduce memory-safety violations in otherwise secure
code. Similar issues have since been shown for stack-pointer
initialization in SGX enclave exception handlers [23] and
for x87 and SSE floating-point configuration registers [22].
The latter was most recently refined once again in an Intel
advisory [27] with additional SSE sanitizations to protect
against certain operand-dependent floating-point instruction
timing channels in otherwise constant-time code. A recent
overview study [41] has documented how these ABI vulner-
ability disclosures necessitated several rounds of widespread
patches throughout popular SGX shielding runtimes.

Symbolic Execution. Symbolic execution [42] statically
interprets a program using symbolic inputs (i.e., mathe-
matical terms) and collects constraints (i.e., mathematical
formulas over these terms) encoding programs paths. These
constraints can be solved with an SMT solver to generate
concrete inputs exercising the path or check security as-
sertions. Its ability to systematically explore program paths
and generate concrete inputs has made symbolic execution
a tool of choice for intensive testing [43] and vulnerability
analysis [44]. More recently, researchers have also started
to apply symbolic execution to the specific context of Intel
SGX enclaves [37]‚Äì[39]. We provide an extensive compari-
son of Pandora to these existing tools in Section 3.1. Some
works [20], [45] have, furthermore, focused on detecting
microarchitectural side-channel vulnerabilities in enclave
applications using symbolic execution, but their goal is or-
thogonal to our scope of validating shielding responsibilities.

Fuzzing. A well-known, complementary approach to static
analysis via symbolic execution is dynamic concrete ex-
ecution via fuzz testing. An orthogonal and concurrent
line of work [34], [35], [46], [47] has started to explore
such fuzzing for Intel SGX enclave applications. Compared
to symbolic execution, fuzzing can more easily scale to
complex code bases by quickly generating test cases and
may find bugs with fewer false positives. However, unlike
symbolic execution, fuzzing requires carefully crafted test
cases to investigate convoluted execution paths. Hence, in

line with existing surveys [48], [49], we regard fuzzing-
based approaches as complementary to symbolic validation.

3. Problem Statement and Overview

The combination of a varied and evolving Intel SGX
runtime ecosystem with the frequent discovery of new attack
techniques that necessitate additional software sanitizations
makes the problem of principled enclave software validation
particularly challenging and, indeed, largely unexplored for
the fundamental shielding runtimes themselves. Therefore,
we set the following goals:
G1 Truthful symbolic exploration. Enclave-aware symbolic
execution should closely mimic the real SGX hard-
ware. Particularly, to not miss vulnerabilities in the
runtime itself, the symbolic exploration should (a) start
from the very first entry instruction without skipping
initialization procedures or stubbing runtime library
functions; and (b) operate on the exact initial memory
contents, as remotely attested via MRENCLAVE [50],
while accurately detecting and symbolizing any subse-
quent accesses to untrusted or unmeasured memory.
G2 Runtime-agnostic. Validation should not be limited to
enclaves developed with any specific single shielding
runtime. The heterogeneous SGX ecosystem with ill-
documented and varying enclave binary formats calls
for a lightweight conversion approach to a unified
format capturing the exact enclave memory layout.
G3 Extensible validation policies. The system should sup-
port prompt reactions to evolving sanitization responsi-
bilities by adding new or modified vulnerability detec-
tion plugins. This calls for an approach that decouples
validation policies from enclave-aware symbolic exe-
cution mechanisms, such that plugins can solely focus
on elegantly expressing the required software security
invariants to be validated for explored paths.

In addition to these three research goals, we define the
following secondary design challenge:
D1 Accessibility. The tool should be open-source and easy
to use, including on closed-source binary targets. Re-
ports should be easily interpretable by human analysts.

3.1. Research Gap

Initially, SGX software vulnerability research was
mainly guided through manual code review [21]‚Äì[23], [41],
whereas automated enclave analysis through symbolic exe-
cution has only more recently started to be explored [37]‚Äì
[39]. Table 1 compares Pandora to these existing tools. In
summary, existing approaches are mostly focused on appli-
cation bug detection instead of principled validation of the
absence of shielding runtime vulnerabilities. This means that
they are inherently insufficient for truthful symbolic explo-
ration (G1), as the focus is on analyzing enclave application
logic only, while (largely) skipping the underlying shielding
runtime and operating on inaccurate initial memory con-
tents. Moreover, existing tools are ill-fitted for the diverse

TABLE 1. COMPARISON OF SYMBOLIC-EXECUTION TOOLS FOR SGX.

Tool

App SDK Entry Init

Runtime

Binary

D u m p

R eentry

Plugins

Ptr ABI √ÜPIC Jmp Open

TEEREX [37]
Guardian [38]
COIN [39]
Pandora

Intel
Intel
Intel
any

(cid:32)
(cid:32)
(cid:32)
(cid:32)

Features can be fully (

(cid:35)
(cid:32)
(cid:35)
(cid:32)
), partially (

(cid:35) (cid:32) (cid:35) (cid:71)(cid:35) (cid:71)(cid:35) (cid:35)
(cid:35) (cid:71)(cid:35) (cid:35) (cid:35) (cid:71)(cid:35) (cid:71)(cid:35)
(cid:35) (cid:35) (cid:35) (cid:35) (cid:71)(cid:35) (cid:35)
(cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32)

(cid:35)
(cid:35)
(cid:35)
(cid:32)
) supported. Columns 4‚Äì7 denote

), or not (

(cid:71)(cid:35)
(cid:71)(cid:35)
(cid:35)
(cid:32)

(cid:35)
(cid:32)
(cid:32)
(cid:32)

whether the tool executes the runtime entry and initialization phases; can handle
binaries without additional specification; and uses the exact memory layout (dump).

(cid:71)(cid:35)

(cid:35)

(cid:32)

SGX ecosystem (G2), as they all make runtime-specific
assumptions that strictly limit them to enclaves developed
with Intel‚Äôs SGX SDK only. Finally, existing tools focus
mainly on a narrow set of classical memory-safety issues
for pointers without principally supporting more intricate
shielding responsibilities (G3), such as recently rolled out
pointer-alignment √ÜPIC mitigations [25], [26].

TEERex. TEEREX [37] is a closed-source prototype to
detect memory corruption vulnerabilities in enclave applica-
tions developed with the Intel SGX SDK. Similarly to our
work, TEEREX is based on angr [48], a popular symbolic
execution tool for binary code, and performs taint tracking of
untrusted attacker arguments and memory accesses outside
the enclave using unconstrained symbolic values.

In contrast

to Pandora, however, TEEREX does not
support truthful symbolic exploration (vs. G1a), as it entirely
skips analysis of the whole trusted runtime and directly
performs symbolic execution of enclave application entry
points, called ecalls. Moreover, TEEREX is inherently
runtime-specific (vs. G2), as it relies on Intel SGX SDK-
specifics to identify addresses of ecall functions, to hook
specific pointer validation functions, and to set up an approx-
imate, non-truthful initial memory layout (vs. G1b). Con-
cerning vulnerability detection (G3), TEEREX only reports
unconstrained and NULL-pointer dereferences and cannot
detect more subtle pointer issues, or ABI and √ÜPIC issues.
Particularly, by hooking the crucial validation functions
(e.g., is_outside_enclave in Listing 1), TEEREX may
miss logical partial validation errors [21] that will be caught
by Pandora‚Äôs precise enclave-aware memory model (cf. Sec-
tion 7). TEEREX is not openly available (vs. D1).

Guardian. Guardian [38] is similarly based on angr and can
partially check API and ABI shielding policies. Regarding
truthful exploration (G1a), Guardian is the only prior work
that starts at the enclave entry point within the trusted run-
time, but it nevertheless skips the complex enclave initial-
ization phase, which may still contain critical vulnerabilities
(cf. Section 7). Furthermore, similar to TEEREX, Guardian
is constrained to binaries developed with specific versions of
the Intel SGX SDK (vs. G2) and only constructs an approx-
imate, non-truthful initial memory layout (vs. G1b). As to
vulnerability detection (G3), Guardian validates a principled,
yet fundamentally incomplete orderliness policy, where the
developer is required to manually annotate execution phases
(vs. D1). Guardian validates that, after the entry phase, an

Figure 2. Overview of the Pandora architecture.

(incomplete) blocklist of ABI configuration registers has
been cleared, and that untrusted memory outside the enclave
is only accessible during execution of the shielding runtime,
but not during the application phase. This simplified permis-
sion state-machine model may be overly conservative for
applications and, more problematically, remains inherently
insufficient to detect critical vulnerabilities (e.g., CVE-2018-
3626 [21]) in the shielding runtime itself, as the latter is
allowed unrestricted access to the full address space.

in enclave

COIN. COIN [39] uses concolic execution to find
applications.
memory-safety vulnerabilities
COIN specifically targets applications developed on top
of the Intel SGX SDK (vs. G2) and requires the enclave
source code (vs. D1) for extracting the parameters of
ecalls in order to set up an approximate, non-truthful
initial state (vs. G1b). Regarding vulnerability detection
(G3), COIN is largely orthogonal to our work by focusing
on traditional memory-safety application vulnerabilities
instead of nuanced, enclave-specific shielding issues and
skipping analysis of the runtime itself (vs. G1a).

Finally, upon finalization of our paper, a concurrent study
called SymGX [51] was published, focusing on detecting
cross-boundary pointer vulnerabilities in the source code of
Intel SGX applications.

3.2. Solution Overview

Figure 2 depicts a high-level overview of the Pandora
software architecture, which we implemented in 5,934 lines
of extensible Python code (as measured by sloccount).
At Pandora‚Äôs core, the engine component 1 augments the

pointersabiintel_sdkPluginsSDKlinux_selftestUI + Reportsangrsconeenclave_dumpcontrolflowaepicDynamic PhaseSGX-Tracer+EnclavebinaryMemorydumpJson layoutEnclave-Aware ExplorationEnclave memorySGX instructionsEnclave reentryExploration limiterPandora Engineunderlying symbolic execution library angr 2 [52] with ac-
curate SGX semantics and drives the enclave-aware truthful
symbolic exploration 3 (G1), described in Section 4. The
engine is primed with the exact initial enclave image via a
novel, runtime-agnostic dynamic memory extraction phase
4 (G2) detailed in Section 5. As such, Pandora is the first
symbolic-execution tool that can find vulnerabilities before
the application code, i.e., in the runtime entry procedures
and in the low-level enclave initialization phase.

5

While symbolically executing a binary, the Pandora en-
(G3), de-
gine triggers vulnerability-detection plugins
scribed in Section 6, that are based on subscribable events
exposed by the SGX-aware exploration. After a completed
run, Pandora formats the findings of each plugin into con-
venient and interactive HTML reports 6 (D1), shown in
Appendix A, including severity levels, descriptions, disas-
sembly, register dumps, and full basic-block backtraces to
enable human analysts to investigate the reported issues.

4. Enclave-Aware Symbolic Execution (G1)

4.1. Modeling x86 Instruction Semantics

The underlying VEX representation used by angr does
not have a symbolic model for many x86 instructions that
commonly occur in enclave binaries. Most prominently,
the ENCLU user leaf instructions [53] are used inside the
tasks, such as creating
enclave to perform architectural
a local attestation report (EREPORT), generating crypto-
graphic keys (EGETKEY), or exiting the enclave (EEXIT).
While prior work faced similar angr limitations and either
did not execute [37] or merely hooked and skipped [38]
over these instructions, Pandora truthfully emulates used
enclave instructions as closely as possible. For example,
in EREPORT, we copy the relevant SGX enclave control
structure (SECS) fields provided by the enclave loader,
including the processor extended features request mask, into
the generated report structure. When specific fields are not
available and no sane defaults can be provided, values are
symbolized to ensure that all possible paths are explored.

Furthermore, in response to advanced ABI attacks [22],
[27], instructions like XSAVE and XRSTOR or their variants
are commonly used to save and restore extended x86 register
on enclave context switches. In contrast to prior work [37],
[38], Pandora carefully emulates their behavior as closely
as possible. Where necessary, we add dedicated shadow
registers to keep track of special x86 registers, such as
MXCSR, which are not normally part of angr‚Äôs execution
model. As shown in Section 7, this precise register view
enables Pandora plugins to accurately uncover subtle over-
sights, e.g., attacker-controlled registers when switching to
enclave functions or insecure MXCSR configuration values.

4.2. Taint Tracking of Attacker Inputs

In order to accurately deal with attacker-controlled in-
puts, Pandora comes with a capable symbolic taint-tracking

mechanism. Specifically, initial register contents on enclave
entry, as well as memory reads from outside the enclave or
from uninitialized unmeasured pages inside the enclave (cf.
Section 4.3), are transparently replaced with unconstrained
symbolic values. Thus,
the symbolic execution initially
makes no assumptions about attacker-provided inputs, until
specific constraints are added by any subsequent sanitiza-
tions performed by the enclave code. Pandora, furthermore,
uses angr‚Äôs annotation system to mark attacker-controlled
symbolic values with an attacker-taint, which is conser-
vatively propagated during symbolic execution and can be
conveniently queried by plugins. For instance, plugins can
check that values are properly sanitized (e.g., Section 6.1) or
react differently based on whether a value is attacker-tainted
or not (e.g., Section 6.2).

Pandora‚Äôs taint tracking mechanism only tracks explicit
data flows. Any implicit flows that result from attacker-
controlled control flow are ignored (e.g., Pandora does not
propagate the taint from x to y in if(x == 1){ y = 1 }).
While tracking only explicit flows may, in principle, lead
to false negatives, it brings a large increase in practical-
ity [54] and is common in taint-tracking-based vulnerability
detection [55].

4.3. Enclave-Aware Memory Model

Pandora features a fully enclave-aware memory model
that truthfully simulates the enclave address space in a more
accurate and expressive way than prior work, while also in-
cluding reasonable performance optimizations. Particularly,
we are the first to realize a precise, runtime-agnostic enclave
memory model that properly recognizes attacker-controlled
symbolic addresses and sizes and that takes into account
novel attack surface from unmeasured SGX enclave pages.

4.3.1. Address-Space Partitioning. At its core, we im-
plemented our enclave-aware memory model as an angr
MemoryMixin extension that performs rigorous checks on
every memory access. Particularly, we use angr‚Äôs constraint
solver to unambiguously decide for every accessed buffer
with a possibly symbolic address and size whether it is re-
stricted to (i) lie fully inside the enclave; (ii) lie fully outside
the enclave; or (iii) partially touch the protected enclave
range. Accesses to memory inside or outside the enclave will
be handled differently, as outline below. Pandora plugins
can, furthermore, subscribe to these respective events to
check and report specific vulnerabilities (cf. Section 6).

Note that the above accurate classification is non-trivial
to implement, and prior work side-stepped these intricacies
by either hooking runtime-specific pointer-validation func-
tions [37] or ignoring the (possibly symbolic and attacker-
controlled) size of memory reads [38]. Our fully symbolic
memory model, on the other hand, allows to meticulously
detect subtle oversights or logical errors in the crucial valida-
tion functions themselves. For instance, Section 7 discusses
a particularly intricate finding where overflow protection
logic was silently optimized away by the compiler.

4.3.2. Untrusted Memory Accesses. For accesses falling
outside the protected enclave range, we model the strongest
type of adversary that utilizes tools such as SGX-Step [56]
to perform instruction-granular time-of-check to time-of-
use attacks. For example, an enclave checking an external
pointer that resides in untrusted memory, before accessing
this pointer again at a later time (as in Listing 1) may
realistically receive two different values. Pandora truthfully
simulates this by ignoring untrusted memory writes and
fully symbolizing all untrusted memory reads with a fresh
attacker-tainted symbolic value on every access.

4.3.3. Enclave Memory Accesses.
In close accordance
with the SGX specification [53], we distinguish two types
of memory inside the enclave: measured and unmeasured
pages. Measured enclave pages are attested as part of
the MRENCLAVE enclave identity and are, hence, always
demonstrably initialized to the exact value provided by the
enclave loader. Unmeasured enclave pages, on the other
hand, are protected from enclave creation time onwards, but
their initial content is not attested as part of the MREN-
CLAVE enclave identity. These unmeasured enclave pages
have many uses in enclaves, for example to reserve heap
memory or to load additional code or data during execution
that did not exist at enclave creation time yet. As the initial
value of these pages is not part of the enclave identity, and
thus under attacker control, enclave software must always
securely overwrite these pages before first use. However,
to the best of our knowledge, to date no sanitizer exists to
validate this critical security property. To enable this with
Pandora, we ensure that any read from unmeasured enclave
memory initially returns an attacker-tainted symbolic value.
Only when unmeasured bytes are securely initialized, we
create an angr memory backing and the newly written secure
values will be taken into account for future reads.

Pandora, furthermore,

implements two types of safe
performance optimizations. First, we remove measured and
initialized unmeasured enclave memory that consists of
all-zero bytes from the angr backend. Any reads from
such regions will statically return zero bytes until they are
overwritten with non-zero data. Second, only for source
and destination buffers that are constrained to fall entirely
inside the enclave, we optionally hook common memory-
management functions (memcpy and memset) and x86
rep string operations with custom SimProcedures that
eliminate loop overhead, while still taking care to trigger
any relevant angr mixins and breakpoints.

4.4. Enclave Entry and Reentry

During enclave lifetime, EEXIT and EENTER instruc-
tions can switch execution to and from the untrusted envi-
ronment. Prior work [37]‚Äì[39] relied on parsing runtime-
specific and fragile data structures to find out the supported
ecalls in order to skip the crucial runtime entry and/or
initialization phases entirely and immediately start executing
at the respective application ecall function.

4.4.1. Enclave Entry. To truthfully execute entry into the
enclave, we parse the actual thread control structure (TCS)
from enclave memory to retrieve the entry point location
and fill registers with the exact same values that they would
receive from the architecture, such as the TCS address and
FS and GS base addresses. All other registers are filled with
unconstrained, attacker-tainted symbolic values to initiate
Pandora‚Äôs taint-tracking mechanism (cf. Section 4.2).

4.4.2. Enclave Exit. Pandora allows to truthfully build up
enclave state by emulating a new EENTER with the same
accumulated memory view after a symbolic path reached
the EEXIT instruction. Hence, the enclave entry code in
the runtime itself will perform any necessary checks and au-
tonomously decide whether the entry request is an ecall or
an ocall return and dispatch this request accordingly. The
strength of this approach is that subtle attack vectors, like
dereferencing a function pointer before in-enclave relocation
(cf. Section 7) or returning from an ocall where no prior
ocall was executed [21], can in principle be detected.

4.5. Path Exploration and State Reduction

Pandora‚Äôs unique focus on truthful symbolic exploration
of the entire enclave binary, including low-level shielding
runtime code, comes with the potential cost of state explo-
sion. To reduce memory consumption for individual explo-
rations, Pandora optionally supports depth-first exploration
in addition to breadth-first exploration.

With regard to reentry, every path that reached EEXIT
would have to be reentered in a naive approach, because
the enclave may have accumulated relevant global state.
However, we observed that many paths result in a clean
failure that
is reported to the untrusted world with the
request to restart the enclave with correct parameters. To
avoid redundantly exploring all these semantically equiva-
lent traces, we implement a novel state uniqueness reduction
before reentering enclave exploration. That is, two symbolic
EEXIT states are different from each other only if they have
made different changes to the internal memory of the en-
clave. For example, two enclave traces that both result in no
changes to the enclave except setting a specific bit indicating
that the enclave failed, are equivalent and reentering both
would be redundant. With this uniqueness criterion, we thus
remove all non-unique enclave traces before preparing them
for reentry, i.e., before Pandora executes on them again. Note
that this approach is a safe over-approximation, e.g., states
may still be semantically equivalent even though they differ
in some de-allocated stack variables. However, we found
that our state uniqueness reduction is sufficient to greatly
reduce the state space without risking that unique states
may be lost. The impact of this optimization ultimately
depends on the runtime, i.e., on the number of individual
paths that lead to enclave exits. Specifically, for the runtimes
investigated in this work, this state reduction has an efficacy
between 14% (EnclaveOS, 13 of 93 exit states pruned) and
60% (Occlum, 1694 of 2811 exit states pruned).

5. Runtime-Agnostic Enclave Loading (G2)

in contrast

Truthful symbolic execution naturally starts with an
accurate representation of the initial enclave memory lay-
out (G1b). Unfortunately, however,
to well-
established standards like the executable and linkable format
(ELF) for Linux binaries, there exists no standardized format
to distribute SGX binaries. Hence, over the last years, all
SGX shielding runtimes have adopted their own custom
formats to describe the additional information needed to
correctly load the enclave, e.g., often by encoding opaque
blobs into additional ELF metadata sections [4], [5]. This is
especially problematic as Intel SGX requires a particularly
involved, multi-stage loading process [1], [53].

First, the untrusted system software constructs the initial
enclave memory layout, containing regions for code and
data, and also including several unique enclave-specific
data structures. The two most prominent data structures are
the SECS structure describing, among others, the enclave
load address and size, as well as the TCSs, describing
the enclave entry point and thread-local data storage. Fur-
thermore, as SGX enclaves are commonly compiled as
position-independent code and loaded as dynamic libraries,
the MRENCLAVE identity must be independent of the load
address. Hence, the enclave cannot rely on the untrusted
loader to perform any remaining ELF relocations (e.g., for
dynamic function-pointer tables). Thus, as a second loading
step, enclave shielding runtimes generally include in-enclave
code to perform any necessary ELF relocations upon the first
enclave entry, i.e., after the enclave has already been created
and loaded into memory.

Static Analysis. Notably, all prior works [37]‚Äì[39] on SGX-
aware symbolic execution entirely side-step the aforemen-
tioned intricacies by restricting themselves to one particular
runtime, specifically the Intel SGX SDK, and by load-
ing the enclave largely as a normal ELF file. Particularly,
existing approaches only take care to create approximate
space for stack and heap and either skip to the application
directly [37], or they manually patch fragile and version-
specific global data structures to falsely mark the symbolic
enclave as initialized and skip over the costly, low-level
runtime initialization and relocation phases [38]. Thus, prior
works simulate an inaccurate enclave memory layout (vs.
G1b) and are, moreover, only compatible with one specific
version of one specific runtime (vs. G2).

it

We argue that, with ample code review or reverse-
engineering efforts,
is in principle possible to devise
an approach that accurately mimics the runtime-specific
loading process to construct a truthful initial memory layout,
satisfying G1b. Indeed, Appendix B describes such optional
support we added to Pandora to load enclave binaries from
selected runtimes based on static analysis of a given en-
clave binary. We found, however, that such a purely static-
analysis approach is highly labor-intensive and inherently
fragile, requiring to implement a custom loader for every
studied enclave runtime, possibly even with changes across
runtime versions. This would evidently limit the scope and

not satisfy our vision of runtime-agnostic analysis for the
sprawling SGX ecosystem that has become heterogeneous
both in runtime capabilities as well as in programming
languages available to the enclave developer.

Dynamic Enclave Memory Extraction. To overcome the
labor-intensity and inherent fragility of the above pure static
analysis approach with runtime-specific loaders, Pandora
supports a more powerful approach that requires a short-
lived dynamic execution phase to load the binary-under-test
once. Specifically, we developed a minimal standalone pro-
gram, called SGX-TRACER, to passively observe the loading
process of an enclave binary on actual Intel SGX hardware.2
SGX-TRACER consists of about 400 lines of C code and uses
the ptrace Linux system call to attach to the untrusted
enclave host process and intercept all calls to the (in-kernel
or out-of-tree) Intel SGX driver. SGX-TRACER can thus
fully transparently (i) detect enclave creation via ECREATE
and record crucial enclave SECS metadata, including load
address and size; (ii) record the exact memory contents of all
pages that are subsequently added via EADD; and (iii) track
additional metadata and permissions for these pages, as
well as locate special pages like TCSs, before the enclave
identity is finalized via EINIT. This allows SGX-TRACER
to accurately extract the exact initial enclave memory (G1b),
as attested by MRENCLAVE, for any SGX process (G2).

The output by SGX-TRACER is stored as a binary dump
and accompanying JSON file and can subsequently be
used on non-SGX hardware by Pandora. Particularly, we
developed a minimal angr loader to reconstruct a truth-
ful symbolic memory view, including permissions of each
page and whether the page is measured or unmeasured (cf.
Section 4.3). This inherently runtime-agnostic loader makes
Pandora compatible with any enclave dump extracted via
SGX-TRACER, regardless of runtime-specific loading details.
One downside of utilizing an enclave memory dump for
symbolic execution is that this process loses all debug sym-
bols, including function names. Pandora can run without any
of these symbols, but upon finding a potential vulnerability,
the generated reports may be less understandable for human
analysts (vs. D1). Hence, we implemented a custom symbol
handler that can augment a plain memory dump extracted
by SGX-TRACER with symbol information from the original
ELF file, if optionally provided via a Pandora command-line
option (together with a static offset).

6. Pluggable Vulnerability Detection (G3)

During symbolic exploration, angr

triggers a set of
breakpoints that can be hooked to investigate the symbolic
state. Exemplary angr breakpoints are memory or register
accesses and function calls. Pandora extends the legacy angr
events with a set of eight new enclave-specific breakpoints
(cf. Appendix C). Specifically, Pandora exposes breakpoints
before and after enclave entry and exit, as well as break-
points before and after symbolic memory reads and writes

2. Real SGX hardware may not even be a strict requirement, as SGX-

TRACER could, in principle, also spoof the existence of the SGX driver.

that are restricted to resolve fully inside, fully outside, or
partially overlapping with the enclave memory range.

Pandora‚Äôs enclave-aware breakpoints form the basis for
our notion of pluggable vulnerability detection (G3). Specif-
ically, specialized plugins can subscribe to relevant enclave
events, as well as legacy angr breakpoints, to accurately vali-
date certain software invariants during symbolic exploration.
We created 4 plugins for a diverse set of enclave shielding
runtime responsibilities at the levels of ABI register cleans-
ing, API-level pointer arguments, √ÜPIC-style pointer align-
ment considerations, and attacker-controlled control flows.
Plugins can, furthermore, make use of Pandora‚Äôs built-in
reporting interface (D1) to conveniently summarize any find-
ings in human-readable HTML reports that are automatically
annotated with all relevant information, e.g., a severity score
and description of the issue and how to reach the vulnerable
state (cf. Appendix A).

6.1. ABI-Level CPU Register Sanitization

Enclaves share the CPU register set with their untrusted
surrounding host process. An important responsibility of the
shielding runtime is, therefore, to securely initialize any low-
level configurations registers on enclave entry. Due to the
intricacies of these low-level register manipulations, those
sanitizations have to be carefully implemented in a fragile,
hand-written assembly stub before a jump into higher-level
languages can be securely made, compliant with ABI ex-
pectations [57], [58] by the compiler.

While the general concept of ABI-level sanitization is
relatively well-understood across SGX shielding runtimes,
an ongoing line of manually discovered vulnerabilities [21]‚Äì
[23], [27], [41] has underlined the intricacies and chal-
lenges for secure register initialization in the complex x86
instruction set. Prior work on automated enclave software
vulnerability detection has either fully ignored CPU register
sanitization by focusing on API validation only [34], [37],
[39], or resorted to a simplistic and incomplete blocklist
approach that merely checks whether selected CPU regis-
ters have certain concrete safe values [38]. On the other
hand, Pandora‚Äôs ABISan plugin proposes a more principled
approach based on taint tracking, which can autonomously
discover insufficient register initialization or cleansing.

6.1.1. Attacker-Tainted Configuration Registers. The
ABISan plugin hooks all angr register read events and relies
on Pandora‚Äôs taint-tracking mechanism (cf. Section 4.2) to
detect when unsanitized CPU configuration registers are
read. To avoid evident false positives, ABISan only requires
a concise allowlist for the x86 data registers, i.e., the 16
general-purpose registers, 16 vector registers, and floating-
point unit (FPU) register stack, which do not contain control
or status bits and, hence, are allowed to be tainted with
attacker inputs. Any other attacker-tainted register reads will
be automatically reported as critical policy violations.

Our systematic taint-tracking approach has two main
strengths compared to simply checking that an incomplete
subset of registers has been initialized to certain values [38].

First, ABISan can autonomously track all relevant occur-
rences where the attacker has influence over the result
of a computation through control registers.3 This may, in
principle, even include yet unknown ABI attack avenues.
For instance, we experimentally validated that ABISan
can fully autonomously discover attacker-tainted reads from
individual bits in the RFLAGS [21] register, e.g., the crucial
direction flag for x86 REP string instructions, as well as
a particularly subtle oversight for floating-point operations
that required several rounds of patches in Rust-EDP and
OpenEnclave to make sure that not only the x87 FPU control
word is initialized, but also the internal x87 tag word [22].
Second, ABISan also enables tracking advanced attack vec-
tors where the enclave would inadvertently restore tainted
control registers prior to using them in a computation.

6.1.2. Enclave Entry Sanitization. Our ABISan plugin
inspects the complete register state when reaching the first
CALL instruction inside the enclave. Indeed, the first func-
tion call inside the enclave revealed to be a surprisingly
effective heuristic for the switch from assembly sanitization
code to the higher-level, compiler-generated API entry point:
across the 11 investigated runtimes, only a single runtime
performed a CALL from inside assembly code before jump-
ing to C code, which we accommodated in our heuristic.
Upon reaching the API entry point, ABISan warns for every
control and data register that has not been entirely cleared
of attacker-tainted data.

Thanks to Pandora‚Äôs powerful taint-tracking mechanism
and enclave-aware execution model, we were able to express
the entire ABISan policy in only 142 lines of Python code.
It is important to note that the flexible nature of our plugins
allows for quickly reacting to the ever-changing landscape
of recommendations to ABI sanitization responsibilities for
Intel SGX. For example, initial research [22] first inves-
tigated issues with incomplete sanitization of floating-point
control registers and recommended setting the MXCSR regis-
ter to the ABI-specified value of 0x1F80 on enclave entry.
More recently, however, Intel [27] further nuanced secure
MXCSR initialization by recommending the value 0x1FBF,
which additionally sets all floating-point exception status
flags, to protect against subtle, one-cycle timing differences
dependent on (possibly secret) floating-point operand values.
We were able to swiftly incorporate this latest recommen-
dation into ABISan‚Äôs validation policy. This demonstrates
that our plugin system can react flexibly and promptly to
such updated recommendations, which, as we will show in
Section 7, require changes that propagate slowly throughout
the Intel SGX software ecosystem.

6.2. Untrusted Pointer Value Sanitization

We implemented a capable PTRSan plugin in 120 lines
of Python code that proposes three expressive security in-

3. The only limitation here is that we are restricted to the subset of x86
behavior that is emulated by angr. For instance, angr does not consider the
alignment-check flag in RFLAGS and largely ignores floating-point precision
configuration bits in the underlying VEX symbolic-execution engine.

variants to catch the pervasive issues of confused-deputy
attacks via untrusted pointer arguments in the shared ad-
dress space. Note that,
to prior work [37]‚Äì
[39], PTRSan is entirely independent of the runtime-specific
sanitization function, solely relying on Pandora‚Äôs built-in
taint tracking and enclave-aware memory model. Hence, as
demonstrated in Section 7, PTRSan for the first time allows
to find subtle logical errors in the sanitization logic itself.

in contrast

6.2.1. Address Inside or Outside Enclave. Any symbolic
memory access that crosses the enclave boundary, even
partially, violates the trusted-untrusted memory division.
This case arises when, according to the constraint solver,
a symbolic address and size pair can have concrete values
that fall both inside and outside the enclave‚Äôs protected
address range. PTRSan, hence, always reports such cases
as a critical issue of a pointer that has not been sufficiently
constrained by the enclave software.

6.2.2. Tainted In-Enclave Address. Attacker-tainted ac-
cesses that are constrained to resolve entirely in untrusted
memory are clearly benign behavior of the enclave. On the
other hand, attacker-tainted accesses that are constrained to
always lie entirely in trusted enclave memory may still be
benign behavior, e.g., an attacker-controlled, yet constrained
index into an in-enclave array data structure. Hence, we
only report a warning in these cases and mark them as
potential issues that may warrant manual and application-
specific further inspection. To simplify such further analysis,
PTRSan reports the size and maximum address range of the
tainted memory access. This criterion to warn for tainted in-
enclave memory accesses thus ensures that no clear violation
of secure memory accesses can occur, at the potential burden
of occasional false-positive warnings. These false positive
are non-straightforward to eliminate generically, but we
discuss possible enhancements and heuristics in Section 8.

6.2.3. Untainted Outside-Enclave Address. Untainted ac-
cesses that are constrained to always resolve entirely in
enclave memory are clearly benign behavior of the enclave.
However, if untrusted memory is ever accessed with an
address that is not tainted by the attacker, PTRSan sees
this as a critical issue hinting at unexpected behavior, e.g.,
an uninitialized or NULL pointer dereference.

6.3. Untrusted Pointer Alignment Sanitization

The recently disclosed √ÜPIC [25] and MMIO stale data
leakage [26] attacks on Intel SGX platforms have shown
that enclave secrets may propagate from microarchitectural
fill buffers into architectural, software-visible registers when
dereferencing unaligned pointers to MMIO devices. While
CPU microcode updates have since been released to trans-
parently cleanse fill buffers upon enclave exits on affected
processors, additional software mitigations are still neces-
sary to prevent confused-deputy exploitation of these issues
during enclave execution [26], [40]. That is, even when
the enclave shielding runtime has properly checked that

untrusted, attacker-tainted pointer arguments fall entirely
outside the enclave memory range, as can be validated by
PTRSan, SGX enclaves have no way of knowing whether
these untrusted memory locations refer to vulnerable MMIO
regions. Indeed, privileged adversaries can trivially map un-
trusted memory pages to arbitrary MMIO devices, including
the x86 APIC configuration registers [56]. As such, deref-
erencing untrusted pointers during enclave execution may
unintentionally expose secret stale data, and Intel explicitly
advises that SGX shielding runtimes should additionally
constrain untrusted pointer dereferences to certain safe com-
binations of alignments and lengths [26], [40]. Note that this
holds both for outside-enclave reads and writes, through the
shared buffers data read (SBDR) and device register partial
write (DRPW) processor vulnerabilities, respectively.

In response to these dynamic challenges, we developed a
specialized √ÜPICSan plugin, which investigates the align-
ment of each symbolic memory access that may resolve
outside the enclave. Specifically, in accordance with Intel‚Äôs
intricate software security guidance [26], [40], we validate
that every untrusted read or write access resolving outside
the enclave is minimally 8-byte aligned, i.e., has the lower
three address bits cleared. We, furthermore, ensure that
untrusted read accesses have a size that is always maximally
eight bytes at a time, whereas untrusted writes should be in
chunks of multiples of eight bytes at a time [26]. Finally,
when detecting unaligned untrusted writes, √ÜPICSan parses
the disassembly of the current basic block to filter out safe
cases where the vulnerable write is preceded by the VERW
instruction to cleanse leaky microarchitectural buffers and
directly followed by an LFENCE; MFENCE instruction pair
to avoid inadvertent transient refills, as per Intel‚Äôs software
security guidance [26].

Our complete √ÜPICSan validator requires only 103
lines of Python code, where the majority of code concerns
parsing the disassembly. This clearly shows the strength
of exposing Pandora‚Äôs enclave-aware memory model (cf.
Section 4.3) to individual plugins that may have partially
overlapping functionality, e.g., PTRSan vs. √ÜPICSan.

The recent SBDR/DRPW disclosures required extensive
manual software mitigations, frequently encompassing sev-
eral rounds of commits and pull requests, throughout the
SGX runtime ecosystem. We are the first to provide any
form of toolchain support for automatically detecting and
validating SGX pointer-alignment considerations, and we
are the first to perform a wide-scale investigation of such
issues remaining in real-world enclaves (cf. Section 7).

6.4. Control-Flow Hijacking Validation

Lastly, Pandora includes a CFSan plugin, implemented
in 110 lines of Python code, that validates enclave control-
flow events. This plugin reports insecure jump targets ac-
cording to the location of the target and whether the target
is attacker-tainted.

First, similar to prior work [37], [38], we report a critical
security issue when the attacker can arbitrarily control a
jump target inside the enclave. Furthermore, similar to the

false-positive heuristic for CFSan, we only report a warning
when attacker-tainted jump targets are constrained to always
fall entirely inside the enclave.

In addition to this first criterion, partially covered by
prior work, CFSan also includes novel rules to detect
any enclave jumps to attacker-controlled memory contents.
Specifically, we found that several shielding runtimes fea-
ture unmeasured and executable memory pages, so as to
dynamically load (encrypted) code at runtime. As explained
in Section 4.3, this type of enclave memory is not part
of the attested MRENCLAVE measurement and is, as such,
initially attacker-controlled until
initialized by
enclave software. Thus, any enclave jumps to unmeasured
memory that has not yet been initialized are reported as a
critical security issue. While, apart from validation on our
own test enclaves, we have not encountered such instances
in our evaluation on real-world enclave binaries, we are the
first to formulate and write a sanitizer for this nuanced class
of novel unmeasured enclave vulnerabilities.

is first

it

Finally, note that, in line with our goal of truthful sym-
bolic execution, the Pandora base engine already intercepts
any jumps to outside the enclave memory range or to non-
executable pages inside the enclave, regardless of CFSan.
We simply abort the symbolic execution paths for these
cases, as both of these events would result in a runtime
exception on real SGX hardware and would, hence, not be
an exploitable vulnerability besides denial-of-service.

7. Evaluation

We evaluated the efficacy of Pandora and its vulner-
ability detection plugins in two distinct ways. First, we
developed a concise unit-test validation framework, loosely
based on the existing Linux selftest enclave [59], to pre-
cisely diagnose (known) vulnerabilities in small benchmark
enclaves compiled with increasing levels of mitigations. Sec-
ond, we performed a comprehensive ecosystem analysis on
11 relevant, real-world SGX shielding runtimes, uncovering
over 200 newly found vulnerable code locations, tracked via
7 common vulnerabilities and exposure (CVE) identifiers.
Additionally, further demonstrating the versatility of Pan-
dora, we made our symbolic-execution tool autonomously
reproduce over 69 previously known vulnerable code loca-
tions from the literature in older versions of the investigated
runtimes.

Table 2 provides an overview of all reported and re-
produced issues, whereas a more detailed breakdown is
included in Table 4 in Appendix D. Notably, among all
the listed vulnerabilities, only one could potentially have
been uncovered with existing state-of-the-art SGX symbolic
execution tools (cf. Table 4) ‚Äî due to either lack of support
for the required runtime, low-level initialization or entry
code, or the specific vulnerability type.

7.1. Selftest Validation Framework

The Linux kernel natively includes drivers for Intel SGX
since the 5.11 release [59]. As part of this effort, Linux

TABLE 2. EVIDENCE OF PANDORA FINDING AND REPRODUCING
VULNERABILITIES BOTH IN PRODUCTION AND RESEARCH RUNTIMES.

Runtime

Version Prod Src Plugin

Instances CVE

Newly found vulnerabilities in shielding runtimes (total 200 instances)
EnclaveOS
EnclaveOS
EnclaveOS
EnclaveOS
GoTEE
GoTEE
GoTEE
Gramine
Intel SDK
Intel SDK
Occlum

3.28
3.28
3.28
3.28
b35f
b35f
b35f
1.4
2.15.1
2.19
0.29.4

CVE-2023-38022
CVE-2023-38021

CVE-2022-26509

‚úì ‚úó‚Ä† ABISan 1
‚úì ‚úó‚Ä† PTRSan 15
‚úì ‚úó‚Ä† √ÜPICSan 33
‚úì ‚úó‚Ä† CFSan
2
‚úó ‚úì PTRSan 31
‚úó ‚úì √ÜPICSan 18
‚úó ‚úì CFSan
1
‚úì ‚úì ABISan 1
‚úì ‚úì PTRSan 2
‚úì ‚úì √ÜPICSan 22
‚úì ‚úì √ÜPICSan 11
‚úó ‚úì ABISan 1
‚úì ‚úì ABISan 1
‚úó ‚úì ABISan 1
‚úó ‚úì PTRSan 5
‚úì ‚úì PTRSan 17
‚úó ‚úì PTRSan 2
‚úó ‚úì CFSan
1
‚úó ‚úì CFSan
1
‚úì ‚úì ABISan 2
‚úì ‚úì ABISan 1

DCAP
Inclavare

Linux selftest 5.18
1.16
0.6.2
Linux selftest 5.18
1.16
0.6.2
Linux selftest 5.18
0.6.2

DCAP
Inclavare

Inclavare

Open Enclave 0.19.0
Rust EDP
SCONE
SCONE
SCONE
SCONE

1.71
5.7 / 5.8 ‚úì ‚úó
5.7 / 5.8 ‚úì ‚úó
5.7 / 5.8 ‚úì ‚úó
‚úì ‚úó
5.8

ABISan 2 / 1
PTRSan 10 / 3
√ÜPICSan 11 / 3
CFSan

1

CVE-2023-37479

CVE-2022-46487
CVE-2022-46486
CVE-2023-38023

b35f
1.2
2.1.1
2.13.3

Reproduced vulnerabilities in older versions (total 69 instances)
GoTEE
Gramine
Intel SDK
Intel SDK
Open Enclave 0.4.1
Open Enclave 0.4.1
Open Enclave 0.4.1
1.63
Rust EDP

‚úó ‚úì ABISan 1
‚úì ‚úì √ÜPICSan 10
‚úì ‚úì ABISan 1
‚úì ‚úì √ÜPICSan 28
‚úì ‚úì ABISan 1
‚úì ‚úì PTRSan 13
‚úì ‚úì √ÜPICSan 13
‚úì ‚úì √ÜPICSan 2

CVE-2019-14565

CVE-2019-1370
CVE-2019-0876

Legend: ‚Ä† Source code was made privately available;

Based on above runtime.

also contains a bare-metal selftest enclave that provides
a minimal example to test the loading and execution of
an enclave binary without relying on any particular SGX
shielding runtime. This Linux selftest enclave consists of
hand-crafted assembly routines for entry and exit, plus an
ecall dispatcher that calls C functions. While this selftest
enclave is not intended to be a production runtime, Linux
developers have noted that its code may be copied and
provides a ‚Äúgreat starting point if you want to do things from
scratch‚Äù [60]. Indeed, we found that at least two real-world
SGX projects directly built on the Linux selftest enclave to
date: Alibaba Inclavare Containers [61] uses it as a skeleton
example of best-practice enclave runtime integration and
Intel‚Äôs Data Center Attestation Primitives (DCAP) [62] for
Windows more critically uses it as the base for a custom
launch enclave that gets access to an SGX platform-specific
cryptographic key to decide which application enclaves can
be ran on the system. We report Pandora‚Äôs findings on these
bare-metal enclaves in the next section.

We developed a unit-test framework based on the Linux
selftest enclave. This test suite contains individually crafted
enclave binaries featuring multiple levels of ABI register
cleansing and input pointer(-to-pointer) sanitizations. These
enclaves, thus, provide a controlled test environment to craft

arbitrarily complex and challenging scenarios to validate
the efficacy of our plugins and Pandora‚Äôs enclave-aware
symbolic memory model. Furthermore, they allow to pro-
totype conceivable vulnerabilities that have not (yet) been
encountered ‚Äúin the wild‚Äù, e.g., jumps to unmeasured and
uninitialized pages (cf. Section 6.4).

7.2. SGX Runtime Ecosystem Analysis

Runtime Selection. To explore the vulnerability landscape
for real-world enclave software, we evaluated Pandora on
a diverse set of 8 production-quality and 3 research-grade
Intel SGX shielding runtimes. Note that, as discussed in
Section 3, we opted to focus on validating the vital enclave
shielding runtime itself, including indispensable, low-level
initialization and entry code, rather than the more acces-
sible challenge of validating higher-level application logic
as explored in complementary prior work [34], [37], [38].
While the latter typically only affects a single (research) ap-
plication that makes incorrect use of shielding abstractions,
e.g., unchecked user_check pointers [4], [5], production-
quality shielding runtimes are supposed to be thoroughly
vetted and any vulnerabilities found would affect universally
all applications developed on top.

Our runtime selection includes diverse enclave program-
ming paradigms, including 2 SDKs (Intel SGX SDK [4] and
Microsoft Open Enclave [5]), 4 libOSs (EnclaveOS [63],
SCONE [64], Occlum [10], and Gramine [65]), 2 secured
language runtimes (Rust-EDP [11] and Go-TEE [12]), and
3 bare-metal enclaves (Linux selftest [59], Inclavare [61],
and DCAP [62]). We included the bare-metal enclaves, as
well as the academic Go-TEE research prototype runtime,
to complement the insights from the more mature produc-
tion ecosystem. Furthermore, while the majority of SGX
shielding runtimes are developed as open-source software,
our selection also includes two proprietary runtimes: En-
claveOS, with source code privately provided by the vendor,
and SCONE, with only binaries available.

Due to the intricacies involved in building old runtime
versions with often complex dependencies, we opted to
limit our choice of known vulnerabilities to a representative
sample across major runtimes. We see a systematic overview
of the vulnerability landscape of past runtimes as an inter-
esting and feasible direction for future work and believe that
Pandora could aid in such a survey. In the following, after
describing our experimental setup, we highlight the most
interesting findings of each plugin.

Experimental Setup. We extracted exact enclave dumps
via SGX-TRACER and ran Pandora on all runtimes with a
time budget of 12 hours and a memory budget of 256 GB,
whichever occurred first. Cloud instances with such memory
budget are commercially available beginning at 4 $ per hour,
making this limit feasible for occasional extensive validation
with Pandora, e.g., as part of continuous integration (CI) for
releases (as at least one vendor privately expressed interest
in). Each runtime was explored twice: once with a default

breadth-first exploration strategy and once with a depth-first
strategy that eagerly followed the longest paths.

We note that in our experiments, the 256 GB memory
limit was only hit twice, namely for the Intel SGX SDK 2.19
when using breadth-first search after approximately 8 hours,
and for GoTEE as the enclave memory dump is exceedingly
large at 64 GB. In all other cases, the memory consump-
tion varied between 24.6 GB and 196.7 GB for breadth-first
search and from 4.9 GB to 154.7 GB for depth-first search.
In some rare cases, our Pandora prototype crashed before
reaching these limits due to remaining unsupported x86
instructions or due to crashes in the underlying angr and
z3 solver. For EnclaveOS specifically, we manually guided
Pandora to skip two functions that either contain still unsup-
ported AES-NI instructions, or execute a waiting loop that
expects a second thread to fill data before continuing. For the
DCAP bare-metal launch enclave, we similarly instrumented
Pandora to skip two functions with unsupported AES-NI
instructions.

7.2.1. ABI Sanitization Issues. Following a
recent
overview study [41], Pandora promptly confirmed known
ABI issues in older Intel SGX SDK and Open Enclave
binaries, which have since been evidently mitigated (cf.
Table 2). Nonetheless, Pandora found that the proprietary
SCONE runtime still lacked any sanitization code for x87
and SSE floating-point configuration registers. We experi-
mentally demonstrated that this lack of ABI sanitization,
can be exploited in practice via a proof-of-concept exploit
that successfully introduces rounding errors in an elemen-
tary ‚Äúsconified‚Äù floating-point application. Following our re-
sponsible disclosure, tracked under CVE-2022-46487, these
issues have been patched in the latest SCONE release 5.8.0.
Additionally, ABISan found that the academic GoTEE
runtime, as well as the Linux selftest, Inclavare, and DCAP
bare-metal enclaves, universally lack ABI entry sanitiza-
tions for RFLAGS and floating-point configuration registers.
Interestingly, Inclavare and DCAP took care to cleanse
extended processor state on enclave exit, but not on en-
try. Highlighting the strength of ABISan‚Äôs taint policy,
the plugin autonomously discovered attacker-tainted reads
from the x86 direction flag for compiler-emitted REP string
instructions that could be fatally corrupted in the DCAP
launch enclave, and notably found that GoTEE even lacks
secure stack pointer initialization, which could be exploited
to obtain full code execution in this runtime (cf. as also
reported by both CFSan and PTRSan). The issues in DCAP
are mitigated in version 1.19 and onward.

Our systematic analysis, furthermore, identified an inter-
esting case of regression in Open Enclave, which was as-
signed CVE-2023-37479 by Microsoft and mitigated in re-
lease 0.19.3. Particularly, in response to prior research [21],
commit efe7504 in Open Enclave included a patch to
properly sanitize the x86 alignment-check flag. However,
ABISan discovered that in current versions of Open En-
clave, the alignment-check flag was no longer properly san-
itized after the initial enclave sanitization routines have com-
pleted. Upon further investigation, we were able to conclude

that Open Enclave accidentally reintroduced the once-fixed
vulnerability with commit 16efbd6 in 2021, in a patch set
to mitigate another attack [23] that places more stringent de-
mands on stack-pointer initialization for exception handlers.
This instance of unintended regression thus provides a clear
illustration of the complexity of shielding responsibilities
and the potential value of including an automated tool like
Pandora in CI pipelines to test against known vulnerabilities
before releasing new software versions.

A final and particularly widespread line of ABI sanitiza-
tion issues follows from Intel‚Äôs recent MXCSR configuration-
dependent
timing (MCDT) software guidance [27]. Par-
ticularly, Intel recommends that shielding runtimes set all
floating-point exception status flags in the MXCSR register
for the lifetime of the enclave to avoid subtle, operand-
dependent
timing differences in otherwise constant-time
code on affected processors. Notably, this refined guidance
did not result from an academic publication or security
advisory and may have been easily missed by runtime
developers. Indeed, ABISan detected that only the Intel
SGX SDK and the dependent Occlum runtime properly set
MXCSR according to the new recommendation, and all other
runtimes did not. Following our disclosure, this has since
been patched in Open Enclave (0.19.3), Rust-EDP (1.71.0),
and EnclaveOS (3.30), and will be patched in the upcoming
SCONE 5.9.0 release.

7.2.2. Pointer Sanitization Issues. The strength of the
PTRSan plugin is to rigorously investigate issues with
pointer dereferences across many enclave runtimes.

In the SCONE production runtime, PTRSan uncovered
10 unique critical issues: 8 entirely unconstrained, attacker-
tainted pointer dereferences and 2 untainted outside-enclave
reads. Although the source code was not available, Pan-
dora was able to generate precise basic-block backtraces
annotated with ELF symbols, aiding in our investigation
and even the development of proof-of-concept exploits.
We reported each issue, tracked as a bundle under CVE-
2022-46486, to the SCONE developers who confirmed our
findings and included patches in the latest release 5.8.0.
However, PTRSan‚Äôs subsequent analysis on SCONE 5.8.0
revealed two more remaining vulnerabilities: an entirely un-
constrained attacker-tainted pointer and an untainted outside
enclave read, to be mitigated in the upcoming 5.9.0 release.
In EnclaveOS, PTRSan was able to detect a particularly
subtle instance of an untrusted pointer dereference as part
of a string length calculation, which is logically correct but
can be abused as a capable side-channel oracle to precisely
locate all null bytes in enclave memory [21]. Fortanix gave
a high severity rating for this finding, tracked under CVE-
2023-38022, and mitigated it in version 3.29. As a sec-
ond notable finding in EnclaveOS, Pandora autonomously
detected that overflow protections were missing in the un-
trusted pointer validation logic of the enclave binary. Upon
closer examination, we found that existing source-level over-
flow checks were silently optimized away by the compiler.
Specifically, the source code utilized void* pointer arith-
metic, which, unfortunately, is undefined behavior in C, lead-

ing to the compiler removing this check completely. Pandora
correctly reported that, with this check missing, the attacker
can cause untrusted pointers to wrap the address space via an
unsigned integer overflow. This issue highlights the strength
of Pandora‚Äôs binary-level validation and accurate symbolic
constraint solving of not only untrusted pointer values but
also their sizes, and is also mitigated in version 3.29.

Furthermore, as part of this research, PTRSan addi-
tionally confirmed an untrusted pointer dereference in the
protected code loader of the Intel SGX SDK version 2.15.1,
tracked via CVE-2022-26509 and patched in later versions.
This issue underlines the importance of validating low-level
runtime initialization code, as this pointer check was missing
before any in-enclave relocations, including global variables
containing the enclave base address and size needed in the
validation function itself, had been performed.

In the GoTEE research runtime, PTRSan discovered
numerous (31) unconstrained pointer dereferences, high-
lighting that even safe languages are not immune to over-
sights in pointer validation for SGX‚Äôs unique attacker model.
Furthermore, all bare-metal enclaves were found especially
vulnerable without any pointer sanitization measures (as
reported both by PTRSan and √ÜPICSan). For the DCAP
launch enclave, Pandora reported 17 unique critical issues,
of which 11 were unconstrained, attacker-controlled reads
and 6 were unconstrained writes to arbitrary in-enclave
locations (mitigated in version 1.19). Likewise, the Inclavare
enclave contains several vulnerable invocations of memcpy
with unconstrained source and destination parameters, and
the Linux selftest enclave contains 5 entirely unconstrained,
attacker-tainted pointer dereference locations that can be
trivially exploited to leak or corrupt arbitrary in-enclave
memory locations.

Finally, for the known-vulnerable version 0.4.1 of Mi-
crosoft Open Enclave, Pandora correctly identified CVE-
2019-0876 [21], which highlights the power of multiple
reentries, as the vulnerability can only be triggered after
the enclave has been initialized. In addition, PTRSan also
reported a (presumably unknown) issue in this old runtime
version,
indicating a lack of pointer sanitization in the
oe_initialize_cpuid() function.

7.2.3. √ÜPIC Sanitization Issues. Pandora is the first tool
to support automated analysis and validation of √ÜPIC-
style untrusted pointer alignment vulnerabilities in SGX
thus, employed our novel √ÜPICSan plu-
enclaves. We,
gin to perform a large-scale, automated analysis to assess
the completeness of Intel‚Äôs particularly complex and error-
prone software mitigation guidelines [26], [40] in real-
world enclave shielding runtimes. As result of this sys-
tematic analysis, Pandora found that SBDR and DRPW
mitigations were missing entirely in GoTEE (18 unique
instances), SCONE (11 instances; tracked via CVE-2022-
46487 and partially mitigated in version 5.8.0), and En-
claveOS (33 instances; tracked via CVE-2023-38021 and
mitigated in release 3.32). Furthermore, when analyzing
the latest SCONE 5.8.0 release, Pandora found that the
in-enclave memcpy function was not properly patched to

exclude SBDR issues which will be fixed in 5.9.0. Existing
mitigations in Gramine, Rust-EDP, and Open Enclave were
found sufficient, but √ÜPICSan autonomously discovered a
missing SBDR sanitization in the enclave initialization phase
of the latest version of the Intel SGX SDK (also inherited by
the derived Occlum runtime), highlighting that adequately
restricting untrusted pointer alignments is challenging even
for mature runtime developers.

As expected, we additionally confirmed that √ÜPICSan
can automatically reproduce ample SBDR and DRPW issues
in older versions of Gramine, Rust-EDP, Open Enclave, and
the Intel SGX SDK without mitigations.

7.2.4. Control Flow Issues. The CFSan plugin found a
delicate issue in EnclaveOS where the global offset table
(GOT) is incorrectly accessed before relocation of the en-
clave has completed. The GOT is used to jump to functions
in position-independent code and has to be securely initial-
ized, i.e., relocated, before it can be used inside enclaves.
The issue found by Pandora, and confirmed and fixed by
Fortanix in version 3.31, concerns an unusual trace where
an error occurs during initialization, which results in the
code calling a debug logging function. A similarly evasive
GOT relocation issue in an early-error path was reported by
CFSan for SCONE 5.8.0, to be patched in 5.9.0.

Furthermore, CFSan found that Inclavare‚Äôs bare-metal
enclave assembly entry stub incorrectly uses a signed JGE
x86 jump instruction, instead of a proper unsigned JAE con-
dition to sanitize the attacker-provided index into the ecall
function-pointer table. Critically, this subtle oversight ulti-
mately allows arbitrary control-flow hijacking by passing a
large negative index into the ecall table and loading the
function pointer from untrusted, attacker-controlled memory.
Likewise, CFSan found that, depending on the optimization
level, in-enclave relocation code for the ecall table was
missing in the dispatcher of the Linux selftest enclave.

Finally, due to the lack of secure stack switching in

GoTEE, CFSan reported unconstrained RET targets.

8. Discussion

We see Pandora as a mature prototype of an enclave-
aware symbolic execution tool that can serve as a basis for
future science. In particular, we designed Pandora with great
care for usability,
through a well-documented command
line interface and detailed HTML reports, and reusability
through our plugin-based approach that makes it easy to
implement additional security analyses. Pandora has demon-
strated its usefulness by automatically finding vulnerabilities
in production runtimes. Hence, we believe that Pandora is a
valuable step forward in vulnerability detection for enclaves.

Coverage. We consider the main limitation of Pandora to
be incomplete coverage, i.e., the infeasibility to explore a
binary as a whole with symbolic execution. This is due to
the fact that Pandora, as any symbolic-execution tool, suffers
from the well-known limitation of state explosion, which can
make exhaustive exploration of larger binaries practically

infeasible. Hence, vulnerabilities can still remain undetected
in unexplored paths. We implemented novel, enclave-aware
performance optimizations, including uninitialized memory
and state-uniqueness reductions (cf. Section 4.5), and we
utilized both breadth-first and depth-first exploration in our
evaluation to cover more enclave behavior.

Our choice for angr [52] as the underlying symbolic-
execution engine may also in itself be a source of in-
complete coverage, as angr is not guaranteed to be sound
and may concretize values during symbolic execution. To
avoid missing program behavior, we adopted the most con-
servative approach whenever possible and tried to refrain
from unnecessary concretization of symbolic values. Despite
these limitations, angr is particularly powerful for rapid
development of vulnerability plugins in comparison to fully
fledged code verification tools.

A further possible technical, but not inherent, limitation
concerns Pandora‚Äôs coverage of any encrypted code that
would be loaded at runtime to execute a confidential enclave
application. Such code could be transparently supported by
providing Pandora with the decryption key, which could then
be used by the symbolic execution engine to automatically
decrypt and execute the code. That being said, the primary
focus of Pandora are runtimes, which are usually not utiliz-
ing such encrypted code loading themselves.

We consider the fact that Pandora was able to automati-
cally uncover vulnerabilities in production runtimes as clear
evidence for the practicality of our approach to validate
enclave shielding runtimes. The (orthogonal) extension of
Pandora‚Äôs truthful enclave-aware symbolic-exploration to
also analyze arbitrary (and potentially larger and deeper)
enclave application logic would require further scaling that
could conceivably benefit from optimizations proposed in
previous work [37], [39].

Accuracy. As any automatic vulnerability scanner, Pandora
may report false-positive issues, which could lead to overly
exhaustive outputs. We attempt to limit the strain on the
human analyst via two steps. First, potential issues are clas-
sified into multiple levels of criticality, and the reports are
formatted in modern HTML forms that allow to filter criti-
cality levels. Second, plugins may downgrade the severity of
issues via sensible heuristics, e.g., Section 6.2 explained how
PTRSan downgrades attacker-tainted pointers when they are
constrained to a region entirely inside the enclave, closely
resembling the benign pattern of an attacker-controlled index
in a trusted enclave buffer. All critical issues found by
Pandora listed in Table 2 were reported to the vendors who
acknowledged the vulnerabilities. Hence, we are not aware
of any false-positive results for these critical issues. Beyond
this, Pandora heuristically downgraded 124 of 452 (27 %)
vulnerabilities to warnings, where we are not aware of any
of those being exploitable.

Regarding false negatives, there is unfortunately no stan-
dardized ground truth of existing vulnerabilities for Intel
SGX runtimes, and a direct comparison of Pandora to re-
lated approaches is not feasible as their target (i.e., enclave
application logic) is orthogonal. Therefore, we followed a

best-effort approach and let Pandora successfully reproduce
known runtime vulnerabilities (cf. Table 2). Our analysis
clearly shows that Pandora reproduced all known vulner-
abilities from selected work [21], [22] and even found
an overlooked issue (cf. ¬ß7.2.2). We consider the main
limitation to be incomplete coverage, which may lead to
vulnerabilities on unexplored paths not being detected (e.g.,
CVE-2021-44421 in Occlum).

Future Work. Potential future extensions of Pandora con-
cern novel vulnerability-detection plugins, as well as the
investigation of transient execution access patterns in en-
claves [66]‚Äì[68]. Furthermore, we see Pandora as a useful
tool for a broad ecosystem analysis of the Intel SGX land-
scape and how fast vulnerability patches propagate across
runtimes. Ultimately, future work could even explore au-
tomated exploit generation and binary patching using Pan-
dora‚Äôs precise vulnerability reports.

There are additionally some performance improvements
that could allow Pandora to explore enclaves in more depth.
While we already implemented a depth-first extension to
Pandora that severely limits the memory use necessary
during exploration, angr still only uses one single CPU
core. Future work could thus investigate how angr symbolic
exploration can be split up onto multiple cores while re-
taining the same enclave-aware characteristics of Pandora
that are necessary to e.g., identify enclave boundaries. Ad-
ditionally, to mitigate path explosion, we could also adopt
state-merging [69] or path prioritization strategies [49], [70].

9. Conclusion

In recent years, a sizable ecosystem of Intel SGX enclave
shielding runtimes has emerged. However, writing secure
SGX software has proven to be particularly challenging due
to the moving nature of the threat landscape, and not even
well-designed and vetted shielding runtimes have been im-
mune to missing nuanced attack vectors or to reintroducing
already known vulnerabilities into their code. The research
community has only recently started to look into SGX-aware
symbolic execution, but has focused on application logic
only, while largely skipping the crucial enclave shielding
runtime itself. In this work, we presented Pandora,
the
first enclave-aware and pluggable symbolic-execution tool
that allows truthfully validating arbitrary enclave binaries,
including low-level runtime initialization and entry phases.
With 4 diverse prototype plugins, we found 200 new and
69 known vulnerable code locations across a wide selection
of 11 SGX runtimes. Ultimately, we envision Pandora not
only as a practical validation tool for real-world enclave run-
times today, but also as a solid, extensible and open-source
foundation for future science on SGX software validation
of enclave shielding runtimes.

Acknowledgments. This research is partially funded by
grants of the Research Foundation ‚Äì Flanders (FWO), un-
der grant numbers 11E5120N, 1261222N, 12B2A24N and

G081322N, and by the Flemish Research Programme Cyber-
security. This research was supported by the UK Engineer-
ing and Physical Sciences Research Council (EPSRC) under
grants EP/R012598/1, EP/V000454/1, and EP/S030867/1.
The results feed into DsbDtech. Some computations de-
scribed in this paper were performed using the University
of Birmingham‚Äôs BlueBEAR HPC service, which provides
a High Performance Computing service to the University‚Äôs
research community.

References

[1] V. Costan and S. Devadas, ‚ÄúIntel SGX explained.‚Äù IACR Cryptology

ePrint Archive, vol. 2016, no. 086, 2016.

[2]

F. McKeen, I. Alexandrovich, A. Berenzon, C. V. Rozas, H. Shafi,
V. Shanbhogue, and U. R. Savagaonkar, ‚ÄúInnovative instructions and
software model for isolated execution,‚Äù in Proceedings of the 2nd
International Workshop on Hardware and Architectural Support for
Security and Privacy. ACM, 2013.

[3]

Intel, ‚ÄúIntel Trust Domain Extensions,‚Äù Feb. 2022.
Available: https://cdrdv2.intel.com/v1/dl/getContent/690419

[Online].

[4] ‚Äî‚Äî, ‚ÄúIntel Software Guard Extensions ‚Äì Get Started with the SDK,‚Äù

2023. [Online]. Available: https://software.intel.com/en-us/sgx/sdk

[5] Microsoft,

‚ÄúOpen Enclave SDK,‚Äù 2023.

[Online]. Available:

https://openenclave.io/

[6] A. Baumann, M. Peinado, and G. Hunt, ‚ÄúShielding applications
from an untrusted cloud with haven,‚Äù in Proceedings of the 11th
USENIX conference on Operating Systems Design and Implementa-
tion. USENIX Association, 2014.

[7]

S. Arnautov, B. Trach, F. Gregor, T. Knauth, A. Martin, C. Priebe,
J. Lind, D. Muthukumaran, D. O‚ÄôKeeffe, M. L. Stillwell et al.,
‚ÄúSCONE: Secure Linux containers with Intel SGX,‚Äù in 12th USENIX
Symposium on Operating Systems Design and Implementation.
USENIX Association, 2016.

[8] C.-C. Tsai, D. E. Porter, and M. Vij, ‚ÄúGraphene-SGX: A practical
library OS for unmodified applications on SGX,‚Äù in USENIX Annual
Technical Conference (ATC), 2017.

[9] C. Priebe, D. Muthukumaran, J. Lind, H. Zhu, S. Cui, V. A. Sartakov,
and P. Pietzuch, ‚ÄúSGX-LKL: securing the host OS interface for trusted
execution,‚Äù arXiv preprint arXiv:1908.11143, 2019.

[10] Y. Shen, H. Tian, Y. Chen, K. Chen, R. Wang, Y. Xu, Y. Xia, and
S. Yan, ‚ÄúOcclum: Secure and efficient multitasking inside a single
enclave of intel sgx,‚Äù in Proceedings of the Twenty-Fifth International
Conference on Architectural Support for Programming Languages
and Operating Systems, 2020.

[11] Fortanix, ‚ÄúFortanix enclave development platform ‚Äì rust edp,‚Äù 2023.

[Online]. Available: https://edp.fortanix.com/

[12] A. Ghosn, J. R. Larus, and E. Bugnion, ‚ÄúSecured routines: Language-
based construction of trusted execution environments,‚Äù in USENIX
Annual Technical Conference (ATC), 2019.

[13] Enarx Project, ‚ÄúEnarx: Webassembly + confidential computing,‚Äù

https://enarx.dev/, 2023.

[14] Edgeless Systems, ‚ÄúEdgeless RT,‚Äù https://github.com/edgelesssys/

edgelessrt, 2022.

[15] A. Nilsson, P. N. Bideh, and J. Brorsson, ‚ÄúA survey of published
attacks on intel sgx,‚Äù arXiv preprint arXiv:2006.13598, 2020.

[16] J. Van Bulck, M. Minkin, O. Weisse, D. Genkin, B. Kasikci,
F. Piessens, M. Silberstein, T. F. Wenisch, Y. Yarom, and R. Strackx,
‚ÄúForeshadow: Extracting the keys to the Intel SGX kingdom with
transient out-of-order execution,‚Äù in Proceedings of the 27th USENIX
Security Symposium, Aug. 2018.

[17] M. Schwarz, M. Lipp, D. Moghimi, J. Van Bulck, J. Stecklina,
T. Prescher, and D. Gruss, ‚ÄúZombieLoad: Cross-privilege-boundary
data sampling,‚Äù in Proceedings of the 26th ACM Conference on
Computer and Communications Security (CCS‚Äô19).
ACM, Nov.
2019.

[18] K. Murdock, D. Oswald, F. D. Garcia, J. Van Bulck, D. Gruss,
and F. Piessens, ‚ÄúPlundervolt: Software-based fault injection attacks
against Intel SGX,‚Äù in Proceedings of the 41th IEEE Symposium on
Security and Privacy (S&P‚Äô20), May 2020.

[19] S. van Schaik, A. Milburn, S. ¬®Osterlund, P. Frigo, G. Maisuradze,
K. Razavi, H. Bos, and C. Giuffrida, ‚ÄúRIDL: Rogue in-flight data
load,‚Äù in S&P, May 2019.

[20] G. Chen, S. Chen, Y. Xiao, Y. Zhang, Z. Lin, and T. H. Lai,
‚ÄúSgxPectre attacks: Stealing Intel secrets from SGX enclaves via
speculative execution,‚Äù in 4th IEEE European Symposium on Security
and Privacy (Euro S&P).
IEEE, 2019.

[21] J. Van Bulck, D. Oswald, E. Marin, A. Aldoseri, F. D. Garcia, and
F. Piessens, ‚ÄúA tale of two worlds: Assessing the vulnerability of
enclave shielding runtimes,‚Äù in 26th ACM Conference on Computer
and Communications Security (CCS), Nov. 2019.

[22] F. Alder, J. Van Bulck, D. Oswald, and F. Piessens, ‚ÄúFaulty point
unit: ABI poisoning attacks on Intel SGX,‚Äù in 36th Annual Computer
Security Applications Conference (ACSAC), Dec. 2020.

[23] J. Cui, J. Z. Yu, S. Shinde, P. Saxena, and Z. Cai, ‚ÄúSmashex:
Smashing sgx enclaves using exceptions,‚Äù in 28th ACM Conference
on Computer and Communications Security (CCS), 2021.

[24] Intel Corporation, ‚ÄúDeep dive: Load value injection,‚Äù 2020.

[25] P. Borrello, A. Kogler, M. Schwarzl, M. Lipp, D. Gruss, and
M. Schwarz, ‚Äú√ÜPIC Leak: Architecturally leaking uninitialized data
from the microarchitecture,‚Äù in 31st USENIX Security Symposium
(USENIX Security 22), 2022.

[26] Intel, ‚ÄúProcessor MMIO stale data vulnerabilities,‚Äù June 2022.
https://www.intel.com/content/www/us/en/

[Online].
developer/articles/technical/software-security-guidance/technical-
documentation/processor-mmio-stale-data-vulnerabilities.html

Available:

[27] ‚Äî‚Äî, ‚ÄúMxcsr configuration dependent timing,‚Äù Aug. 2022. [Online].
https://www.intel.com/content/www/us/en/developer/

Available:
articles/technical/software-security-guidance/best-practices/mxcsr-
configuration-dependent-timing.html

[28] J. Van Bulck, D. Moghimi, M. Schwarz, M. Lipp, M. Minkin,
D. Genkin, Y. Yuval, B. Sunar, D. Gruss, and F. Piessens, ‚ÄúLVI: Hi-
jacking transient execution through microarchitectural load value in-
jection,‚Äù in 41st IEEE Symposium on Security and Privacy (S&P‚Äô20),
May 2020.

[29] A. Kogler, D. Gruss, and M. Schwarz, ‚ÄúMinefield: A software-only
protection for SGX enclaves against DVFS attacks,‚Äù in 31st USENIX
Security Symposium (USENIX Security 22), 2022.

[30] L. Giner, A. Kogler, C. Canella, M. Schwarz, and D. Gruss, ‚ÄúRepur-
posing segmentation as a practical LVI-NULL mitigation in SGX,‚Äù
in 31st USENIX Security Symposium (USENIX Security 22), 2022.

[31] M.-W. Shih, S. Lee, T. Kim, and M. Peinado, ‚ÄúT-SGX: Eradicating
controlled-channel attacks against enclave programs,‚Äù in Proceedings
of the 2017 Annual Network and Distributed System Security Sympo-
sium (NDSS), San Diego, CA, Feb. 2017.

[32] S. Hosseinzadeh, H. Liljestrand, V. Lepp¬®anen, and A. Paverd, ‚ÄúMiti-
gating branch-shadowing attacks on intel sgx using control flow ran-
domization,‚Äù in Proceedings of the 3rd Workshop on System Software
for Trusted Execution, 2018.

[33] F. Brasser, S. Capkun, A. Dmitrienko, T. Frassetto, K. Kostiainen, and
A.-R. Sadeghi, ‚ÄúDr. SGX: automated and adjustable side-channel pro-
tection for SGX using data location randomization,‚Äù in Proceedings
of the 35th Annual Computer Security Applications Conference, 2019.

[35] R. Cui, L. Zhao, and D. Lie, ‚ÄúEmilia: Catching iago in legacy code.‚Äù

in NDSS, 2021.

[36] M. Orenbach, B. Raveh, A. Berkenstadt, Y. Michalevsky, S. Itzhaky,
and M. Silberstein, ‚ÄúSecuring access to untrusted services from TEEs
with GateKeeper,‚Äù arXiv preprint arXiv:2211.07185, 2022.

[37] T. Cloosters, M. Rodler, and L. Davi, ‚ÄúTeerex: Discovery and ex-
ploitation of memory corruption vulnerabilities in SGX enclaves,‚Äù in
Proceedings of the 29th USENIX Security Symposium, 2020.

[38] P. Antonino, W. A. Woloszyn, and A. Roscoe, ‚ÄúGuardian: Symbolic
validation of orderliness in sgx enclaves,‚Äù in Proceedings of the 2021
on Cloud Computing Security Workshop, 2021.

[39] M. R. Khandaker, Y. Cheng, Z. Wang, and T. Wei, ‚ÄúCOIN Attacks: On
Insecurity of Enclave Untrusted Interfaces in SGX,‚Äù in Proceedings of
the Twenty-Fifth International Conference on Architectural Support
for Programming Languages and Operating Systems, 2020.

[40] Intel, ‚ÄúStale data read from legacy xAPIC,‚Äù Aug. 2022. [Online].
https://www.intel.com/content/www/us/en/developer/

Available:
articles/technical/software-security-guidance/advisory-guidance/
stale-data-read-from-xapic.html

[41] J. Van Bulck, F. Alder, and F. Piessens, ‚ÄúA case for unified ABI
shielding in Intel SGX runtimes,‚Äù in 5th Workshop on System Software
for Trusted Execution (SysTEX). ACM, Mar. 2022.

[42] J. C. King, ‚ÄúSymbolic execution and program testing,‚Äù Commun.

ACM, vol. 19, no. 7, 1976.

[43] P. Godefroid, M. Y. Levin, and D. A. Molnar, ‚ÄúSAGE: whitebox

fuzzing for security testing,‚Äù Commun. ACM, vol. 55, no. 3, 2012.

[44] S. K. Cha, T. Avgerinos, A. Rebert, and D. Brumley, ‚ÄúUnleashing
mayhem on binary code,‚Äù in IEEE Symposium on Security and
Privacy, SP 2012, 21-23 May 2012, San Francisco, California, USA.
IEEE Computer Society, 2012.

[45] T. Yavuz, F. Fowze, G. Hernandez, K. Y. Bai, K. R. Butler, and
D. J. Tian, ‚ÄúENCIDER: Detecting Timing and Cache Side Channels
in SGX Enclaves and Cryptographic APIs,‚Äù IEEE Transactions on
Dependable and Secure Computing, 2022.

[46] G. Duan, Y. Fu, B. Zhang, P. Deng, J. Sun, H. Chen, and Z. Chen,
‚ÄúTeefuzzer: A fuzzing framework for trusted execution environments
with heuristic seed mutation,‚Äù Future Generation Computer Systems,
2023.

[47] A. Khan, M. Zou, K. Kim, D. Xu, A. Bianchi, and D. J. Tian,
‚ÄúFuzzing sgx enclaves via host program mutations,‚Äù in 8th European
Symposium on Security and Privacy (EuroS&P).

IEEE, 2023.

[48] Y. Shoshitaishvili, R. Wang, C. Salls, N. Stephens, M. Polino,
A. Dutcher, J. Grosen, S. Feng, C. Hauser, C. Kruegel, and G. Vigna,
‚ÄúSoK: (State of) The Art of War: Offensive Techniques in Binary
Analysis,‚Äù in IEEE Symposium on Security and Privacy, 2016.

[49] R. Baldoni, E. Coppa, D. C. D‚ÄôElia, C. Demetrescu, and I. Finocchi,
‚ÄúA survey of symbolic execution techniques,‚Äù ACM Comput. Surv.,
vol. 51, no. 3, 2018.

[50] I. Anati, S. Gueron, S. Johnson, and V. Scarlata, ‚ÄúInnovative tech-
nology for CPU based attestation and sealing,‚Äù in Proceedings of the
2nd international workshop on hardware and architectural support
for security and privacy, vol. 13, 2013.

[51] Y. Wang, Z. Zhang, N. He, Z. Zhong, S. Guo, Q. Bao, D. Li,
Y. Guo, and X. Chen, ‚ÄúSymgx: Detecting cross-boundary pointer
vulnerabilities of sgx applications via static symbolic execution,‚Äù in
30th ACM Conference on Computer and Communications Security
(CCS), 2023, p. 2710‚Äì2724.

[52] F. Wang and Y. Shoshitaishvili, ‚ÄúAngr-the next generation of binary

analysis,‚Äù in Cybersecurity Development (SecDev).

IEEE, 2017.

[53] Intel Corporation, Intel 64 and IA-32 architectures software devel-

oper‚Äôs manual, 2020, reference no. 325462-062US.

[34] T. Cloosters, J. Willbold, T. Holz, and L. Davi, ‚ÄúSGXFuzz: Efficiently
synthesizing nested structures for SGX enclave fuzzing,‚Äù in 31st
USENIX Security Symposium (USENIX Security 22), 2022.

[54] D. Schoepe, M. Balliu, B. C. Pierce, and A. Sabelfeld, ‚ÄúExplicit
secrecy: A policy for taint tracking,‚Äù in 2016 IEEE European Sym-
posium on Security and Privacy (EuroS&P).

IEEE, 2016.

[55] W. Xu, S. Bhatkar, and R. Sekar, ‚ÄúTaint-enhanced policy enforcement:
A practical approach to defeat a wide range of attacks,‚Äù in 15th
USENIX Security Symposium, 2006.

[56] J. Van Bulck, F. Piessens, and R. Strackx, ‚ÄúSGX-Step: A practical
attack framework for precise enclave execution control,‚Äù in 2nd
Workshop on System Software for Trusted Execution (SysTEX 2017).
ACM, Oct. 2017.

[57] H. Lu, D. L. Kreitzer, M. Girkar, and Z. Ansari, ‚ÄúSystem V appli-
cation binary interface,‚Äù Intel386 Architecture Processor Supplement,
Version 1.1, December 2015.

[58] A. Fog, ‚ÄúCalling conventions for different c++ compilers and operat-
ing systems,‚Äù http://www.agner.org/optimize/calling conventions.pdf,
Apr. 2018.

[59] L. Torvalds, ‚ÄúLinux operating system,‚Äù kernel.org, 2023.

[60] J. Sakkinen and N. McCallum, ‚Äúselftests/x86: Add a selftest
for sgx,‚Äù Mar. 2020. [Online]. Available: https://lkml.kernel.org/lkml/
04362c0cf66bf66e8f7c25a531830b9f294d2d09.camel@linux.intel.com/

[61] AliBaba,

‚ÄúInclavare

cloud-
confidential
[Online]. Avail-
Jun.
https://www.alibabacloud.com/blog/inclavare-containers-the-

native
able:
future-of-cloud-native-confidential-computing 598992

computing,‚Äù

containers:

future

2022.

The

of

[62] V. Scarlata, S. Johnson, J. Beaney, and P. Zmijewski, ‚ÄúSupporting
third party attestation for Intel SGX with Intel data center attestation
primitives,‚Äù White paper, 2018.

[63] Fortanix, ‚ÄúFortanix runtime encryption platform and enclaveos,‚Äù https:

//www.fortanix.com/platform/runtime-encryption, 2023.

[64] Scontain GmbH, ‚ÄúScone ‚Äì a secure container environment,‚Äù 2023.

[Online]. Available: https://scontain.com/

[65] The Gramine Workgroup, ‚ÄúGramine ‚Äì a library os for unmodified

applications,‚Äù https://gramineproject.io/, 2023.

[66] M. Guarnieri, B. K¬®opf, J. F. Morales, J. Reineke, and A. S¬¥anchez,
‚ÄúSpectector: Principled detection of speculative information flows,‚Äù
in IEEE Symposium on Security and Privacy.

IEEE, 2020.

[67] L. Daniel, S. Bardin, and T. Rezk, ‚ÄúHunting the haunter - efficient
relational symbolic execution for spectre with haunted relse,‚Äù in
NDSS. The Internet Society, 2021.

[68] S. Cauligi, C. Disselkoen, K. von Gleissenthall, D. M. Tullsen,
D. Stefan, T. Rezk, and G. Barthe, ‚ÄúConstant-time foundations for
the new spectre era,‚Äù in PLDI. ACM, 2020.

[69] V. Kuznetsov, J. Kinder, S. Bucur, and G. Candea, ‚ÄúEfficient state

merging in symbolic execution,‚Äù in PLDI. ACM, 2012.

[70] Y. Li, Z. Su, L. Wang, and X. Li, ‚ÄúSteering symbolic execution to
less traveled paths,‚Äù SIGPLAN Not., vol. 48, no. 10, oct 2013.

Appendix A.
Pandora CLI and Report Generation (D1)

We designed Pandora with great care for usability (D1),
through a well-documented command line interface (CLI)
and detailed HTML reports. Figure 3 shows an example of a
human-readable, interactive HTML report from the PTRSan
plugin discovering unconstrained pointer dereferences in the
Linux selftest enclave (cf. Section 7.1). Figure 4 shows a
part of the interactive command line interface of Pandora,
which is intended to be highly usable for both rapid proto-
typing of new plugins and for long, unattended exploration
runs. Issues are reported on the command line during a run,
but are also logged in a JSON file that can later be expanded
into the fully-fledged HTML reports visible in Figure 3. If
the human analyst wishes, multiple breakpoints regarding

Figure 3. Example of an HTML report generated by Pandora.

the exploration and the plugins are readily available from
the command line, i.e., to interrupt execution on interesting
events and switch into a Python shell. This allows to quickly
implement and troubleshoot plugins. Lastly, several options
of Pandora are, in addition to the CLI, exposed via config-
uration files, allowing to define long-lasting analysis setups
that can be controlled by changing few program options.

We leave it for future work to rigorously investigate
to what extent Pandora achieved D1, e.g., by means of
a comprehensive and unbiased user study. Such a user
study should investigate whether the reporting generated by
Pandora is factually useful for a human analyst, and perform
a quantitative analysis on the benefit of additional CLI and
reporting features.

Appendix B.
Static Analysis of Enclave Runtimes

This appendix describes optional support we added to
Pandora to load enclave binaries from selected runtimes with
purely static analysis only, i.e., without first requiring the
SGX-TRACER dynamic memory extraction phase described

TRACER enclave memory extractor approach as the default
runtime-agnostic and truthful loader in Pandora, as also used
in the evaluation of Section 7.

Linux Selftest Enclave. First,
the Linux selftest en-
clave [59] is a minimal, self-contained enclave that has a
fixed memory layout, with the TCS always being stored
at the start of the enclave range. This makes it an ideal
baseline runtime as no enclave initialization is necessary
and all relevant addresses are statically known at compile
time. The Linux selftest enclave serves as the foundation
for Pandora‚Äôs unit-test validation framework, discussed in
Section 7.1.

Intel SGX SDK. Second, the Intel SGX SDK [4] encodes
all
information for the loading process in an additional
ELF metadata section. Based on manual analysis of the
open-source code of the Intel SGX SDK enclave loader,
we added full support in Pandora to decode this opaque
blob and extract the expected locations of TCSs, stack and
heap regions, and patches to initialize enclave global data
structures. We implemented mature support to perform these
steps in Intel SGX SDK version 2.18.1 and also validated
backwards compatibility and added support for version-
specific fields in versions 2.18 and 2.17.1.

SCONE. Lastly, we show that, in principle, the static en-
clave loading approach is even feasible without access to
source code by implementing an elementary (incomplete)
static loader for the proprietary SCONE [7] runtime. Specifi-
cally, we manually reverse engineered the enclave layout and
location of TCS data structures and thread-local memory
using a debugger. Based on this partial layout, our static
loader inserts the required data structures into the symbolic
memory layout when loading the SCONE runtime binary
ELF file.

Appendix C.
Pandora Breakpoints

Table 3 lists all enclave-aware breakpoints added by
Pandora. To accommodate various investigation scenarios,
all breakpoints can be triggered before and after the event
happened, i.e., to investigate an event both before or after it
had an impact on a Pandora state. For example, Pandora
memory read breakpoint, similarly to angr memory read
breakpoints, can be triggered before the read has happened,
exposing, among other, its address and size; or after the read
has happened, additionally exposing its value.

Appendix D.
Vulnerability Details

Table 4 provides a more detailed breakdown of the
vulnerable code locations found by Pandora, as also sum-
marized in Table 2 and discussed in Section 7.

Figure 4. Part of the command line interface of Pandora depicting helpful
command options to the user.

in Section 5. The difficulty in adequately supporting arbi-
trary enclave runtimes in this way lies in parsing opaque
enclave memory layout metadata from the binary and load-
ing SGX-specific data structures into the symbolic execu-
tion memory after the ELF file has been loaded. Although
inherently fragile and version-specific, we show that it is
in principle possible to implement such support entirely
statically for three exemplary runtime loaders.

While we consider some of these static loaders to be
mature and satisfying our truthful initial memory layout cri-
terion (G1b), we note that this highly labor-intensive static-
analysis approach is evidently not runtime-agnostic (vs.
G2). Furthermore, even for the individual runtimes that are
supported, the static-analysis approach remains inherently
fragile, as new versions of these runtimes may completely
break or change the way runtime-specific data structures
are utilized in the enclave.4 Thus, we use our novel SGX-

4. Examples of such changes in the past were versions 2.4, 2.14, and 2.17
of the Intel SGX SDK when the internal _global_data_t C structure
was modified which resulted in altered offsets for the address of the enclave
base address, a crucial piece of information to properly resolve addresses
inside the enclave.

TABLE 3. LIST OF BREAKPOINTS ADDED BY PANDORA. PLUGINS CAN HOOK THESE NEW BREAKPOINTS, IN ADDITION TO ALL LEGACY ANGR
BREAKPOINTS, TO INVESTIGATE SPECIFIC EVENTS DURING EXPLORATION. ALL EVENTS CAN BE HOOKED BEFORE AND AFTER THEY ARE EXPLORED.
INDIVIDUAL BREAKPOINTS MAY ADDITIONALLY EXPOSE SPECIFIC ARGUMENTS, E.G., SYMBOLIC MEMORY ADDRESSES AND SIZES.

Breakpoint event

Triggered by Pandora module

Description

eenter
eexit
untrusted_mem_read
trusted_mem_read
inside_or_outside_mem_read
untrusted_mem_write
trusted_mem_write
inside_or_outside_mem_write

Enclave (Re)entry
SGX Instructions
Enclave Memory
Enclave Memory
Enclave Memory
Enclave Memory
Enclave Memory
Enclave Memory

A state is prepared to (re)enter the enclave
An EEXIT ENCLU is executed
Reads that fully lie in untrusted memory
Reads that fully lie in enclave memory
Reads that may lie in either region
Writes that fully lie in untrusted memory
Writes that fully lie in enclave memory
Writes that may lie in either region

TABLE 4. DETAILED EVIDENCE OF PANDORA FINDING AND REPRODUCING VULNERABILITIES BOTH IN PRODUCTION AND RESEARCH RUNTIMES,
WHERE THE ‚ÄúDEPTH‚Äù COLUMN LISTS THE NUMBER OF BASIC BLOCKS EXPLORED BEFORE THE VULNERABILITY (MIN‚ÄìMAX); ‚ÄúL‚Äù INDICATES THE
LOCATION (ENTRY, INITIALIZATION, APPLICATION) OF THE VULNERABILITY; AND COLUMN ‚ÄúO‚Äù INDICATES WHETHER THE VULNERABILITY COULD
HAVE BEEN FOUND BY EXISTING, STATE-OF-THE-ART SGX SYMBOLIC-EXECUTION TOOLS [37], [38].

Runtime

Version Prod Src Plugin

L Depth

Instances Description

O

DCAP
Inclavare

Newly found vulnerabilities in shielding runtimes (total 200 instances)
1
EnclaveOS
EnclaveOS
10
EnclaveOS
EnclaveOS
EnclaveOS
GoTEE
GoTEE
GoTEE
Gramine
Intel SDK
Intel SDK
Occlum

3.28
3.28
3.28
3.28
3.28
014b35f
014b35f
014b35f
1.4
2.15.1
2.19
0.29.4

‚úì ‚úó‚Ä† ABISan
8
E
‚úì ‚úó‚Ä† PTRSan
14‚Äì48
E
‚úì ‚úó‚Ä† PTRSan
15495‚Äì15521 5
I
‚úì ‚úó‚Ä† √ÜPICSan I
33
14‚Äì100
‚úì ‚úó‚Ä† CFSan
2
I
51
‚úó ‚úì PTRSan
31
E/I 2‚Äì82
‚úó ‚úì √ÜPICSan E/I 2‚Äì82
18
‚úó ‚úì CFSan
I
1
‚úì ‚úì ABISan
E
1
‚úì ‚úì PTRSan
2
I
‚úì ‚úì √ÜPICSan I
22
‚úì ‚úì √ÜPICSan I
11
‚úó ‚úì ABISan
1
E
‚úì ‚úì ABISan
1
E
‚úó ‚úì ABISan
1
E
‚úó ‚úì PTRSan A 4‚Äì7
5
‚úì ‚úì PTRSan A 3‚Äì1075
17
‚úó ‚úì PTRSan A 8‚Äì539
2
‚úó ‚úì CFSan
A 5
1
‚úó ‚úì CFSan
3
E
1
‚úì ‚úì ABISan
11
E
1
‚úì ‚úì ABISan
11
E
1
‚úì ‚úì ABISan
7
E
1
‚úì ‚úó
ABISan
3
E
1
‚úì ‚úó
PTRSan
10
25‚Äì1827
I
‚úì ‚úó
√ÜPICSan I
11
25‚Äì1827
‚úì ‚úó
ABISan
1
5
I
‚úì ‚úó
√ÜPICSan I
3
1342‚Äì1624
‚úì ‚úó
PTRSan
3
1621
I
‚úì ‚úó
CFSan
1
864
I

Linux selftest 5.18
1.16
0.6.2
Linux selftest 5.18
1.16
0.6.2
Linux selftest 5.18
0.6.2
Open Enclave 0.19.0
Open Enclave 0.19.0
Rust EDP
SCONE
SCONE
SCONE
SCONE
SCONE
SCONE
SCONE

82
8
29‚Äì30
234
17222
1
1
1

1.71
5.7.0
5.7.0
5.7.0
5.8.0
5.8.0
5.8.0
5.8.0

DCAP
Inclavare

Inclavare

SBDR inherited

Unsanitized AC/DF, MXCSR, and FPU

‚úó
MXCSR dependent timing
‚úó
Compiler removed overflow check
strlen on unconstrained ptr (CVE-2023-38022) ‚úó
‚úó
Various SBDR issues (CVE-2023-38021)
‚úó
PIC jump before relocation
‚úó
Various unconstrained pointers
‚úó
Various SBDR/DRPW issues
‚úó
Unconstrained RET targets
‚úó
MXCSR dependent timing
‚úó
Unconstrained pointer (CVE-2022-26509)
‚úó
SBDR in enclave initialization
‚úó
‚úó
‚úó
Missing sanitization on entry
‚úó
Missing sanitization on entry
‚úó
Various unconstrained pointers
‚úó
Various unconstrained pointers
‚úó
Unconstrained src/dst addresses in memcpy
‚úó
PIC jump before relocation
Unsigned jump target comparison in ecall array ‚úó
‚úó
Unsanitized AC (regression) (CVE-2023-37479)
‚úó
MXCSR dependent timing
‚úó
MXCSR dependent timing
‚úó
Unsanitized FPU (CVE-2022-46487)
‚úó
Various pointer issues (CVE-2022-46486)
‚úó
Various SBDR/DRPW issues (CVE-2023-38023)
‚úó
MXCSR dependent timing
‚úó
Various SBDR issues
‚úó
Unconstrained read
‚úó
PIC jump before relocation

014b35f
1.2
2.1.1
2.13.3

Reproduced vulnerabilities in older versions (total 69 instances)
GoTEE
Gramine
Intel SDK
Intel SDK
Open Enclave 0.4.1
Open Enclave 0.4.1
Open Enclave 0.4.1
1.63
Rust EDP

‚úó ‚úì ABISan
E
‚úì ‚úì √ÜPICSan I
‚úì ‚úì ABISan
E
‚úì ‚úì √ÜPICSan I
‚úì ‚úì ABISan
E
‚úì ‚úì PTRSan
I
‚úì ‚úì √ÜPICSan I
‚úì ‚úì √ÜPICSan I

3
22‚Äì55
3
207‚Äì6198
4
402‚Äì1712
442‚Äì1712
1041‚Äì1043

1
10
1
28
1
13
13
2

Unsanitized FPU [22]
Various SBDR/DRPW issues
Unsanitized DF/AC [21]; FPU [22]
Various SBDR/DRPW issues
Unsanitized DF [21]
Unconstrained pointers [21]
Various SBDR/DRPW issues
Various SBDR/DRPW issues

‚úó
‚úó
‚úì
‚úó
‚úó
‚úó
‚úó
‚úó

Legend: ‚Ä† Not open source, but source code was made privately available;

Based on above runtime.

Appendix E.
Meta-Review

The following meta-review was prepared by the program
committee for the 2024 IEEE Symposium on Security and
Privacy (S&P) as part of the review process as detailed in
the call for papers.

E.1. Summary

This paper introduces Pandora, a symbolic execution
tool that analyzes the security of enclave runtimes. The de-
sign of Pandora is focused on providing end-to-end analysis
(including low-level runtime initialization and entry phases)
and being runtime agnostic, extensible, and accessible. Pan-
dora is shown to provide for the first time a comprehensive
analysis of enclave shielding runtimes, discovering 200 new
vulnerabilities across 11 widely used enclave shielding run-
times.

E.2. Scientific Contributions

‚Ä¢ Creates a new tool to enable future science
‚Ä¢ Identifies an impactful vulnerability
‚Ä¢ Provides a valuable step forward in an established field

E.3. Reasons for Acceptance

1) The paper introduces Pandora, a symbolic execution
tool for enclave shielding runtimes. The central goal
of Pandora is on truthful validation of SGX binaries,
considering critical initialization code that prior sys-
tems have overlooked. The tool is runtime agnostic and
therefore applicable to many enclave applications.
2) The paper identifies several new vulnerabilities. The ex-
periments demonstrate the Pandora discovers 200 new
vulnerabilities across 11 widely used enclave shielding
runtimes.

3) The paper provides a valuable step forward in the study
of enclave security. The paper describes the challenges
associated with a sound end-to-end analysis of enclave
interfaces, and the results show that there is still a
significant amount of work to be done to improve the
security of enclave applications.



=== Content from sconedocs.github.io_869bea8e_20250114_195807.html ===


[Skip to content](#scone-570)

[![logo](../img/SCONE-logo-white.png)](.. "Confidential Computing")

Confidential Computing

SCONE 5.7.0

Initializing search

* [Home](..)
* [News and Overview](../news/)
* [Quick Start](../scone_mesh_tutorial/)
* [Kubernetes](../k8s_concepts/)
* [Configuration & Attestation](../CASOverview/)
* [SconeApps](../helm/)
* [DevOps Workflows](../operations/)
* [Azure Kubernetes Services](../aks/)
* [Use Cases](../usecases/)
* [Sign up](../registry/)
* [More](../iexec_sconify_image/)

[![logo](../img/SCONE-logo-white.png)](.. "Confidential Computing")
Confidential Computing

* [Home](..)
* News and Overview

  News and Overview
  + [Overview](../news/)
  + [CC Soap Opera](../cc-telenovela/)
  + [CC University](../cc-university/)
  + [Confidential Computing](../vm_vs_enclave/)
  + [Advantages of SCONE](../advantages/)
  + [SCONE vs Intel SGX SDK](../whyscone/)
  + [Technical summary of SCONE](../technical_summary/)
  + [(No) Cross-Compilation](../buildingApps/)
  + [Curated Images](../curated_images/)
  + [Community Version](../community_version/)
* Quick Start

  Quick Start
  + sconectl

    sconectl
    - [Hello World](../scone_mesh_tutorial/)
    - [sconectl cli](../sconectl/)
    - [install sconectl](../install_sconectl/)
    - [openAPI description service](../service.html)
    - [openAPI description mesh](../mesh.html)
    - [Java Hello World](../java_mesh_tutorial/)
  + Overview

    Overview
    - [Workflows](../workflows/)
    - [Example](../sconify_hw_k8s/)
    - [kubectl](../lean_deployment/)
    - [Sconify](../sconify/)
    - [File Types](../sconify_filetypes/)
    - [Sconify Image SE](../ee_sconify_image/)
  + [Multi-Stakeholder Example](../multi-stakeholder-workflow/)
  + [Policy Update](../example_policy/)
  + [Boutique Demo](../microservices-demo/)
  + [Troubleshooting](../faq_sconify/)
  + Installation

    Installation
    - [Host Execution](../hostexample/)
    - [Installation overview](../installation/)
    - [Installing docker](../dockerinstall/)
    - [Installing Intel SGX driver](../sgxinstall/)
    - [Installing SCONE](../sconeinstall/)
    - [Updating CPU microcode](../microcode/)
    - [Windows 10](../windows10/)
  + Workshop

    Workshop
    - [getting access](../workshop/setup/)
    - [background](../workshop/details/)
    - [Task 1](../workshop/task_1/)
    - [Task 2](../workshop/task_2/)
    - [hands on A](../workshop/hands_on_1/)
    - [hands on B](../workshop/hands_on_2/)
    - [next steps](../workshop/next_steps/)
  + Tutorial

    Tutorial
    - [Assignments](../Exercise-Docu/exercises/)
    - [Assignment 0](../Exercise-Docu/exercise0/)
    - [Assignment 1](../Exercise-Docu/exercise1/)
    - [Assignment 2](../Exercise-Docu/exercise2/)
    - [Assignment 3](../Exercise-Docu/exercise3/)
    - [Assignment 4](../Exercise-Docu/exercise4/)
    - [Assignment 5](../Exercise-Docu/exercise5/)
    - [Section 2 OTP](../Exercise-Docu/section_otp/)
  + SCONE Execution Modes

    SCONE Execution Modes
    - [Execution Modes](../outline/)
    - [Simulation Mode](../firstcontainer/)
    - [Hardware Mode](../hardwaremode/)
* Kubernetes

  Kubernetes
  + [Concepts](../k8s_concepts/)
  + SCONE Operator

    SCONE Operator
    - [Introduction](../1_scone_operator/)
    - [Reconciliation](../2_operator_installation/)
    - [Deploying CAS and Vault](../5_kubectl/)
    - [Custom Resource Definitions](../3_resource_definitions/)
  + Helm Charts

    Helm Charts
    - [Kubernetes SGX Plugin](../helm_sgxdevplugin/)
    - [CAS Deploy & Attest](../helm_cas/)
    - [LAS Deploy & Platforms](../helm_las/)
    - [MariaDB Deploy & Attest](../helm_mariadb/)
    - [TEEMon Deployment](../helm_teemon/)
  + Dashboards

    Dashboards
    - [Helm Dashboard](../helm_dashboard/)
    - [Kubernetes Dashboard](../k8s_dashboard/)
    - [Kubeapps](../kubeapps/)
  + Examples

    Examples
    - [Hello World Kubernetes](../hello_world_kubernetes/)
    - [PySpark on Azure](../azure/scone-pyspark/)
* Configuration & Attestation

  Configuration & Attestation
  + [Introduction](../CASOverview/)
  + [Concepts](../cas_intro/)
  + [Policy Language](../CAS_session_lang_0_3/)
  + Policy Examples

    Policy Examples
    - [Audit Log](../auditLog/)
    - [Posting Policies](../cas_blender_example/)
    - [CLI](../CAS_cli-intro/)
    - [envcas](../envcas/)
    - [Platform-based attestation](../platform_attestation/)
    - Secure Arguments

      Secure Arguments
      * [Part 1 - print arguments](../print-arg-env/)
      * [Part 2 - session hash](../print-arg-env-p2/)
    - [Encrypted Volume](../encrypted_vol/)
    - [Binary Translation](../scone-signer-example/)
    - [Host Arguments](../host_arguments/)
    - [One-time Passwords](../otp_demo/)
    - [Encrypted Code and Input](../EncryptedWordCount/)
    - [Namespaces](../namespace/)
    - [Network Shield](../network_shield/)
  + Alternative CAS deployments

    Alternative CAS deployments
    - [CAS with helm](../CAS_production/)
    - [CAS with docker compose](../CAS_for_development/)
    - [CAS Backup Controller for Kubernetes](../cas-backup-controller/)
    - [CAS Backup Controller Quick Start](../cas-backup-controller-quick-start/)
    - [CAS Configuration](../CAS_config/)
    - [Public CAS](../public-CAS/)
    - [Starting LAS](../LASIntro/)
    - [Self-Provisioned CAS](../self-provisioned-cas/)
* SconeApps

  SconeApps
  + [SconeApps](../helm/)
  + [database](../sconeapps_database/)
  + [maxscale](../sconeapps_maxscale/)
  + [memcached](../sconeapps_memcached/)
  + [nginx](../sconeapps_nginx/)
  + [openvino](../sconeapps_openvino/)
  + [pytorch](../sconeapps_pytorch/)
  + [spark](../sconeapps_spark/)
  + [tensorflow](../sconeapps_tensorflow/)
  + [tensorflowlite](../sconeapps_tensorflowlite/)
  + [zookeeper](../sconeapps_zookeeper/)
* DevOps Workflows

  DevOps Workflows
  + [Workflows](../operations/)
  + [Attack mitigation](../mitigation/)
  + [Security advisories](../sadvisories/)
  + [Software updates](../software_updates/)
  + [Signing of enclaves](../scone-signer/)
  + [EDMM support](../edmm/)
  + [SCONE versioning](../scone_semantic_versioning/)
  + [Attestation by client](../attestation_by_client/)
  + [Technotes](../technotes/)
* Azure Kubernetes Services

  Azure Kubernetes Services
  + [Confidential AKS](../aks/)
  + [SCONE Playground on Azure](../azure/scone-playground/)
  + [Flask Demo](../aks/flask_demo/)
  + [Python Images](../python_images/)
  + [AKS Integration](../aks_integration/)
  + [AKS Integration Tutorial](../MicrosoftAzureIntegrations/)
  + [AKS Applications](../aks_charts/)
  + [AKS Setup](../aks_setup/)
* Use Cases

  Use Cases
  + [Introduction](../usecases/)
  + [Confidential Document Management](../secure_document_management/)
  + [Federated Machine Learning](../federated_machine_learning/)
  + [Confidential Code Deployment](../shared_source_code/)
  + [Blender](../blender/)
  + [PySpark](../pyspark/)
  + [TensorFlow](../tensorflow/)
  + [TensorFlow Lite](../tensorflowlite/)
  + [OpenVino](../openvino/)
  + [Vault](../vault/)
  + [Examples](../scone-use-case-overview/)
  + [Secure Remote Execution](../secure_remote_execution/)
  + [Dockerfile Example](../dockerfileexample/)
  + [Multi-stage build](../multistagebuild/)
  + [GO example](../groupcacheUseCase/)
  + [Finding Secrets](../memory_dump/)
  + [Trusted DApps](../dapps/)
  + [Flask Demo](../flask_demo/)
* Sign up

  Sign up
  + [Scontain Registy](../registry/)
* More

  More
  + Client Docu

    Client Docu
    - [iExec Sconify Image](../iexec_sconify_image/)
  + Language Support

    Language Support
    - [C](../C/)
    - [C#](../mono/)
    - [C++](../C%2B%2B/)
    - [Fortran](../Fortran/)
    - [GO](../GO/)
    - [Java](../Java/)
    - [Java with remote attestation](../Running_Java_Applications_in_Scone_with_remote_attestation/)
    - [Python](../Python/)
    - [PyPy](../pypyscone/)
    - [C#](../mono/)
    - [Node](../Nodejs/)
    - [Node example](../node-example/)
    - [R](../R/)
    - [Rust](../Rust/)
  + IDE Integration

    IDE Integration
    - [Eclipse](../eclipse/)
    - [Visual Studio Code](../helm_vscode/)
  + Command Line Interface

    Command Line Interface
    - [CLI Reference](../CAS_cli/)
    - [scone fspf](../SCONE_Fileshield/)
    - [scone binary fs](../binary_fs/)
    - [environment variables](../SCONE_ENV/)
    - [MrEnclave](../MrEnclave/)
    - [affinity](../scone_affinity/)
  + Performance

    Performance
    - [Applications](../performance/)
    - [Monitoring tool](../teemon/)
  + Background

    Background
    - [Application-Oriented Security](../appsecurity/)
    - [SCONE Background](../background/)
  + Security

    Security
    - [Threat Model](../S1_threat_model/)
    - [Random numbers](../S2_random_numbers/)
    - [Governance](../S3_governance/)
    - [Attestation](../S4_attestation/)
    - [Debug Mode](../S5_debug_mode/)
    - [Best Practices](../S6_best_practices/)
  + [Publications](../SCONE_Publications/)
  + [About](../aboutScone/)
  + [Glossary](../glossary/)
  + Releases

    Releases
    - [SCONE 5.9.0](../release5.9/)
    - [SCONE 5.8.0](../release5.8/)
    - SCONE 5.7.0

      [SCONE 5.7.0](./)

      Table of contents
      * [Bug Fixes](#bug-fixes)
      * [Features](#features)
    - [SCONE 5.6.0](../release5.6/)
    - [SCONE 5.5.0](../release5.5/)
    - [SCONE 5.4.0](../release5.4/)
  + [FAQ](../faq/)

Table of contents

* [Bug Fixes](#bug-fixes)
* [Features](#features)

# SCONE 5.7.0

## Bug Fixes

A large number of fixes.

## Features

* **cas:** Add enclave identities to audit log (e86743a)
* **cas:** Add PKCS#12 secret injection (7186d12)
* **cas:** Better error message on runtime->CAS authentication failure (0ad72f1)
* **cas:** Print CAS keys when SCONE\_VERSION=1 (74d0bc3)
* **cas:** Runtime connection timeouts (6ac8aef)
* **cas:** Send TLS close notify when closing enclave connection (6240ee8)
* **cas:** Support DCAP attestation reports in audit logs (1c9cc09)
* **cas:** Update OpenSSL libcrypto from v1.1.1d to v1.1.1k (72dae01)
* **cas:** Update SQLCipher from v4.3.0 to v4.5.0 (cdfbf78)
* **cas:** Use tracing as log backend (42badfd)
* **cross-compiler:** check hash of the prebuilt cross-compiler archive (20da4d3)
* **dockerfiles:** add glibc Makefile, ubuntu runtime image (3133d24)
* **dockerfiles:** add memcached pyclient for kubeapps demo (b134e0a)
* **dockerfiles:** Add sconecuratedimages/kubernetes:las.no-epid alias (d6b2435)
* **dockerfiles:** add TensorFlow-2.7.0 (ac215e0)
* **dockerfiles:** This commit extends fork to support sgx2. (e402aa0)
* **dockerfiles:** Introduces a feature to do partial heap transfers. (069dbc3)
* **dockerfiles:** Update to Intel SGX SDK 2.15.1 (1c93ed8)
* **dockerfiles:** Add Microsoft Azure LAS image for ICX (5337712)
* **dockerfiles:** support DT\_FILTER (d759362)
* **dockerfiles:** make cargo-clippy CLIPPY\_ARGS="--fix" (2b37c2a)
* **dockerfiles:** support /proc/self/cmdline (e27434c)
* **dockerfiles:** Add CAS info to error messages when attestation fails (c7e8079)
* **dockerfiles:** Add sendfile for Network Shield (135f7d8)
* **runtime:** add sendmmsg syscall (5a4e4db)
* **runtime:** Show hints when connecting to non-default CAS port (ca909c7)
* **runtime:** support dynamically linked position-dependent executables (34f0ddd)
* **rust:** Update from Rust 1.56.1 to Rust 1.57.0 (fbb0b01)
* **sconify:** add GLibC support (25dd3cb)
* **runtime:** add virtual syscalls for handling dlopen in glibc (7d9ceb7)
* **runtime:** crash when c runtime tries to get a rust runtime fd (81edcc9)
* **runtime:** filter getdent results (f52a30f)
* **runtime:** improve dynamic library loader (56d549a)
* **runtime:** introduce elf fs (29837e8)
* **runtime:** introduce optional optimization for fork in sim mode (fafb8c6)
* **runtime:** Network Shield (9c79a94)
* **runtime:** Reconnect to CAS (c49e102)
* **runtime:** Send keep-alive messages (0746d89)
* **runtime:** Set CAS connection read timeout (5b6ea86)
* **runtime:** support ethtool ioctl (da3b990)
* **runtime:** support loading glibc applications (546d8fc)
* **runtime:** support runtime extensions with glibc (10d05e9)
* **rust:** Update to Rust 1.56.1 (f161374)
* **signer:** print list of dependencies during signing with --verbose (3084be4)
* **runtime:** support switching between application and runtime tls (5559560)
* **rust:** Allow X.509 identities with partial certificate chains (1085a6e)

[Previous

SCONE 5.8.0](../release5.8/)
[Next

SCONE 5.6.0](../release5.6/)

Copyright Scontain ¬© 2018-2023

Made with
[Material for MkDocs](https://squidfunk.github.io/mkdocs-material/)


