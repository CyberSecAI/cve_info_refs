=== Content from github.com_5a80e012_20250114_181743.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fsecurity%2Fadvisories%2FGHSA-m4hf-j54p-p353)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fsecurity%2Fadvisories%2FGHSA-m4hf-j54p-p353)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Frepos%2Fadvisories%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  826](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

# Type confusion in shape inference for `ConcatV2`

Moderate

[mihaimaruseac](/mihaimaruseac)
published
GHSA-m4hf-j54p-p353
Feb 2, 2022

## Package

pip

tensorflow, tensorflow-cpu, tensorflow-gpu
([pip](/advisories?query=ecosystem%3Apip))

## Affected versions

< 2.8.0

## Patched versions

2.5.3, 2.6.3, 2.7.1

## Description

### Impact

The [implementation of shape inference for `ConcatV2`](https://github.com/tensorflow/tensorflow/blob/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework/common_shape_fns.cc#L1961-L2059) can be used to trigger a denial of service attack via a segfault caused by a type confusion:

```
import tensorflow as tf

@tf.function
def test():
  y = tf.raw_ops.ConcatV2(
    values=[[1,2,3],[4,5,6]],
    axis = 0xb500005b)
  return y

test()
```

The `axis` argument is translated into `concat_dim` in the `ConcatShapeHelper` helper function. Then, a value for `min_rank` is computed based on `concat_dim`. This is then used to validate that the `values` tensor has at least the required rank:

```
  int64_t concat_dim;
  if (concat_dim_t->dtype() == DT_INT32) {
    concat_dim = static_cast<int64_t>(concat_dim_t->flat<int32>()(0));
  } else {
    concat_dim = concat_dim_t->flat<int64_t>()(0);
  }

  // Minimum required number of dimensions.
  const int min_rank = concat_dim < 0 ? -concat_dim : concat_dim + 1;

  // ...
  ShapeHandle input = c->input(end_value_index - 1);
  TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, min_rank, &input));
```

However, [`WithRankAtLeast`](https://github.com/tensorflow/tensorflow/blob/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework/shape_inference.cc#L345-L358) receives the lower bound as a 64-bits value and then compares it against the maximum 32-bits integer value that could be represented:

```
Status InferenceContext::WithRankAtLeast(ShapeHandle shape, int64_t rank,
                                         ShapeHandle* out) {
  if (rank > kint32max) {
    return errors::InvalidArgument("Rank cannot exceed kint32max");
  }
  // ...
}
```

Due to the fact that `min_rank` is a 32-bits value and the value of `axis`, the `rank` argument is a [negative value](https://godbolt.org/z/Gcr5haMob), so the error check is bypassed.

### Patches

We have patched the issue in GitHub commit [08d7b00c0a5a20926363849f611729f53f3ec022](https://github.com/tensorflow/tensorflow/commit/08d7b00c0a5a20926363849f611729f53f3ec022).

The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.

### For more information

Please consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.

### Attribution

This vulnerability has been reported by Yu Tian of Qihoo 360 AIVul Team.

### Severity

Moderate

### CVE ID

CVE-2022-21731

### Weaknesses

No CWEs

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_228ef716_20250114_181742.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2F08d7b00c0a5a20926363849f611729f53f3ec022)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2F08d7b00c0a5a20926363849f611729f53f3ec022)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fcommit_fragments%2Frepo_layout&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  826](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Commit

[Permalink](/tensorflow/tensorflow/commit/08d7b00c0a5a20926363849f611729f53f3ec022)

This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.

Fix Segfault in Concat V2 shape function.

[Browse files](/tensorflow/tensorflow/tree/08d7b00c0a5a20926363849f611729f53f3ec022)
Browse the repository at this point in the history

```
PiperOrigin-RevId: 412120654
Change-Id: I3ff915faea694f9ad8b00024e9af2de9909011be
```

* Loading branch information

[![@ishark](https://avatars.githubusercontent.com/u/723624?s=40&v=4)](/ishark) [![@tensorflower-gardener](https://avatars.githubusercontent.com/u/17151892?s=40&v=4)](/tensorflower-gardener)

[ishark](/tensorflow/tensorflow/commits?author=ishark "View all commits by ishark")
authored and
[tensorflower-gardener](/tensorflow/tensorflow/commits?author=tensorflower-gardener "View all commits by tensorflower-gardener")
committed
Nov 24, 2021

1 parent
[fb51d44](/tensorflow/tensorflow/commit/fb51d44500539c11c5f6731091ba5330f283ce70)

commit 08d7b00

 Show file tree

 Hide file tree

Showing
**2 changed files**
with
**13 additions**
and
**1 deletion**.

* Whitespace
* Ignore whitespace

* Split
* Unified

* tensorflow

  + core/framework

    - tensorflow/core/framework/common\_shape\_fns.cc
      [common\_shape\_fns.cc](#diff-c203ab87147f37a0e6d951cf076862075638bb41e1a7b8f7f051232ce60688ed)
  + python/kernel\_tests/array\_ops

    - tensorflow/python/kernel\_tests/array\_ops/concat\_op\_test.py
      [concat\_op\_test.py](#diff-d5a146a3b8818b665c1182683225d159cb3c452eceb84e102b7ccae3cbe9e138)

## There are no files selected for viewing

2 changes: 1 addition & 1 deletion

2
[tensorflow/core/framework/common\_shape\_fns.cc](#diff-c203ab87147f37a0e6d951cf076862075638bb41e1a7b8f7f051232ce60688ed "tensorflow/core/framework/common_shape_fns.cc")

Show comments

[View file](/tensorflow/tensorflow/blob/08d7b00c0a5a20926363849f611729f53f3ec022/tensorflow/core/framework/common_shape_fns.cc)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -2005,7 +2005,7 @@ Status ConcatShapeHelper(InferenceContext\* c, int start\_value\_index, |
|  |  | } |
|  |  |  |
|  |  | // Minimum required number of dimensions. |
|  |  | const int min\_rank = concat\_dim < 0 ? -concat\_dim : concat\_dim + 1; |
|  |  | const int64 min\_rank = concat\_dim < 0 ? -concat\_dim : concat\_dim + 1; |
|  |  |  |
|  |  | ShapeHandle output\_before; |
|  |  | ShapeHandle output\_after; |
| Expand Down | |  |

12 changes: 12 additions & 0 deletions

12
[tensorflow/python/kernel\_tests/array\_ops/concat\_op\_test.py](#diff-d5a146a3b8818b665c1182683225d159cb3c452eceb84e102b7ccae3cbe9e138 "tensorflow/python/kernel_tests/array_ops/concat_op_test.py")

Show comments

[View file](/tensorflow/tensorflow/blob/08d7b00c0a5a20926363849f611729f53f3ec022/tensorflow/python/kernel_tests/array_ops/concat_op_test.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -16,6 +16,7 @@ |
|  |  |  |
|  |  | import numpy as np |
|  |  |  |
|  |  | from tensorflow.python.eager import def\_function |
|  |  | from tensorflow.python.framework import constant\_op |
|  |  | from tensorflow.python.framework import dtypes |
|  |  | from tensorflow.python.framework import errors\_impl |
| Expand Down  Expand Up | | @@ -570,6 +571,17 @@ def testConcatInvalidAxis(self): |
|  |  | t2 = [2] |
|  |  | gen\_array\_ops.concat\_v2([t1, t2], 1).eval() |
|  |  |  |
|  |  | def testConcatInvalidAxisInTfFunction(self): |
|  |  |  |
|  |  | @def\_function.function |
|  |  | def concat\_wrapper(): |
|  |  | y = gen\_array\_ops.concat\_v2( |
|  |  | values=[[1, 2, 3], [4, 5, 6]], axis=0xb500005b) |
|  |  | return y |
|  |  |  |
|  |  | with self.assertRaises(ValueError): |
|  |  | concat\_wrapper() |
|  |  |  |
|  |  | def testConcatNegativeAxis(self): |
|  |  | with test\_util.use\_gpu(): |
|  |  | t1 = [[1, 2, 3], [4, 5, 6]] |
| Expand Down | |  |

Toggle all file notes
Toggle all file annotations

### 0 comments on commit `08d7b00`

Please
[sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2F08d7b00c0a5a20926363849f611729f53f3ec022) to comment.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_5aaaf6c9_20250114_181738.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2F5100e359aef5c8021f2e71c7b986420b85ce7b3d%2Ftensorflow%2Fcore%2Fframework%2Fcommon_shape_fns.cc)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2F5100e359aef5c8021f2e71c7b986420b85ce7b3d%2Ftensorflow%2Fcore%2Fframework%2Fcommon_shape_fns.cc)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  826](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Files

 5100e35
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d)
2. /[tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core)
4. /[framework](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework)
/
# common\_shape\_fns.cc

Copy path Blame  Blame
## Latest commit

## History

[History](/tensorflow/tensorflow/commits/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework/common_shape_fns.cc)2624 lines (2332 loc) · 100 KB 5100e35
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d)
2. /[tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core)
4. /[framework](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework)
/
# common\_shape\_fns.cc

Top
## File metadata and controls

* Code
* Blame

2624 lines (2332 loc) · 100 KB[Raw](https://github.com/tensorflow/tensorflow/raw/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework/common_shape_fns.cc)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000/\* Copyright 2016 The TensorFlow Authors. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");you may not use this file except in compliance with the License.You may obtain a copy of the License at
 http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.==============================================================================\*/#include "tensorflow/core/framework/common\_shape\_fns.h"
#include "absl/container/flat\_hash\_map.h"#include "absl/container/flat\_hash\_set.h"#include "absl/strings/match.h"#include "absl/strings/str\_split.h"#include "absl/strings/string\_view.h"#include "tensorflow/core/framework/attr\_value.pb.h"#include "tensorflow/core/framework/shape\_inference.h"#include "tensorflow/core/lib/core/errors.h"#include "tensorflow/core/lib/gtl/inlined\_vector.h"#include "tensorflow/core/util/einsum\_op\_util.h"
namespace tensorflow {
namespace shape\_inference {
// The V2 version computes windowed output size with arbitrary dilation\_rate and// explicit padding, while the original version only handles the cases where// dilation\_rates equal to 1 and the padding is SAME or VALID.Status GetWindowedOutputSizeFromDimsV2( shape\_inference::InferenceContext\* c, shape\_inference::DimensionHandle input\_size, shape\_inference::DimensionOrConstant filter\_size, int64\_t dilation\_rate, int64\_t stride, Padding padding\_type, int64\_t padding\_before, int64\_t padding\_after, shape\_inference::DimensionHandle\* output\_size) { if (stride <= 0) { return errors::InvalidArgument("Stride must be > 0, but got ", stride); }
 if (dilation\_rate < 1) { return errors::InvalidArgument("Dilation rate must be >= 1, but got ", dilation\_rate); }
 // See also the parallel implementation in GetWindowedOutputSizeVerbose. switch (padding\_type) { case Padding::VALID: padding\_before = padding\_after = 0; TF\_FALLTHROUGH\_INTENDED; case Padding::EXPLICIT: TF\_RETURN\_IF\_ERROR( c->Add(input\_size, padding\_before + padding\_after, &input\_size)); if (dilation\_rate > 1) { DimensionHandle window\_size; TF\_RETURN\_IF\_ERROR( c->Subtract(c->MakeDim(filter\_size), 1, &window\_size)); TF\_RETURN\_IF\_ERROR( c->Multiply(window\_size, dilation\_rate, &window\_size)); TF\_RETURN\_IF\_ERROR(c->Add(window\_size, 1, &window\_size)); TF\_RETURN\_IF\_ERROR(c->Subtract(input\_size, window\_size, output\_size)); } else { TF\_RETURN\_IF\_ERROR(c->Subtract(input\_size, filter\_size, output\_size)); } TF\_RETURN\_IF\_ERROR(c->Add(\*output\_size, stride, output\_size)); TF\_RETURN\_IF\_ERROR(c->Divide(\*output\_size, stride, /\*evenly\_divisible=\*/false, output\_size)); break; case Padding::SAME: TF\_RETURN\_IF\_ERROR(c->Add(input\_size, stride - 1, output\_size)); TF\_RETURN\_IF\_ERROR(c->Divide(\*output\_size, stride, /\*evenly\_divisible=\*/false, output\_size)); break; } return Status::OK();}
Status GetWindowedOutputSizeFromDims( shape\_inference::InferenceContext\* c, shape\_inference::DimensionHandle input\_size, shape\_inference::DimensionOrConstant filter\_size, int64\_t stride, Padding padding\_type, shape\_inference::DimensionHandle\* output\_size) { if (padding\_type == Padding::EXPLICIT) { return errors::Internal( "GetWindowedOutputSizeFromDims does not handle EXPLICIT padding; call " "GetWindowedOutputSizeFromDimsV2 instead"); } return GetWindowedOutputSizeFromDimsV2(c, input\_size, filter\_size, /\*dilation\_rate=\*/1, stride, padding\_type, // Give dummy values of -1 to // padding\_before and padding\_after, // since explicit padding is not used. -1, -1, output\_size);}
Status UnchangedShape(shape\_inference::InferenceContext\* c) { c->set\_output(0, c->input(0)); auto\* handle\_data = c->input\_handle\_shapes\_and\_types(0); if (handle\_data != nullptr) { c->set\_output\_handle\_shapes\_and\_types(0, \*handle\_data); } return Status::OK();}
Status MatMulShape(shape\_inference::InferenceContext\* c) { ShapeHandle a; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 2, &a));
 ShapeHandle b; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 2, &b));
 bool transpose\_a, transpose\_b; TF\_RETURN\_IF\_ERROR(c->GetAttr("transpose\_a", &transpose\_a)); TF\_RETURN\_IF\_ERROR(c->GetAttr("transpose\_b", &transpose\_b)); DimensionHandle output\_rows = transpose\_a ? c->Dim(a, 1) : c->Dim(a, 0); DimensionHandle output\_cols = transpose\_b ? c->Dim(b, 0) : c->Dim(b, 1);
 // Validate that the inner shapes are compatible. DimensionHandle inner\_a = transpose\_a ? c->Dim(a, 0) : c->Dim(a, 1); DimensionHandle inner\_b = transpose\_b ? c->Dim(b, 1) : c->Dim(b, 0); DimensionHandle merged; TF\_RETURN\_IF\_ERROR(c->Merge(inner\_a, inner\_b, &merged));
 c->set\_output(0, c->Matrix(output\_rows, output\_cols)); return Status::OK();}
namespace {
// Validate that an Einsum subscript contains exactly one or zero ellipsis; and// that periods (.) occur only within an ellipses (...).Status ValidateEinsumEllipsis(absl::string\_view subscript, bool\* found\_ellipsis) { const int num\_periods = absl::c\_count(subscript, '.'); if (num\_periods != 0 && num\_periods != 3) { return errors::InvalidArgument( "Expected at most one ellipsis (...), but found ", num\_periods, " periods (.) in the input subscript: ", subscript); } if (num\_periods == 3 && !absl::StrContains(subscript, "...")) { return errors::InvalidArgument( "Periods found outside of ellipsis in subscript: ", subscript); } \*found\_ellipsis = num\_periods > 0; return Status::OK();}
} // namespace
Status EinsumShape(shape\_inference::InferenceContext\* c) { // We assume that the equation has a valid format. Either (x),(y)->(z) // or (x)->(z), where each of (x), (y) and (z) are concatenation of zero or // more latin alphabets and contains at most one ellipsis ('...'). string equation; TF\_RETURN\_IF\_ERROR(c->GetAttr("equation", &equation)); gtl::InlinedVector<string, 2> input\_labels; string output\_labels; TF\_RETURN\_IF\_ERROR( ParseEinsumEquation(equation, &input\_labels, &output\_labels));
 if (c->num\_inputs() == 0 || c->num\_inputs() > 2) { return errors::InvalidArgument("Expected either 1 or 2 inputs but got: ", c->num\_inputs()); } const int input\_labels\_size = input\_labels.size(); if (c->num\_inputs() != input\_labels\_size) { return errors::InvalidArgument("Expected ", input\_labels.size(), " inputs for equation ", equation, " but got: ", c->num\_inputs()); }
 // Validate input subscripts, build the label to dimension mapping and obtain // the broadcast shapes that map to ellipsis. absl::flat\_hash\_map<char, DimensionHandle> label\_to\_dimension; gtl::InlinedVector<ShapeHandle, 2> input\_bcast\_shapes(c->num\_inputs()); for (int i = 0, end = c->num\_inputs(); i < end; ++i) { bool has\_ellipsis = false; TF\_RETURN\_IF\_ERROR(ValidateEinsumEllipsis(input\_labels[i], &has\_ellipsis)); ShapeHandle input\_shape = c->input(i); // Validate that the input rank is sufficient for the given number of named // labels. if (c->RankKnown(input\_shape)) { if (has\_ellipsis) { const int num\_named\_labels = static\_cast<int>(input\_labels[i].size()) - 3; TF\_RETURN\_WITH\_CONTEXT\_IF\_ERROR( c->WithRankAtLeast(input\_shape, num\_named\_labels, &input\_shape), " for ", i, "th input and equation: ", equation); } else { const int num\_named\_labels = static\_cast<int>(input\_labels[i].size()); TF\_RETURN\_WITH\_CONTEXT\_IF\_ERROR( c->WithRank(input\_shape, num\_named\_labels, &input\_shape), " for ", i, "th input and equation: ", equation); } }
 bool seen\_ellipsis = false; input\_bcast\_shapes[i] = c->Scalar(); // Run through the input labels; populate label\_to\_dimension mapping and // compute the broadcast shapes corresponding to the ellipsis (if present). for (int label\_idx = 0, end = input\_labels[i].size(); label\_idx < end; ++label\_idx) { const char label = input\_labels[i][label\_idx]; // Calculate the input axis that the current label is referring to. After // the ellipsis, the axis may be found by using negative indices; i.e the // (rank - k)th dimension corresponds to the (num\_labels - k)th label. const int64\_t axis\_before\_ellipsis = label\_idx; const int64\_t axis\_after\_ellipsis = c->RankKnown(input\_shape) ? label\_idx + c->Rank(input\_shape) - input\_labels[i].size() : -1;
 // Populate the input broadcast shape when we encounter an ellipsis (...). if (label == '.') { if (!c->RankKnown(input\_shape)) { input\_bcast\_shapes[i] = c->UnknownShape(); } else { // The broadcast shape runs till the named label right after the // ellipsis, the label with index (label\_idx + 3). TF\_RETURN\_IF\_ERROR(c->Subshape(input\_shape, axis\_before\_ellipsis, axis\_after\_ellipsis + 3, &input\_bcast\_shapes[i])); } label\_idx += 2; // Skip the rest of the ellipsis. seen\_ellipsis = true; continue; } // Obtain the dimension that the current label corresponds to. int64\_t axis = seen\_ellipsis ? axis\_after\_ellipsis : axis\_before\_ellipsis; DimensionHandle new\_dim = c->RankKnown(input\_shape) ? c->Dim(input\_shape, axis) : c->UnknownDim(); // If we've seen this label before, make sure previous and current // dimensions are compatible. if (label\_to\_dimension.contains(label)) { DimensionHandle merged; TF\_RETURN\_IF\_ERROR( c->Merge(label\_to\_dimension[label], new\_dim, &merged)); label\_to\_dimension[label] = merged; } else { label\_to\_dimension[label] = new\_dim; } } }
 // For two inputs, broadcast the two input broadcast shapes to create the // output broadcast shape. For one input, just copy the single broadcast // shape. ShapeHandle output\_bcast\_shape; if (input\_bcast\_shapes.size() == 1) { output\_bcast\_shape = input\_bcast\_shapes[0]; } else if (input\_bcast\_shapes.size() == 2) { TF\_RETURN\_IF\_ERROR(BroadcastBinaryOpOutputShapeFnHelper( c, input\_bcast\_shapes[0], input\_bcast\_shapes[1], true, &output\_bcast\_shape)); }
 bool output\_has\_ellipsis = false; TF\_RETURN\_IF\_ERROR( ValidateEinsumEllipsis(output\_labels, &output\_has\_ellipsis)); if (output\_has\_ellipsis) { // If the output subscript has ellipsis and the output broadcast rank is // unknown, then the output shape should have unknown rank. if (!c->RankKnown(output\_bcast\_shape)) { c->set\_output(0, c->UnknownShape()); return Status::OK(); } } else { // If the output subscripts don't have ellipsis then make sure the output // broadcasting shape is empty. TF\_RETURN\_WITH\_CONTEXT\_IF\_ERROR( c->WithRankAtMost(output\_bcast\_shape, 0, &output\_bcast\_shape), " for einsum equation '", equation, "' without ellipsis (...) in the output subscripts where input(s) have " "non-empty broadcasting shape"); output\_bcast\_shape = c->Scalar(); }
 // Create the output shape from output labels and label\_to\_dimension mapping. std::vector<DimensionHandle> output\_dims; for (int label\_idx = 0, end = output\_labels.size(); label\_idx < end; ++label\_idx) { const char label = output\_labels[label\_idx]; // Append the output\_bcast\_shape when the ellipsis is encountered. if (label == '.') { for (int k = 0; k < c->Rank(output\_bcast\_shape); ++k) { output\_dims.push\_back(c->Dim(output\_bcast\_shape, k)); } label\_idx += 2; // Skip the rest of the ellipsis. continue; } auto dimension\_it = label\_to\_dimension.find(label); if (dimension\_it == label\_to\_dimension.end()) { return errors::InvalidArgument( "Einsum output subscripts for equation '", equation, "' has label '", label, "' which is not present in the input subscripts"); } output\_dims.push\_back(dimension\_it->second); } c->set\_output(0, c->MakeShape(output\_dims)); return Status::OK();}
Status BatchMatMulV2Shape(shape\_inference::InferenceContext\* c) { ShapeHandle a\_shape; ShapeHandle b\_shape; TF\_RETURN\_IF\_ERROR(c->WithRankAtLeast(c->input(0), 2, &a\_shape)); TF\_RETURN\_IF\_ERROR(c->WithRankAtLeast(c->input(1), 2, &b\_shape));
 // Determine output rows and columns. bool adj\_x; bool adj\_y; TF\_RETURN\_IF\_ERROR(c->GetAttr("adj\_x", &adj\_x)); TF\_RETURN\_IF\_ERROR(c->GetAttr("adj\_y", &adj\_y)); DimensionHandle output\_rows = c->Dim(a\_shape, adj\_x ? -1 : -2); DimensionHandle output\_cols = c->Dim(b\_shape, adj\_y ? -2 : -1);
 // Inner dimensions should be compatible. DimensionHandle inner\_merged; TF\_RETURN\_IF\_ERROR(c->Merge(c->Dim(a\_shape, adj\_x ? -2 : -1), c->Dim(b\_shape, adj\_y ? -1 : -2), &inner\_merged));
 // Batch dimensions should broadcast with each other. ShapeHandle a\_batch\_shape; ShapeHandle b\_batch\_shape; ShapeHandle output\_batch\_shape; TF\_RETURN\_IF\_ERROR(c->Subshape(a\_shape, 0, -2, &a\_batch\_shape)); TF\_RETURN\_IF\_ERROR(c->Subshape(b\_shape, 0, -2, &b\_batch\_shape));
 TF\_RETURN\_IF\_ERROR(BroadcastBinaryOpOutputShapeFnHelper( c, a\_batch\_shape, b\_batch\_shape, true, &output\_batch\_shape));
 ShapeHandle output\_shape; TF\_RETURN\_IF\_ERROR(c->Concatenate( output\_batch\_shape, c->Matrix(output\_rows, output\_cols), &output\_shape));
 c->set\_output(0, output\_shape); return Status::OK();}
Status BatchMatMulShape(shape\_inference::InferenceContext\* c) { ShapeHandle a\_shape; ShapeHandle b\_shape; TF\_RETURN\_IF\_ERROR(c->WithRankAtLeast(c->input(0), 2, &a\_shape)); TF\_RETURN\_IF\_ERROR(c->WithRankAtLeast(c->input(1), 2, &b\_shape));
 // Determine output rows and cols. bool adj\_x; bool adj\_y; TF\_RETURN\_IF\_ERROR(c->GetAttr("adj\_x", &adj\_x)); TF\_RETURN\_IF\_ERROR(c->GetAttr("adj\_y", &adj\_y)); DimensionHandle output\_rows = c->Dim(a\_shape, adj\_x ? -1 : -2); DimensionHandle output\_cols = c->Dim(b\_shape, adj\_y ? -2 : -1);
 // Batch dims match between inputs. ShapeHandle a\_batch\_dims; ShapeHandle b\_batch\_dims; ShapeHandle batch\_dims; TF\_RETURN\_IF\_ERROR(c->Subshape(a\_shape, 0, -2, &a\_batch\_dims)); TF\_RETURN\_IF\_ERROR(c->Subshape(b\_shape, 0, -2, &b\_batch\_dims)); TF\_RETURN\_IF\_ERROR(c->Merge(a\_batch\_dims, b\_batch\_dims, &batch\_dims));
 // Assert inner dims match. DimensionHandle unused; TF\_RETURN\_IF\_ERROR(c->Merge(c->Dim(a\_shape, adj\_x ? -2 : -1), c->Dim(b\_shape, adj\_y ? -1 : -2), &unused));
 ShapeHandle out; TF\_RETURN\_IF\_ERROR( c->Concatenate(batch\_dims, c->Matrix(output\_rows, output\_cols), &out)); c->set\_output(0, out); return Status::OK();}
// --------------------------------------------------------------------------
Status BiasAddShape(shape\_inference::InferenceContext\* c) { ShapeHandle input\_shape;
 // Fetch the data\_format attribute, which may not exist. string data\_format; Status s = c->GetAttr("data\_format", &data\_format);
 if (s.ok() && data\_format == "NCHW") { TF\_RETURN\_IF\_ERROR(c->WithRankAtLeast(c->input(0), 3, &input\_shape)); } else { TF\_RETURN\_IF\_ERROR(c->WithRankAtLeast(c->input(0), 2, &input\_shape)); }
 ShapeHandle bias\_shape; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 1, &bias\_shape)); DimensionHandle bias\_dim = c->Dim(bias\_shape, 0);
 // If rank unknown, return unknown shape. if (!c->RankKnown(input\_shape)) { c->set\_output(0, c->UnknownShape()); return Status::OK(); }
 // Output has the same shape as the input, and matches the length of // the bias in its bias dimension. ShapeHandle output\_shape; if (s.ok() && data\_format == "NCHW") { // Merge the length of bias\_shape into the third to last dimension ShapeHandle first; TF\_RETURN\_IF\_ERROR(c->Subshape(input\_shape, 0, 1, &first));
 ShapeHandle last; TF\_RETURN\_IF\_ERROR(c->Subshape(input\_shape, 2, &last));
 DimensionHandle input\_bias\_dim = c->Dim(input\_shape, 1); DimensionHandle merged\_bias\_dim; TF\_RETURN\_IF\_ERROR(c->Merge(input\_bias\_dim, bias\_dim, &merged\_bias\_dim)); ShapeHandle merged\_bias = c->Vector(merged\_bias\_dim);
 ShapeHandle temp; TF\_RETURN\_IF\_ERROR(c->Concatenate(first, merged\_bias, &temp)); TF\_RETURN\_IF\_ERROR(c->Concatenate(temp, last, &output\_shape)); } else { ShapeHandle all\_but\_bias; TF\_RETURN\_IF\_ERROR(c->Subshape(input\_shape, 0, -1, &all\_but\_bias));
 DimensionHandle input\_bias\_dim = c->Dim(input\_shape, -1); DimensionHandle merged\_bias\_dim; TF\_RETURN\_IF\_ERROR(c->Merge(input\_bias\_dim, bias\_dim, &merged\_bias\_dim));
 ShapeHandle merged\_bias = c->Vector(merged\_bias\_dim); TF\_RETURN\_IF\_ERROR( c->Concatenate(all\_but\_bias, merged\_bias, &output\_shape)); }
 c->set\_output(0, output\_shape); return Status::OK();}
Status BiasAddGradShape(shape\_inference::InferenceContext\* c) { ShapeHandle input\_shape; // Fetch the data\_format attribute, which may not exist. string data\_format; Status s = c->GetAttr("data\_format", &data\_format);
 if (s.ok() && data\_format == "NCHW") { TF\_RETURN\_IF\_ERROR(c->WithRankAtLeast(c->input(0), 3, &input\_shape)); c->set\_output(0, c->Vector(c->Dim(input\_shape, 1))); } else { TF\_RETURN\_IF\_ERROR(c->WithRankAtLeast(c->input(0), 2, &input\_shape)); c->set\_output(0, c->Vector(c->Dim(input\_shape, -1))); }
 return Status::OK();}
Status CheckFormatConstraintsOnShape(const TensorFormat tensor\_format, const ShapeHandle shape\_handle, const string& tensor\_name, shape\_inference::InferenceContext\* c) { if (tensor\_format == FORMAT\_NCHW\_VECT\_C) { // Check that the vect dim has size 4 or 32. const int num\_dims = c->Rank(shape\_handle); DimensionHandle vect\_dim = c->Dim( shape\_handle, GetTensorInnerFeatureDimIndex(num\_dims, tensor\_format)); int64\_t vect\_dim\_val = c->Value(vect\_dim); if (vect\_dim\_val != 4 && vect\_dim\_val != 32) { return errors::InvalidArgument( "VECT\_C dimension must be 4 or 32, but is ", vect\_dim\_val); } }
 return Status::OK();}
Status DatasetIteratorShape(shape\_inference::InferenceContext\* c) { shape\_inference::ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 0, &unused)); std::vector<PartialTensorShape> output\_shapes; TF\_RETURN\_IF\_ERROR(c->GetAttr("output\_shapes", &output\_shapes)); const int output\_shapes\_size = output\_shapes.size(); if (output\_shapes\_size != c->num\_outputs()) { return errors::InvalidArgument( "`output\_shapes` must be the same length as `output\_types` (", output\_shapes.size(), " vs. ", c->num\_outputs()); } for (size\_t i = 0; i < output\_shapes.size(); ++i) { shape\_inference::ShapeHandle output\_shape\_handle; TF\_RETURN\_IF\_ERROR(c->MakeShapeFromPartialTensorShape( output\_shapes[i], &output\_shape\_handle)); c->set\_output(static\_cast<int>(i), output\_shape\_handle); } return Status::OK();}
Status MakeShapeFromFormat(TensorFormat format, DimensionOrConstant N, const std::vector<DimensionOrConstant>& spatial, DimensionOrConstant C, ShapeHandle\* out, shape\_inference::InferenceContext\* context) { const int num\_dims = GetTensorDimsFromSpatialDims(spatial.size(), format); std::vector<DimensionHandle> dims\_actual(num\_dims); dims\_actual[GetTensorBatchDimIndex(num\_dims, format)] = context->MakeDim(N); int outer\_c\_index = GetTensorFeatureDimIndex(num\_dims, format); dims\_actual[outer\_c\_index] = context->MakeDim(C); if (format == FORMAT\_NCHW\_VECT\_C) { dims\_actual[GetTensorInnerFeatureDimIndex(num\_dims, format)] = context->MakeDim(4); } else if (format == FORMAT\_NHWC\_VECT\_W) { dims\_actual[GetTensorInnerWidthDimIndex(num\_dims, format)] = context->MakeDim(4); } for (int spatial\_dim = 0, end = spatial.size(); spatial\_dim < end; spatial\_dim++) { dims\_actual[GetTensorSpatialDimIndex(num\_dims, format, spatial\_dim)] = context->MakeDim(spatial[spatial\_dim]); } \*out = context->MakeShape(dims\_actual); return Status::OK();}
Status DimensionsFromShape(ShapeHandle shape, TensorFormat format, DimensionHandle\* batch\_dim, gtl::MutableArraySlice<DimensionHandle> spatial\_dims, DimensionHandle\* filter\_dim, InferenceContext\* context) { const int32\_t rank = GetTensorDimsFromSpatialDims(spatial\_dims.size(), format); // Batch. \*batch\_dim = context->Dim(shape, GetTensorBatchDimIndex(rank, format)); // Spatial. for (int spatial\_dim\_index = 0, end = spatial\_dims.size(); spatial\_dim\_index < end; ++spatial\_dim\_index) { spatial\_dims[spatial\_dim\_index] = context->Dim( shape, GetTensorSpatialDimIndex(rank, format, spatial\_dim\_index)); } // Channel. \*filter\_dim = context->Dim(shape, GetTensorFeatureDimIndex(rank, format)); if (format == FORMAT\_NCHW\_VECT\_C) { TF\_RETURN\_IF\_ERROR(context->Multiply( \*filter\_dim, context->Dim(shape, GetTensorInnerFeatureDimIndex(rank, format)), filter\_dim)); } return Status::OK();}
// vect\_size must be provided if format is NCHW\_VECT\_C.Status ShapeFromDimensions(DimensionHandle batch\_dim, gtl::ArraySlice<DimensionHandle> spatial\_dims, DimensionHandle filter\_dim, TensorFormat format, absl::optional<DimensionHandle> vect\_size, InferenceContext\* context, ShapeHandle\* shape) { const int32\_t rank = GetTensorDimsFromSpatialDims(spatial\_dims.size(), format); std::vector<DimensionHandle> out\_dims(rank);
 // Batch. out\_dims[tensorflow::GetTensorBatchDimIndex(rank, format)] = batch\_dim; // Spatial. for (int spatial\_dim\_index = 0, end = spatial\_dims.size(); spatial\_dim\_index < end; ++spatial\_dim\_index) { out\_dims[tensorflow::GetTensorSpatialDimIndex( rank, format, spatial\_dim\_index)] = spatial\_dims[spatial\_dim\_index]; } // Channel. if (format == tensorflow::FORMAT\_NCHW\_VECT\_C) { // When format is NCHW\_VECT\_C, factor the feature map count into the outer // feature count and the inner feature count (4 or 32). CHECK(vect\_size.has\_value()); // Crash ok. TF\_RETURN\_IF\_ERROR(context->Divide( filter\_dim, \*vect\_size, /\*evenly\_divisible=\*/true, &out\_dims[tensorflow::GetTensorFeatureDimIndex(rank, format)])); out\_dims[GetTensorInnerFeatureDimIndex(rank, format)] = \*vect\_size; } else { out\_dims[tensorflow::GetTensorFeatureDimIndex(rank, format)] = filter\_dim; }
 \*shape = context->MakeShape(out\_dims); return tensorflow::Status::OK();}
namespace {
Status Conv2DShapeImpl(shape\_inference::InferenceContext\* c, bool supports\_explicit\_padding) { string data\_format\_str, filter\_format\_str; if (!c->GetAttr("data\_format", &data\_format\_str).ok()) { data\_format\_str = "NHWC"; } if (!c->GetAttr("filter\_format", &filter\_format\_str).ok()) { filter\_format\_str = "HWIO"; }
 TensorFormat data\_format; if (!FormatFromString(data\_format\_str, &data\_format)) { return errors::InvalidArgument("Invalid data format string: ", data\_format\_str); } FilterTensorFormat filter\_format; if (!FilterFormatFromString(filter\_format\_str, &filter\_format)) { return errors::InvalidArgument("Invalid filter format string: ", filter\_format\_str); }
 constexpr int num\_spatial\_dims = 2; const int rank = GetTensorDimsFromSpatialDims(num\_spatial\_dims, data\_format); ShapeHandle conv\_input\_shape; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), rank, &conv\_input\_shape)); TF\_RETURN\_IF\_ERROR(CheckFormatConstraintsOnShape( data\_format, conv\_input\_shape, "conv\_input", c));
 // The filter rank should match the input (4 for NCHW, 5 for NCHW\_VECT\_C). ShapeHandle filter\_shape; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), rank, &filter\_shape)); TF\_RETURN\_IF\_ERROR( CheckFormatConstraintsOnShape(data\_format, filter\_shape, "filter", c));
 std::vector<int32> dilations; TF\_RETURN\_IF\_ERROR(c->GetAttr("dilations", &dilations));
 if (dilations.size() != 4) { return errors::InvalidArgument( "Conv2D requires the dilation attribute to contain 4 values, but got: ", dilations.size()); }
 std::vector<int32> strides; TF\_RETURN\_IF\_ERROR(c->GetAttr("strides", &strides));
 // strides.size() should be 4 (NCHW) even if the input is 5 (NCHW\_VECT\_C). if (strides.size() != 4) { return errors::InvalidArgument("Conv2D on data format ", data\_format\_str, " requires the stride attribute to contain" " 4 values, but got: ", strides.size()); }
 const int32\_t stride\_rows = GetTensorDim(strides, data\_format, 'H'); const int32\_t stride\_cols = GetTensorDim(strides, data\_format, 'W'); const int32\_t dilation\_rows = GetTensorDim(dilations, data\_format, 'H'); const int32\_t dilation\_cols = GetTensorDim(dilations, data\_format, 'W');
 DimensionHandle batch\_size\_dim; DimensionHandle input\_depth\_dim; gtl::InlinedVector<DimensionHandle, 2> input\_spatial\_dims(2); TF\_RETURN\_IF\_ERROR(DimensionsFromShape( conv\_input\_shape, data\_format, &batch\_size\_dim, absl::MakeSpan(input\_spatial\_dims), &input\_depth\_dim, c));
 DimensionHandle output\_depth\_dim = c->Dim( filter\_shape, GetFilterDimIndex<num\_spatial\_dims>(filter\_format, 'O')); DimensionHandle filter\_rows\_dim = c->Dim( filter\_shape, GetFilterDimIndex<num\_spatial\_dims>(filter\_format, 'H')); DimensionHandle filter\_cols\_dim = c->Dim( filter\_shape, GetFilterDimIndex<num\_spatial\_dims>(filter\_format, 'W')); DimensionHandle filter\_input\_depth\_dim; if (filter\_format == FORMAT\_OIHW\_VECT\_I) { TF\_RETURN\_IF\_ERROR(c->Multiply( c->Dim(filter\_shape, GetFilterDimIndex<num\_spatial\_dims>(filter\_format, 'I')), c->Dim(filter\_shape, GetFilterTensorInnerInputChannelsDimIndex(rank, filter\_format)), &filter\_input\_depth\_dim)); } else { filter\_input\_depth\_dim = c->Dim( filter\_shape, GetFilterDimIndex<num\_spatial\_dims>(filter\_format, 'I')); }
 // Check that the input tensor and the filter tensor agree on the channel // count. if (c->ValueKnown(input\_depth\_dim) && c->ValueKnown(filter\_input\_depth\_dim)) { int64\_t input\_depth\_value = c->Value(input\_depth\_dim), filter\_input\_depth\_value = c->Value(filter\_input\_depth\_dim); if (filter\_input\_depth\_value == 0) return errors::InvalidArgument("Depth of filter must not be 0"); if (input\_depth\_value % filter\_input\_depth\_value != 0) return errors::InvalidArgument( "Depth of input (", input\_depth\_value, ") is not a multiple of input depth of filter (", filter\_input\_depth\_value, ")"); if (input\_depth\_value != filter\_input\_depth\_value) { int64\_t num\_groups = input\_depth\_value / filter\_input\_depth\_value; if (c->ValueKnown(output\_depth\_dim)) { int64\_t output\_depth\_value = c->Value(output\_depth\_dim); if (num\_groups == 0) return errors::InvalidArgument("Number of groups must not be 0"); if (output\_depth\_value % num\_groups != 0) return errors::InvalidArgument( "Depth of output (", output\_depth\_value, ") is not a multiple of the number of groups (", num\_groups, ")"); } } }
 Padding padding; TF\_RETURN\_IF\_ERROR(c->GetAttr("padding", &padding));
 std::vector<int64\_t> explicit\_paddings; if (supports\_explicit\_padding) { Status s = c->GetAttr("explicit\_paddings", &explicit\_paddings); // Use the default value, which is an empty list, if the attribute is not // found. Otherwise return the error to the caller. if (!s.ok() && !errors::IsNotFound(s)) { return s; } TF\_RETURN\_IF\_ERROR(CheckValidPadding(padding, explicit\_paddings, /\*num\_dims=\*/4, data\_format)); } else { CHECK(padding != Padding::EXPLICIT); // Crash ok. }
 DimensionHandle output\_rows, output\_cols; int64\_t pad\_rows\_before = -1, pad\_rows\_after = -1; int64\_t pad\_cols\_before = -1, pad\_cols\_after = -1; if (padding == Padding::EXPLICIT) { GetExplicitPaddingForDim(explicit\_paddings, data\_format, 'H', &pad\_rows\_before, &pad\_rows\_after); GetExplicitPaddingForDim(explicit\_paddings, data\_format, 'W', &pad\_cols\_before, &pad\_cols\_after); } TF\_RETURN\_IF\_ERROR(GetWindowedOutputSizeFromDimsV2( c, input\_spatial\_dims[0], filter\_rows\_dim, dilation\_rows, stride\_rows, padding, pad\_rows\_before, pad\_rows\_after, &output\_rows)); TF\_RETURN\_IF\_ERROR(GetWindowedOutputSizeFromDimsV2( c, input\_spatial\_dims[1], filter\_cols\_dim, dilation\_cols, stride\_cols, padding, pad\_cols\_before, pad\_cols\_after, &output\_cols));
 absl::optional<DimensionHandle> vect\_size; if (data\_format == FORMAT\_NCHW\_VECT\_C) { vect\_size.emplace(c->Dim(conv\_input\_shape, GetTensorInnerFeatureDimIndex(rank, data\_format))); } ShapeHandle output\_shape; TF\_RETURN\_IF\_ERROR(ShapeFromDimensions( batch\_size\_dim, {output\_rows, output\_cols}, output\_depth\_dim, data\_format, vect\_size, c, &output\_shape)); c->set\_output(0, output\_shape); return Status::OK();}
} // namespace
// Shape function for Conv2D-like operations that support explicit padding.Status Conv2DShapeWithExplicitPadding(shape\_inference::InferenceContext\* c) { return Conv2DShapeImpl(c, true);}
// Shape function for Conv2D-like operations that do not support explicit// padding.Status Conv2DShape(shape\_inference::InferenceContext\* c) { return Conv2DShapeImpl(c, false);}
// TODO(mjanusz): Unify all conv/pooling shape functions.Status Conv3DShape(shape\_inference::InferenceContext\* c) { ShapeHandle input\_shape; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 5, &input\_shape)); ShapeHandle filter\_shape; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 5, &filter\_shape));
 string data\_format; Status s = c->GetAttr("data\_format", &data\_format);
 std::vector<int32> dilations; TF\_RETURN\_IF\_ERROR(c->GetAttr("dilations", &dilations));
 if (dilations.size() != 5) { return errors::InvalidArgument( "Conv3D requires the dilation attribute to contain 5 values, but got: ", dilations.size()); }
 std::vector<int32> strides; TF\_RETURN\_IF\_ERROR(c->GetAttr("strides", &strides)); if (strides.size() != 5) { return errors::InvalidArgument( "Conv3D requires the stride attribute to contain 5 values, but got: ", strides.size()); }
 int32\_t stride\_planes, stride\_rows, stride\_cols; int32\_t dilation\_planes, dilation\_rows, dilation\_cols; if (s.ok() && data\_format == "NCDHW") { // Convert input\_shape to NDHWC. auto dim = [&](char dimension) { return c->Dim(input\_shape, GetTensorDimIndex<3>(FORMAT\_NCHW, dimension)); }; input\_shape = c->MakeShape({{dim('N'), dim('0'), dim('1'), dim('2'), dim('C')}}); stride\_planes = strides[2]; stride\_rows = strides[3]; stride\_cols = strides[4]; dilation\_planes = dilations[2]; dilation\_cols = dilations[3]; dilation\_rows = dilations[4]; } else { stride\_planes = strides[1]; stride\_rows = strides[2]; stride\_cols = strides[3]; dilation\_planes = dilations[1]; dilation\_cols = dilations[2]; dilation\_rows = dilations[3]; }
 DimensionHandle batch\_size\_dim = c->Dim(input\_shape, 0); DimensionHandle in\_planes\_dim = c->Dim(input\_shape, 1); DimensionHandle in\_rows\_dim = c->Dim(input\_shape, 2); DimensionHandle in\_cols\_dim = c->Dim(input\_shape, 3); DimensionHandle input\_depth\_dim = c->Dim(input\_shape, 4);
 DimensionHandle filter\_planes\_dim = c->Dim(filter\_shape, 0); DimensionHandle filter\_rows\_dim = c->Dim(filter\_shape, 1); DimensionHandle filter\_cols\_dim = c->Dim(filter\_shape, 2); DimensionHandle filter\_input\_depth\_dim = c->Dim(filter\_shape, 3); DimensionHandle output\_depth\_dim = c->Dim(filter\_shape, 4);
 // Check that the input tensor and the filter tensor agree on the channel // count. if (c->ValueKnown(input\_depth\_dim) && c->ValueKnown(filter\_input\_depth\_dim)) { int64\_t input\_depth\_value = c->Value(input\_depth\_dim), filter\_input\_depth\_value = c->Value(filter\_input\_depth\_dim); if (filter\_input\_depth\_value == 0) return errors::InvalidArgument("Depth of filter must not be 0"); if (input\_depth\_value % filter\_input\_depth\_value != 0) return errors::InvalidArgument( "Depth of input (", input\_depth\_value, ") is not a multiple of input depth of filter (", filter\_input\_depth\_value, ")"); if (input\_depth\_value != filter\_input\_depth\_value) { int64\_t num\_groups = input\_depth\_value / filter\_input\_depth\_value; if (c->ValueKnown(output\_depth\_dim)) { int64\_t output\_depth\_value = c->Value(output\_depth\_dim); if (num\_groups == 0) return errors::InvalidArgument("Number of groups must not be 0"); if (output\_depth\_value % num\_groups != 0) return errors::InvalidArgument( "Depth of output (", output\_depth\_value, ") is not a multiple of the number of groups (", num\_groups, ")"); } } }
 Padding padding; TF\_RETURN\_IF\_ERROR(c->GetAttr("padding", &padding)); DimensionHandle output\_planes, output\_rows, output\_cols;
 TF\_RETURN\_IF\_ERROR(GetWindowedOutputSizeFromDimsV2( c, in\_planes\_dim, filter\_planes\_dim, dilation\_planes, stride\_planes, padding, -1, -1, &output\_planes)); TF\_RETURN\_IF\_ERROR(GetWindowedOutputSizeFromDimsV2( c, in\_rows\_dim, filter\_rows\_dim, dilation\_rows, stride\_rows, padding, -1, -1, &output\_rows)); TF\_RETURN\_IF\_ERROR(GetWindowedOutputSizeFromDimsV2( c, in\_cols\_dim, filter\_cols\_dim, dilation\_cols, stride\_cols, padding, -1, -1, &output\_cols));
 ShapeHandle output\_shape; if (data\_format == "NCDHW") { output\_shape = c->MakeShape({batch\_size\_dim, output\_depth\_dim, output\_planes, output\_rows, output\_cols}); } else { output\_shape = c->MakeShape({batch\_size\_dim, output\_planes, output\_rows, output\_cols, output\_depth\_dim}); } c->set\_output(0, output\_shape); return Status::OK();}
Status Conv2DBackpropInputShape(shape\_inference::InferenceContext\* c) { string data\_format\_str; if (!c->GetAttr("data\_format", &data\_format\_str).ok()) { data\_format\_str = "NHWC"; } TensorFormat data\_format; if (!FormatFromString(data\_format\_str, &data\_format)) { return errors::InvalidArgument("Invalid data format string: ", data\_format\_str); }
 // For the rest of this function, output\_grad\_\* describes out\_backprop and // input\_grad\_\* describes in\_backprop. ShapeHandle output\_grad\_shape = c->input(2); TF\_RETURN\_IF\_ERROR(c->WithRank(output\_grad\_shape, 4, &output\_grad\_shape)); ShapeHandle filter\_shape = c->input(1); TF\_RETURN\_IF\_ERROR(c->WithRank(filter\_shape, 4, &filter\_shape));
 DimensionHandle batch\_size\_dim; DimensionHandle output\_grad\_depth\_dim; gtl::InlinedVector<DimensionHandle, 2> output\_grad\_spatial\_dims(2); TF\_RETURN\_IF\_ERROR(DimensionsFromShape( output\_grad\_shape, data\_format, &batch\_size\_dim, absl::MakeSpan(output\_grad\_spatial\_dims), &output\_grad\_depth\_dim, c)); DimensionHandle unused; TF\_RETURN\_IF\_ERROR( c->Merge(output\_grad\_depth\_dim, c->Dim(filter\_shape, 3), &unused));
 ShapeHandle specified\_input\_grad\_shape; TF\_RETURN\_IF\_ERROR( c->MakeShapeFromShapeTensor(0, &specified\_input\_grad\_shape)); if (c->Rank(specified\_input\_grad\_shape) == InferenceContext::kUnknownRank) { TF\_RETURN\_IF\_ERROR(c->WithRank(specified\_input\_grad\_shape, 4, &specified\_input\_grad\_shape)); }
 // input\_grad\_depth\_dim doesn't equal c->Dim(filter\_shape,2) when the number // of groups is larger than 1. If input\_sizes is a 4D shape, we collect // input\_grad\_depth\_dim from input\_sizes; otherwise we compute it as // c->Dim(filter\_shape,2). DimensionHandle input\_grad\_depth\_dim; gtl::InlinedVector<DimensionHandle, 2> specified\_input\_grad\_spatial\_dims(2); int specified\_input\_grad\_rank = c->Rank(specified\_input\_grad\_shape); if (specified\_input\_grad\_rank == 4) { DimensionHandle specified\_batch\_size\_dim; TF\_RETURN\_IF\_ERROR(DimensionsFromShape( specified\_input\_grad\_shape, data\_format, &specified\_batch\_size\_dim, absl::MakeSpan(specified\_input\_grad\_spatial\_dims), &input\_grad\_depth\_dim, c)); TF\_RETURN\_IF\_ERROR( c->Merge(specified\_batch\_size\_dim, batch\_size\_dim, &unused)); } else if (specified\_input\_grad\_rank == 2) { specified\_input\_grad\_spatial\_dims[0] = c->Dim(specified\_input\_grad\_shape, 0); specified\_input\_grad\_spatial\_dims[1] = c->Dim(specified\_input\_grad\_shape, 1); input\_grad\_depth\_dim = c->Dim(filter\_shape, 2); } else { return errors::InvalidArgument( "Conv2DBackpropInput requires input\_sizes to contain 4 values or 2 " "values, but got: ", specified\_input\_grad\_rank); }
 ShapeHandle input\_grad\_shape; TF\_RETURN\_IF\_ERROR(ShapeFromDimensions( batch\_size\_dim, specified\_input\_grad\_spatial\_dims, input\_grad\_depth\_dim, data\_format, /\*vect\_size=\*/absl::nullopt, c, &input\_grad\_shape)); c->set\_output(0, input\_grad\_shape); return Status::OK();}
Status Conv2DBackpropFilterWithBiasShape(shape\_inference::InferenceContext\* c) { ShapeHandle input\_shape; // Fetch the data\_format attribute, which may not exist. string data\_format; Status s = c->GetAttr("data\_format", &data\_format);
 TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 4, &input\_shape)); if (s.ok() && data\_format == "NCHW") { c->set\_output(1, c->Vector(c->Dim(input\_shape, -3))); } else { c->set\_output(1, c->Vector(c->Dim(input\_shape, -1))); } ShapeHandle sh; TF\_RETURN\_IF\_ERROR(c->MakeShapeFromShapeTensor(1, &sh)); TF\_RETURN\_IF\_ERROR(c->WithRank(sh, 4, &sh)); c->set\_output(0, sh); return Status::OK();}
namespace {
Status DepthwiseConv2DNativeShapeImpl(shape\_inference::InferenceContext\* c, bool supports\_explicit\_padding) { ShapeHandle input\_shape; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 4, &input\_shape)); ShapeHandle filter\_shape; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 4, &filter\_shape));
 std::vector<int32> strides; TF\_RETURN\_IF\_ERROR(c->GetAttr("strides", &strides));
 if (strides.size() != 4) { return errors::InvalidArgument( "DepthwiseConv2D requires the stride attribute to contain 4 values, " "but got: ", strides.size()); }
 std::vector<int32> dilations; if (!c->GetAttr("dilations", &dilations).ok()) { dilations.resize(4, 1); }
 if (dilations.size() != 4) { return errors::InvalidArgument( "DepthwiseConv2D requires the dilations attribute to contain 4 values, " "but got: ", dilations.size()); }
 string data\_format\_str; Status s = c->GetAttr("data\_format", &data\_format\_str); TensorFormat data\_format; if (!s.ok() || !FormatFromString(data\_format\_str, &data\_format)) { data\_format = FORMAT\_NHWC; } int32\_t stride\_rows; int32\_t stride\_cols; int32\_t dilation\_rows;[View remainder of file in raw view](https://github.com/tensorflow/tensorflow/raw/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework/common_shape_fns.cc)

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_906b978d_20250114_181741.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2F5100e359aef5c8021f2e71c7b986420b85ce7b3d%2Ftensorflow%2Fcore%2Fframework%2Fshape_inference.cc)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2F5100e359aef5c8021f2e71c7b986420b85ce7b3d%2Ftensorflow%2Fcore%2Fframework%2Fshape_inference.cc)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  826](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Files

 5100e35
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d)
2. /[tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core)
4. /[framework](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework)
/
# shape\_inference.cc

Copy path Blame  Blame
## Latest commit

## History

[History](/tensorflow/tensorflow/commits/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework/shape_inference.cc)1322 lines (1209 loc) · 44 KB 5100e35
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d)
2. /[tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core)
4. /[framework](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework)
/
# shape\_inference.cc

Top
## File metadata and controls

* Code
* Blame

1322 lines (1209 loc) · 44 KB[Raw](https://github.com/tensorflow/tensorflow/raw/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework/shape_inference.cc)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000/\* Copyright 2016 The TensorFlow Authors. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");you may not use this file except in compliance with the License.You may obtain a copy of the License at
 http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.==============================================================================\*/#include "tensorflow/core/framework/shape\_inference.h"
#include <cstdint>
#include "tensorflow/core/framework/bounds\_check.h"#include "tensorflow/core/framework/full\_type\_util.h"#include "tensorflow/core/framework/node\_def.pb.h"#include "tensorflow/core/framework/op\_def.pb.h"#include "tensorflow/core/framework/partial\_tensor\_shape.h"#include "tensorflow/core/framework/tensor\_shape.pb.h"#include "tensorflow/core/lib/core/errors.h"#include "tensorflow/core/lib/strings/numbers.h"#include "tensorflow/core/lib/strings/scanner.h"#include "tensorflow/core/lib/strings/str\_util.h"
namespace tensorflow {namespace shape\_inference {
constexpr int32\_t InferenceContext::kUnknownRank;constexpr int64\_t InferenceContext::kUnknownDim;
// Same as above, but with PartialTensorShape instead of TensorShapeProtoInferenceContext::InferenceContext( int graph\_def\_version, const AttrSlice& attrs, const OpDef& op\_def, const std::vector<PartialTensorShape>& input\_shapes, const std::vector<const Tensor\*>& input\_tensors, const std::vector<PartialTensorShape>& input\_tensors\_as\_shapes, const std::vector< std::unique\_ptr<std::vector<std::pair<PartialTensorShape, DataType>>>>& input\_handle\_shapes\_and\_types) : graph\_def\_version\_(graph\_def\_version), attrs\_(attrs) { std::vector<ShapeHandle> input\_tensors\_as\_shape\_handles; input\_tensors\_as\_shape\_handles.reserve(input\_tensors\_as\_shapes.size()); for (const PartialTensorShape& p : input\_tensors\_as\_shapes) { ShapeHandle shape; construction\_status\_.Update(MakeShapeFromPartialTensorShape(p, &shape)); if (!construction\_status\_.ok()) { return; } input\_tensors\_as\_shape\_handles.push\_back(shape); } PreInputInit(op\_def, input\_tensors, input\_tensors\_as\_shape\_handles); if (!construction\_status\_.ok()) return; inputs\_.reserve(input\_shapes.size()); for (const PartialTensorShape& p : input\_shapes) { ShapeHandle shape; construction\_status\_.Update(MakeShapeFromPartialTensorShape(p, &shape)); if (!construction\_status\_.ok()) { return; } inputs\_.push\_back(shape); } std::vector<std::unique\_ptr<std::vector<ShapeAndType>>> handle\_data( input\_shapes.size()); for (int i = 0, end = input\_handle\_shapes\_and\_types.size(); i < end; ++i) { const auto& v = input\_handle\_shapes\_and\_types[i]; if (v == nullptr) { continue; } handle\_data[i].reset(new std::vector<ShapeAndType>(v->size())); auto& new\_v = \*handle\_data[i]; for (int j = 0, end = v->size(); j < end; ++j) { const auto& p = (\*v)[j]; construction\_status\_.Update( MakeShapeFromPartialTensorShape(p.first, &new\_v[j].shape)); if (!construction\_status\_.ok()) { return; } new\_v[j].dtype = p.second; } } PostInputInit(std::move(handle\_data));}
InferenceContext::InferenceContext( int graph\_def\_version, const AttrSlice& attrs, const OpDef& op\_def, const std::vector<ShapeHandle>& input\_shapes, const std::vector<const Tensor\*>& input\_tensors, const std::vector<ShapeHandle>& input\_tensors\_as\_shapes, std::vector<std::unique\_ptr<std::vector<ShapeAndType>>> input\_handle\_shapes\_and\_types) : graph\_def\_version\_(graph\_def\_version), attrs\_(attrs) { PreInputInit(op\_def, input\_tensors, input\_tensors\_as\_shapes); if (!construction\_status\_.ok()) return; inputs\_ = input\_shapes;
 PostInputInit(std::move(input\_handle\_shapes\_and\_types));}
InferenceContext::~InferenceContext() {}
Status InferenceContext::Run( const std::function<Status(shape\_inference::InferenceContext\* c)>& fn) { ForgetMerges(); Status s = fn(this); if (!s.ok()) { ForgetMerges(); return AttachContext(s); }#ifndef NDEBUG for (int i = 0; i < num\_outputs(); ++i) { DCHECK(output(i).IsSet()) << i << " for " << attrs\_.SummarizeNode(); }#endif // NDEBUG return s;}
Status InferenceContext::set\_output(StringPiece output\_name, const std::vector<ShapeHandle>& shapes) { auto result = output\_name\_map\_.find(output\_name); if (result == output\_name\_map\_.end()) { return errors::InvalidArgument("Unknown output name: ", output\_name); } else { const int start = result->second.first; const int size = result->second.second - start; const int shapes\_size = shapes.size(); if (size != shapes\_size) { return errors::InvalidArgument("Must have exactly ", shapes.size(), " shapes."); } for (int i = 0; i < shapes\_size; ++i) { outputs\_[i + start] = shapes[i]; } } return Status::OK();}
Status InferenceContext::input(StringPiece input\_name, std::vector<ShapeHandle>\* output) const { const auto result = input\_name\_map\_.find(input\_name); if (result == input\_name\_map\_.end()) { return errors::InvalidArgument("Unknown input name: ", input\_name); } else { output->clear(); for (int i = result->second.first; i < result->second.second; ++i) { output->push\_back(inputs\_[i]); } } return Status::OK();}
Status InferenceContext::output(StringPiece output\_name, std::vector<ShapeHandle>\* output) const { const auto result = output\_name\_map\_.find(output\_name); if (result == output\_name\_map\_.end()) { return errors::InvalidArgument("Unknown output name: ", output\_name); } else { output->clear(); for (int i = result->second.first; i < result->second.second; ++i) { output->push\_back(outputs\_[i]); } } return Status::OK();}
void InferenceContext::PreInputInit( const OpDef& op\_def, const std::vector<const Tensor\*>& input\_tensors, const std::vector<ShapeHandle>& input\_tensors\_as\_shapes) { // TODO(mdan): This is also done at graph construction. Run only here instead? const auto ret = full\_type::SpecializeType(attrs\_, op\_def); if (!ret.status().ok()) { construction\_status\_ = ret.status(); return; } ret\_types\_ = ret.ValueOrDie();
 input\_tensors\_ = input\_tensors; input\_tensors\_as\_shapes\_ = input\_tensors\_as\_shapes;
 construction\_status\_ = NameRangesForNode(attrs\_, op\_def, &input\_name\_map\_, &output\_name\_map\_); if (!construction\_status\_.ok()) return;
 int num\_outputs = 0; for (const auto& e : output\_name\_map\_) { num\_outputs = std::max(num\_outputs, e.second.second); } outputs\_.assign(num\_outputs, nullptr); output\_handle\_shapes\_and\_types\_.resize(num\_outputs);}
Status InferenceContext::ExpandOutputs(int new\_output\_size) { const int outputs\_size = outputs\_.size(); if (new\_output\_size < outputs\_size) { return errors::InvalidArgument("Trying to reduce number of outputs of op."); } outputs\_.resize(new\_output\_size, nullptr); output\_handle\_shapes\_and\_types\_.resize(new\_output\_size); return Status::OK();}
void InferenceContext::PostInputInit( std::vector<std::unique\_ptr<std::vector<ShapeAndType>>> input\_handle\_data) { int num\_inputs\_from\_node\_def = 0; for (const auto& e : input\_name\_map\_) { num\_inputs\_from\_node\_def = std::max(num\_inputs\_from\_node\_def, e.second.second); }
 // Allow passing empty shapes/dtypes to avoid changing every single test. if (input\_handle\_data.empty()) { input\_handle\_shapes\_and\_types\_.resize(inputs\_.size()); } else { if (input\_handle\_data.size() != inputs\_.size()) { construction\_status\_ = errors::InvalidArgument( "Wrong number of handle shapes passed; expected ", inputs\_.size(), " got ", input\_handle\_data.size()); return; } input\_handle\_shapes\_and\_types\_ = std::move(input\_handle\_data); } const int inputs\_size = inputs\_.size(); if (inputs\_size != num\_inputs\_from\_node\_def) { construction\_status\_ = errors::InvalidArgument( "Wrong number of inputs passed: ", inputs\_.size(), " while ", num\_inputs\_from\_node\_def, " expected based on NodeDef"); return; }
 CHECK\_LE(input\_tensors\_.size(), inputs\_.size()); input\_tensors\_.resize(inputs\_.size()); requested\_input\_tensor\_.resize(inputs\_.size()); requested\_input\_tensor\_as\_partial\_shape\_.resize(inputs\_.size());}
void InferenceContext::ShapeHandleToProto(ShapeHandle handle, TensorShapeProto\* proto) { if (!RankKnown(handle)) { proto->set\_unknown\_rank(true); return; }
 for (int32\_t i = 0; i < Rank(handle); ++i) { DimensionHandle dim = Dim(handle, i); auto\* dim\_shape = proto->add\_dim(); if (ValueKnown(dim)) { dim\_shape->set\_size(Value(dim)); } else { dim\_shape->set\_size(-1); } }}
bool InferenceContext::FullyDefined(ShapeHandle s) { if (!RankKnown(s)) return false; for (int i = 0; i < Rank(s); ++i) { if (!ValueKnown(Dim(s, i))) return false; } return true;}
DimensionHandle InferenceContext::NumElements(ShapeHandle s) { const auto rank = Rank(s); if (rank == kUnknownRank) return UnknownDim(); bool found\_unknown = false; int64\_t size = 1; for (int i = 0; i < rank; ++i) { int64\_t dim\_val = Value(Dim(s, i)); if (dim\_val == kUnknownDim) { found\_unknown = true; } else if (dim\_val == 0) { return MakeDim(0); } else { size \*= dim\_val; } } if (found\_unknown) { return UnknownDim(); } else { return MakeDim(size); }}
string InferenceContext::DebugString(ShapeHandle s) { if (RankKnown(s)) { std::vector<string> vals; for (auto d : s->dims\_) vals.push\_back(DebugString(d)); return strings::StrCat("[", absl::StrJoin(vals, ","), "]"); } else { return "?"; }}
string InferenceContext::DebugString(DimensionHandle d) { return ValueKnown(d) ? strings::StrCat(Value(d)) : "?";}
string InferenceContext::DebugString() const { return strings::StrCat("InferenceContext for node: ", attrs\_.SummarizeNode());}
string InferenceContext::DebugString(const ShapeAndType& shape\_and\_type) { return strings::StrCat(DebugString(shape\_and\_type.shape), ":", DataTypeString(shape\_and\_type.dtype));}
string InferenceContext::DebugString( gtl::ArraySlice<ShapeAndType> shape\_and\_types) { std::vector<string> pieces; for (const ShapeAndType& s : shape\_and\_types) { pieces.push\_back(DebugString(s)); } return strings::StrCat("[", absl::StrJoin(pieces, ","), "]");}
Status InferenceContext::WithRank(ShapeHandle shape, int64\_t rank, ShapeHandle\* out) { if (rank > kint32max) { return errors::InvalidArgument("Rank cannot exceed kint32max"); } const int32\_t existing = Rank(shape); if (existing == rank) { \*out = shape; return Status::OK(); } if (existing == kUnknownRank) { std::vector<DimensionHandle> dims; dims.reserve(rank); for (int i = 0; i < rank; ++i) { dims.push\_back(UnknownDim()); } ShapeHandle shp = shape\_manager\_.MakeShape(dims); return Merge(shape, shp, out); } \*out = nullptr;
 return errors::InvalidArgument("Shape must be rank ", rank, " but is rank ", existing);}
Status InferenceContext::WithRankAtLeast(ShapeHandle shape, int64\_t rank, ShapeHandle\* out) { if (rank > kint32max) { return errors::InvalidArgument("Rank cannot exceed kint32max"); } const int32\_t existing = Rank(shape); if (existing >= rank || existing == kUnknownRank) { \*out = shape; return Status::OK(); } \*out = nullptr; return errors::InvalidArgument("Shape must be at least rank ", rank, " but is rank ", existing);}
Status InferenceContext::WithRankAtMost(ShapeHandle shape, int64\_t rank, ShapeHandle\* out) { if (rank > kint32max) { return errors::InvalidArgument("Rank cannot exceed kint32max"); } const int32\_t existing = Rank(shape); if (existing <= rank || existing == kUnknownRank) { \*out = shape; return Status::OK(); } \*out = nullptr; return errors::InvalidArgument("Shape must be at most rank ", rank, " but is rank ", existing);}
Status InferenceContext::WithValue(DimensionHandle dim, int64\_t value, DimensionHandle\* out) { const int64\_t existing = Value(dim); if (existing == value) { \*out = dim; return Status::OK(); } if (existing == kUnknownDim) { DimensionHandle d = MakeDim(value); return Merge(dim, d, out); } \*out = nullptr; return errors::InvalidArgument("Dimension must be ", value, " but is ", existing);}
void InferenceContext::Relax(DimensionHandle d\_old, DimensionHandle d\_new, DimensionHandle\* out) { if (d\_old.SameHandle(d\_new)) { \*out = d\_old; } else if (!ValueKnown(d\_old) && !ValueKnown(d\_new)) { // The node will be fed by the dimension d\_new instead of d\_old: any // equality assertion between d\_old and other input dimension on this node // may not be true anymore, so forget them all. ForgetMerges(); // Return the new shape handle to force the relaxation to propagate to the // fanout of the context. \*out = d\_new; } else if (!ValueKnown(d\_new)) { ForgetMerges(); \*out = d\_new; } else if (Value(d\_old) == Value(d\_new)) { // Return the old shape handle. This will stop the relaxation in the fanout // of the context. \*out = d\_old; } else { // Return a new handle that encodes a different unknown dim. ForgetMerges(); \*out = UnknownDim(); }}
Status InferenceContext::Merge(DimensionHandle d0, DimensionHandle d1, DimensionHandle\* out) { if (d0.SameHandle(d1)) { \*out = d0; return Status::OK(); } else if (!ValueKnown(d1)) { \*out = d0; merged\_dims\_.emplace\_back(d0, d1); return Status::OK(); } else if (!ValueKnown(d0)) { \*out = d1; merged\_dims\_.emplace\_back(d0, d1); return Status::OK(); } else if (Value(d0) == Value(d1)) { \*out = d0; return Status::OK(); } else { \*out = nullptr; return errors::InvalidArgument("Dimensions must be equal, but are ", Value(d0), " and ", Value(d1)); }}
Status InferenceContext::MergePrefix(ShapeHandle s, ShapeHandle prefix, ShapeHandle\* s\_out, ShapeHandle\* prefix\_out) { \*s\_out = \*prefix\_out = nullptr; if (!RankKnown(prefix) || !RankKnown(s)) { \*s\_out = s; \*prefix\_out = prefix; return Status::OK(); } const int32\_t rank = Rank(prefix); TF\_RETURN\_IF\_ERROR(WithRankAtLeast(s, rank, &s));
 // Merge the prefix dims and create the new output shapes. const int32\_t rank\_s = Rank(s); std::vector<DimensionHandle> dims; dims.reserve(std::max(rank, rank\_s)); dims.resize(rank); for (int i = 0; i < rank; ++i) { TF\_RETURN\_IF\_ERROR(Merge(Dim(s, i), Dim(prefix, i), &dims[i])); } \*prefix\_out = MakeShape(dims); for (int i = rank; i < rank\_s; ++i) dims.push\_back(Dim(s, i)); \*s\_out = MakeShape(dims); return Status::OK();}
void InferenceContext::Relax(ShapeHandle s\_old, ShapeHandle s\_new, ShapeHandle\* out) { if (s\_old.SameHandle(s\_new)) { \*out = s\_old; return; } else if (!RankKnown(s\_new) || !s\_old.IsSet()) { ForgetMerges(); \*out = s\_new; return; }
 const int32\_t rank = Rank(s\_old); if (rank != Rank(s\_new)) { ForgetMerges(); \*out = UnknownShape(); return; }
 bool return\_s\_old = true; for (int i = 0; i < rank; ++i) { auto d0 = Dim(s\_old, i); auto d1 = Dim(s\_new, i); if (d0.SameHandle(d1)) continue;
 auto v0 = Value(d0); auto v1 = Value(d1); if (v0 == kUnknownDim || v1 == kUnknownDim || v0 != v1) { return\_s\_old = false; break; } } if (return\_s\_old) { \*out = s\_old; return; }
 // Relax dims. std::vector<DimensionHandle> dims(rank); for (int i = 0; i < rank; ++i) { Relax(Dim(s\_old, i), Dim(s\_new, i), &dims[i]); } ForgetMerges(); \*out = MakeShape(dims);}
Status InferenceContext::Merge(ShapeHandle s0, ShapeHandle s1, ShapeHandle\* out) { if (s0.SameHandle(s1)) { \*out = s0; return Status::OK(); } else if (!RankKnown(s1)) { \*out = s0; merged\_shapes\_.emplace\_back(s0, s1); return Status::OK(); } else if (!RankKnown(s0)) { \*out = s1; merged\_shapes\_.emplace\_back(s0, s1); return Status::OK(); }
 const int32\_t rank = Rank(s0); if (rank != Rank(s1)) { \*out = nullptr; return errors::InvalidArgument("Shapes must be equal rank, but are ", rank, " and ", Rank(s1)); }
 bool return\_s0 = true; bool return\_s1 = true; for (int i = 0; i < rank; ++i) { auto d0 = Dim(s0, i); auto d1 = Dim(s1, i); if (d0.SameHandle(d1)) continue;
 auto v0 = Value(d0); auto v1 = Value(d1); if (v0 == kUnknownDim) { if (v1 != kUnknownDim) { return\_s0 = false; } } else if (v1 == kUnknownDim) { return\_s1 = false; } else if (v0 != v1) { \*out = nullptr; return errors::InvalidArgument( "Dimension ", i, " in both shapes must be equal, but are ", Value(d0), " and ", Value(d1), ". Shapes are ", DebugString(s0), " and ", DebugString(s1), "."); } }
 merged\_shapes\_.emplace\_back(s0, s1);
 if (return\_s0 || return\_s1) { \*out = return\_s0 ? s0 : s1; return Status::OK(); }
 // Merge dims. std::vector<DimensionHandle> dims(rank, nullptr); for (int i = 0; i < rank; ++i) { // Invariant for merge was checked earlier, so CHECK is ok. TF\_CHECK\_OK(Merge(Dim(s0, i), Dim(s1, i), &dims[i])); }
 Status s = ReturnCreatedShape(dims, out); if (s.ok()) { // Merge the new shape with s0. Since s0 and s1 are merged, this implies // that s1 and out are also merged. merged\_shapes\_.emplace\_back(s0, \*out); } return s;}
Status InferenceContext::Subshape(ShapeHandle s, int64\_t start, ShapeHandle\* out) { return Subshape(s, start, std::numeric\_limits<int64\_t>::max() /\* end \*/, out);}
Status InferenceContext::Subshape(ShapeHandle s, int64\_t start, int64\_t end, ShapeHandle\* out) { return Subshape(s, start, end, 1 /\* stride \*/, out);}
Status InferenceContext::Subshape(ShapeHandle s, int64\_t start, int64\_t end, int64\_t stride, ShapeHandle\* out) { int64\_t start\_in = start; int64\_t end\_in = end;
 const int32\_t rank = Rank(s); if (start == 0 && stride == 1 && ((RankKnown(s) && end >= rank) || end == std::numeric\_limits<int64\_t>::max())) { \*out = s; return Status::OK(); } if (!RankKnown(s)) { return ReturnUnknownShape(out); }
 if (start > rank) start = rank; if (end > rank) end = rank;
 if (stride < 0 && start == rank) --start;
 if (start < 0) { start = rank + start; if (start < 0) { \*out = nullptr; return errors::InvalidArgument("Subshape start out of bounds: ", start\_in, ", for shape with rank ", rank); } }
 if (end < 0) { end = rank + end; if (end < 0) { \*out = nullptr; return errors::InvalidArgument("Subshape end out of bounds: ", end\_in, ", for shape with rank ", rank); } } if (stride > 0 && start > end) { \*out = nullptr; return errors::InvalidArgument( "Subshape must have computed start <= end, but is ", start, " and ", end, " (computed from start ", start\_in, " and end ", end\_in, " over shape with rank ", rank, ")"); } else if (stride < 0 && start < end) { \*out = nullptr; return errors::InvalidArgument( "Subshape must have computed start >= end since stride is negative, " "but is ", start, " and ", end, " (computed from start ", start\_in, " and end ", end\_in, " over shape with rank ", rank, " and stride", stride, ")"); }
 std::vector<DimensionHandle> dims; for (int i = start; stride > 0 ? i < end : i > end; i += stride) { dims.push\_back(Dim(s, i)); } return ReturnCreatedShape(dims, out);}
Status InferenceContext::Concatenate(ShapeHandle s1, ShapeHandle s2, ShapeHandle\* out) { if (!RankKnown(s1) || !RankKnown(s2)) { return ReturnUnknownShape(out); } const int32\_t s1\_rank = Rank(s1); const int32\_t s2\_rank = Rank(s2); const int32\_t rank = s1\_rank + s2\_rank; std::vector<DimensionHandle> dims; dims.reserve(rank); for (int i = 0; i < s1\_rank; ++i) dims.push\_back(Dim(s1, i)); for (int i = 0; i < s2\_rank; ++i) dims.push\_back(Dim(s2, i)); return ReturnCreatedShape(dims, out);}
Status InferenceContext::ReplaceDim(ShapeHandle s, int64\_t dim\_index\_in, DimensionHandle new\_dim, ShapeHandle\* out) { if (!RankKnown(s)) { return ReturnUnknownShape(out); } int64\_t dim\_index = dim\_index\_in; if (dim\_index < 0) { dim\_index = s->dims\_.size() + dim\_index; } if (!FastBoundsCheck(dim\_index, s->dims\_.size())) { \*out = nullptr; return errors::InvalidArgument("Out of range dim\_index ", dim\_index\_in, " for shape with ", s->dims\_.size(), " dimensions"); } std::vector<DimensionHandle> dims(s->dims\_); dims[dim\_index] = new\_dim; return ReturnCreatedShape(dims, out);}
ShapeHandle InferenceContext::MakeShape( const std::vector<DimensionHandle>& dims) { return shape\_manager\_.MakeShape(dims);}
ShapeHandle InferenceContext::MakeShape( std::initializer\_list<DimensionOrConstant> dims) { std::vector<DimensionHandle> dims\_actual; dims\_actual.reserve(dims.size()); for (const DimensionOrConstant& d : dims) { dims\_actual.push\_back(MakeDim(d)); }
 return shape\_manager\_.MakeShape(dims\_actual);}
ShapeHandle InferenceContext::UnknownShape() { return shape\_manager\_.UnknownShape();}
ShapeHandle InferenceContext::UnknownShapeOfRank(int64\_t rank) { CHECK\_LE(rank, kint32max) << "rank must be less than kint32max"; if (rank == kUnknownRank) { return UnknownShape(); } CHECK\_GE(rank, 0) << "rank must not be negative"; std::vector<DimensionHandle> dims(rank); for (int32\_t i = 0; i < rank; ++i) { dims[i] = UnknownDim(); } return MakeShape(dims);}
ShapeHandle InferenceContext::Scalar() { return MakeShape({}); }
ShapeHandle InferenceContext::Vector(DimensionOrConstant dim) { return MakeShape({dim});}
ShapeHandle InferenceContext::Matrix(DimensionOrConstant dim1, DimensionOrConstant dim2) { return MakeShape({dim1, dim2});}
Status InferenceContext::MakeShapeFromShapeTensorTreatScalarAsUnknownShape( int input\_idx, ShapeHandle\* out) { ShapeHandle input\_shape; TF\_RETURN\_IF\_ERROR(WithRankAtMost(input(input\_idx), 1, &input\_shape));
 request\_input\_tensor\_as\_partial\_shape(input\_idx); const int input\_tensors\_as\_shapes\_size = input\_tensors\_as\_shapes\_.size(); if (input\_idx < input\_tensors\_as\_shapes\_size && input\_tensors\_as\_shapes\_[input\_idx].IsSet() && RankKnown(input\_tensors\_as\_shapes\_[input\_idx])) { \*out = input\_tensors\_as\_shapes\_[input\_idx]; return Status::OK(); }
 return InternalMakeShapeFromTensor( true /\* treat\_unknown\_scalar\_tensor\_as\_unknown\_shape \*/, input\_tensor(input\_idx), input\_shape, out);}
Status InferenceContext::MakeShapeFromShapeTensor(int input\_idx, ShapeHandle\* out) { ShapeHandle input\_shape; TF\_RETURN\_IF\_ERROR(WithRank(input(input\_idx), 1, &input\_shape));
 request\_input\_tensor\_as\_partial\_shape(input\_idx); const int input\_tensors\_as\_shapes\_size = input\_tensors\_as\_shapes\_.size(); if (input\_idx < input\_tensors\_as\_shapes\_size && input\_tensors\_as\_shapes\_[input\_idx].IsSet() && RankKnown(input\_tensors\_as\_shapes\_[input\_idx])) { \*out = input\_tensors\_as\_shapes\_[input\_idx]; return Status::OK(); }
 return InternalMakeShapeFromTensor( false /\* treat\_unknown\_scalar\_tensor\_as\_unknown\_shape \*/, input\_tensor(input\_idx), input\_shape, out);}
Status InferenceContext::MakeShapeFromTensor(const Tensor\* t, ShapeHandle tensor\_shape, ShapeHandle\* out) { return InternalMakeShapeFromTensor( false /\* treat\_unknown\_scalar\_tensor\_as\_unknown\_shape \*/, t, tensor\_shape, out);}
Status InferenceContext::InternalMakeShapeFromTensor( bool treat\_unknown\_scalar\_tensor\_as\_unknown\_shape, const Tensor\* t, ShapeHandle tensor\_shape, ShapeHandle\* out) { // Only callers who have set if (!treat\_unknown\_scalar\_tensor\_as\_unknown\_shape) { TF\_RETURN\_IF\_ERROR(WithRank(tensor\_shape, 1, &tensor\_shape)); } if (t == nullptr) { // This is guarded by the check above. if (Rank(tensor\_shape) == 0) { return ReturnUnknownShape(out); } // Shape tensor is not known, but if the shape of the shape tensor is then // the right number of unknown dims can be created. DimensionHandle shape\_dim = Dim(tensor\_shape, 0); if (!ValueKnown(shape\_dim)) { return ReturnUnknownShape(out); } const auto num\_dims = Value(shape\_dim); // TODO(mihaimaruseac): Should be `TensorShape::MaxDimensions()` as we are // not able to materialize shapes with more than this number of dimensions // but then shape inference would fail for operations such as // `tf.range`/`tf.ones`, etc. where the shape is not really materialized, // only used during the inference. Hence, just prevent doing a `reserve` // with a very large argument. const int64\_t max\_dimensions = 1 << 20; if (num\_dims >= max\_dimensions) { return errors::Internal( "Cannot create a tensor with ", num\_dims, " dimensions, as these would be more than maximum of ", max\_dimensions); } std::vector<DimensionHandle> dims; dims.reserve(num\_dims); for (int i = 0; i < num\_dims; i++) dims.push\_back(UnknownDim()); return ReturnCreatedShape(dims, out); }
 if (t->shape().dims() == 0) { if (t->dtype() == DataType::DT\_INT32) { auto flat\_t = t->scalar<int32>(); if (flat\_t() != -1) { \*out = nullptr; return errors::InvalidArgument( "Input tensor must be rank 1, or if its rank 0 it must have value " "-1 " "(representing an unknown shape). Saw value: ", flat\_t()); } return ReturnUnknownShape(out); } else if (t->dtype() == DataType::DT\_INT64) { auto flat\_t = t->scalar<int64\_t>(); if (flat\_t() != -1) { \*out = nullptr; return errors::InvalidArgument( "Input tensor must be rank 1, or if its rank 0 it must have value " "-1 " "(representing an unknown shape). Saw value: ", flat\_t()); } return ReturnUnknownShape(out); } else { \*out = nullptr; return errors::InvalidArgument( "Input tensor must be int32 or int64, but was ", DataTypeString(t->dtype())); } }
 if (t->shape().dims() != 1) { \*out = nullptr; return errors::InvalidArgument( "Input tensor must be rank 1, but was rank ", t->shape().dims(), ".", ((t->shape().dims() == 0) ? "If it is rank 0 rank 0 it must have statically known value -1 " "(representing an unknown shape). " : " "), "Saw tensor shape ", t->shape().DebugString()); } std::vector<DimensionHandle> dims; if (t->dtype() == DataType::DT\_INT32) { auto flat\_t = t->flat<int32>(); for (int i = 0; i < flat\_t.size(); ++i) { const int32\_t val = flat\_t(i); if (val < -1) { return errors::InvalidArgument( "Invalid value in tensor used for shape: ", val); } // -1 will become an unknown dim. dims.push\_back(MakeDim(val)); } } else if (t->dtype() == DataType::DT\_INT64) { auto flat\_t = t->flat<int64\_t>(); for (int i = 0; i < flat\_t.size(); ++i) { const int64\_t val = flat\_t(i); if (val < -1) { return errors::InvalidArgument( "Invalid value in tensor used for shape: ", val); } // -1 will become an unknown dim. dims.push\_back(MakeDim(val)); } } else { \*out = nullptr; return errors::InvalidArgument( "Input tensor must be int32 or int64, but was ", DataTypeString(t->dtype())); }
 return ReturnCreatedShape(dims, out);}
Status InferenceContext::MakeShapeFromPartialTensorShape( const PartialTensorShape& partial\_shape, ShapeHandle\* out) { \*out = nullptr; if (partial\_shape.dims() == -1) { return ReturnUnknownShape(out); } const int num\_dims = partial\_shape.dims(); std::vector<DimensionHandle> dims(num\_dims); for (int i = 0; i < num\_dims; ++i) { // -1 is unknown in PartialTensorShape and in InferenceContext, so this size // can be passed directly to MakeDim. dims[i] = MakeDim(partial\_shape.dim\_size(i)); } return ReturnCreatedShape(dims, out);}
Status InferenceContext::MakeShapeFromTensorShape(const TensorShape& shape, ShapeHandle\* out) { return MakeShapeFromPartialTensorShape(PartialTensorShape(shape.dim\_sizes()), out);}
Status InferenceContext::MakeShapeFromShapeProto(const TensorShapeProto& proto, ShapeHandle\* out) { \*out = nullptr; TF\_RETURN\_IF\_ERROR(PartialTensorShape::IsValidShape(proto)); PartialTensorShape partial\_shape(proto); return MakeShapeFromPartialTensorShape(partial\_shape, out);}
Status InferenceContext::GetScalarFromTensor(const Tensor\* t, int64\_t\* val) { // Caller must ensure that <t> is not NULL. const int rank = t->dims(); if (rank != 0) { return errors::InvalidArgument("Input must be scalar but has rank ", rank); }
 if (t->dtype() == DataType::DT\_INT32) { \*val = t->scalar<int32>()(); return Status::OK(); } else if (t->dtype() == DataType::DT\_INT64) { \*val = t->scalar<int64\_t>()(); return Status::OK(); } else { return errors::InvalidArgument("Scalar input must be int32 or int64."); }}
Status InferenceContext::GetScalarFromTensor(const Tensor\* t, int64\_t idx, int64\_t\* val) { // Caller must ensure that <t> is not NULL. const int rank = t->dims(); if (rank != 1) { return errors::InvalidArgument("Input must be 1D but has rank ", rank); }
 if (t->dtype() == DataType::DT\_INT32) { auto flat\_t = t->flat<int32>(); if (idx < 0 || idx >= flat\_t.size()) { return errors::InvalidArgument("Invalid index ", idx, " for Tensor of size ", flat\_t.size()); } \*val = flat\_t(idx); return Status::OK(); } else if (t->dtype() == DataType::DT\_INT64) { auto flat\_t = t->flat<int64\_t>(); if (idx < 0 || idx >= flat\_t.size()) { return errors::InvalidArgument("Invalid index ", idx, " for Tensor of size ", flat\_t.size()); } \*val = flat\_t(idx); return Status::OK(); } else { return errors::InvalidArgument("Tensor input must be int32 or int64."); }}
// Returns a new dimension whose value is given by a scalar input tensor.Status InferenceContext::MakeDimForScalarInput(int idx, DimensionHandle\* out) { int64\_t val; const Tensor\* t = input\_tensor(idx); if (t == nullptr) { \*out = UnknownDim(); return Status::OK(); } TF\_RETURN\_IF\_ERROR(GetScalarFromTensor(t, &val)); if (val < 0) { return errors::InvalidArgument("Dimension size, given by scalar input ", idx, ", must be non-negative but is ", val); } \*out = MakeDim(val); return Status::OK();}
Status InferenceContext::MakeDimForScalarInputWithNegativeIndexing( int idx, int input\_rank, DimensionHandle\* out) { int64\_t val; const Tensor\* t = input\_tensor(idx); if (t == nullptr) { \*out = UnknownDim(); return Status::OK(); } TF\_RETURN\_IF\_ERROR(GetScalarFromTensor(t, &val)); if (val < 0) { if (input\_rank < 0) { \*out = UnknownDim(); return Status::OK(); } else if (val + input\_rank < 0) { return errors::InvalidArgument("Dimension size, given by scalar input ", val, " must be in range [-", input\_rank, ", ", input\_rank, ")"); } else { val += input\_rank; }[View remainder of file in raw view](https://github.com/tensorflow/tensorflow/raw/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework/shape_inference.cc)

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.


