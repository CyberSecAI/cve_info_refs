=== Content from github.com_1ec53af2_20250114_190400.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2F5100e359aef5c8021f2e71c7b986420b85ce7b3d%2Ftensorflow%2Flite%2Fkernels%2Fdepthwise_conv.cc)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2F5100e359aef5c8021f2e71c7b986420b85ce7b3d%2Ftensorflow%2Flite%2Fkernels%2Fdepthwise_conv.cc)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  827](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Files

 5100e35
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d)
2. /[tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow)
3. /[lite](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite)
4. /[kernels](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite/kernels)
/
# depthwise\_conv.cc

Copy path Blame  Blame
## Latest commit

## History

[History](/tensorflow/tensorflow/commits/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite/kernels/depthwise_conv.cc)648 lines (584 loc) · 27.7 KB 5100e35
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d)
2. /[tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow)
3. /[lite](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite)
4. /[kernels](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite/kernels)
/
# depthwise\_conv.cc

Top
## File metadata and controls

* Code
* Blame

648 lines (584 loc) · 27.7 KB[Raw](https://github.com/tensorflow/tensorflow/raw/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite/kernels/depthwise_conv.cc)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648/\* Copyright 2017 The TensorFlow Authors. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");you may not use this file except in compliance with the License.You may obtain a copy of the License at
 http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.==============================================================================\*/
#include "tensorflow/lite/kernels/internal/optimized/integer\_ops/depthwise\_conv.h"
#include <stddef.h>#include <stdint.h>
#include <vector>
#include "tensorflow/lite/c/builtin\_op\_data.h"#include "tensorflow/lite/c/common.h"#include "tensorflow/lite/kernels/cpu\_backend\_context.h"#include "tensorflow/lite/kernels/internal/compatibility.h"#include "tensorflow/lite/kernels/internal/optimized/cpu\_check.h"#include "tensorflow/lite/kernels/internal/optimized/depthwiseconv\_multithread.h"#include "tensorflow/lite/kernels/internal/optimized/integer\_ops/depthwise\_conv\_hybrid.h"#include "tensorflow/lite/kernels/internal/optimized/neon\_check.h"#include "tensorflow/lite/kernels/internal/quantization\_util.h"#include "tensorflow/lite/kernels/internal/reference/depthwiseconv\_float.h"#include "tensorflow/lite/kernels/internal/reference/depthwiseconv\_uint8.h"#include "tensorflow/lite/kernels/internal/reference/integer\_ops/depthwise\_conv.h"#include "tensorflow/lite/kernels/internal/tensor.h"#include "tensorflow/lite/kernels/internal/tensor\_ctypes.h"#include "tensorflow/lite/kernels/internal/tensor\_utils.h"#include "tensorflow/lite/kernels/internal/types.h"#include "tensorflow/lite/kernels/kernel\_util.h"#include "tensorflow/lite/kernels/padding.h"
namespace tflite {namespace ops {namespace builtin {namespace depthwise\_conv {
constexpr int kInputTensor = 0;constexpr int kFilterTensor = 1;constexpr int kBiasTensor = 2;constexpr int kOutputTensor = 0;
// This file has three implementation of DepthwiseConv.enum KernelType { kReference, kGenericOptimized, // Neon-free kNeonOptimized,};
const int kTensorNotAllocated = -1;
struct OpData { TfLitePaddingValues padding; // The scaling factor from input to output (aka the 'real multiplier') can // be represented as a fixed point multiplier plus a left shift. int32\_t output\_multiplier; int output\_shift; // The range of the fused activation layer. For example for kNone and // uint8\_t these would be 0 and 255. int32\_t output\_activation\_min; int32\_t output\_activation\_max;
 // Per channel output multiplier and shift. std::vector<int32\_t> per\_channel\_output\_multiplier; std::vector<int> per\_channel\_output\_shift;
 // Hybrid per channel temporary tensors. int input\_quantized\_id = kTensorNotAllocated; int scaling\_factors\_id = kTensorNotAllocated; int input\_offset\_id = kTensorNotAllocated; int32\_t input\_quantized\_index; int32\_t scaling\_factors\_index; int32\_t input\_offset\_index;};
void\* Init(TfLiteContext\* context, const char\* buffer, size\_t length) { // This is a builtin op, so we don't use the contents in 'buffer', if any. // Instead, we allocate a new object to carry information from Prepare() to // Eval(). return new OpData;}
void Free(TfLiteContext\* context, void\* buffer) { delete reinterpret\_cast<OpData\*>(buffer);}
TfLiteStatus Prepare(TfLiteContext\* context, TfLiteNode\* node) { auto\* params = reinterpret\_cast<TfLiteDepthwiseConvParams\*>(node->builtin\_data); OpData\* data = reinterpret\_cast<OpData\*>(node->user\_data);
 bool has\_bias = NumInputs(node) == 3;
 TF\_LITE\_ENSURE(context, has\_bias || NumInputs(node) == 2); const TfLiteTensor\* input; TF\_LITE\_ENSURE\_OK(context, GetInputSafe(context, node, kInputTensor, &input)); const TfLiteTensor\* filter; TF\_LITE\_ENSURE\_OK(context, GetInputSafe(context, node, kFilterTensor, &filter)); const TfLiteTensor\* bias = nullptr;
 TF\_LITE\_ENSURE\_EQ(context, NumOutputs(node), 1); TfLiteTensor\* output; TF\_LITE\_ENSURE\_OK(context, GetOutputSafe(context, node, kOutputTensor, &output));
 TF\_LITE\_ENSURE\_EQ(context, NumDimensions(input), 4); TF\_LITE\_ENSURE\_EQ(context, NumDimensions(filter), 4);
 const TfLiteType data\_type = input->type;
 const TfLiteType filter\_type = filter->type; const bool is\_hybrid = data\_type == kTfLiteFloat32 && filter\_type == kTfLiteInt8; TF\_LITE\_ENSURE(context, data\_type == kTfLiteFloat32 || data\_type == kTfLiteUInt8 || data\_type == kTfLiteInt8 || data\_type == kTfLiteInt16); TF\_LITE\_ENSURE\_TYPES\_EQ(context, output->type, data\_type); if (!is\_hybrid) { TF\_LITE\_ENSURE(context, filter->type == data\_type || data\_type == kTfLiteInt16); }
 if (data\_type == kTfLiteInt16) { TF\_LITE\_ENSURE\_EQ(context, input->params.zero\_point, 0); TF\_LITE\_ENSURE\_EQ(context, output->params.zero\_point, 0); }
 // Filter in DepthwiseConv is expected to be [1, H, W, O]. TF\_LITE\_ENSURE\_EQ(context, SizeOfDimension(filter, 0), 1);
 if (has\_bias) { TF\_LITE\_ENSURE\_OK(context, GetInputSafe(context, node, kBiasTensor, &bias)); if (data\_type == kTfLiteUInt8 || data\_type == kTfLiteInt8) { TF\_LITE\_ENSURE\_TYPES\_EQ(context, bias->type, kTfLiteInt32); TF\_LITE\_ENSURE\_EQ(context, bias->params.zero\_point, 0); } else if (data\_type == kTfLiteInt16) { TF\_LITE\_ENSURE\_TYPES\_EQ(context, bias->type, kTfLiteInt64); TF\_LITE\_ENSURE\_EQ(context, bias->params.zero\_point, 0); } else { TF\_LITE\_ENSURE\_TYPES\_EQ(context, bias->type, data\_type); } TF\_LITE\_ENSURE\_EQ(context, NumDimensions(bias), 1); TF\_LITE\_ENSURE\_EQ(context, SizeOfDimension(filter, 3), SizeOfDimension(bias, 0)); }
 int channels\_out = SizeOfDimension(filter, 3); int width = SizeOfDimension(input, 2); int height = SizeOfDimension(input, 1); int filter\_width = SizeOfDimension(filter, 2); int filter\_height = SizeOfDimension(filter, 1); int batches = SizeOfDimension(input, 0);
 // Matching GetWindowedOutputSize in TensorFlow. auto padding = params->padding; int out\_width, out\_height;
 data->padding = ComputePaddingHeightWidth( params->stride\_height, params->stride\_width, params->dilation\_height\_factor, params->dilation\_width\_factor, height, width, filter\_height, filter\_width, padding, &out\_height, &out\_width);
 // Note that quantized inference requires that all tensors have their // parameters set. This is usually done during quantized training or // calibration. if (data\_type != kTfLiteFloat32) { TF\_LITE\_ENSURE\_EQ(context, filter->quantization.type, kTfLiteAffineQuantization); TF\_LITE\_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization); const auto\* affine\_quantization = reinterpret\_cast<TfLiteAffineQuantization\*>( filter->quantization.params); TF\_LITE\_ENSURE(context, affine\_quantization); TF\_LITE\_ENSURE(context, affine\_quantization->scale); TF\_LITE\_ENSURE(context, (affine\_quantization->scale->size == 1 || affine\_quantization->scale->size == channels\_out));
 data->per\_channel\_output\_multiplier.resize(channels\_out); data->per\_channel\_output\_shift.resize(channels\_out); TF\_LITE\_ENSURE\_STATUS(tflite::PopulateConvolutionQuantizationParams( context, input, filter, bias, output, params->activation, &data->output\_multiplier, &data->output\_shift, &data->output\_activation\_min, &data->output\_activation\_max, data->per\_channel\_output\_multiplier.data(), data->per\_channel\_output\_shift.data(), channels\_out)); }
 if (is\_hybrid) { TF\_LITE\_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization); const auto\* affine\_quantization = reinterpret\_cast<TfLiteAffineQuantization\*>( filter->quantization.params); TF\_LITE\_ENSURE(context, affine\_quantization); TF\_LITE\_ENSURE(context, affine\_quantization->scale); TF\_LITE\_ENSURE\_EQ( context, affine\_quantization->scale->size, filter->dims->data[affine\_quantization->quantized\_dimension]);
 int temporaries\_count = 0; data->input\_quantized\_index = temporaries\_count; if (data->input\_quantized\_id == kTensorNotAllocated) { TF\_LITE\_ENSURE\_OK( context, context->AddTensors(context, 1, &data->input\_quantized\_id)); } ++temporaries\_count; data->scaling\_factors\_index = temporaries\_count; if (data->scaling\_factors\_id == kTensorNotAllocated) { TF\_LITE\_ENSURE\_OK( context, context->AddTensors(context, 1, &data->scaling\_factors\_id)); } ++temporaries\_count; data->input\_offset\_index = temporaries\_count; if (data->input\_offset\_id == kTensorNotAllocated) { TF\_LITE\_ENSURE\_OK( context, context->AddTensors(context, 1, &data->input\_offset\_id)); } ++temporaries\_count;
 TfLiteIntArrayFree(node->temporaries); node->temporaries = TfLiteIntArrayCreate(temporaries\_count);
 node->temporaries->data[data->input\_quantized\_index] = data->input\_quantized\_id; TfLiteTensor\* input\_quantized; TF\_LITE\_ENSURE\_OK( context, GetTemporarySafe(context, node, data->input\_quantized\_index, &input\_quantized)); input\_quantized->type = kTfLiteInt8; input\_quantized->allocation\_type = kTfLiteArenaRw; if (!TfLiteIntArrayEqual(input\_quantized->dims, input->dims)) { TfLiteIntArray\* input\_quantized\_size = TfLiteIntArrayCopy(input->dims); TF\_LITE\_ENSURE\_OK(context, context->ResizeTensor(context, input\_quantized, input\_quantized\_size)); } node->temporaries->data[data->scaling\_factors\_index] = data->scaling\_factors\_id; TfLiteTensor\* scaling\_factors; TF\_LITE\_ENSURE\_OK( context, GetTemporarySafe(context, node, data->scaling\_factors\_index, &scaling\_factors)); scaling\_factors->type = kTfLiteFloat32; scaling\_factors->allocation\_type = kTfLiteArenaRw; const int batch\_size = SizeOfDimension(input, 0); int scaling\_dims[1] = {batch\_size}; if (!TfLiteIntArrayEqualsArray(scaling\_factors->dims, 1, scaling\_dims)) { TfLiteIntArray\* scaling\_factors\_size = TfLiteIntArrayCreate(1); scaling\_factors\_size->data[0] = batch\_size; TF\_LITE\_ENSURE\_OK(context, context->ResizeTensor(context, scaling\_factors, scaling\_factors\_size)); } node->temporaries->data[data->input\_offset\_index] = data->input\_offset\_id; TfLiteTensor\* input\_offsets; TF\_LITE\_ENSURE\_OK(context, GetTemporarySafe(context, node, data->input\_offset\_index, &input\_offsets)); input\_offsets->type = kTfLiteInt32; input\_offsets->allocation\_type = kTfLiteArenaRw; if (!TfLiteIntArrayEqualsArray(input\_offsets->dims, 1, scaling\_dims)) { TfLiteIntArray\* input\_offsets\_size = TfLiteIntArrayCreate(1); input\_offsets\_size->data[0] = batch\_size; TF\_LITE\_ENSURE\_OK(context, context->ResizeTensor(context, input\_offsets, input\_offsets\_size)); } }
 TfLiteIntArray\* outputSize = TfLiteIntArrayCreate(4); outputSize->data[0] = batches; outputSize->data[1] = out\_height; outputSize->data[2] = out\_width; outputSize->data[3] = channels\_out; return context->ResizeTensor(context, output, outputSize);}
TfLiteStatus ComputeDepthMultiplier(TfLiteContext\* context, const TfLiteTensor\* input, const TfLiteTensor\* filter, int16\* depth\_multiplier) { int num\_filter\_channels = SizeOfDimension(filter, 3); int num\_input\_channels = SizeOfDimension(input, 3); TF\_LITE\_ENSURE(context, num\_input\_channels != 0); TF\_LITE\_ENSURE\_EQ(context, num\_filter\_channels % num\_input\_channels, 0); \*depth\_multiplier = num\_filter\_channels / num\_input\_channels; return kTfLiteOk;}
template <KernelType kernel\_type>TfLiteStatus EvalFloat(TfLiteContext\* context, TfLiteNode\* node, TfLiteDepthwiseConvParams\* params, OpData\* data, const TfLiteTensor\* input, const TfLiteTensor\* filter, const TfLiteTensor\* bias, TfLiteTensor\* output) { float output\_activation\_min, output\_activation\_max; CalculateActivationRange(params->activation, &output\_activation\_min, &output\_activation\_max);
 DepthwiseParams op\_params; op\_params.padding\_type = PaddingType::kSame; op\_params.padding\_values.width = data->padding.width; op\_params.padding\_values.height = data->padding.height; op\_params.stride\_width = params->stride\_width; op\_params.stride\_height = params->stride\_height; op\_params.dilation\_width\_factor = params->dilation\_width\_factor; op\_params.dilation\_height\_factor = params->dilation\_height\_factor; op\_params.float\_activation\_min = output\_activation\_min; op\_params.float\_activation\_max = output\_activation\_max; TF\_LITE\_ENSURE\_STATUS(ComputeDepthMultiplier(context, input, filter, &op\_params.depth\_multiplier)); if (kernel\_type == kReference) { reference\_ops::DepthwiseConv( op\_params, GetTensorShape(input), GetTensorData<float>(input), GetTensorShape(filter), GetTensorData<float>(filter), GetTensorShape(bias), GetTensorData<float>(bias), GetTensorShape(output), GetTensorData<float>(output)); } else { optimized\_ops::DepthwiseConv<float, float>( op\_params, GetTensorShape(input), GetTensorData<float>(input), GetTensorShape(filter), GetTensorData<float>(filter), GetTensorShape(bias), GetTensorData<float>(bias), GetTensorShape(output), GetTensorData<float>(output), CpuBackendContext::GetFromContext(context)); } return kTfLiteOk;}
template <KernelType kernel\_type>TfLiteStatus EvalQuantized(TfLiteContext\* context, TfLiteNode\* node, TfLiteDepthwiseConvParams\* params, OpData\* data, const TfLiteTensor\* input, const TfLiteTensor\* filter, const TfLiteTensor\* bias, TfLiteTensor\* output) { auto input\_offset = -input->params.zero\_point; auto filter\_offset = -filter->params.zero\_point; auto output\_offset = output->params.zero\_point;
 DepthwiseParams op\_params; op\_params.padding\_type = PaddingType::kSame; op\_params.padding\_values.width = data->padding.width; op\_params.padding\_values.height = data->padding.height; op\_params.stride\_width = params->stride\_width; op\_params.stride\_height = params->stride\_height; op\_params.dilation\_width\_factor = params->dilation\_width\_factor; op\_params.dilation\_height\_factor = params->dilation\_height\_factor; op\_params.input\_offset = input\_offset; op\_params.weights\_offset = filter\_offset; op\_params.output\_offset = output\_offset; op\_params.output\_multiplier = data->output\_multiplier; op\_params.output\_shift = -data->output\_shift; op\_params.quantized\_activation\_min = data->output\_activation\_min; op\_params.quantized\_activation\_max = data->output\_activation\_max; TF\_LITE\_ENSURE\_STATUS(ComputeDepthMultiplier(context, input, filter, &op\_params.depth\_multiplier)); if (kernel\_type == kReference) { reference\_ops::DepthwiseConv( op\_params, GetTensorShape(input), GetTensorData<uint8\_t>(input), GetTensorShape(filter), GetTensorData<uint8\_t>(filter), GetTensorShape(bias), GetTensorData<int32\_t>(bias), GetTensorShape(output), GetTensorData<uint8\_t>(output)); } else { optimized\_ops::DepthwiseConv<uint8, int32>( op\_params, GetTensorShape(input), GetTensorData<uint8\_t>(input), GetTensorShape(filter), GetTensorData<uint8\_t>(filter), GetTensorShape(bias), GetTensorData<int32\_t>(bias), GetTensorShape(output), GetTensorData<uint8\_t>(output), CpuBackendContext::GetFromContext(context)); } return kTfLiteOk;}
template <KernelType kernel\_type>TfLiteStatus EvalQuantizedPerChannel(TfLiteContext\* context, TfLiteNode\* node, TfLiteDepthwiseConvParams\* params, OpData\* data, const TfLiteTensor\* input, const TfLiteTensor\* filter, const TfLiteTensor\* bias, TfLiteTensor\* output) { DepthwiseParams op\_params; op\_params.padding\_type = PaddingType::kSame; op\_params.padding\_values.width = data->padding.width; op\_params.padding\_values.height = data->padding.height; op\_params.stride\_width = params->stride\_width; op\_params.stride\_height = params->stride\_height; op\_params.dilation\_width\_factor = params->dilation\_width\_factor; op\_params.dilation\_height\_factor = params->dilation\_height\_factor; op\_params.input\_offset = -input->params.zero\_point; op\_params.weights\_offset = 0; op\_params.output\_offset = output->params.zero\_point; op\_params.quantized\_activation\_min = data->output\_activation\_min; op\_params.quantized\_activation\_max = data->output\_activation\_max; TF\_LITE\_ENSURE\_STATUS(ComputeDepthMultiplier(context, input, filter, &op\_params.depth\_multiplier));
 if (kernel\_type == kReference) { reference\_integer\_ops::DepthwiseConvPerChannel( op\_params, data->per\_channel\_output\_multiplier.data(), data->per\_channel\_output\_shift.data(), GetTensorShape(input), GetTensorData<int8>(input), GetTensorShape(filter), GetTensorData<int8>(filter), GetTensorShape(bias), GetTensorData<int32>(bias), GetTensorShape(output), GetTensorData<int8>(output)); } else { optimized\_integer\_ops::DepthwiseConvPerChannel( op\_params, data->per\_channel\_output\_multiplier.data(), data->per\_channel\_output\_shift.data(), GetTensorShape(input), GetTensorData<int8>(input), GetTensorShape(filter), GetTensorData<int8>(filter), GetTensorShape(bias), GetTensorData<int32>(bias), GetTensorShape(output), GetTensorData<int8>(output), CpuBackendContext::GetFromContext(context)); } return kTfLiteOk;}
TfLiteStatus EvalQuantizedPerChannel16x8( const TfLiteDepthwiseConvParams\* params, const OpData\* data, const TfLiteTensor\* input, const TfLiteTensor\* filter, const TfLiteTensor\* bias, TfLiteTensor\* output) { DepthwiseParams op\_params; op\_params.padding\_type = PaddingType::kSame; op\_params.padding\_values.width = data->padding.width; op\_params.padding\_values.height = data->padding.height; op\_params.stride\_width = params->stride\_width; op\_params.stride\_height = params->stride\_height; op\_params.dilation\_width\_factor = params->dilation\_width\_factor; op\_params.dilation\_height\_factor = params->dilation\_height\_factor; op\_params.depth\_multiplier = params->depth\_multiplier; op\_params.weights\_offset = 0; op\_params.quantized\_activation\_min = data->output\_activation\_min; op\_params.quantized\_activation\_max = data->output\_activation\_max;
 reference\_integer\_ops::DepthwiseConvPerChannel( op\_params, data->per\_channel\_output\_multiplier.data(), data->per\_channel\_output\_shift.data(), GetTensorShape(input), GetTensorData<int16>(input), GetTensorShape(filter), GetTensorData<int8>(filter), GetTensorShape(bias), GetTensorData<std::int64\_t>(bias), GetTensorShape(output), GetTensorData<int16>(output));
 return kTfLiteOk;}
template <KernelType kernel\_type>TfLiteStatus EvalHybridPerChannel(TfLiteContext\* context, TfLiteNode\* node, TfLiteDepthwiseConvParams\* params, OpData\* data, const TfLiteTensor\* input, const TfLiteTensor\* filter, const TfLiteTensor\* bias, TfLiteTensor\* output) { float output\_activation\_min, output\_activation\_max; CalculateActivationRange(params->activation, &output\_activation\_min, &output\_activation\_max); const int batch\_size = SizeOfDimension(input, 0); TF\_LITE\_ENSURE(context, batch\_size != 0); const int input\_size = NumElements(input) / batch\_size; TfLiteTensor\* input\_quantized; TF\_LITE\_ENSURE\_OK(context, GetTemporarySafe(context, node, data->input\_quantized\_index, &input\_quantized)); int8\_t\* quantized\_input\_ptr\_batch = input\_quantized->data.int8; TfLiteTensor\* scaling\_factors\_tensor; TF\_LITE\_ENSURE\_OK(context, GetTemporarySafe(context, node, data->scaling\_factors\_index, &scaling\_factors\_tensor)); float\* scaling\_factors\_ptr = GetTensorData<float>(scaling\_factors\_tensor); TfLiteTensor\* input\_offset\_tensor; TF\_LITE\_ENSURE\_OK(context, GetTemporarySafe(context, node, data->input\_offset\_index, &input\_offset\_tensor)); int32\_t\* input\_offset\_ptr = GetTensorData<int32\_t>(input\_offset\_tensor);
 for (int b = 0; b < batch\_size; ++b) { const int offset = b \* input\_size; tensor\_utils::AsymmetricQuantizeFloats( GetTensorData<float>(input) + offset, input\_size, quantized\_input\_ptr\_batch + offset, &scaling\_factors\_ptr[b], &input\_offset\_ptr[b]); }
 DepthwiseParams op\_params; op\_params.padding\_type = PaddingType::kSame; op\_params.padding\_values.width = data->padding.width; op\_params.padding\_values.height = data->padding.height; op\_params.stride\_width = params->stride\_width; op\_params.stride\_height = params->stride\_height; op\_params.dilation\_width\_factor = params->dilation\_width\_factor; op\_params.dilation\_height\_factor = params->dilation\_height\_factor; op\_params.depth\_multiplier = params->depth\_multiplier;
 op\_params.weights\_offset = 0; op\_params.float\_activation\_min = output\_activation\_min; op\_params.float\_activation\_max = output\_activation\_max; TF\_LITE\_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization); const auto\* affine\_quantization = reinterpret\_cast<TfLiteAffineQuantization\*>(filter->quantization.params); if (kernel\_type == kReference) { reference\_integer\_ops::DepthwiseConvHybridPerChannel( op\_params, scaling\_factors\_ptr, GetTensorShape(input), quantized\_input\_ptr\_batch, GetTensorShape(filter), GetTensorData<int8>(filter), GetTensorShape(bias), GetTensorData<float>(bias), GetTensorShape(output), GetTensorData<float>(output), affine\_quantization->scale->data, input\_offset\_ptr); } else { optimized\_integer\_ops::DepthwiseConvHybridPerChannel( op\_params, scaling\_factors\_ptr, GetTensorShape(input), quantized\_input\_ptr\_batch, GetTensorShape(filter), GetTensorData<int8>(filter), GetTensorShape(bias), GetTensorData<float>(bias), GetTensorShape(output), GetTensorData<float>(output), affine\_quantization->scale->data, input\_offset\_ptr, CpuBackendContext::GetFromContext(context)); }
 return kTfLiteOk;}
template <KernelType kernel\_type, TfLiteType input\_type>TfLiteStatus EvalImpl(TfLiteContext\* context, TfLiteNode\* node) { auto\* params = reinterpret\_cast<TfLiteDepthwiseConvParams\*>(node->builtin\_data); OpData\* data = reinterpret\_cast<OpData\*>(node->user\_data);
 TfLiteTensor\* output; TF\_LITE\_ENSURE\_OK(context, GetOutputSafe(context, node, kOutputTensor, &output)); const TfLiteTensor\* input; TF\_LITE\_ENSURE\_OK(context, GetInputSafe(context, node, kInputTensor, &input)); const TfLiteTensor\* filter; TF\_LITE\_ENSURE\_OK(context, GetInputSafe(context, node, kFilterTensor, &filter)); const TfLiteTensor\* bias = (NumInputs(node) == 3) ? GetInput(context, node, kBiasTensor) : nullptr; TFLITE\_DCHECK\_EQ(input\_type, input->type);
 switch (input\_type) { // Already know in/out types are same. case kTfLiteFloat32: if (filter->type == kTfLiteFloat32) { return EvalFloat<kernel\_type>(context, node, params, data, input, filter, bias, output); } else if (filter->type == kTfLiteInt8) { return EvalHybridPerChannel<kernel\_type>(context, node, params, data, input, filter, bias, output); } else { TF\_LITE\_KERNEL\_LOG( context, "Type %s with filter type %s not currently supported.", TfLiteTypeGetName(input->type), TfLiteTypeGetName(filter->type)); return kTfLiteError; } break; case kTfLiteUInt8: return EvalQuantized<kernel\_type>(context, node, params, data, input, filter, bias, output); break; case kTfLiteInt8: return EvalQuantizedPerChannel<kernel\_type>(context, node, params, data, input, filter, bias, output); break; case kTfLiteInt16: return EvalQuantizedPerChannel16x8(params, data, input, filter, bias, output); break; default: context->ReportError(context, "Type %d not currently supported.", input->type); return kTfLiteError; }}
template <KernelType kernel\_type>TfLiteStatus Eval(TfLiteContext\* context, TfLiteNode\* node) { const TfLiteTensor\* input; TF\_LITE\_ENSURE\_OK(context, GetInputSafe(context, node, kInputTensor, &input));
 switch (input->type) { // Already know in/out types are same. case kTfLiteFloat32: return EvalImpl<kernel\_type, kTfLiteFloat32>(context, node); case kTfLiteUInt8: return EvalImpl<kernel\_type, kTfLiteUInt8>(context, node); case kTfLiteInt8: return EvalImpl<kernel\_type, kTfLiteInt8>(context, node); case kTfLiteInt16: return EvalImpl<kernel\_type, kTfLiteInt16>(context, node); default: context->ReportError(context, "Type %d not currently supported.", input->type); return kTfLiteError; }}
} // namespace depthwise\_conv
TfLiteRegistration\* Register\_DEPTHWISE\_CONVOLUTION\_REF() { static TfLiteRegistration r = { depthwise\_conv::Init, depthwise\_conv::Free, depthwise\_conv::Prepare, depthwise\_conv::Eval<depthwise\_conv::kReference>}; return &r;}
TfLiteRegistration\* Register\_DEPTHWISE\_CONVOLUTION\_GENERIC\_OPT() { static TfLiteRegistration r = { depthwise\_conv::Init, depthwise\_conv::Free, depthwise\_conv::Prepare, depthwise\_conv::Eval<depthwise\_conv::kGenericOptimized>}; return &r;}
TfLiteRegistration\* Register\_DEPTHWISE\_CONVOLUTION\_NEON\_OPT() { static TfLiteRegistration r = { depthwise\_conv::Init, depthwise\_conv::Free, depthwise\_conv::Prepare, depthwise\_conv::Eval<depthwise\_conv::kNeonOptimized>}; return &r;}
TfLiteRegistration\* Register\_DEPTHWISE\_CONVOLUTION\_NEON\_OPT\_UINT8() { static TfLiteRegistration r = { depthwise\_conv::Init, depthwise\_conv::Free, depthwise\_conv::Prepare, depthwise\_conv::EvalImpl<depthwise\_conv::kNeonOptimized, kTfLiteUInt8>}; return &r;}
TfLiteRegistration\* Register\_DEPTHWISE\_CONV\_2D() {#ifdef USE\_NEON return Register\_DEPTHWISE\_CONVOLUTION\_NEON\_OPT();#else return Register\_DEPTHWISE\_CONVOLUTION\_GENERIC\_OPT();#endif}
// Warning: Clients using this variant are responsible for ensuring that their// models only need the UINT8 type. TFLite's op registration mechanism doesn't// yet allow for more nuanced registration mechanisms.TfLiteRegistration\* Register\_DEPTHWISE\_CONV\_2D\_UINT8() {#ifdef USE\_NEON return Register\_DEPTHWISE\_CONVOLUTION\_NEON\_OPT\_UINT8();#else return Register\_DEPTHWISE\_CONV\_2D();#endif}
} // namespace builtin} // namespace ops} // namespace tflite

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_7a588dca_20250114_190401.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2Fe5b0eec199c2d03de54fd6a7fd9275692218e2bc)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2Fe5b0eec199c2d03de54fd6a7fd9275692218e2bc)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fcommit_fragments%2Frepo_layout&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  827](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Commit

[Permalink](/tensorflow/tensorflow/commit/e5b0eec199c2d03de54fd6a7fd9275692218e2bc)

This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.

[lite] Add validation check for dilation height/width to be positive …

[Browse files](/tensorflow/tensorflow/tree/e5b0eec199c2d03de54fd6a7fd9275692218e2bc)
Browse the repository at this point in the history

```
…integers.

PiperOrigin-RevId: 416429178
Change-Id: If7cdcddca54486434d9b2f06e7e2b401d7c3ee25
```

* Loading branch information

[![@karimnosseir](https://avatars.githubusercontent.com/u/44206880?s=40&v=4)](/karimnosseir) [![@tensorflower-gardener](https://avatars.githubusercontent.com/u/17151892?s=40&v=4)](/tensorflower-gardener)

[karimnosseir](/tensorflow/tensorflow/commits?author=karimnosseir "View all commits by karimnosseir")
authored and
[tensorflower-gardener](/tensorflow/tensorflow/commits?author=tensorflower-gardener "View all commits by tensorflower-gardener")
committed
Dec 15, 2021

1 parent
[ece78f4](/tensorflow/tensorflow/commit/ece78f4001dd87f50daab1d1b43f70a51726b8fb)

commit e5b0eec

Showing
**1 changed file**
with
**2 additions**
and
**0 deletions**.

* Whitespace
* Ignore whitespace

* Split
* Unified

## There are no files selected for viewing

2 changes: 2 additions & 0 deletions

2
[tensorflow/lite/kernels/depthwise\_conv.cc](#diff-126b609754675fc31d0392463d94a881508019faa4913aa607f58ecd430f7cfb "tensorflow/lite/kernels/depthwise_conv.cc")

Show comments

[View file](/tensorflow/tensorflow/blob/e5b0eec199c2d03de54fd6a7fd9275692218e2bc/tensorflow/lite/kernels/depthwise_conv.cc)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -115,6 +115,8 @@ TfLiteStatus Prepare(TfLiteContext\* context, TfLiteNode\* node) { |
|  |  |  |
|  |  | TF\_LITE\_ENSURE\_EQ(context, NumDimensions(input), 4); |
|  |  | TF\_LITE\_ENSURE\_EQ(context, NumDimensions(filter), 4); |
|  |  | TF\_LITE\_ENSURE(context, params->dilation\_height\_factor > 0); |
|  |  | TF\_LITE\_ENSURE(context, params->dilation\_width\_factor > 0); |
|  |  |  |
|  |  | const TfLiteType data\_type = input->type; |
|  |  |  |
| Expand Down | |  |

Toggle all file notes
Toggle all file annotations

### 0 comments on commit `e5b0eec`

Please
[sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2Fe5b0eec199c2d03de54fd6a7fd9275692218e2bc) to comment.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_46820ad4_20250114_190402.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fsecurity%2Fadvisories%2FGHSA-428x-9xc2-m8mj)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fsecurity%2Fadvisories%2FGHSA-428x-9xc2-m8mj)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Frepos%2Fadvisories%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  827](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

# FPE in depthwise convolutions in TFLite

Low

[mihaimaruseac](/mihaimaruseac)
published
GHSA-428x-9xc2-m8mj
Feb 2, 2022

## Package

pip

tensorflow, tensorflow-cpu, tensorflow-gpu
([pip](/advisories?query=ecosystem%3Apip))

## Affected versions

< 2.8.0

## Patched versions

2.5.3, 2.6.3, 2.7.1

## Description

### Impact

An attacker can craft a TFLite model that would trigger a division by zero in [the implementation of depthwise convolutions](https://github.com/tensorflow/tensorflow/blob/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite/kernels/depthwise_conv.cc#L96).

The parameters of the convolution can be user controlled and are also used within a division operation to determine the size of the padding that needs to be added before applying the convolution. There is no check before this division that the divisor is stricly positive.

### Patches

We have patched the issue in GitHub commit [e5b0eec199c2d03de54fd6a7fd9275692218e2bc](https://github.com/tensorflow/tensorflow/commit/e5b0eec199c2d03de54fd6a7fd9275692218e2bc).

The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.

### For more information

Please consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.

### Attribution

This vulnerability has been reported by Wang Xuan of Qihoo 360 AIVul Team.

### Severity

Low

### CVE ID

CVE-2022-21741

### Weaknesses

No CWEs

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.


