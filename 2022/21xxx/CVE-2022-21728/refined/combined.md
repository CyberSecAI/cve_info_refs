=== Content from github.com_2f75e73f_20250114_181034.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fsecurity%2Fadvisories%2FGHSA-6gmv-pjp9-p8w8)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fsecurity%2Fadvisories%2FGHSA-6gmv-pjp9-p8w8)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Frepos%2Fadvisories%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  826](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

# Heap OOB read in shape inference for `ReverseSequence`

Moderate

[mihaimaruseac](/mihaimaruseac)
published
GHSA-6gmv-pjp9-p8w8
Feb 2, 2022

## Package

pip

tensorflow, tensorflow-cpu, tensorflow-gpu
([pip](/advisories?query=ecosystem%3Apip))

## Affected versions

< 2.8.0

## Patched versions

2.5.3, 2.6.3, 2.7.1

## Description

### Impact

The [implementation of shape inference for `ReverseSequence`](https://github.com/tensorflow/tensorflow/blob/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/ops/array_ops.cc#L1636-L1671) does not fully validate the value of `batch_dim` and can result in a heap OOB read:

```
import tensorflow as tf

@tf.function
def test():
  y = tf.raw_ops.ReverseSequence(
    input = ['aaa','bbb'],
    seq_lengths = [1,1,1],
    seq_dim = -10,
    batch_dim = -10 )
  return y

test()
```

There is a check to make sure the value of `batch_dim` does not go over the rank of the input, but there is no check for negative values:

```
  const int32_t input_rank = c->Rank(input);
  if (batch_dim >= input_rank) {
    return errors::InvalidArgument(
        "batch_dim must be < input rank: ", batch_dim, " vs. ", input_rank);
  }
  // ...

  DimensionHandle batch_dim_dim = c->Dim(input, batch_dim);
```

Negative dimensions are allowed in some cases to mimic Python's negative indexing (i.e., indexing from the end of the array), however if the value is too negative then [the implementation of `Dim`](https://github.com/tensorflow/tensorflow/blob/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework/shape_inference.h#L415-L428) would access elements before the start of an array:

```
  DimensionHandle Dim(ShapeHandle s, int64_t idx) {
    if (!s.Handle() || s->rank_ == kUnknownRank) {
      return UnknownDim();
    }
    return DimKnownRank(s, idx);
  }
·
  static DimensionHandle DimKnownRank(ShapeHandle s, int64_t idx) {
    CHECK_NE(s->rank_, kUnknownRank);
    if (idx < 0) {
      return s->dims_[s->dims_.size() + idx];
    }
    return s->dims_[idx];
  }
```
### Patches

We have patched the issue in GitHub commit [37c01fb5e25c3d80213060460196406c43d31995](https://github.com/tensorflow/tensorflow/commit/37c01fb5e25c3d80213060460196406c43d31995).

The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.

### For more information

Please consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.

### Attribution

This vulnerability has been reported by Yu Tian of Qihoo 360 AIVul Team.

### Severity

Moderate

### CVE ID

CVE-2022-21728

### Weaknesses

No CWEs

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_046b5cfc_20250114_181030.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2F5100e359aef5c8021f2e71c7b986420b85ce7b3d%2Ftensorflow%2Fcore%2Fframework%2Fshape_inference.h)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2F5100e359aef5c8021f2e71c7b986420b85ce7b3d%2Ftensorflow%2Fcore%2Fframework%2Fshape_inference.h)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  826](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Files

 5100e35
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d)
2. /[tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core)
4. /[framework](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework)
/
# shape\_inference.h

Copy path Blame  Blame
## Latest commit

## History

[History](/tensorflow/tensorflow/commits/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework/shape_inference.h)902 lines (761 loc) · 36.6 KB 5100e35
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d)
2. /[tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core)
4. /[framework](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework)
/
# shape\_inference.h

Top
## File metadata and controls

* Code
* Blame

902 lines (761 loc) · 36.6 KB[Raw](https://github.com/tensorflow/tensorflow/raw/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/framework/shape_inference.h)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902/\* Copyright 2016 The TensorFlow Authors. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");you may not use this file except in compliance with the License.You may obtain a copy of the License at
 http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.==============================================================================\*/#ifndef TENSORFLOW\_CORE\_FRAMEWORK\_SHAPE\_INFERENCE\_H\_#define TENSORFLOW\_CORE\_FRAMEWORK\_SHAPE\_INFERENCE\_H\_
#include <vector>
#include "absl/memory/memory.h"#include "tensorflow/core/framework/full\_type.pb.h"#include "tensorflow/core/framework/node\_def\_util.h"#include "tensorflow/core/framework/tensor.h"#include "tensorflow/core/lib/core/errors.h"#include "tensorflow/core/lib/core/status.h"#include "tensorflow/core/lib/gtl/inlined\_vector.h"#include "tensorflow/core/platform/macros.h"
namespace tensorflow {
namespace grappler {class GraphProperties;class SymbolicShapeManager;} // namespace grappler
namespace shape\_inference {
struct DimensionOrConstant;class InferenceContext;
// This header contains the InferenceContext that is used to infer the shape of// the results of an operation or flag an operation with invalid inputs (e.g.,// mismatched shapes for elementwise operation) by ShapeRefiner. The shape of an// operation is computed using the OpShapeInferenceFn set via SetShapeFn in op// registration. The OpShapeInferenceFn uses a per op InferenceContext populated// with input shapes to compute resultant shape (including resource shapes).//// The shapes created in the InferenceContext are bound to the lifetime of the// InferenceContext in which it was created. E.g., in//// ```c++// InferenceContext c;// // Below a ShapeHandle is returned by MakeShape, while UnknownDim returns a// // DimensionHandle.// ShapeHandle in0 = c.MakeShape({10, c.UnknownDim()});// ```//// the ShapeHandle `in0` (and the nested unknown dim inside) is only valid while// `c` is in scope, as ShapeHandle and DimensionHandle are effectively// wrappers around pointers stored inside the context with the lifetime of the// value pointed to managed by the context. The result from one operation's// inference context will be passed as input to the inference of consumer// operations. Hence it is possible for ShapeHandles produced by inference on a// node to consist of ShapeHandles owned by different InferenceContexts. While// inferring the shapes of a Graph, the InferenceContext of all nodes/operations// in the Graph remain resident for the lifetime of the Graph (e.g, there is a// map from each node to its InferenceContext, technically its// ExtendedInferencContext which additionally stores the element types of inputs// & outputs, which remains resident).//// For functions, the body of the function is instantiated as a Graph while// inferring the result shapes of a function call node. The rules above apply// while the function's shape is being inferred, but the contexts associated// with nodes in the function body are released once the function call's// resultant shapes are inferred. The shapes of results returned by a function// are propagated to the InferenceContext of the function call's op (which is// associated with a Graph of nodes whose shape is being inferred) as the return// values of a function call node are the inputs of its consumer, but the return// values are produced by nodes inside the function whose InferenceContexts// (which owns the values pointed to by ShapeHandle and DimensionHandle) are// reclaimed after inferring function result shapes. Recursive user-defined// function are not supported hence inference of functions are fully nested with// the InferenceContext's of function calls forming a stack.//// For example, consider the following call and function://// ```python// @tf.function// def g(st):// d = tf.add(st, st)// return d//// @tf.function// def f():// st = tf.A()// result = g(st)// return h(result)// ```//// During inference of f, the shape of `A` will be inferred and the results from// its InferenceContext used as inputs to function call `g(st)`. The call node// will have an InferenceContext created (call it outer context) and the graph// corresponding to function `g` will be instantiated. The result shape of the// Arg nodes of the function will be associated with input from outer context.// During inference of `g` (for the callsite `g(st)` in `f`), the// InferenceContext of all nodes inside `g` will remain alive. Thus, when shape// of `tf.add` is computed it may rely on all inputs. Once the RetVal nodes of a// function is reached, we know the shape of its input may correspond to a shape// queried in the outer context and it is explicitly copied to outer context. In// this case that means that the shape of `d` is copied to the InferenceContext// of `g(st)` and so when `h(result)` is executed this shape may be queried.// Furthermore, no shapes computed due to call `g(st)` can be queried post this// point and, as the RetVal shapes have been coppied into outer context, all// InferenceContexts associated with nodes in function `g` instantiated for// `g(st)` may be and are released.
// Dimension values are accessed through InferenceContext.class Dimension { private: Dimension(); Dimension(int64\_t value); ~Dimension() {}
 const int64\_t value\_;
 friend class InferenceContext; friend class ShapeManager; TF\_DISALLOW\_COPY\_AND\_ASSIGN(Dimension);};
class DimensionHandle { public: DimensionHandle() {} bool SameHandle(DimensionHandle d) const { return ptr\_ == d.ptr\_; } std::size\_t Handle() const { return reinterpret\_cast<std::size\_t>(ptr\_); }
 private: DimensionHandle(const Dimension\* dim) { ptr\_ = dim; }
 const Dimension\* operator->() const { return ptr\_; } bool IsSet() const { return ptr\_ != nullptr; }
 const Dimension\* ptr\_ = nullptr;
 friend struct DimensionOrConstant; friend class InferenceContext; friend class ShapeInferenceTest; friend class ShapeInferenceTestutil; friend class ::tensorflow::grappler::GraphProperties; friend class ::tensorflow::grappler::SymbolicShapeManager;
 // Intentionally copyable.};
// Shape rank and dimensions are accessed through InferenceContext.class Shape { private: Shape(); Shape(const std::vector<DimensionHandle>& dims); ~Shape() {}
 const int32 rank\_; const std::vector<DimensionHandle> dims\_;
 friend class InferenceContext; friend class ::tensorflow::grappler::SymbolicShapeManager;
 TF\_DISALLOW\_COPY\_AND\_ASSIGN(Shape);};
class ShapeHandle { public: ShapeHandle() {} bool SameHandle(ShapeHandle s) const { return ptr\_ == s.ptr\_; } std::size\_t Handle() const { return reinterpret\_cast<std::size\_t>(ptr\_); }
 private: ShapeHandle(const Shape\* shape) { ptr\_ = shape; } const Shape\* operator->() const { return ptr\_; } bool IsSet() const { return ptr\_ != nullptr; }
 const Shape\* ptr\_ = nullptr;
 friend class InferenceContext; friend class ShapeInferenceTest; friend class ShapeInferenceTestutil; friend class ::tensorflow::grappler::SymbolicShapeManager;
 // Intentionally copyable.};
// Struct used to allow functions to take DimensionHandle or a dimension value.// Not meant to be constructed directly.struct DimensionOrConstant { public: // Intentionally not explicit. DimensionOrConstant(DimensionHandle dim);
 // val must be non-negative or InferenceContext::kUnknownDim. DimensionOrConstant(int64\_t val);
 // dim takes precedence. If dim != nullptr, val is ignored. DimensionHandle dim; int64\_t val;
 private: DimensionOrConstant();};
struct ShapeAndType { ShapeAndType() {} ShapeAndType(ShapeHandle s, DataType t) : shape(s), dtype(t) {} // TODO(mdan): Remove dtype from constructor, and use type\_ instead. // dtype is kept here for backward compatibiity. Its information should // be redundant to that in type; ShapeAndType(ShapeHandle s, DataType t, FullTypeDef type\_) : shape(s), dtype(t), type(type\_) {}
 ShapeHandle shape; DataType dtype = DT\_INVALID; FullTypeDef type;};
// Shape inference functions registered on ops in REGISTER\_OP implement// their shape functions in terms of this InferenceContext. An InferenceContext// is created by the framework and passed to a shape inference function. The// shape inference function calls functions on the context, and should call// set\_output() to set the shape on all outputs.//// To infer shapes for user-defined functions see ShapeRefiner.//// All Shape\* and Dimension\* returned by functions of InferenceContext are owned// by the InferenceContext.class InferenceContext { public: static constexpr int64\_t kUnknownDim = -1; static constexpr int32\_t kUnknownRank = -1;
 // <input\_tensors> is NULL-padded to be the same size as <input\_shapes>. // // Elements of <input\_tensors\_as\_shapes> are used for when a shape function // makes a call to MakeShapeFromShapeTensor; in particular, when the // input\_tensors[i] is nullptr but the shape represented by it is partially // known from analysis of the graph. // <input\_tensors\_as\_shapes> can have fewer elements than <input\_shapes>. // Values of <input\_tensors\_as\_shapes> do not need to outlive the context. InferenceContext(int graph\_def\_version, const AttrSlice& attrs, const OpDef& op\_def, const std::vector<ShapeHandle>& input\_shapes, const std::vector<const Tensor\*>& input\_tensors, const std::vector<ShapeHandle>& input\_tensors\_as\_shapes, std::vector<std::unique\_ptr<std::vector<ShapeAndType>>> input\_handle\_shapes\_and\_types);
 // <input\_tensors> is NULL-padded to be the same size as <input\_shapes>. // // Elements of <input\_tensors\_as\_shapes> are used for when a shape // function makes a call to MakeShapeFromShapeTensor; in particular, when // the input\_tensors[i] is nullptr but the shape represented by it is // partially known from analysis of the graph. <input\_tensors\_as\_shapes> // can have fewer elements than <input\_shapes>. Values of // <input\_tensors\_as\_shapes> do not need to outlive the context. InferenceContext( int graph\_def\_version, const AttrSlice& attrs, const OpDef& op\_def, const std::vector<PartialTensorShape>& input\_shapes, const std::vector<const Tensor\*>& input\_tensors, const std::vector<PartialTensorShape>& input\_tensors\_as\_shapes, const std::vector<std::unique\_ptr< std::vector<std::pair<PartialTensorShape, DataType>>>>& input\_handle\_shapes\_and\_types);
 ~InferenceContext();
 // Runs the shape inference function 'fn' with 'this' as the // argument, returns the status of the inference. // // On error, additional context is provided in the error message. Status Run( const std::function<Status(shape\_inference::InferenceContext\* c)>& fn);
 // Merge the stored shape of the input in position idx with <shape> according // to the following rules: // // - If the ShapeHandles are the same or <shape> is unknown, there will be no // change. Otherwise if the stored shape is unknown, the new shape will be // <shape>. // - If both shapes are known, then they must have the same rank. // - For any one dimension, if the values for that dimension in both shapes // are known, then the values must match. // - If one shape has equal or more information than the other shape in every // dimension, the new shape will become the shape with more information. // - Example: merging [2,?] and [?,2] results in [2,2] // - Example: [2,2] cannot be merged with [1,2] // // This requires idx to be in the [0, num\_inputs) range. If the merge is // successful, return true. Return false otherwise. bool MergeInput(int idx, ShapeHandle shape) { ShapeHandle new\_shape; if (!Merge(inputs\_[idx], shape, &new\_shape).ok()) return false; inputs\_[idx] = new\_shape; return true; }
 // Relax the stored shape of the input in position idx with <shape> according // to the following rules: // // - If the ShapeHandles are the same then the stored shape will be returned. // - If either of the ShapeHandles are unknown, then a new UnknownShape will // be returned. A new shape must be returned because we cannot claim that // the resulting shape is necessarily the same as either of the input // shapes. // - If the shapes both have known ranks but their ranks are different, a new // UnknownShape will be returned. // - For any one dimension, if the value for that dimension in either of the // shapes is unknown, a new shape will be returned with a new UnknownDim in // that dimension. // - For any one dimension, if the values for that dimension in both shapes // are known but do not match, a new shape will be returned with a new // UnknownDim in that dimension. // - If both shapes have the same known rank and match in every dimension, // the stored shape will be returned. // - Example: relaxing [2,?] and [?,2] results in [?,?] // - Example: relaxing [2,2] and [3,2] results in [?,2] // - Example: relaxing [2,2] with [1,2,3] results in ? // // This requires idx to be in the [0, num\_inputs) range. If the relax is // successful and the new shape differs from the old one, store the new // shape and return true. Return false otherwise. bool RelaxInput(int idx, ShapeHandle shape) { ShapeHandle new\_shape; Relax(inputs\_[idx], shape, &new\_shape); if (inputs\_[idx].SameHandle(new\_shape)) { return false; } inputs\_[idx] = new\_shape; return true; }
 void SetInput(int idx, ShapeHandle shape) { inputs\_[idx] = shape; }
 ShapeHandle input(int64\_t idx) const { return inputs\_[idx]; } Status input(StringPiece input\_name, std::vector<ShapeHandle>\* output) const; int num\_inputs() const { return inputs\_.size(); }
 // Returns the input tensor at index <idx>, or nullptr if the input tensor is // not available at the time of shape inference. const Tensor\* input\_tensor(int idx) { // Mark that this idx was requested. request\_input\_tensor(idx); return input\_tensors\_[idx]; }
 // Notifies the shape refiner that the value of the tensor at index <idx> // is needed. The shape refiner tries to statically compute this tensor, // and if successful re-runs the shape function with this tensor available // in the call to 'input\_tensor(idx)'. void request\_input\_tensor(int idx) { requested\_input\_tensor\_[idx] = true; }
 // Returns true iff input\_tensor(idx) was called by the shape function. bool requested\_input\_tensor(int idx) const { return requested\_input\_tensor\_[idx]; }
 // Notifies the shape refiner that the value of the tensor at index <idx> // as a partial shape is needed. The shape refiner tries to statically compute // this, and if successful re-runs the shape function with the // computed PartialTensorShape available in the call to // 'MakeShapeFromShapeTensor(idx, handle)' or // 'MakeShapeFromShapeTensorTreatScalarAsUnknownShape(idx, handle)'. void request\_input\_tensor\_as\_partial\_shape(int idx) { requested\_input\_tensor\_as\_partial\_shape\_[idx] = true; }
 // Returns true if MakeShapeFromInputTensor was called but the constant // input\_tensor was not present. bool requested\_input\_tensor\_as\_partial\_shape(int idx) const { return requested\_input\_tensor\_as\_partial\_shape\_[idx]; }
 void set\_input\_tensors(const std::vector<const Tensor\*>& input\_tensors) { input\_tensors\_ = input\_tensors; }
 void set\_input\_tensors\_as\_shapes( const std::vector<ShapeHandle>& input\_tensors\_as\_shapes) { input\_tensors\_as\_shapes\_ = input\_tensors\_as\_shapes; }
 const std::vector<ShapeHandle>& input\_tensors\_as\_shapes() const { return input\_tensors\_as\_shapes\_; }
 ShapeHandle output(int64\_t idx) const { return outputs\_.at(idx); } void set\_output(int idx, ShapeHandle shape) { outputs\_.at(idx) = shape; } Status set\_output(StringPiece output\_name, const std::vector<ShapeHandle>& shapes);
 int num\_outputs() const { return outputs\_.size(); } ShapeHandle output(int idx) const { return outputs\_.at(idx); } Status output(StringPiece output\_name, std::vector<ShapeHandle>\* output) const;
 // Returns the value for attribute named `attr\_name`. Status GetAttr(StringPiece attr\_name, const AttrValue\*\* attr\_value) const { return attrs\_.Find(attr\_name, attr\_value); } const AttrValue\* GetAttr(StringPiece attr\_name) const { return attrs\_.Find(attr\_name); }
 const FullTypeDef& ret\_types() const { return ret\_types\_; }
 // idx can be negative for an offset from end of dimensions. // idx must be in the range [-1 \* s.rank, s.rank). DimensionHandle Dim(ShapeHandle s, int64\_t idx) { if (!s.Handle() || s->rank\_ == kUnknownRank) { return UnknownDim(); } return DimKnownRank(s, idx); } // As above, but asserts that the rank of the shape is known. static DimensionHandle DimKnownRank(ShapeHandle s, int64\_t idx) { CHECK\_NE(s->rank\_, kUnknownRank); if (idx < 0) { return s->dims\_[s->dims\_.size() + idx]; } return s->dims\_[idx]; }
 static int32 Rank(ShapeHandle s) { return s.IsSet() ? s->rank\_ : kUnknownRank; } static bool RankKnown(ShapeHandle s) { return (s.IsSet() && (Rank(s) != kUnknownRank)); } static inline int64\_t Value(DimensionOrConstant d) { return d.dim.IsSet() ? d.dim->value\_ : d.val; } static inline bool ValueKnown(DimensionOrConstant d) { return Value(d) != kUnknownDim; }
 // Fills the output proto with the shape defined by the handle. // "proto" is expected to be empty prior to the call. void ShapeHandleToProto(ShapeHandle handle, TensorShapeProto\* proto);
 // Returns true if the rank and all dimensions of the Shape are known. bool FullyDefined(ShapeHandle s);
 // Returns the total number of elements, or an unknown dimension for an // incomplete shape. DimensionHandle NumElements(ShapeHandle s);
 std::string DebugString(ShapeHandle s); std::string DebugString(DimensionHandle d); std::string DebugString(const ShapeAndType& shape\_and\_type); std::string DebugString(gtl::ArraySlice<ShapeAndType> shape\_and\_types);
 // Describes the whole context, for debugging purposes. std::string DebugString() const;
 // If <shape> has rank <rank>, or its rank is unknown, return OK and return // the shape with asserted rank in <\*out>. Otherwise return an error. // // Note that <\*out> may be set to <shape>. Status WithRank(ShapeHandle shape, int64\_t rank, ShapeHandle\* out) TF\_MUST\_USE\_RESULT; Status WithRankAtLeast(ShapeHandle shape, int64\_t rank, ShapeHandle\* out) TF\_MUST\_USE\_RESULT; Status WithRankAtMost(ShapeHandle shape, int64\_t rank, ShapeHandle\* out) TF\_MUST\_USE\_RESULT;
 // If <dim> has value <value>, or its value is unknown, returns OK and returns // the dimension with asserted value in <\*out>. Otherwise returns an error. // // Note that <\*out> may be set to <dim>. Status WithValue(DimensionHandle dim, int64\_t value, DimensionHandle\* out) TF\_MUST\_USE\_RESULT;
 // Merges <s0> and <s1> and returns the merged shape in <\*out>. See // 'MergeInput' function for full details and examples. Status Merge(ShapeHandle s0, ShapeHandle s1, ShapeHandle\* out) TF\_MUST\_USE\_RESULT;
 // Asserts that <s>'s rank >= <prefix>'s rank, and the first // <prefix.rank> dimensions of <s> are compatible with the dimensions of // <prefix>. // Returns the merged results in <\*s\_out> and <\*prefix\_out>. Status MergePrefix(ShapeHandle s, ShapeHandle prefix, ShapeHandle\* s\_out, ShapeHandle\* prefix\_out) TF\_MUST\_USE\_RESULT;
 // Merges <d0> and <d1> and returns the merged dimension in <\*out>. If <d0> // and <d1> have incompatible values, returns an error. // // Note that <\*out> may be set to <d0> or <d1>. Status Merge(DimensionHandle d0, DimensionHandle d1, DimensionHandle\* out) TF\_MUST\_USE\_RESULT;
 // Returns in <\*out> a sub-shape of <s> with dimensions [start:]. // <start> can be negative to index from the end of the shape. If <start> > // rank of <s>, then an empty subshape is returned. Status Subshape(ShapeHandle s, int64\_t start, ShapeHandle\* out) TF\_MUST\_USE\_RESULT;
 // Returns in <\*out> a sub-shape of <s>, with dimensions [start:end]. // <start> and <end> can be negative, to index from the end of the shape. // <start> and <end> are set to the rank of <s> if > rank of <s>. Status Subshape(ShapeHandle s, int64\_t start, int64\_t end, ShapeHandle\* out) TF\_MUST\_USE\_RESULT;
 // Returns in <\*out> a sub-shape of <s>, with dimensions [start:end:stride]. // <start> and <end> can be negative, to index from the end of the shape. // <start> and <end> are set to the rank of <s> if > rank of <s>. // <stride> can be negative, to reverse the <s>. Status Subshape(ShapeHandle s, int64\_t start, int64\_t end, int64\_t stride, ShapeHandle\* out) TF\_MUST\_USE\_RESULT;
 // Returns in <\*out> the result of appending the dimensions of <s2> to those // of <s1>. Status Concatenate(ShapeHandle s1, ShapeHandle s2, ShapeHandle\* out) TF\_MUST\_USE\_RESULT;
 // Returns in <out> the shape from replacing <s.dim[dim\_index]> with // <new\_dim>. Status ReplaceDim(ShapeHandle s, int64\_t dim\_index, DimensionHandle new\_dim, ShapeHandle\* out) TF\_MUST\_USE\_RESULT;
 // Returns a new shape with the given dims. The returned value is owned by // this context. ShapeHandle MakeShape(const std::vector<DimensionHandle>& dims); ShapeHandle MakeShape(std::initializer\_list<DimensionOrConstant> dims);
 // Returns a new unknown shape. ShapeHandle UnknownShape();
 // Returns a shape with specified rank but unknown dims. ShapeHandle UnknownShapeOfRank(int64\_t rank);
 // Returns a new shape of zero dimensions. ShapeHandle Scalar();
 // Returns a new shape of one dimension. ShapeHandle Vector(DimensionOrConstant dim);
 // Returns a new shape of two dimensions. ShapeHandle Matrix(DimensionOrConstant dim1, DimensionOrConstant dim2);
 // Returns in <out> a new shape whose dimension sizes come from input tensor // <input\_idx>. The tensor must be a 1-dimensional int32 or int64 tensor. If // the input tensor is NULL, then an unknown shape is returned. Status MakeShapeFromShapeTensor(int input\_idx, ShapeHandle\* out);
 // Like the function above, but treats scalar values as unknown // shapes. \*\*NOTE\*\* If the scalar is statically known, its value // must be -1 or an error is returned. Status MakeShapeFromShapeTensorTreatScalarAsUnknownShape(int input\_idx, ShapeHandle\* out);
 // Returns in <out> a new shape corresponding to <proto>. Status MakeShapeFromShapeProto(const TensorShapeProto& proto, ShapeHandle\* out);
 // Returns in <out> a new shape corresponding to <partial\_shape>. Status MakeShapeFromPartialTensorShape( const PartialTensorShape& partial\_shape, ShapeHandle\* out);
 // Returns in <out> a new shape corresponding to <shape>. Status MakeShapeFromTensorShape(const TensorShape& shape, ShapeHandle\* out);
 // Returns a new dimension of the given size. The returned value is owned by // this context. inline DimensionHandle MakeDim(DimensionOrConstant d) { return shape\_manager\_.MakeDim(d); }
 inline DimensionHandle UnknownDim() { return MakeDim(kUnknownDim); }
 // Returns in <val> a scalar value from an input tensor <t>. The input tensor // must be a 0-dimensional int32 or int64 tensor. Caller must ensure that the // input tensor is not NULL. Status GetScalarFromTensor(const Tensor\* t, int64\_t\* val);
 // Returns in <val> a scalar value from a 1D input tensor <t> with int32 or // int64 elements. Caller must ensure that the input tensor is not NULL. Status GetScalarFromTensor(const Tensor\* t, int64\_t idx, int64\_t\* val);
 // Returns a new dimension whose value is given by a scalar input tensor. // The input tensor must be in host memory, since it is dereferenced to get // the value. Status MakeDimForScalarInput(int idx, DimensionHandle\* out);
 // Returns a new dimension whose value is given by a scalar input tensor. // This allows for a negative input dimension given the rank of a separate // tensor. This rank can be negative if unknown. // The input tensor must be in host memory, since it is dereferenced to get // the value. Status MakeDimForScalarInputWithNegativeIndexing(int idx, int input\_rank, DimensionHandle\* out);
 // Look up the attr being evaluated with name attr\_name and set \*value to its // value. If no attr with attr\_name is found in def(), or the attr does not // have a matching type, a non-ok status will be returned. template <class T> Status GetAttr(StringPiece attr\_name, T\* value) const;
 // Returns in <out> the result of dividing <dividend> by <divisor>. // Returns an error if <divisor> is not positive or if <evenly\_divisible> // and <divisor> does not evenly divide <dividend>. Status Divide(DimensionHandle dividend, DimensionOrConstant divisor, bool evenly\_divisible, DimensionHandle\* out);
 // Returns in <out> the sum of <first> and <second>. Status Add(DimensionHandle first, DimensionOrConstant second, DimensionHandle\* out);
 // Returns in <out> the dimension that is <first> minus <second>. Status Subtract(DimensionHandle first, DimensionOrConstant second, DimensionHandle\* out);
 // Returns in <out> the product of <first> and <second>. Status Multiply(DimensionHandle first, DimensionOrConstant second, DimensionHandle\* out);
 // Returns in <out> the minimum of <first> and <second>. If either <first> or // <second> is zero the results is zero. Otherwise, if either <first> or // <second> is unknown the results is unknown. Status Min(DimensionHandle first, DimensionOrConstant second, DimensionHandle\* out);
 // Returns in <out> the maximum of <first> and <second>. If either <first> or // <second> is unknown the results is unknown. Status Max(DimensionHandle first, DimensionOrConstant second, DimensionHandle\* out);
 Status construction\_status() const { return construction\_status\_; }
 // Methods to propagate shape and dtype on edges of handles. Handles are the // dtype DT\_RESOURCE which can be used to access state stored in a // ResourceManager. When ops (such as variables) consume these handles to // produce tensors they might need to know side-information about the shapes // and dtypes of tensors which can be accessed via the handle. These methods // propagate that information. Output handle dtypes and shapes are ignored if // the output tensor is not of type DT\_RESOURCE.
 // Merge the stored shapes and types corresponding to the input handle in // position idx with the specified shapes and types. This requires idx to be // in the [0, num\_inputs) range. // // If the merge is successful and any of the new shapes differs from the old // one, or any of the old dtypes was DT\_INVALID, store the new shapes and // return true. Return false otherwise. // // See 'MergeInput' function for full details and examples. bool MergeInputHandleShapesAndTypes( int idx, const std::vector<ShapeAndType>& shapes\_and\_types) TF\_MUST\_USE\_RESULT;
 // As MergeInputHandleShapesAndTypes, but for an output. bool MergeOutputHandleShapesAndTypes( int idx, const std::vector<ShapeAndType>& shapes\_and\_types) TF\_MUST\_USE\_RESULT;
 // Relaxes the stored shapes and types corresponding to the input handle in // position idx with the specified shapes and types. This requires idx to be // in the [0, num\_inputs) range. // // If the relax is successful (sizes are the same, old dtypes match new ones // or are DT\_INVALID), then store the relaxed shapes and return true. // Return false otherwise. // // See 'RelaxInput' function for full details and examples. bool RelaxInputHandleShapesAndMergeTypes( int idx, const std::vector<ShapeAndType>& shapes\_and\_types) TF\_MUST\_USE\_RESULT;
 // As RelaxInputHandleShapesAndTypes, but for an output. bool RelaxOutputHandleShapesAndMergeTypes( int idx, const std::vector<ShapeAndType>& shapes\_and\_types) TF\_MUST\_USE\_RESULT;
 void set\_input\_handle\_shapes\_and\_types( int idx, const std::vector<ShapeAndType>& shapes\_and\_types) { input\_handle\_shapes\_and\_types\_[idx] = absl::make\_unique<std::vector<ShapeAndType>>(shapes\_and\_types); }
 // Returns the output handle shapes and types, for the resource tensor output // at index <idx>. Returns NULL if the shape and types were never set. const std::vector<ShapeAndType>\* output\_handle\_shapes\_and\_types(int idx) { return output\_handle\_shapes\_and\_types\_[idx].get(); }
 // Returns the inputs handle shapes and types, for the resource tensor output // at index <idx>. Returns NULL if the shape and types were not available. const std::vector<ShapeAndType>\* input\_handle\_shapes\_and\_types(int idx) { return input\_handle\_shapes\_and\_types\_[idx].get(); }
 void set\_output\_handle\_shapes\_and\_types( int idx, const std::vector<ShapeAndType>& shapes\_and\_types) { output\_handle\_shapes\_and\_types\_[idx].reset( new std::vector<ShapeAndType>(shapes\_and\_types)); }
 // Note that shape functions should usually call MakeShapeFromShapeTensor, // as it does more analysis to provide partial shapes. // // Returns in <out> a new shape whose dimension sizes come from tensor <t>. // The tensor must be a 1-dimensional int32 or int64 tensor. If <t> is NULL, // then an unknown shape is returned. Status MakeShapeFromTensor(const Tensor\* t, ShapeHandle tensor\_shape, ShapeHandle\* out);
 int graph\_def\_version() const { return graph\_def\_version\_; }
 const std::vector<std::pair<ShapeHandle, ShapeHandle>>& MergedShapes() const { return merged\_shapes\_; } const std::vector<std::pair<DimensionHandle, DimensionHandle>>& MergedDims() const { return merged\_dims\_; }
 // Adds new outputs; useful when mutating the graph. Status ExpandOutputs(int new\_output\_size);
 private: // Creates and stores shapes for use in InferenceContext. class ShapeManager { public: ShapeManager(); ~ShapeManager();
 // Returns a new shape with the given dims. The returned value is owned by // this class. ShapeHandle MakeShape(const std::vector<DimensionHandle>& dims);
 // Returns a new unknown shape. ShapeHandle UnknownShape();
 // Returns a new dimension of the given size. The returned value // is owned by this class. inline DimensionHandle MakeDim(DimensionOrConstant d) { if (d.dim.IsSet()) { return d.dim; } else { all\_dims\_.push\_back(new Dimension(d.val)); return all\_dims\_.back(); } }
 private: std::vector<Shape\*> all\_shapes\_; // values are owned. std::vector<Dimension\*> all\_dims\_; // values are owned. };
 friend class ::tensorflow::grappler::GraphProperties;
 friend class ShapeInferenceTest; // For testing Relax functions. friend class ShapeInferenceTestutil; // For testing shapes.
 // Shared initialization across the two constructors. Remove // once we get rid of one of them. void PreInputInit(const OpDef& op\_def, const std::vector<const Tensor\*>& input\_tensors, const std::vector<ShapeHandle>& input\_tensors\_as\_shapes); void PostInputInit(std::vector<std::unique\_ptr<std::vector<ShapeAndType>>> input\_handle\_data);
 Status ReturnUnknownShape(ShapeHandle\* out) { \*out = UnknownShape(); return Status::OK(); } Status ReturnCreatedShape(const std::vector<DimensionHandle>& dims, ShapeHandle\* out) { \*out = MakeShape(dims); return Status::OK(); }
 // Adds additional context to the given status. Status AttachContext(const Status& status);
 // Relaxes an existing value <d\_old> with a new value <d\_new> and returns the // relaxed dimension in <\*out>. If <d\_old> and <d\_new> have incompatible // values, returns an error. // // Note that <\*out> may be set to <d\_old> or <d\_new>. void Relax(DimensionHandle d\_old, DimensionHandle d\_new, DimensionHandle\* out); // Relaxes an existing shape <s\_old> with a new shape <s\_new> and returns the // relaxed shape in <\*out>. See 'RelaxInput' function for full details and // examples. void Relax(ShapeHandle s\_old, ShapeHandle s\_new, ShapeHandle\* out);
 // Used to implement MergeInputHandleShapesAndTypes and // MergeOutputHandleShapesAndTypes. bool MergeHandleShapesAndTypes( const std::vector<ShapeAndType>& shapes\_and\_types, std::vector<ShapeAndType>\* to\_update) TF\_MUST\_USE\_RESULT; // Used to implement RelaxInputHandleShapesAndMergeTypes and // RelaxOutputHandleShapesAndMergeTypes. bool RelaxHandleShapesAndMergeTypes( const std::vector<ShapeAndType>& shapes\_and\_types, std::vector<ShapeAndType>\* to\_update) TF\_MUST\_USE\_RESULT;
 // Forget all the previous merged shapes and dims. void ForgetMerges() { merged\_shapes\_.clear(); merged\_dims\_.clear(); }
 // Helper method for MakeShapeFromTensor and MakeShapeFromShapeTensor. Status InternalMakeShapeFromTensor( bool treat\_unknown\_scalar\_tensor\_as\_unknown\_shape, const Tensor\* t, ShapeHandle tensor\_shape, ShapeHandle\* out);
 ShapeManager shape\_manager\_;
 // inputs\_, outputs\_, and input\_tensors\_as\_shapes\_ refer to values from // `shape\_manager\_`. std::vector<ShapeHandle> inputs\_; std::vector<const Tensor\*> input\_tensors\_; std::vector<bool> requested\_input\_tensor\_; std::vector<ShapeHandle> outputs\_; // Can have fewer elements than inputs\_. std::vector<ShapeHandle> input\_tensors\_as\_shapes\_; std::vector<bool> requested\_input\_tensor\_as\_partial\_shape\_;
 // input\_handle\_shapes\_and\_types\_[i] is the list of shape/type pairs available // through the resource handle passed along input i of the node. // // Values may be NULL. std::vector<std::unique\_ptr<std::vector<ShapeAndType>>> input\_handle\_shapes\_and\_types\_;
 // output\_handle\_shapes\_and\_types\_[i] is the list of shape/type pairs // available through the resource handle passed along output i of the node. // // Values may be NULL. std::vector<std::unique\_ptr<std::vector<ShapeAndType>>> output\_handle\_shapes\_and\_types\_;
 // Return types for the node this context is associated with. This information // is to eventually consolidate all the dtype and shape info, allowing for // output\_handle\_shapes\_and\_types\_ to be removed. FullTypeDef ret\_types\_;
 const int graph\_def\_version\_; AttrSlice attrs\_; NameRangeMap input\_name\_map\_; NameRangeMap output\_name\_map\_;
 // An error set during construction. TODO(cwhipkey): remove when test // constructor is removed. Status construction\_status\_;
 // Pair of shape or dim handles that are equivalent, ie that represent the // same underlying shape of dimension. Note that for each pair at least one of // the handles must contain an unknown shape, since we don't keep track of // known shapes or dims here. std::vector<std::pair<ShapeHandle, ShapeHandle>> merged\_shapes\_; std::vector<std::pair<DimensionHandle, DimensionHandle>> merged\_dims\_;
 TF\_DISALLOW\_COPY\_AND\_ASSIGN(InferenceContext);};
// -----------------------------------------------------------------------------// Template and inline method implementations, please ignore
inline Dimension::Dimension() : value\_(InferenceContext::kUnknownDim) {}inline Dimension::Dimension(int64\_t value) : value\_(value) { DCHECK(value >= 0 || value == InferenceContext::kUnknownDim) << "Dimension must be non-negative or equal to " "InferenceContext::kUnknownDim but got " << value;}
inline Shape::Shape() : rank\_(InferenceContext::kUnknownRank) {}inline Shape::Shape(const std::vector<DimensionHandle>& dims) : rank\_(dims.size()), dims\_(dims) {}
inline DimensionOrConstant::DimensionOrConstant(DimensionHandle dim) : dim(dim) { DCHECK(dim.IsSet()) << "Internal error: Got nullptr for Dimension.";}
inline DimensionOrConstant::DimensionOrConstant(int64\_t val) : val(val) { DCHECK(val >= 0 || val == InferenceContext::kUnknownDim) << "Dimension must be non-negative or equal to " "InferenceContext::kUnknownDim but got " << val;}
template <class T>Status InferenceContext::GetAttr(StringPiece attr\_name, T\* value) const { return GetNodeAttr(attrs\_, attr\_name, value);}
} // namespace shape\_inference} // namespace tensorflow
#endif // TENSORFLOW\_CORE\_FRAMEWORK\_SHAPE\_INFERENCE\_H\_

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_3167070d_20250114_181034.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2F37c01fb5e25c3d80213060460196406c43d31995)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2F37c01fb5e25c3d80213060460196406c43d31995)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fcommit_fragments%2Frepo_layout&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  826](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Commit

[Permalink](/tensorflow/tensorflow/commit/37c01fb5e25c3d80213060460196406c43d31995)

This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.

Fix out of bound error in ReverseSequence Op shape function

[Browse files](/tensorflow/tensorflow/tree/37c01fb5e25c3d80213060460196406c43d31995)
Browse the repository at this point in the history

```
PiperOrigin-RevId: 411896080
Change-Id: I7e59a38e2f960886edf2b6c54ed5a84e86a9b193
```

* Loading branch information

[![@ishark](https://avatars.githubusercontent.com/u/723624?s=40&v=4)](/ishark) [![@tensorflower-gardener](https://avatars.githubusercontent.com/u/17151892?s=40&v=4)](/tensorflower-gardener)

[ishark](/tensorflow/tensorflow/commits?author=ishark "View all commits by ishark")
authored and
[tensorflower-gardener](/tensorflow/tensorflow/commits?author=tensorflower-gardener "View all commits by tensorflower-gardener")
committed
Nov 23, 2021

1 parent
[3218043](/tensorflow/tensorflow/commit/3218043d6d3a019756607643cf65574fbfef5d7a)

commit 37c01fb

Showing
**1 changed file**
with
**10 additions**
and
**0 deletions**.

* Whitespace
* Ignore whitespace

* Split
* Unified

## There are no files selected for viewing

10 changes: 10 additions & 0 deletions

10
[tensorflow/core/ops/array\_ops.cc](#diff-b66fb13cef30f4e05f1551ba813bd2c1024bf8269809a0ff2c62676c6d4331a6 "tensorflow/core/ops/array_ops.cc")

Show comments

[View file](/tensorflow/tensorflow/blob/37c01fb5e25c3d80213060460196406c43d31995/tensorflow/core/ops/array_ops.cc)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -1653,11 +1653,21 @@ REGISTER\_OP("ReverseSequence") |
|  |  | return errors::InvalidArgument( |
|  |  | "batch\_dim must be < input rank: ", batch\_dim, " vs. ", input\_rank); |
|  |  | } |
|  |  |  |
|  |  | if (seq\_dim >= input\_rank) { |
|  |  | return errors::InvalidArgument( |
|  |  | "seq\_dim must be < input rank: ", seq\_dim, " vs. ", input\_rank); |
|  |  | } |
|  |  |  |
|  |  | // To prevent out of bound access when calling c->Dim(input, batch\_dim), |
|  |  | // batch\_dim range [-1 \* input rank, input rank) is allowed. However, |
|  |  | // the op implementation has a stricter bound for batch\_dim requiring >= 0 |
|  |  | // value. Thus, perform strict check here. |
|  |  | if (batch\_dim < 0) { |
|  |  | return errors::InvalidArgument("batch\_dim must be >=0, got ", |
|  |  | batch\_dim); |
|  |  | } |
|  |  |  |
|  |  | DimensionHandle batch\_dim\_dim = c->Dim(input, batch\_dim); |
|  |  | TF\_RETURN\_IF\_ERROR( |
|  |  | c->Merge(batch\_dim\_dim, c->Dim(seq\_lens\_shape, 0), &batch\_dim\_dim)); |
| Expand Down | |  |

Toggle all file notes
Toggle all file annotations

### 0 comments on commit `37c01fb`

Please
[sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2F37c01fb5e25c3d80213060460196406c43d31995) to comment.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_b127704d_20250114_181033.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2F5100e359aef5c8021f2e71c7b986420b85ce7b3d%2Ftensorflow%2Fcore%2Fops%2Farray_ops.cc)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2F5100e359aef5c8021f2e71c7b986420b85ce7b3d%2Ftensorflow%2Fcore%2Fops%2Farray_ops.cc)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  826](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Files

 5100e35
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d)
2. /[tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core)
4. /[ops](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/ops)
/
# array\_ops.cc

Copy path Blame  Blame
## Latest commit

## History

[History](/tensorflow/tensorflow/commits/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/ops/array_ops.cc)3415 lines (3082 loc) · 119 KB 5100e35
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d)
2. /[tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core)
4. /[ops](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/ops)
/
# array\_ops.cc

Top
## File metadata and controls

* Code
* Blame

3415 lines (3082 loc) · 119 KB[Raw](https://github.com/tensorflow/tensorflow/raw/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/ops/array_ops.cc)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000/\* Copyright 2015 The TensorFlow Authors. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");you may not use this file except in compliance with the License.You may obtain a copy of the License at
 http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.==============================================================================\*/
#include <algorithm>#include <ostream>
#include "tensorflow/core/framework/common\_shape\_fns.h"#include "tensorflow/core/framework/kernel\_shape\_util.h"#include "tensorflow/core/framework/op.h"#include "tensorflow/core/framework/shape\_inference.h"#include "tensorflow/core/framework/tensor.pb.h"#include "tensorflow/core/framework/types.h"#include "tensorflow/core/framework/types.pb.h"#include "tensorflow/core/lib/core/errors.h"#include "tensorflow/core/util/mirror\_pad\_mode.h"#include "tensorflow/core/util/padding.h"#include "tensorflow/core/util/strided\_slice\_op.h"#include "tensorflow/core/util/tensor\_format.h"
namespace tensorflow {
using shape\_inference::DimensionHandle;using shape\_inference::InferenceContext;using shape\_inference::ShapeHandle;using shape\_inference::UnchangedShape;
namespace {
Status GetAxisForPackAndUnpack(InferenceContext\* c, int32\_t rank\_after\_pack, int32\* axis) { TF\_RETURN\_IF\_ERROR(c->GetAttr("axis", axis)); if (\*axis < -1 \* rank\_after\_pack || \*axis >= rank\_after\_pack) { return errors::InvalidArgument("Invalid axis: ", \*axis, "; must be in [", -1 \* rank\_after\_pack, ",", rank\_after\_pack, ")"); } if (\*axis < 0) \*axis = (rank\_after\_pack + \*axis); return Status::OK();}
template <typename T>std::vector<int64\_t> AsInt64(const Tensor\* tensor, int64\_t num\_elements) { std::vector<int64\_t> ret(num\_elements); auto data = tensor->vec<T>(); for (int64\_t i = 0; i < num\_elements; ++i) { ret[i] = data(i); } return ret;}
template <typename T>Status PadKnown(InferenceContext\* c, ShapeHandle input, const Tensor\* paddings\_t, int64\_t num\_dims) { // paddings\_t is known. std::vector<DimensionHandle> dims(num\_dims); auto paddings\_data = paddings\_t->matrix<T>(); for (int64\_t i = 0; i < num\_dims; ++i) { const T pad0 = paddings\_data(i, 0); const T pad1 = paddings\_data(i, 1); if (pad0 < 0 || pad1 < 0) { return errors::InvalidArgument("Paddings must be non-negative"); } TF\_RETURN\_IF\_ERROR(c->Add(c->Dim(input, i), pad0 + pad1, &dims[i])); } c->set\_output(0, c->MakeShape(dims)); return Status::OK();}
Status PadShapeFn(InferenceContext\* c) { // Paddings is a matrix of [input\_rank, 2]. ShapeHandle paddings; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 2, &paddings)); DimensionHandle unused; TF\_RETURN\_IF\_ERROR(c->WithValue(c->Dim(paddings, 1), 2, &unused));
 // n\_dim and input.rank are equivalent. ShapeHandle input = c->input(0); DimensionHandle n\_dim = c->Dim(paddings, 0); if (c->ValueKnown(n\_dim)) { TF\_RETURN\_IF\_ERROR(c->WithRank(input, c->Value(n\_dim), &input)); } else if (c->RankKnown(input)) { TF\_RETURN\_IF\_ERROR(c->WithValue(n\_dim, c->Rank(input), &n\_dim)); }
 const Tensor\* paddings\_t = c->input\_tensor(1);
 // paddings\_t is unknown if (paddings\_t == nullptr) { if (c->ValueKnown(n\_dim)) { // Make output with n\_dim unknown dims. c->set\_output(0, c->UnknownShapeOfRank(c->Value(n\_dim))); } else { c->set\_output(0, c->UnknownShape()); } return Status::OK(); }
 const int64\_t num\_dims = paddings\_t->shape().dim\_size(0); TF\_RETURN\_IF\_ERROR(c->WithRank(input, num\_dims, &input)); TF\_RETURN\_IF\_ERROR(c->WithValue(n\_dim, num\_dims, &n\_dim));
 if (paddings\_t->dtype() == DT\_INT32) { return PadKnown<int32>(c, input, paddings\_t, num\_dims); } else { return PadKnown<int64\_t>(c, input, paddings\_t, num\_dims); }}
Status TransposeShapeFn(InferenceContext\* c) { ShapeHandle input = c->input(0); ShapeHandle perm\_shape = c->input(1); const Tensor\* perm = c->input\_tensor(1); DimensionHandle perm\_elems = c->NumElements(perm\_shape); // If we don't have rank information on the input or value information on // perm we can't return any shape information, otherwise we have enough // information to at least find the rank of the output. if (!c->RankKnown(input) && !c->ValueKnown(perm\_elems) && perm == nullptr) { c->set\_output(0, c->UnknownShape()); return Status::OK(); }
 // Find our value of the rank. int64\_t rank; if (c->RankKnown(input)) { rank = c->Rank(input); } else if (c->ValueKnown(perm\_elems)) { rank = c->Value(perm\_elems); } else { rank = perm->NumElements(); } if (!c->RankKnown(input) && rank < 2) { // A permutation array containing a single element is ambiguous. It could // indicate either a scalar or a 1-dimensional array, both of which the // transpose op returns unchanged. c->set\_output(0, input); return Status::OK(); }
 std::vector<DimensionHandle> dims; dims.resize(rank); TF\_RETURN\_IF\_ERROR(c->WithRank(input, rank, &input)); // Ensure that perm is a vector and has rank elements. TF\_RETURN\_IF\_ERROR(c->WithRank(perm\_shape, 1, &perm\_shape)); TF\_RETURN\_IF\_ERROR(c->WithValue(perm\_elems, rank, &perm\_elems));
 // If we know the rank of the input and the value of perm, we can return // all shape information, otherwise we can only return rank information, // but no information for the dimensions. if (perm != nullptr) { std::vector<int64\_t> data; if (perm->dtype() == DT\_INT32) { data = AsInt64<int32>(perm, rank); } else { data = AsInt64<int64\_t>(perm, rank); }
 for (int32\_t i = 0; i < rank; ++i) { int64\_t in\_idx = data[i]; if (in\_idx >= rank || in\_idx <= -rank) { return errors::InvalidArgument("perm dim ", in\_idx, " is out of range of input rank ", rank); } dims[i] = c->Dim(input, in\_idx); } } else { for (int i = 0; i < rank; ++i) { dims[i] = c->UnknownDim(); } }
 c->set\_output(0, c->MakeShape(dims)); return Status::OK();}
Status SetOutputShapeForReshape(InferenceContext\* c) { ShapeHandle in = c->input(0); ShapeHandle out; TF\_RETURN\_IF\_ERROR(c->MakeShapeFromShapeTensor(1, &out));
 if (!c->RankKnown(out)) { // We have no information about the shape of the output. c->set\_output(0, out); return Status::OK(); } if (c->RankKnown(in)) { // We don't know the number of output elements, but we can try to infer // the missing dimension. bool too\_many\_unknown = false; int32\_t out\_unknown\_idx = -1;
 DimensionHandle known\_out\_elems = c->NumElements(out); if (!c->ValueKnown(known\_out\_elems)) { known\_out\_elems = c->MakeDim(1); for (int32\_t i = 0; i < c->Rank(out); ++i) { DimensionHandle dim = c->Dim(out, i); if (!c->ValueKnown(dim)) { if (out\_unknown\_idx >= 0) { too\_many\_unknown = true; break; } out\_unknown\_idx = i; } else { TF\_RETURN\_IF\_ERROR( c->Multiply(known\_out\_elems, dim, &known\_out\_elems)); } } } int32\_t in\_unknown\_idx = -1; DimensionHandle known\_in\_elems = c->NumElements(in); if (!c->ValueKnown(known\_in\_elems)) { known\_in\_elems = c->MakeDim(1); for (int32\_t i = 0; i < c->Rank(in); ++i) { DimensionHandle dim = c->Dim(in, i); if (!c->ValueKnown(dim)) { if (in\_unknown\_idx >= 0) { too\_many\_unknown = true; break; } in\_unknown\_idx = i; } else { TF\_RETURN\_IF\_ERROR(c->Multiply(known\_in\_elems, dim, &known\_in\_elems)); } } }
 if (!too\_many\_unknown) { if (in\_unknown\_idx < 0 && out\_unknown\_idx < 0) { // Just check that the dimensions match. if (c->Value(known\_in\_elems) != c->Value(known\_out\_elems)) { return errors::InvalidArgument( "Cannot reshape a tensor with ", c->DebugString(known\_in\_elems), " elements to shape ", c->DebugString(out), " (", c->DebugString(known\_out\_elems), " elements)"); } } else if (in\_unknown\_idx < 0 && out\_unknown\_idx >= 0 && c->Value(known\_out\_elems) > 0) { // Input fully known, infer the one missing output dim DimensionHandle inferred\_dim; TF\_RETURN\_IF\_ERROR(c->Divide(known\_in\_elems, c->Value(known\_out\_elems), true /\* evenly\_divisible \*/, &inferred\_dim)); TF\_RETURN\_IF\_ERROR( c->ReplaceDim(out, out\_unknown\_idx, inferred\_dim, &out));
 } else if (in\_unknown\_idx >= 0 && out\_unknown\_idx < 0 && c->Value(known\_in\_elems) != 0) { // Output fully known, infer the one missing input dim DimensionHandle inferred\_dim; TF\_RETURN\_IF\_ERROR(c->Divide(known\_out\_elems, c->Value(known\_in\_elems), true /\* evenly\_divisible \*/, &inferred\_dim)); DimensionHandle unknown\_in\_dim = c->Dim(in, in\_unknown\_idx); TF\_RETURN\_IF\_ERROR( c->Merge(unknown\_in\_dim, inferred\_dim, &unknown\_in\_dim)); } else if (in\_unknown\_idx >= 0 && out\_unknown\_idx >= 0) { // Exactly one unknown dimension in both input and output. These 2 are // equal iff the known elements are equal. if (c->Value(known\_in\_elems) == c->Value(known\_out\_elems)) { DimensionHandle unknown\_in\_dim = c->Dim(in, in\_unknown\_idx); TF\_RETURN\_IF\_ERROR( c->ReplaceDim(out, out\_unknown\_idx, unknown\_in\_dim, &out)); } } } } c->set\_output(0, out); return Status::OK();}
} // namespace
REGISTER\_OP("ParallelConcat") .Input("values: N \* T") .Output("output: T") .Attr("N: int >= 1") .Attr("T: type") .Attr("shape: shape") .SetShapeFn([](InferenceContext\* c) { // Validate that the shape attr is correct. PartialTensorShape shape; TF\_RETURN\_IF\_ERROR(c->GetAttr("shape", &shape)); ShapeHandle passed\_shape; TF\_RETURN\_IF\_ERROR( c->MakeShapeFromPartialTensorShape(shape, &passed\_shape)); if (!c->FullyDefined(passed\_shape)) { return errors::InvalidArgument("shape attr must be fully defined."); } ShapeHandle cur; TF\_RETURN\_IF\_ERROR(c->ReplaceDim( passed\_shape, 0, c->MakeDim(shape\_inference::DimensionOrConstant(1)), &cur)); for (int i = 0; i < c->num\_inputs(); ++i) { if (!c->FullyDefined(c->input(i))) { return errors::InvalidArgument( "All input shapes must be fully defined."); } DimensionHandle unused; if (!c->WithValue(c->Dim(c->input(i), 0), 1, &unused).ok()) { return errors::InvalidArgument("Size of first dimension must be 1."); } TF\_RETURN\_WITH\_CONTEXT\_IF\_ERROR(c->Merge(c->input(i), cur, &cur), "From merging shape ", i, " with other shapes."); }
 c->set\_output(0, passed\_shape);
 return Status::OK(); });
REGISTER\_OP("Pack") .Input("values: N \* T") .Output("output: T") .Attr("N: int >= 1") .Attr("T: type") .Attr("axis: int = 0") .SetShapeFn([](InferenceContext\* c) { // Validate shapes of all inputs are compatible ShapeHandle cur = c->input(c->num\_inputs() - 1); for (int i = c->num\_inputs() - 2; i >= 0; --i) { TF\_RETURN\_WITH\_CONTEXT\_IF\_ERROR(c->Merge(c->input(i), cur, &cur), "From merging shape ", i, " with other shapes."); } if (!c->RankKnown(cur)) { c->set\_output(0, c->UnknownShape()); return Status::OK(); } // Determine the axis that will be added, converting from negative // axes to a positive point per negative indexing rules. int32\_t rank = c->Rank(cur); int32\_t axis; TF\_RETURN\_IF\_ERROR(GetAxisForPackAndUnpack(c, rank + 1, &axis));
 // Copy all dimensions over, inserting a dimension of value #inputs // at <axis>. std::vector<DimensionHandle> dims; int index = 0; while (index < axis) dims.push\_back(c->Dim(cur, index++)); dims.push\_back(c->MakeDim(c->num\_inputs())); while (index < rank) dims.push\_back(c->Dim(cur, index++));
 c->set\_output(0, c->MakeShape(dims)); for (int i = 0; i < c->num\_inputs(); ++i) { auto\* shape\_and\_type = c->input\_handle\_shapes\_and\_types(i); if (shape\_and\_type) { if (!c->RelaxOutputHandleShapesAndMergeTypes(0, \*shape\_and\_type)) { c->set\_output\_handle\_shapes\_and\_types( 0, std::vector<shape\_inference::ShapeAndType>({})); break; } } } return Status::OK(); });
REGISTER\_OP("DeepCopy") .Input("x: T") .Output("y: T") .Attr("T: type") .SetIsStateful() .SetShapeFn(UnchangedShape);
REGISTER\_OP("InplaceUpdate") .Input("x: T") .Input("i: int32") .Input("v: T") .Output("y: T") .Attr("T: type") .SetShapeFn(UnchangedShape);
REGISTER\_OP("InplaceAdd") .Input("x: T") .Input("i: int32") .Input("v: T") .Output("y: T") .Attr("T: type") .SetShapeFn(UnchangedShape);
REGISTER\_OP("InplaceSub") .Input("x: T") .Input("i: int32") .Input("v: T") .Output("y: T") .Attr("T: type") .SetShapeFn(UnchangedShape);
REGISTER\_OP("Empty") .Input("shape: int32") .Output("output: dtype") .Attr("dtype: type") .Attr("init: bool = false") .SetDoNotOptimize() .SetShapeFn([](InferenceContext\* c) { ShapeHandle out; TF\_RETURN\_IF\_ERROR(c->MakeShapeFromShapeTensor(0, &out)); c->set\_output(0, out); return Status::OK(); });
// --------------------------------------------------------------------------REGISTER\_OP("Unpack") .Input("value: T") .Output("output: num \* T") .Attr("num: int >= 0") .Attr("T: type") .Attr("axis: int = 0") .SetShapeFn([](InferenceContext\* c) { ShapeHandle s = c->input(0); ShapeHandle out; if (c->RankKnown(s)) { // Determine the axis that will be removed, converting from negative // axes to a positive point per negative indexing rules. int32\_t rank = c->Rank(s); int32\_t axis; TF\_RETURN\_IF\_ERROR(GetAxisForPackAndUnpack(c, rank, &axis));
 // The axis dim matches the number of outputs. DimensionHandle unused; TF\_RETURN\_IF\_ERROR( c->WithValue(c->Dim(s, axis), c->num\_outputs(), &unused));
 // Copy all dimensions, removing the <axis> dimension. std::vector<DimensionHandle> dims; for (int i = 0; i < rank; ++i) { if (i != axis) dims.push\_back(c->Dim(s, i)); } out = c->MakeShape(dims); } else { // All outputs are the same shape, but it's not known. out = c->UnknownShape(); } for (int i = 0; i < c->num\_outputs(); ++i) c->set\_output(i, out); return Status::OK(); });
REGISTER\_OP("UnravelIndex") .Input("indices: Tidx") .Input("dims: Tidx") .Output("output: Tidx") .Attr("Tidx: {int32, int64} = DT\_INT32") .SetShapeFn([](InferenceContext\* c) { ShapeHandle indices = c->input(0); ShapeHandle dims; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 1, &dims)); if (c->RankKnown(indices) && c->Rank(indices) == 0) { c->set\_output(0, c->Vector(c->Dim(dims, 0))); } else if (c->RankKnown(indices)) { c->set\_output(0, c->Matrix(c->Dim(dims, 0), c->NumElements(indices))); } else { c->set\_output(0, c->UnknownShape()); } return Status::OK(); });
REGISTER\_OP("BroadcastTo") .Input("input: T") .Input("shape: Tidx") .Output("output: T") .Attr("T: type") .Attr("Tidx: {int32, int64} = DT\_INT32") .SetShapeFn([](InferenceContext\* c) { ShapeHandle shape\_in = c->input(1); TF\_RETURN\_IF\_ERROR(c->WithRank(shape\_in, 1, &shape\_in)); ShapeHandle out; TF\_RETURN\_IF\_ERROR(c->MakeShapeFromShapeTensor(1, &out)); if (!c->RankKnown(out)) { // We have no information about the shape of the output. c->set\_output(0, out); return Status::OK(); }
 ShapeHandle in = c->input(0); if (!c->RankKnown(in)) { // We have no information about the shape of the input, // nothing to do here. c->set\_output(0, out); return Status::OK(); } int out\_rank = c->Rank(out); TF\_RETURN\_IF\_ERROR(c->WithRankAtMost(in, out\_rank, &in)); int in\_rank = c->Rank(in); for (int i = 0; i < in\_rank; ++i) { auto in\_dim = c->Dim(in, in\_rank - i - 1); if (c->Value(in\_dim) > 1) { // If the input dimension is greater than 1 then the output dimension // must be equal to it, since we only broadcast "from left to right". auto out\_dim = c->Dim(out, out\_rank - i - 1); TF\_RETURN\_IF\_ERROR(c->Merge(in\_dim, out\_dim, &out\_dim)); TF\_RETURN\_IF\_ERROR( c->ReplaceDim(out, out\_rank - i - 1, out\_dim, &out)); } } c->set\_output(0, out); return Status::OK(); });
// --------------------------------------------------------------------------// TODO(josh11b): Remove the >= 2 constraint, once we can rewrite the graph// in the N == 1 case to remove the node.REGISTER\_OP("Concat") .Input("concat\_dim: int32") .Input("values: N \* T") .Output("output: T") .Attr("N: int >= 2") .Attr("T: type") .SetShapeFn([](InferenceContext\* c) { return shape\_inference::ConcatShape(c, c->num\_inputs() - 1); });
REGISTER\_OP("ConcatV2") .Input("values: N \* T") .Input("axis: Tidx") .Output("output: T") .Attr("N: int >= 2") .Attr("T: type") .Attr("Tidx: {int32, int64} = DT\_INT32") .SetShapeFn(shape\_inference::ConcatV2Shape);
// TODO(vivek.v.rane@intel.com): Prefix the op names with underscore if the ops// are not to be made user-accessible.#ifdef INTEL\_MKLREGISTER\_OP("\_MklConcatV2") .Input("values: N \* T") .Input("axis: Tidx") .Input("mkl\_values: N \* uint8") .Input("mkl\_axis: uint8") .Output("output: T") .Output("mkl\_output: uint8") .Attr("N: int >= 2") .Attr("T: type") .Attr("Tidx: {int32, int64} = DT\_INT32") .SetShapeFn(shape\_inference::ConcatV2Shape) .Doc(R"doc(MKL version of ConcatV2 operator. Uses MKL DNN APIs to perform concatenation.
NOTE Do not invoke this operator directly in Python. Graph rewrite pass isexpected to invoke these operators.)doc");#endif
REGISTER\_OP("ConcatOffset") .Input("concat\_dim: int32") .Input("shape: N \* int32") .Output("offset: N \* int32") .Attr("N: int >= 2") .SetShapeFn([](InferenceContext\* c) { for (int i = 1; i < c->num\_inputs(); ++i) { c->set\_output(i - 1, c->input(i)); } return Status::OK(); });
// --------------------------------------------------------------------------REGISTER\_OP("Split") .Input("split\_dim: int32") .Input("value: T") .Output("output: num\_split \* T") .Attr("num\_split: int >= 1") .Attr("T: type") .SetShapeFn([](InferenceContext\* c) { DimensionHandle split\_dimension; ShapeHandle input = c->input(1); TF\_RETURN\_IF\_ERROR(c->MakeDimForScalarInputWithNegativeIndexing( 0, c->Rank(input), &split\_dimension)); int num\_split = c->num\_outputs(); ShapeHandle out; if (!c->ValueKnown(split\_dimension)) { if (c->RankKnown(input)) { out = c->UnknownShapeOfRank(c->Rank(input)); } else { out = c->UnknownShape(); } } else { int64\_t split\_dim = c->Value(split\_dimension); TF\_RETURN\_IF\_ERROR(c->WithRankAtLeast(input, split\_dim + 1, &input)); DimensionHandle split\_dim\_size; TF\_RETURN\_WITH\_CONTEXT\_IF\_ERROR( c->Divide(c->Dim(input, split\_dim), num\_split, true /\* evenly\_divisible \*/, &split\_dim\_size), "Number of ways to split should evenly divide the split dimension"); TF\_RETURN\_IF\_ERROR( c->ReplaceDim(input, split\_dim, split\_dim\_size, &out)); } for (int i = 0; i < num\_split; ++i) c->set\_output(i, out); return Status::OK(); });
REGISTER\_OP("SplitV") .Input("value: T") .Input("size\_splits: Tlen") .Input("split\_dim: int32") .Output("output: num\_split \* T") .Attr("num\_split: int >= 1") .Attr("T: type") .Attr("Tlen: {int32, int64} = DT\_INT64") .SetShapeFn([](InferenceContext\* c) { DimensionHandle split\_dimension; ShapeHandle input = c->input(0); TF\_RETURN\_IF\_ERROR(c->MakeDimForScalarInputWithNegativeIndexing( 2, c->Rank(input), &split\_dimension)); int32\_t num\_outputs = c->num\_outputs(); int32\_t rank = c->Rank(input); ShapeHandle output\_shape; const Tensor\* size\_splits = c->input\_tensor(1); if (rank == InferenceContext::kUnknownRank) { // If the rank of input tensor is unknown, then return unknown shapes. // Note that the shape of each output can be different. for (int i = 0; i < num\_outputs; ++i) { c->set\_output(i, c->UnknownShape()); } } else if (rank == 0) { // Throw error if input is a scalar. return errors::InvalidArgument("Can't split scalars"); } else if (size\_splits == nullptr && c->ValueKnown(split\_dimension)) { // If split dimension is known, but the sizes are unknown, then // only the split dimension is unknown output\_shape = input; for (int i = 0; i < num\_outputs; ++i) { TF\_RETURN\_IF\_ERROR(c->ReplaceDim(output\_shape, c->Value(split\_dimension), c->UnknownDim(), &output\_shape)); c->set\_output(i, output\_shape); } } else if (size\_splits == nullptr && !c->ValueKnown(split\_dimension)) { // If split dimension or tensor containing the split sizes is unknown, // then return unknown shapes of same rank as input. Note that each // output shape can be different since splitv doesn't always split // tensors evenly. for (int i = 0; i < num\_outputs; ++i) { c->set\_output(i, c->UnknownShapeOfRank(rank)); } } else { // Determine the output shape if split dimension and split sizes are // known. int64\_t split\_dim = c->Value(split\_dimension); TF\_RETURN\_IF\_ERROR(c->WithRankAtLeast(input, split\_dim + 1, &input)); std::vector<int64\_t> data; if (size\_splits->dtype() == DT\_INT32) { data = AsInt64<int32>(size\_splits, size\_splits->shape().dim\_size(0)); } else { data = AsInt64<int64\_t>(size\_splits, size\_splits->shape().dim\_size(0)); } if (num\_outputs != data.size()) { return errors::InvalidArgument( "Length of size\_splits should be equal to num\_outputs"); } int64\_t total\_size = 0; bool has\_neg\_one = false; for (const auto size : data) { if (size == -1) { if (has\_neg\_one) { return errors::InvalidArgument( "size\_splits can only have one -1"); } has\_neg\_one = true; } else { total\_size += size; } } auto split\_dim\_size = c->Value(c->Dim(input, split\_dim)); // If the sizes of the splits are known, then // make sure that the sizes add up to the expected // dimension size, with the possibility of a -1. // Specify the full output shapes. for (int i = 0; i < num\_outputs; ++i) { auto size = data[i]; if (data[i] == -1 && c->ValueKnown(split\_dim\_size)) { size = split\_dim\_size - total\_size; } // If we have a negative known size (either explicit, or computed // via -1), then the split sizes are invalid. if (size < -1 || (size == -1 && c->ValueKnown(split\_dim\_size))) { return errors::InvalidArgument("Split size at index ", i, " must be >= 0. Got: ", size); } TF\_RETURN\_IF\_ERROR( c->ReplaceDim(input, split\_dim, c->MakeDim(size), &output\_shape)); c->set\_output(i, output\_shape); } if (c->ValueKnown(split\_dim\_size)) { if (has\_neg\_one ? total\_size > split\_dim\_size : total\_size != split\_dim\_size) { return errors::InvalidArgument( "can't split axis of size ", split\_dim\_size, " into pieces of size [", absl::StrJoin(data, ","), "]"); } } }
 return Status::OK(); });
// --------------------------------------------------------------------------REGISTER\_OP("Const") .Output("output: dtype") .Attr("value: tensor") .Attr("dtype: type") .SetShapeFn([](InferenceContext\* c) { const TensorProto\* proto = nullptr; TF\_RETURN\_IF\_ERROR(c->GetAttr("value", &proto)); TF\_RETURN\_IF\_ERROR(TensorShape::IsValidShape(proto->tensor\_shape())); TensorShape shape(proto->tensor\_shape()); std::vector<DimensionHandle> dims; dims.reserve(shape.dims()); for (int i = 0; i < shape.dims(); ++i) { dims.push\_back(c->MakeDim(shape.dim\_size(i))); } c->set\_output(0, c->MakeShape(dims)); return Status::OK(); });
// Returns a constant tensor on the host. Useful for writing C++ tests// and benchmarks which run on GPU but require arguments pinned to the host.// Used by test::graph::HostConstant.// value: Attr `value` is the tensor to return.REGISTER\_OP("HostConst") .Output("output: dtype") .Attr("value: tensor") .Attr("dtype: type") .SetShapeFn(shape\_inference::UnknownShape);
// Used executing op-by-op to copy constants to the current device without// serializing tensors as TensorProtos, after a host tensor has been// created. Same behavior as Identity, but no gradient and potentially relaxed// copy semantics.REGISTER\_OP("\_EagerConst") .Input("input: T") .Output("output: T") .Attr("T: type") .SetShapeFn(shape\_inference::UnchangedShape);
// --------------------------------------------------------------------------// TODO(mgubin): Update the doc when the freeze\_graph script supports converting// into memmapped format.REGISTER\_OP("ImmutableConst") .Attr("dtype: type") .Attr("shape: shape") .Attr("memory\_region\_name: string") .Output("tensor: dtype") .SetShapeFn(shape\_inference::ExplicitShape);
REGISTER\_OP("GuaranteeConst") .Input("input: T") .Output("output: T") .Attr("T: type") .SetShapeFn([](shape\_inference::InferenceContext\* c) { return UnchangedShape(c); }) // We don't want this to be optimized away. .SetDoNotOptimize();
// --------------------------------------------------------------------------REGISTER\_OP("ZerosLike") .Input("x: T") .Output("y: T") .Attr("T: type") .SetShapeFn(shape\_inference::UnchangedShape);
// --------------------------------------------------------------------------REGISTER\_OP("OnesLike") .Input("x: T") .Output("y: T") .Attr( "T: {bfloat16, half, float, double, int8, uint8, int16, uint16, int32, " "uint32, int64, uint64, complex64, complex128, bool}") .SetShapeFn(shape\_inference::UnchangedShape);
// --------------------------------------------------------------------------REGISTER\_OP("Diag") .Input("diagonal: T") .Output("output: T") .Attr( "T: {bfloat16, half, float, double, int32, int64, complex64, " "complex128}") .SetShapeFn([](InferenceContext\* c) { ShapeHandle in = c->input(0); TF\_RETURN\_IF\_ERROR(c->WithRankAtLeast(in, 1, &in)); // Output shape is original concatenated with itself. ShapeHandle out; TF\_RETURN\_IF\_ERROR(c->Concatenate(in, in, &out)); c->set\_output(0, out); return Status::OK(); });
// --------------------------------------------------------------------------REGISTER\_OP("DiagPart") .Input("input: T") .Output("diagonal: T") .Attr( "T: {bfloat16, half, float, double, int32, int64, complex64, " "complex128}") .SetShapeFn([](InferenceContext\* c) { ShapeHandle in = c->input(0); if (!c->RankKnown(in)) { c->set\_output(0, c->UnknownShape()); return Status::OK(); } // Rank must be even, and result will have rank <rank/2>. const int32\_t rank = c->Rank(in); if ((rank % 2) != 0 || rank <= 0) { return errors::InvalidArgument( "Input must have even and non-zero rank, input rank is ", rank); } const int32\_t mid = rank / 2;
 // output dim[i] is the merge of in.dim[i] and in.dim[i+mid]. std::vector<DimensionHandle> dims(mid); for (int i = 0; i < mid; ++i) { TF\_RETURN\_IF\_ERROR( c->Merge(c->Dim(in, i), c->Dim(in, i + mid), &dims[i])); } c->set\_output(0, c->MakeShape(dims)); return Status::OK(); });
// --------------------------------------------------------------------------REGISTER\_OP("MatrixDiag") .Input("diagonal: T") .Output("output: T") .Attr("T: type") .SetShapeFn([](InferenceContext\* c) { ShapeHandle in; TF\_RETURN\_IF\_ERROR(c->WithRankAtLeast(c->input(0), 1, &in)); if (!c->RankKnown(in)) { c->set\_output(0, c->UnknownShape()); return Status::OK(); } const int32\_t rank = c->Rank(in); ShapeHandle out; TF\_RETURN\_IF\_ERROR( c->Concatenate(in, c->Vector(c->Dim(in, rank - 1)), &out)); c->set\_output(0, out); return Status::OK(); });
REGISTER\_OP("MatrixDiagV2") .Input("diagonal: T") .Input("k: int32") .Input("num\_rows: int32") .Input("num\_cols: int32") .Input("padding\_value: T") .Output("output: T") .Attr("T: type") .SetShapeFn(shape\_inference::MatrixDiagV2Shape);
REGISTER\_OP("MatrixDiagV3") .Input("diagonal: T") .Input("k: int32") .Input("num\_rows: int32") .Input("num\_cols: int32") .Input("padding\_value: T") .Output("output: T") .Attr("T: type") .Attr( "align: {'LEFT\_RIGHT', 'RIGHT\_LEFT', 'LEFT\_LEFT', 'RIGHT\_RIGHT'} = " "'RIGHT\_LEFT'") .SetShapeFn(shape\_inference::MatrixDiagV2Shape);
// --------------------------------------------------------------------------REGISTER\_OP("MatrixSetDiag") .Input("input: T") .Input("diagonal: T") .Output("output: T") .Attr("T: type") .SetShapeFn([](InferenceContext\* c) { ShapeHandle input; ShapeHandle diag; TF\_RETURN\_IF\_ERROR(c->WithRankAtLeast(c->input(0), 2, &input)); TF\_RETURN\_IF\_ERROR(c->WithRankAtLeast(c->input(1), 1, &diag)); if (c->RankKnown(input)) { TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), c->Rank(input) - 1, &diag)); } DimensionHandle smallest\_dim; TF\_RETURN\_IF\_ERROR( c->Min(c->Dim(input, -2), c->Dim(input, -1), &smallest\_dim)); TF\_RETURN\_IF\_ERROR( c->Merge(smallest\_dim, c->Dim(diag, -1), &smallest\_dim));
 ShapeHandle output = input; if (c->RankKnown(diag) && !c->FullyDefined(input)) { // Try to infer parts of shape from diag. ShapeHandle diag\_batch\_shape; TF\_RETURN\_IF\_ERROR(c->Subshape(diag, 0, -1, &diag\_batch\_shape)); TF\_RETURN\_IF\_ERROR( c->Concatenate(diag\_batch\_shape, c->UnknownShapeOfRank(2), &diag)); TF\_RETURN\_IF\_ERROR(c->Merge(input, diag, &output)); } c->set\_output(0, output); return Status::OK(); });
REGISTER\_OP("MatrixSetDiagV2") .Input("input: T") .Input("diagonal: T") .Input("k: int32") .Output("output: T") .Attr("T: type") .SetShapeFn(shape\_inference::MatrixSetDiagV2Shape);
REGISTER\_OP("MatrixSetDiagV3") .Input("input: T") .Input("diagonal: T") .Input("k: int32") .Output("output: T") .Attr("T: type") .Attr( "align: {'LEFT\_RIGHT', 'RIGHT\_LEFT', 'LEFT\_LEFT', 'RIGHT\_RIGHT'} = " "'RIGHT\_LEFT'") .SetShapeFn(shape\_inference::MatrixSetDiagV2Shape);
// --------------------------------------------------------------------------REGISTER\_OP("MatrixDiagPart") .Input("input: T") .Output("diagonal: T") .Attr("T: type") .SetShapeFn([](InferenceContext\* c) { ShapeHandle in; TF\_RETURN\_IF\_ERROR(c->WithRankAtLeast(c->input(0), 2, &in)); if (!c->RankKnown(in)) { c->set\_output(0, c->UnknownShape()); return Status::OK(); } const int32\_t rank = c->Rank(in); std::vector<DimensionHandle> dims; dims.reserve(rank - 2); for (int i = 0; i < rank - 2; ++i) dims.push\_back(c->Dim(in, i));
 DimensionHandle min\_dim; TF\_RETURN\_IF\_ERROR( c->Min(c->Dim(in, rank - 2), c->Dim(in, rank - 1), &min\_dim)); dims.push\_back(min\_dim); c->set\_output(0, c->MakeShape(dims)); return Status::OK(); });
REGISTER\_OP("MatrixDiagPartV2") .Input("input: T") .Input("k: int32") .Input("padding\_value: T") .Output("diagonal: T") .Attr("T: type") .SetShapeFn(shape\_inference::MatrixDiagPartV2Shape);
REGISTER\_OP("MatrixDiagPartV3") .Input("input: T") .Input("k: int32") .Input("padding\_value: T") .Output("diagonal: T") .Attr("T: type") .Attr( "align: {'LEFT\_RIGHT', 'RIGHT\_LEFT', 'LEFT\_LEFT', 'RIGHT\_RIGHT'} = " "'RIGHT\_LEFT'") .SetShapeFn(shape\_inference::MatrixDiagPartV2Shape);
// --------------------------------------------------------------------------REGISTER\_OP("MatrixBandPart") .Input("input: T") .Input("num\_lower: Tindex") .Input("num\_upper: Tindex") .Output("band: T") .Attr("T: type") .Attr("Tindex: {int32, int64} = DT\_INT64") .SetShapeFn(shape\_inference::UnchangedShape);
// --------------------------------------------------------------------------REGISTER\_OP("Reverse") .Input("tensor: T") .Input("dims: bool") .Output("output: T") .Attr( "T: {uint8, int8, uint16, int16, uint32, int32, uint64, int64, bool, " "bfloat16, half, float, double, complex64, complex128, string}") .SetShapeFn([](InferenceContext\* c) { ShapeHandle input = c->input(0); ShapeHandle dims; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 1, &dims)); DimensionHandle dims\_dim = c->Dim(dims, 0); if (c->ValueKnown(dims\_dim)) { TF\_RETURN\_IF\_ERROR(c->WithRank(input, c->Value(dims\_dim), &input)); } if (c->Rank(input) > 8) { return errors::InvalidArgument( "reverse does not work on tensors with more than 8 dimensions"); } c->set\_output(0, input); return Status::OK();[View remainder of file in raw view](https://github.com/tensorflow/tensorflow/raw/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/core/ops/array_ops.cc)

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.


