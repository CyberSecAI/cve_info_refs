=== Content from github.com_211dc451_20250114_232929.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fsecurity%2Fadvisories%2FGHSA-gf2j-f278-xh4v)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fsecurity%2Fadvisories%2FGHSA-gf2j-f278-xh4v)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Frepos%2Fadvisories%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  828](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

# FPE in `BiasAndClamp` in TFLite

Low

[mihaimaruseac](/mihaimaruseac)
published
GHSA-gf2j-f278-xh4v
Feb 2, 2022

## Package

pip

tensorflow, tensorflow-cpu, tensorflow-gpu
([pip](/advisories?query=ecosystem%3Apip))

## Affected versions

< 2.8.0

## Patched versions

2.5.3, 2.6.3, 2.7.1

## Description

### Impact

An attacker can craft a TFLite model that would trigger a division by zero in [`BiasAndClamp` implementation](https://github.com/tensorflow/tensorflow/blob/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite/kernels/internal/common.h#L75):

```
inline void BiasAndClamp(float clamp_min, float clamp_max, int bias_size,
                         const float* bias_data, int array_size,
                         float* array_data) {
  // ...
  TFLITE_DCHECK_EQ((array_size % bias_size), 0);
  // ...
}
```

There is no check that the `bias_size` is non zero.

### Patches

We have patched the issue in GitHub commit [8c6f391a2282684a25cbfec7687bd5d35261a209](https://github.com/tensorflow/tensorflow/commit/8c6f391a2282684a25cbfec7687bd5d35261a209).

The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.

### For more information

Please consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.

### Attribution

This vulnerability has been reported by Wang Xuan of Qihoo 360 AIVul Team.

### Severity

Low

### CVE ID

CVE-2022-23557

### Weaknesses

No CWEs

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_01bbe6a1_20250114_232927.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2F8c6f391a2282684a25cbfec7687bd5d35261a209)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2F8c6f391a2282684a25cbfec7687bd5d35261a209)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fcommit_fragments%2Frepo_layout&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  828](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Commit

[Permalink](/tensorflow/tensorflow/commit/8c6f391a2282684a25cbfec7687bd5d35261a209)

This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.

[lite] Add check for bias\_size is zero to avoid division by zero. Thi…

[Browse files](/tensorflow/tensorflow/tree/8c6f391a2282684a25cbfec7687bd5d35261a209)
Browse the repository at this point in the history

```
…s shouldn't happen for properly converted models. Just safety check

PiperOrigin-RevId: 416383645
Change-Id: If8e508bf696ae8ecfb927e69c139a8ccf7fe60cb
```

* Loading branch information

[![@karimnosseir](https://avatars.githubusercontent.com/u/44206880?s=40&v=4)](/karimnosseir) [![@tensorflower-gardener](https://avatars.githubusercontent.com/u/17151892?s=40&v=4)](/tensorflower-gardener)

[karimnosseir](/tensorflow/tensorflow/commits?author=karimnosseir "View all commits by karimnosseir")
authored and
[tensorflower-gardener](/tensorflow/tensorflow/commits?author=tensorflower-gardener "View all commits by tensorflower-gardener")
committed
Dec 14, 2021

1 parent
[c8dafc9](/tensorflow/tensorflow/commit/c8dafc9f9ae6658d922e443e59e0f553167c990b)

commit 8c6f391

Showing
**1 changed file**
with
**1 addition**
and
**0 deletions**.

* Whitespace
* Ignore whitespace

* Split
* Unified

## There are no files selected for viewing

1 change: 1 addition & 0 deletions

1
[tensorflow/lite/kernels/internal/common.h](#diff-12b8b526d5fda290ee64fffd6db1c8b7908d6b375a79ac08335f9b6a76ff72ff "tensorflow/lite/kernels/internal/common.h")

Show comments

[View file](/tensorflow/tensorflow/blob/8c6f391a2282684a25cbfec7687bd5d35261a209/tensorflow/lite/kernels/internal/common.h)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -75,6 +75,7 @@ float ActivationFunction(float x) { |
|  |  | inline void BiasAndClamp(float clamp\_min, float clamp\_max, int bias\_size, |
|  |  | const float\* bias\_data, int array\_size, |
|  |  | float\* array\_data) { |
|  |  | if (bias\_size == 0) return; |
|  |  | // Note: see b/132215220: in May 2019 we thought it would be OK to replace |
|  |  | // this with the Eigen one-liner: |
|  |  | // return (array.colwise() + bias).cwiseMin(clamp\_max).cwiseMin(clamp\_max). |
| Expand Down | |  |

Toggle all file notes
Toggle all file annotations

### 0 comments on commit `8c6f391`

Please
[sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2F8c6f391a2282684a25cbfec7687bd5d35261a209) to comment.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_2b898574_20250114_232924.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2F5100e359aef5c8021f2e71c7b986420b85ce7b3d%2Ftensorflow%2Flite%2Fkernels%2Finternal%2Fcommon.h)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2F5100e359aef5c8021f2e71c7b986420b85ce7b3d%2Ftensorflow%2Flite%2Fkernels%2Finternal%2Fcommon.h)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  828](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Files

 5100e35
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d)
2. /[tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow)
3. /[lite](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite)
4. /[kernels](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite/kernels)
5. /[internal](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite/kernels/internal)
/
# common.h

Copy path Blame  Blame
## Latest commit

## History

[History](/tensorflow/tensorflow/commits/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite/kernels/internal/common.h)1083 lines (974 loc) · 42.8 KB 5100e35
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d)
2. /[tensorflow](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow)
3. /[lite](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite)
4. /[kernels](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite/kernels)
5. /[internal](/tensorflow/tensorflow/tree/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite/kernels/internal)
/
# common.h

Top
## File metadata and controls

* Code
* Blame

1083 lines (974 loc) · 42.8 KB[Raw](https://github.com/tensorflow/tensorflow/raw/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite/kernels/internal/common.h)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000/\* Copyright 2017 The TensorFlow Authors. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");you may not use this file except in compliance with the License.You may obtain a copy of the License at
 http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.==============================================================================\*/#ifndef TENSORFLOW\_LITE\_KERNELS\_INTERNAL\_COMMON\_H\_#define TENSORFLOW\_LITE\_KERNELS\_INTERNAL\_COMMON\_H\_
#ifndef ALLOW\_SLOW\_GENERIC\_DEPTHWISECONV\_FALLBACK#ifdef GEMMLOWP\_ALLOW\_SLOW\_SCALAR\_FALLBACK#define ALLOW\_SLOW\_GENERIC\_DEPTHWISECONV\_FALLBACK#endif#endif
#include <functional>
#include "fixedpoint/fixedpoint.h"#include "tensorflow/lite/kernels/internal/cppmath.h"#include "tensorflow/lite/kernels/internal/optimized/neon\_check.h"#include "tensorflow/lite/kernels/internal/types.h"
namespace tflite {
constexpr int kReverseShift = -1;
inline void GetActivationMinMax(FusedActivationFunctionType ac, float\* output\_activation\_min, float\* output\_activation\_max) { switch (ac) { case FusedActivationFunctionType::kNone: \*output\_activation\_min = std::numeric\_limits<float>::lowest(); \*output\_activation\_max = std::numeric\_limits<float>::max(); break; case FusedActivationFunctionType::kRelu: \*output\_activation\_min = 0.f; \*output\_activation\_max = std::numeric\_limits<float>::max(); break; case FusedActivationFunctionType::kRelu1: \*output\_activation\_min = -1.f; \*output\_activation\_max = 1.f; break; case FusedActivationFunctionType::kRelu6: \*output\_activation\_min = 0.f; \*output\_activation\_max = 6.f; break; }}
template <typename T>inline T ActivationFunctionWithMinMax(T x, T output\_activation\_min, T output\_activation\_max) { using std::max; using std::min; return min(max(x, output\_activation\_min), output\_activation\_max);}
// Legacy function, left for compatibility only.template <FusedActivationFunctionType Ac>float ActivationFunction(float x) { float output\_activation\_min, output\_activation\_max; GetActivationMinMax(Ac, &output\_activation\_min, &output\_activation\_max); return ActivationFunctionWithMinMax(x, output\_activation\_min, output\_activation\_max);}
inline void BiasAndClamp(float clamp\_min, float clamp\_max, int bias\_size, const float\* bias\_data, int array\_size, float\* array\_data) { // Note: see b/132215220: in May 2019 we thought it would be OK to replace // this with the Eigen one-liner: // return (array.colwise() + bias).cwiseMin(clamp\_max).cwiseMin(clamp\_max). // This turned out to severely regress performance: +4ms (i.e. 8%) on // MobileNet v2 / 1.0 / 224. So we keep custom NEON code for now. TFLITE\_DCHECK\_EQ((array\_size % bias\_size), 0);#ifdef USE\_NEON float\* array\_ptr = array\_data; float\* array\_end\_ptr = array\_ptr + array\_size; const auto clamp\_min\_vec = vdupq\_n\_f32(clamp\_min); const auto clamp\_max\_vec = vdupq\_n\_f32(clamp\_max); for (; array\_ptr != array\_end\_ptr; array\_ptr += bias\_size) { int i = 0; for (; i <= bias\_size - 16; i += 16) { auto b0 = vld1q\_f32(bias\_data + i); auto b1 = vld1q\_f32(bias\_data + i + 4); auto b2 = vld1q\_f32(bias\_data + i + 8); auto b3 = vld1q\_f32(bias\_data + i + 12); auto a0 = vld1q\_f32(array\_ptr + i); auto a1 = vld1q\_f32(array\_ptr + i + 4); auto a2 = vld1q\_f32(array\_ptr + i + 8); auto a3 = vld1q\_f32(array\_ptr + i + 12); auto x0 = vaddq\_f32(a0, b0); auto x1 = vaddq\_f32(a1, b1); auto x2 = vaddq\_f32(a2, b2); auto x3 = vaddq\_f32(a3, b3); x0 = vmaxq\_f32(clamp\_min\_vec, x0); x1 = vmaxq\_f32(clamp\_min\_vec, x1); x2 = vmaxq\_f32(clamp\_min\_vec, x2); x3 = vmaxq\_f32(clamp\_min\_vec, x3); x0 = vminq\_f32(clamp\_max\_vec, x0); x1 = vminq\_f32(clamp\_max\_vec, x1); x2 = vminq\_f32(clamp\_max\_vec, x2); x3 = vminq\_f32(clamp\_max\_vec, x3); vst1q\_f32(array\_ptr + i, x0); vst1q\_f32(array\_ptr + i + 4, x1); vst1q\_f32(array\_ptr + i + 8, x2); vst1q\_f32(array\_ptr + i + 12, x3); } for (; i <= bias\_size - 4; i += 4) { auto b = vld1q\_f32(bias\_data + i); auto a = vld1q\_f32(array\_ptr + i); auto x = vaddq\_f32(a, b); x = vmaxq\_f32(clamp\_min\_vec, x); x = vminq\_f32(clamp\_max\_vec, x); vst1q\_f32(array\_ptr + i, x); } for (; i < bias\_size; i++) { array\_ptr[i] = ActivationFunctionWithMinMax(array\_ptr[i] + bias\_data[i], clamp\_min, clamp\_max); } }#else // not NEON for (int array\_offset = 0; array\_offset < array\_size; array\_offset += bias\_size) { for (int i = 0; i < bias\_size; i++) { array\_data[array\_offset + i] = ActivationFunctionWithMinMax( array\_data[array\_offset + i] + bias\_data[i], clamp\_min, clamp\_max); } }#endif}
inline int32\_t MultiplyByQuantizedMultiplierSmallerThanOneExp( int32\_t x, int32\_t quantized\_multiplier, int left\_shift) { using gemmlowp::RoundingDivideByPOT; using gemmlowp::SaturatingRoundingDoublingHighMul; return RoundingDivideByPOT( SaturatingRoundingDoublingHighMul(x, quantized\_multiplier), -left\_shift);}
inline int32\_t MultiplyByQuantizedMultiplierGreaterThanOne( int32\_t x, int32\_t quantized\_multiplier, int left\_shift) { using gemmlowp::SaturatingRoundingDoublingHighMul; return SaturatingRoundingDoublingHighMul(x \* (1 << left\_shift), quantized\_multiplier);}
inline int32\_t MultiplyByQuantizedMultiplier(int32\_t x, int32\_t quantized\_multiplier, int shift) { using gemmlowp::RoundingDivideByPOT; using gemmlowp::SaturatingRoundingDoublingHighMul; int left\_shift = shift > 0 ? shift : 0; int right\_shift = shift > 0 ? 0 : -shift; return RoundingDivideByPOT(SaturatingRoundingDoublingHighMul( x \* (1 << left\_shift), quantized\_multiplier), right\_shift);}
inline int32\_t MultiplyByQuantizedMultiplier(int64\_t x, int32\_t quantized\_multiplier, int shift) { // Inputs: // - quantized\_multiplier has fixed point at bit 31 // - shift is -31 to +7 (negative for right shift) // // Assumptions: The following input ranges are assumed // - quantize\_scale>=0 (the usual range is (1<<30) to (1>>31)-1) // - scaling is chosen so final scaled result fits in int32\_t // - input x is in the range -(1<<47) <= x < (1<<47) assert(quantized\_multiplier >= 0); assert(shift >= -31 && shift < 8); assert(x >= -(static\_cast<int64\_t>(1) << 47) && x < (static\_cast<int64\_t>(1) << 47));
 int32\_t reduced\_multiplier = (quantized\_multiplier < 0x7FFF0000) ? ((quantized\_multiplier + (1 << 15)) >> 16) : 0x7FFF; int total\_shift = 15 - shift; x = (x \* (int64\_t)reduced\_multiplier) + ((int64\_t)1 << (total\_shift - 1)); int32\_t result = x >> total\_shift; return result;}
#ifdef USE\_NEON// Round uses ARM's rounding shift right.inline int32x4x4\_t MultiplyByQuantizedMultiplier4Rows( int32x4x4\_t input\_val, int32\_t quantized\_multiplier, int shift) { const int left\_shift = std::max(shift, 0); const int right\_shift = std::min(shift, 0); int32x4x4\_t result;
 int32x4\_t multiplier\_dup = vdupq\_n\_s32(quantized\_multiplier); int32x4\_t left\_shift\_dup = vdupq\_n\_s32(left\_shift); int32x4\_t right\_shift\_dup = vdupq\_n\_s32(right\_shift);
 result.val[0] = vrshlq\_s32(vqrdmulhq\_s32(vshlq\_s32(input\_val.val[0], left\_shift\_dup), multiplier\_dup), right\_shift\_dup);
 result.val[1] = vrshlq\_s32(vqrdmulhq\_s32(vshlq\_s32(input\_val.val[1], left\_shift\_dup), multiplier\_dup), right\_shift\_dup);
 result.val[2] = vrshlq\_s32(vqrdmulhq\_s32(vshlq\_s32(input\_val.val[2], left\_shift\_dup), multiplier\_dup), right\_shift\_dup);
 result.val[3] = vrshlq\_s32(vqrdmulhq\_s32(vshlq\_s32(input\_val.val[3], left\_shift\_dup), multiplier\_dup), right\_shift\_dup);
 return result;}#endif
template <typename T>int CountLeadingZeros(T integer\_input) { static\_assert(std::is\_unsigned<T>::value, "Only unsigned integer types handled.");#if defined(\_\_GNUC\_\_) return integer\_input ? \_\_builtin\_clz(integer\_input) : std::numeric\_limits<T>::digits;#else if (integer\_input == 0) { return std::numeric\_limits<T>::digits; }
 const T one\_in\_leading\_positive = static\_cast<T>(1) << (std::numeric\_limits<T>::digits - 1); int leading\_zeros = 0; while (integer\_input < one\_in\_leading\_positive) { integer\_input <<= 1; ++leading\_zeros; } return leading\_zeros;#endif}
template <typename T>inline int CountLeadingSignBits(T integer\_input) { static\_assert(std::is\_signed<T>::value, "Only signed integer types handled.");#if defined(\_\_GNUC\_\_) && !defined(\_\_clang\_\_) return integer\_input ? \_\_builtin\_clrsb(integer\_input) : std::numeric\_limits<T>::digits;#else using U = typename std::make\_unsigned<T>::type; return integer\_input >= 0 ? CountLeadingZeros(static\_cast<U>(integer\_input)) - 1 : integer\_input != std::numeric\_limits<T>::min() ? CountLeadingZeros(2 \* static\_cast<U>(-integer\_input) - 1) : 0;#endif}
// Use "count leading zeros" helper functions to do a fast Floor(log\_2(x)).template <typename Integer>inline Integer FloorLog2(Integer n) { static\_assert(std::is\_integral<Integer>::value, ""); static\_assert(std::is\_signed<Integer>::value, ""); static\_assert(sizeof(Integer) == 4 || sizeof(Integer) == 8, ""); TFLITE\_CHECK\_GT(n, 0); if (sizeof(Integer) == 4) { return 30 - CountLeadingSignBits(n); } else { return 62 - CountLeadingSignBits(n); }}
// The size of the LUT depends on the type of input. For int8 inputs a simple// 256 entries LUT is used. For int16 inputs the high 9 bits are used for// indexing and the 7 remaining bits are used for interpolation. We thus use a// 513-entries LUT for int16 cases, 512 for the 9-bit indexing and 1 extra entry// to interpolate the last value.template <typename LutInT>constexpr int lut\_size() { static\_assert(std::is\_same<LutInT, int8\_t>::value || std::is\_same<LutInT, int16\_t>::value, "Only LUTs with int8 or int16 inputs are supported."); return std::is\_same<LutInT, int8\_t>::value ? 256 : 513;}
// Generate a LUT for 'func' which can be used to approximate functions like// exp, log, ...//// - func: the function to build the LUT for (e.g exp(x))// - input\_min, input\_max: range of the func inputs// - output\_min, output\_max: range of the func outputs// - lut: pointer to the LUT table to fill, the table must be of size// lut\_size<LutInT>()template <typename FloatT, typename LutInT, typename LutOutT>inline void gen\_lut(FloatT (\*func)(FloatT), FloatT input\_min, FloatT input\_max, FloatT output\_min, FloatT output\_max, LutOutT\* lut) { static\_assert(std::is\_same<LutInT, int8\_t>::value || std::is\_same<LutInT, int16\_t>::value, "Only LUTs with int8 or int16 inputs are supported."); static\_assert(std::is\_same<LutOutT, int8\_t>::value || std::is\_same<LutOutT, int16\_t>::value, "Only LUTs with int8 or int16 outputs are supported."); static\_assert(std::is\_floating\_point<FloatT>::value, "FloatT must be a floating-point type.");
 const int nb\_steps = std::is\_same<LutInT, int8\_t>::value ? 256 : 512; const FloatT step = (input\_max - input\_min) / nb\_steps; const FloatT half\_step = step / 2; const FloatT output\_scaling\_inv = static\_cast<FloatT>(std::numeric\_limits<LutOutT>::max() - std::numeric\_limits<LutOutT>::min() + 1) / (output\_max - output\_min); const FloatT table\_min = static\_cast<FloatT>(std::numeric\_limits<LutOutT>::min()); const FloatT table\_max = static\_cast<FloatT>(std::numeric\_limits<LutOutT>::max());
 for (int i = 0; i < nb\_steps; i++) { const FloatT val = func(input\_min + i \* step); const FloatT val\_midpoint = func(input\_min + i \* step + half\_step); const FloatT val\_next = func(input\_min + (i + 1) \* step);
 const FloatT sample\_val = TfLiteRound(val \* output\_scaling\_inv); const FloatT midpoint\_interp\_val = TfLiteRound((val\_next \* output\_scaling\_inv + TfLiteRound(val \* output\_scaling\_inv)) / 2); const FloatT midpoint\_val = TfLiteRound(val\_midpoint \* output\_scaling\_inv); const FloatT midpoint\_err = midpoint\_interp\_val - midpoint\_val; const FloatT bias = TfLiteRound(midpoint\_err / 2);
 lut[i] = static\_cast<LutOutT>(std::min<FloatT>( std::max<FloatT>(sample\_val - bias, table\_min), table\_max)); }
 const bool with\_extra\_interpolation\_value = std::is\_same<LutInT, int16\_t>::value; if (with\_extra\_interpolation\_value) { lut[nb\_steps] = static\_cast<LutOutT>(std::min<FloatT>( std::max<FloatT>(TfLiteRound(func(input\_max) \* output\_scaling\_inv), table\_min), table\_max)); }}
// LUT must have 513 valuestemplate <typename LutOutT>inline LutOutT lut\_lookup\_with\_interpolation(int16\_t value, const LutOutT\* lut) { static\_assert(std::is\_same<LutOutT, int8\_t>::value || std::is\_same<LutOutT, int16\_t>::value, "Only LUTs with int8 or int16 outputs are supported."); // 512 base values, lut[513] is only used to calculate the slope const uint16\_t index = static\_cast<uint16\_t>(256 + (value >> 7)); assert(index < 512 && "LUT index out of range."); const int16\_t offset = value & 0x7f;
 // Base and slope are Q0.x const LutOutT base = lut[index]; const LutOutT slope = lut[index + 1] - lut[index];
 // Q0.x \* Q0.7 = Q0.(x + 7) // Round and convert from Q0.(x + 7) to Q0.x const int delta = (slope \* offset + 64) >> 7;
 // Q0.15 + Q0.15 return static\_cast<LutOutT>(base + delta);}
// int16\_t -> int16\_t table lookup with interpolation// LUT must have 513 valuesinline int16\_t lut\_lookup(int16\_t value, const int16\_t\* lut) { return lut\_lookup\_with\_interpolation(value, lut);}
// int16\_t -> int8\_t table lookup with interpolation// LUT must have 513 valuesinline int8\_t lut\_lookup(int16\_t value, const int8\_t\* lut) { return lut\_lookup\_with\_interpolation(value, lut);}
// int8\_t -> int8\_t table lookup without interpolation// LUT must have 256 valuesinline int8\_t lut\_lookup(int8\_t value, const int8\_t\* lut) { return lut[128 + value];}
// int8\_t -> int16\_t table lookup without interpolation// LUT must have 256 valuesinline int16\_t lut\_lookup(int8\_t value, const int16\_t\* lut) { return lut[128 + value];}
// Table of sigmoid(i/24) at 0.16 format - 256 elements.
// We use combined sigmoid and tanh look-up table, since// tanh(x) = 2\*sigmoid(2\*x) -1.// Both functions are symmetric, so the LUT table is only needed// for the absolute value of the input.static const uint16\_t sigmoid\_table\_uint16[256] = { 32768, 33451, 34133, 34813, 35493, 36169, 36843, 37513, 38180, 38841, 39498, 40149, 40794, 41432, 42064, 42688, 43304, 43912, 44511, 45102, 45683, 46255, 46817, 47369, 47911, 48443, 48964, 49475, 49975, 50464, 50942, 51409, 51865, 52311, 52745, 53169, 53581, 53983, 54374, 54755, 55125, 55485, 55834, 56174, 56503, 56823, 57133, 57433, 57724, 58007, 58280, 58544, 58800, 59048, 59288, 59519, 59743, 59959, 60168, 60370, 60565, 60753, 60935, 61110, 61279, 61441, 61599, 61750, 61896, 62036, 62172, 62302, 62428, 62549, 62666, 62778, 62886, 62990, 63090, 63186, 63279, 63368, 63454, 63536, 63615, 63691, 63765, 63835, 63903, 63968, 64030, 64090, 64148, 64204, 64257, 64308, 64357, 64405, 64450, 64494, 64536, 64576, 64614, 64652, 64687, 64721, 64754, 64786, 64816, 64845, 64873, 64900, 64926, 64950, 64974, 64997, 65019, 65039, 65060, 65079, 65097, 65115, 65132, 65149, 65164, 65179, 65194, 65208, 65221, 65234, 65246, 65258, 65269, 65280, 65291, 65301, 65310, 65319, 65328, 65337, 65345, 65352, 65360, 65367, 65374, 65381, 65387, 65393, 65399, 65404, 65410, 65415, 65420, 65425, 65429, 65433, 65438, 65442, 65445, 65449, 65453, 65456, 65459, 65462, 65465, 65468, 65471, 65474, 65476, 65479, 65481, 65483, 65485, 65488, 65489, 65491, 65493, 65495, 65497, 65498, 65500, 65501, 65503, 65504, 65505, 65507, 65508, 65509, 65510, 65511, 65512, 65513, 65514, 65515, 65516, 65517, 65517, 65518, 65519, 65520, 65520, 65521, 65522, 65522, 65523, 65523, 65524, 65524, 65525, 65525, 65526, 65526, 65526, 65527, 65527, 65528, 65528, 65528, 65529, 65529, 65529, 65529, 65530, 65530, 65530, 65530, 65531, 65531, 65531, 65531, 65531, 65532, 65532, 65532, 65532, 65532, 65532, 65533, 65533, 65533, 65533, 65533, 65533, 65533, 65533, 65534, 65534, 65534, 65534, 65534, 65534, 65534, 65534, 65534, 65534, 65535};
// TODO(b/77858996): Add these to gemmlowp.template <typename IntegerType>IntegerType SaturatingAddNonGemmlowp(IntegerType a, IntegerType b) { static\_assert(std::is\_same<IntegerType, void>::value, "unimplemented"); return a;}
template <>inline std::int32\_t SaturatingAddNonGemmlowp(std::int32\_t a, std::int32\_t b) { std::int64\_t a64 = a; std::int64\_t b64 = b; std::int64\_t sum = a64 + b64; return static\_cast<std::int32\_t>(std::min( static\_cast<std::int64\_t>(std::numeric\_limits<std::int32\_t>::max()), std::max( static\_cast<std::int64\_t>(std::numeric\_limits<std::int32\_t>::min()), sum)));}
template <typename tRawType, int tIntegerBits>gemmlowp::FixedPoint<tRawType, tIntegerBits> SaturatingAddNonGemmlowp( gemmlowp::FixedPoint<tRawType, tIntegerBits> a, gemmlowp::FixedPoint<tRawType, tIntegerBits> b) { return gemmlowp::FixedPoint<tRawType, tIntegerBits>::FromRaw( SaturatingAddNonGemmlowp(a.raw(), b.raw()));}
template <typename IntegerType>IntegerType SaturatingSub(IntegerType a, IntegerType b) { static\_assert(std::is\_same<IntegerType, void>::value, "unimplemented"); return a;}
template <>inline std::int16\_t SaturatingSub(std::int16\_t a, std::int16\_t b) { std::int32\_t a32 = a; std::int32\_t b32 = b; std::int32\_t diff = a32 - b32; return static\_cast<std::int16\_t>( std::min(static\_cast<int32\_t>(32767), std::max(static\_cast<int32\_t>(-32768), diff)));}
template <>inline std::int32\_t SaturatingSub(std::int32\_t a, std::int32\_t b) { std::int64\_t a64 = a; std::int64\_t b64 = b; std::int64\_t diff = a64 - b64; return static\_cast<std::int32\_t>(std::min( static\_cast<std::int64\_t>(std::numeric\_limits<std::int32\_t>::max()), std::max( static\_cast<std::int64\_t>(std::numeric\_limits<std::int32\_t>::min()), diff)));}
template <typename tRawType, int tIntegerBits>gemmlowp::FixedPoint<tRawType, tIntegerBits> SaturatingSub( gemmlowp::FixedPoint<tRawType, tIntegerBits> a, gemmlowp::FixedPoint<tRawType, tIntegerBits> b) { return gemmlowp::FixedPoint<tRawType, tIntegerBits>::FromRaw( SaturatingSub(a.raw(), b.raw()));}// End section to be moved to gemmlowp.
template <typename IntegerType>IntegerType SaturatingRoundingMultiplyByPOTParam(IntegerType x, int exponent) { if (exponent == 0) { return x; } using ScalarIntegerType = typename gemmlowp::FixedPointRawTypeTraits<IntegerType>::ScalarRawType; const IntegerType min = gemmlowp::Dup<IntegerType>(std::numeric\_limits<ScalarIntegerType>::min()); const IntegerType max = gemmlowp::Dup<IntegerType>(std::numeric\_limits<ScalarIntegerType>::max()); const int ScalarIntegerTypeBits = 8 \* sizeof(ScalarIntegerType);
 const std::int32\_t threshold = ((1 << (ScalarIntegerTypeBits - 1 - exponent)) - 1); const IntegerType positive\_mask = gemmlowp::MaskIfGreaterThan(x, gemmlowp::Dup<IntegerType>(threshold)); const IntegerType negative\_mask = gemmlowp::MaskIfLessThan(x, gemmlowp::Dup<IntegerType>(-threshold));
 IntegerType result = gemmlowp::ShiftLeft(x, exponent); result = gemmlowp::SelectUsingMask(positive\_mask, max, result); result = gemmlowp::SelectUsingMask(negative\_mask, min, result); return result;}
// If we want to leave IntegerBits fixed, then multiplication// by a power of two has to be saturating/rounding, not exact anymore.template <typename tRawType, int tIntegerBits>gemmlowp::FixedPoint<tRawType, tIntegerBits>SaturatingRoundingMultiplyByPOTParam( gemmlowp::FixedPoint<tRawType, tIntegerBits> a, int exponent) { return gemmlowp::FixedPoint<tRawType, tIntegerBits>::FromRaw( SaturatingRoundingMultiplyByPOTParam(a.raw(), exponent));}
// Convert int32\_t multiplier to int16\_t with rounding.inline void DownScaleInt32ToInt16Multiplier(int32\_t multiplier\_int32\_t, int16\_t\* multiplier\_int16\_t) { TFLITE\_DCHECK\_GE(multiplier\_int32\_t, 0); static constexpr int32\_t kRoundingOffset = 1 << 15; if (multiplier\_int32\_t >= std::numeric\_limits<int32\_t>::max() - kRoundingOffset) { \*multiplier\_int16\_t = std::numeric\_limits<int16\_t>::max(); return; } const int32\_t result = (multiplier\_int32\_t + kRoundingOffset) >> 16; TFLITE\_DCHECK\_LE(result << 16, multiplier\_int32\_t + kRoundingOffset); TFLITE\_DCHECK\_GT(result << 16, multiplier\_int32\_t - kRoundingOffset); \*multiplier\_int16\_t = result; TFLITE\_DCHECK\_EQ(\*multiplier\_int16\_t, result);}
// Minimum output bits to accommodate log of maximum input range. It actually// does not matter if one considers, say, [-64,64] or [-64,64).//// For example, run this through Octave:// [0:127; ...// ceil(log(abs( log(2.^(0:127))+1 ))/log(2)); ...// ceil(log(abs( log(2.^(0:127))+1 ))/log(2))]constexpr int min\_log\_x\_output\_bits(int input\_bits) { return input\_bits > 90 ? 7 : input\_bits > 44 ? 6 : input\_bits > 21 ? 5 : input\_bits > 10 ? 4 : input\_bits > 4 ? 3 : input\_bits > 1 ? 2 : 1;}
// Although currently the name of this function says that it cannot handle// values less than 1, in practice it can handle as low as 1/x\_max, where// x\_max is the largest representable input. In other words, the output range// is symmetric.template <int OutputIntegerBits, int InputIntegerBits>inline gemmlowp::FixedPoint<int32\_t, OutputIntegerBits>log\_x\_for\_x\_greater\_than\_or\_equal\_to\_1\_impl( gemmlowp::FixedPoint<int32\_t, InputIntegerBits> input\_val) { // assert(\_\_builtin\_clz(0u) >= std::numeric\_limits<uint32\_t>::digits - 1); // assert(\_\_builtin\_clz(0u) <= std::numeric\_limits<uint32\_t>::digits); using FixedPoint0 = gemmlowp::FixedPoint<int32\_t, 0>; // The reason for accumulating the result with an extra bit of headroom is // that z\_pow\_2\_adj \* log\_2 might be saturated, and adding num\_scaled \* // recip\_denom will otherwise introduce an error. static constexpr int kAccumIntegerBits = OutputIntegerBits + 1; using FixedPointAccum = gemmlowp::FixedPoint<int32\_t, kAccumIntegerBits>;
 const FixedPoint0 log\_2 = GEMMLOWP\_CHECKED\_FIXEDPOINT\_CONSTANT( FixedPoint0, 1488522236, std::log(2.0)); const FixedPoint0 sqrt\_sqrt\_half = GEMMLOWP\_CHECKED\_FIXEDPOINT\_CONSTANT( FixedPoint0, 1805811301, std::sqrt(std::sqrt(0.5))); const FixedPoint0 sqrt\_half = GEMMLOWP\_CHECKED\_FIXEDPOINT\_CONSTANT( FixedPoint0, 1518500250, std::sqrt(0.5)); const FixedPoint0 one\_quarter = GEMMLOWP\_CHECKED\_FIXEDPOINT\_CONSTANT(FixedPoint0, 536870912, 1.0 / 4.0);
 const FixedPoint0 alpha\_n = GEMMLOWP\_CHECKED\_FIXEDPOINT\_CONSTANT( FixedPoint0, 117049297, 11.0 / 240.0 \* std::sqrt(std::sqrt(2.0))); const FixedPoint0 alpha\_d = GEMMLOWP\_CHECKED\_FIXEDPOINT\_CONSTANT( FixedPoint0, 127690142, 1.0 / 20.0 \* std::sqrt(std::sqrt(2.0))); const FixedPoint0 alpha\_i = GEMMLOWP\_CHECKED\_FIXEDPOINT\_CONSTANT( FixedPoint0, 1057819769, 2.0 / std::sqrt(std::sqrt(2.0)) - std::sqrt(std::sqrt(2.0))); const FixedPoint0 alpha\_f = GEMMLOWP\_CHECKED\_FIXEDPOINT\_CONSTANT( FixedPoint0, 638450708, 1.0 / 4.0 \* std::sqrt(std::sqrt(2.0)));
 const FixedPointAccum shifted\_quarter = gemmlowp::Rescale<kAccumIntegerBits>(one\_quarter);
 // Reinterpret the input value as Q0.31, because we will figure out the // required shift "ourselves" instead of using, say, Rescale. FixedPoint0 z\_a = FixedPoint0::FromRaw(input\_val.raw()); // z\_a\_pow\_2 = input\_integer\_bits - z\_a\_headroom; int z\_a\_headroom\_plus\_1 = CountLeadingZeros(static\_cast<uint32\_t>(z\_a.raw())); FixedPoint0 r\_a\_tmp = SaturatingRoundingMultiplyByPOTParam(z\_a, (z\_a\_headroom\_plus\_1 - 1)); const int32\_t r\_a\_raw = SaturatingRoundingMultiplyByPOTParam((r\_a\_tmp \* sqrt\_half).raw(), 1); // z\_pow\_2\_adj = max(z\_pow\_2\_a - 0.75, z\_pow\_2\_b - 0.25); // z\_pow\_2\_adj = max(InputIntegerBits - z\_a\_headroom\_plus\_1 + 0.25, // InputIntegerBits - z\_b\_headroom - 0.25); const FixedPointAccum z\_a\_pow\_2\_adj = SaturatingAddNonGemmlowp( FixedPointAccum::FromRaw(SaturatingRoundingMultiplyByPOTParam( static\_cast<int32\_t>(InputIntegerBits - z\_a\_headroom\_plus\_1), 31 - kAccumIntegerBits)), shifted\_quarter);
 // z\_b is treated like z\_a, but premultiplying by sqrt(0.5). FixedPoint0 z\_b = z\_a \* sqrt\_half; int z\_b\_headroom = CountLeadingZeros(static\_cast<uint32\_t>(z\_b.raw())) - 1; const int32\_t r\_b\_raw = SaturatingRoundingMultiplyByPOTParam(z\_a.raw(), z\_b\_headroom); const FixedPointAccum z\_b\_pow\_2\_adj = SaturatingSub( FixedPointAccum::FromRaw(SaturatingRoundingMultiplyByPOTParam( static\_cast<int32\_t>(InputIntegerBits - z\_b\_headroom), 31 - kAccumIntegerBits)), shifted\_quarter);
 const FixedPoint0 r = FixedPoint0::FromRaw(std::min(r\_a\_raw, r\_b\_raw)); const FixedPointAccum z\_pow\_2\_adj = FixedPointAccum::FromRaw( std::max(z\_a\_pow\_2\_adj.raw(), z\_b\_pow\_2\_adj.raw()));
 const FixedPoint0 p = gemmlowp::RoundingHalfSum(r, sqrt\_sqrt\_half); FixedPoint0 q = r - sqrt\_sqrt\_half; q = q + q;
 const FixedPoint0 common\_sq = q \* q; const FixedPoint0 num = q \* r + q \* common\_sq \* alpha\_n; const FixedPoint0 denom\_minus\_one\_0 = p \* (alpha\_i + q + alpha\_d \* common\_sq) + alpha\_f \* q; const FixedPoint0 recip\_denom = one\_over\_one\_plus\_x\_for\_x\_in\_0\_1(denom\_minus\_one\_0);
 const FixedPointAccum num\_scaled = gemmlowp::Rescale<kAccumIntegerBits>(num); return gemmlowp::Rescale<OutputIntegerBits>(z\_pow\_2\_adj \* log\_2 + num\_scaled \* recip\_denom);}
template <int OutputIntegerBits, int InputIntegerBits>inline gemmlowp::FixedPoint<int32\_t, OutputIntegerBits>log\_x\_for\_x\_greater\_than\_or\_equal\_to\_1( gemmlowp::FixedPoint<int32\_t, InputIntegerBits> input\_val) { static\_assert( OutputIntegerBits >= min\_log\_x\_output\_bits(InputIntegerBits), "Output integer bits must be sufficient to accommodate logs of inputs."); return log\_x\_for\_x\_greater\_than\_or\_equal\_to\_1\_impl<OutputIntegerBits, InputIntegerBits>( input\_val);}
inline int32\_t GetReciprocal(int32\_t x, int x\_integer\_digits, int\* num\_bits\_over\_unit) { int headroom\_plus\_one = CountLeadingZeros(static\_cast<uint32\_t>(x)); // This is the number of bits to the left of the binary point above 1.0. // Consider x=1.25. In that case shifted\_scale=0.8 and // no later adjustment will be needed. \*num\_bits\_over\_unit = x\_integer\_digits - headroom\_plus\_one; const int32\_t shifted\_sum\_minus\_one = static\_cast<int32\_t>((static\_cast<uint32\_t>(x) << headroom\_plus\_one) - (static\_cast<uint32\_t>(1) << 31));
 gemmlowp::FixedPoint<int32\_t, 0> shifted\_scale = gemmlowp::one\_over\_one\_plus\_x\_for\_x\_in\_0\_1( gemmlowp::FixedPoint<int32\_t, 0>::FromRaw(shifted\_sum\_minus\_one)); return shifted\_scale.raw();}
inline void GetInvSqrtQuantizedMultiplierExp(int32\_t input, int reverse\_shift, int32\_t\* output\_inv\_sqrt, int\* output\_shift) { TFLITE\_DCHECK\_GE(input, 0); if (input <= 1) { // Handle the input value 1 separately to avoid overflow in that case // in the general computation below (b/143972021). Also handle 0 as if it // were a 1. 0 is an invalid input here (divide by zero) and 1 is a valid // but rare/unrealistic input value. We can expect both to occur in some // incompletely trained models, but probably not in fully trained models. \*output\_inv\_sqrt = std::numeric\_limits<std::int32\_t>::max(); \*output\_shift = 0; return; } TFLITE\_DCHECK\_GT(input, 1); \*output\_shift = 11; while (input >= (1 << 29)) { input /= 4; ++\*output\_shift; } const unsigned max\_left\_shift\_bits = CountLeadingZeros(static\_cast<uint32\_t>(input)) - 1; const unsigned max\_left\_shift\_bit\_pairs = max\_left\_shift\_bits / 2; const unsigned left\_shift\_bit\_pairs = max\_left\_shift\_bit\_pairs - 1; \*output\_shift -= left\_shift\_bit\_pairs; input <<= 2 \* left\_shift\_bit\_pairs; TFLITE\_DCHECK\_GE(input, (1 << 27)); TFLITE\_DCHECK\_LT(input, (1 << 29)); using gemmlowp::FixedPoint; using gemmlowp::Rescale; using gemmlowp::SaturatingRoundingMultiplyByPOT; // Using 3 integer bits gives us enough room for the internal arithmetic in // this Newton-Raphson iteration. using F3 = FixedPoint<int32\_t, 3>; using F0 = FixedPoint<int32\_t, 0>; const F3 fixedpoint\_input = F3::FromRaw(input >> 1); const F3 fixedpoint\_half\_input = SaturatingRoundingMultiplyByPOT<-1>(fixedpoint\_input); const F3 fixedpoint\_half\_three = GEMMLOWP\_CHECKED\_FIXEDPOINT\_CONSTANT(F3, (1 << 28) + (1 << 27), 1.5); // Newton-Raphson iteration // Naive unoptimized starting guess: x = 1 F3 x = F3::One(); // Naive unoptimized number of iterations: 5 for (int i = 0; i < 5; i++) { const F3 x3 = Rescale<3>(x \* x \* x); x = Rescale<3>(fixedpoint\_half\_three \* x - fixedpoint\_half\_input \* x3); } const F0 fixedpoint\_half\_sqrt\_2 = GEMMLOWP\_CHECKED\_FIXEDPOINT\_CONSTANT(F0, 1518500250, std::sqrt(2.) / 2.); x = x \* fixedpoint\_half\_sqrt\_2; \*output\_inv\_sqrt = x.raw(); if (\*output\_shift < 0) { \*output\_inv\_sqrt <<= -\*output\_shift; \*output\_shift = 0; } // Convert right shift (right is positive) to left shift. \*output\_shift \*= reverse\_shift;}
// DO NOT USE THIS STRUCT FOR NEW FUNCTIONALITY BEYOND IMPLEMENTING// BROADCASTING.//// NdArrayDesc<N> describes the shape and memory layout of an N-dimensional// rectangular array of numbers.//// NdArrayDesc<N> is basically identical to Dims<N> defined in types.h.// However, as Dims<N> is to be deprecated, this class exists as an adaptor// to enable simple unoptimized implementations of element-wise broadcasting// operations.template <int N>struct NdArrayDesc { // The "extent" of each dimension. Indices along dimension d must be in the // half-open interval [0, extents[d]). int extents[N];
 // The number of \*elements\* (not bytes) between consecutive indices of each // dimension. int strides[N];};
// DO NOT USE THIS FUNCTION FOR NEW FUNCTIONALITY BEYOND IMPLEMENTING// BROADCASTING.//// Same as Offset(), except takes as NdArrayDesc<N> instead of Dims<N>.inline int SubscriptToIndex(const NdArrayDesc<4>& desc, int i0, int i1, int i2, int i3) { TFLITE\_DCHECK(i0 >= 0 && i0 < desc.extents[0]); TFLITE\_DCHECK(i1 >= 0 && i1 < desc.extents[1]); TFLITE\_DCHECK(i2 >= 0 && i2 < desc.extents[2]); TFLITE\_DCHECK(i3 >= 0 && i3 < desc.extents[3]); return i0 \* desc.strides[0] + i1 \* desc.strides[1] + i2 \* desc.strides[2] + i3 \* desc.strides[3];}
inline int SubscriptToIndex(const NdArrayDesc<5>& desc, int indexes[5]) { return indexes[0] \* desc.strides[0] + indexes[1] \* desc.strides[1] + indexes[2] \* desc.strides[2] + indexes[3] \* desc.strides[3] + indexes[4] \* desc.strides[4];}
inline int SubscriptToIndex(const NdArrayDesc<8>& desc, int indexes[8]) { return indexes[0] \* desc.strides[0] + indexes[1] \* desc.strides[1] + indexes[2] \* desc.strides[2] + indexes[3] \* desc.strides[3] + indexes[4] \* desc.strides[4] + indexes[5] \* desc.strides[5] + indexes[6] \* desc.strides[6] + indexes[7] \* desc.strides[7];}
// Given the dimensions of the operands for an element-wise binary broadcast,// adjusts them so that they can be directly iterated over with simple loops.// Returns the adjusted dims as instances of NdArrayDesc in 'desc0\_out' and// 'desc1\_out'. 'desc0\_out' and 'desc1\_out' cannot be nullptr.//// This function assumes that the two input shapes are compatible up to// broadcasting and the shorter one has already been prepended with 1s to be the// same length. E.g., if shape0 is (1, 16, 16, 64) and shape1 is (1, 64),// shape1 must already have been prepended to be (1, 1, 1, 64). Recall that// Dims<N> refer to shapes in reverse order. In this case, input0\_dims will be// (64, 16, 16, 1) and input1\_dims will be (64, 1, 1, 1).//// When two shapes are compatible up to broadcasting, for each dimension d,// the input extents are either equal, or one of them is 1.//// This function performs the following for each dimension d:// - If the extents are equal, then do nothing since the loop that walks over// both of the input arrays is correct.// - Otherwise, one (and only one) of the extents must be 1. Say extent0 is 1// and extent1 is e1. Then set extent0 to e1 and stride0 \*to 0\*. This allows// array0 to be referenced \*at any index\* in dimension d and still access the// same slice.template <int N>inline void NdArrayDescsForElementwiseBroadcast(const Dims<N>& input0\_dims, const Dims<N>& input1\_dims, NdArrayDesc<N>\* desc0\_out, NdArrayDesc<N>\* desc1\_out) { TFLITE\_DCHECK(desc0\_out != nullptr); TFLITE\_DCHECK(desc1\_out != nullptr);
 // Copy dims to desc. for (int i = 0; i < N; ++i) { desc0\_out->extents[i] = input0\_dims.sizes[i]; desc0\_out->strides[i] = input0\_dims.strides[i]; desc1\_out->extents[i] = input1\_dims.sizes[i]; desc1\_out->strides[i] = input1\_dims.strides[i]; }
 // Walk over each dimension. If the extents are equal do nothing. // Otherwise, set the desc with extent 1 to have extent equal to the other and // stride 0. for (int i = 0; i < N; ++i) { const int extent0 = ArraySize(input0\_dims, i); const int extent1 = ArraySize(input1\_dims, i); if (extent0 != extent1) { if (extent0 == 1) { desc0\_out->strides[i] = 0; desc0\_out->extents[i] = extent1; } else { TFLITE\_DCHECK\_EQ(extent1, 1); desc1\_out->strides[i] = 0; desc1\_out->extents[i] = extent0; } } }}
// Copies dims to desc, calculating strides.template <int N>inline void CopyDimsToDesc(const RuntimeShape& input\_shape, NdArrayDesc<N>\* desc\_out) { int desc\_stride = 1; for (int i = N - 1; i >= 0; --i) { desc\_out->extents[i] = input\_shape.Dims(i); desc\_out->strides[i] = desc\_stride; desc\_stride \*= input\_shape.Dims(i); }}
template <int N>inline void NdArrayDescsForElementwiseBroadcast( const RuntimeShape& input0\_shape, const RuntimeShape& input1\_shape, NdArrayDesc<N>\* desc0\_out, NdArrayDesc<N>\* desc1\_out) { TFLITE\_DCHECK(desc0\_out != nullptr); TFLITE\_DCHECK(desc1\_out != nullptr);
 auto extended\_input0\_shape = RuntimeShape::ExtendedShape(N, input0\_shape); auto extended\_input1\_shape = RuntimeShape::ExtendedShape(N, input1\_shape);
 // Copy dims to desc, calculating strides. CopyDimsToDesc<N>(extended\_input0\_shape, desc0\_out); CopyDimsToDesc<N>(extended\_input1\_shape, desc1\_out);
 // Walk over each dimension. If the extents are equal do nothing. // Otherwise, set the desc with extent 1 to have extent equal to the other and // stride 0. for (int i = 0; i < N; ++i) { const int extent0 = extended\_input0\_shape.Dims(i); const int extent1 = extended\_input1\_shape.Dims(i); if (extent0 != extent1) { if (extent0 == 1) { desc0\_out->strides[i] = 0; desc0\_out->extents[i] = extent1; } else { TFLITE\_DCHECK\_EQ(extent1, 1); desc1\_out->strides[i] = 0; desc1\_out->extents[i] = extent0; } } }}
template <int N>inline void NdArrayDescsForElementwiseBroadcast( const RuntimeShape& input0\_shape, const RuntimeShape& input1\_shape, const RuntimeShape& input2\_shape, NdArrayDesc<N>\* desc0\_out, NdArrayDesc<N>\* desc1\_out, NdArrayDesc<N>\* desc2\_out) { TFLITE\_DCHECK(desc0\_out != nullptr); TFLITE\_DCHECK(desc1\_out != nullptr); TFLITE\_DCHECK(desc2\_out != nullptr);
 auto extended\_input0\_shape = RuntimeShape::ExtendedShape(N, input0\_shape); auto extended\_input1\_shape = RuntimeShape::ExtendedShape(N, input1\_shape); auto extended\_input2\_shape = RuntimeShape::ExtendedShape(N, input2\_shape);
 // Copy dims to desc, calculating strides. CopyDimsToDesc<N>(extended\_input0\_shape, desc0\_out); CopyDimsToDesc<N>(extended\_input1\_shape, desc1\_out); CopyDimsToDesc<N>(extended\_input2\_shape, desc2\_out);
 // Walk over each dimension. If the extents are equal do nothing. // Otherwise, set the desc with extent 1 to have extent equal to the other and // stride 0. for (int i = 0; i < N; ++i) { const int extent0 = extended\_input0\_shape.Dims(i); const int extent1 = extended\_input1\_shape.Dims(i); const int extent2 = extended\_input2\_shape.Dims(i);
 int extent = extent0; if (extent1 != 1) extent = extent1; if (extent2 != 1) extent = extent2;
 TFLITE\_DCHECK(extent0 == 1 || extent0 == extent); TFLITE\_DCHECK(extent1 == 1 || extent1 == extent); TFLITE\_DCHECK(extent2 == 1 || extent2 == extent);
 if (!(extent0 == extent1 && extent1 == extent2)) { if (extent0 == 1) { desc0\_out->strides[i] = 0; desc0\_out->extents[i] = extent; } if (extent1 == 1) { desc1\_out->strides[i] = 0; desc1\_out->extents[i] = extent; } if (extent2 == 1) { desc2\_out->strides[i] = 0; desc2\_out->extents[i] = extent; } } }}
// Detailed implementation of NDOpsHelper, the indexes must be a zero array.// This implementation is equivalent to N nested loops. Ex, if N=4, it can be// re-writen as:// for (int b = 0; b < output.extents[0]; ++b) {// for (int y = 0; y < output.extents[1]; ++y) {// for (int x = 0; x < output.extents[2]; ++x) {// for (int c = 0; c < output.extents[3]; ++c) {// calc({b,y,x,c});// }// }// }// }template <int N, int DIM, typename Calc>typename std::enable\_if<DIM != N - 1, void>::type NDOpsHelperImpl( const NdArrayDesc<N>& output, const Calc& calc, int indexes[N]) { for (indexes[DIM] = 0; indexes[DIM] < output.extents[DIM]; ++indexes[DIM]) { NDOpsHelperImpl<N, DIM + 1, Calc>(output, calc, indexes); }}
template <int N, int DIM, typename Calc>typename std::enable\_if<DIM == N - 1, void>::type NDOpsHelperImpl( const NdArrayDesc<N>& output, const Calc& calc, int indexes[N]) { for (indexes[DIM] = 0; indexes[DIM] < output.extents[DIM]; ++indexes[DIM]) { calc(indexes); }}
// Execute the calc function in the innermost iteration based on the shape of// the output. The calc function should take a single argument of type int[N].template <int N, typename Calc>inline void NDOpsHelper(const NdArrayDesc<N>& output, const Calc& calc) { int indexes[N] = {0}; NDOpsHelperImpl<N, 0, Calc>(output, calc, indexes);}// Copied from gemmlowp::RoundDown when we dropped direct dependency on// gemmlowp.//// Returns the runtime argument rounded down to the nearest multiple of// the fixed Modulus.template <unsigned Modulus, typename Integer>Integer RoundDown(Integer i) { return i - (i % Modulus);}
// Copied from gemmlowp::RoundUp when we dropped direct dependency on// gemmlowp.//// Returns the runtime argument rounded up to the nearest multiple of// the fixed Modulus.template <unsigned Modulus, typename Integer>Integer RoundUp(Integer i) { return RoundDown<Modulus>(i + Modulus - 1);}[View remainder of file in raw view](https://github.com/tensorflow/tensorflow/raw/5100e359aef5c8021f2e71c7b986420b85ce7b3d/tensorflow/lite/kernels/internal/common.h)

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.


