The provided content relates to CVE-2022-35970.

**Root cause of vulnerability:**
The vulnerability stems from a lack of proper input validation in the `QuantizedInstanceNorm` operation within TensorFlow. Specifically, the operation fails to check if the `x_min` and `x_max` tensors, representing the minimum and maximum values for quantization, have a rank of zero (i.e., they are scalars). When these tensors have a non-zero rank, it leads to a segfault.

**Weaknesses/vulnerabilities present:**
- Missing input validation: The `QuantizedInstanceNorm` operation does not validate the rank of the `x_min` and `x_max` tensors.
- Type confusion/Incorrect use of tensors: Passing non-scalar tensors when scalar tensors are expected.

**Impact of exploitation:**
- Denial of service: Exploiting this vulnerability can cause a segfault, leading to a denial-of-service attack against TensorFlow applications.

**Attack vectors:**
- Malicious input: An attacker can craft specific inputs to the `QuantizedInstanceNorm` operation where `x_min` and `x_max` tensors have non-zero rank, causing the segfault.

**Required attacker capabilities/position:**
- Ability to provide inputs to a TensorFlow model or operation that utilizes `QuantizedInstanceNorm`.

**Additional details:**
- The vulnerability was fixed by adding checks to ensure `x_min` and `x_max` are scalar tensors, as shown in the provided commit diff. The commit also includes fixes for other quantization ops that had similar input validation issues, such as `FakeQuantWithMinMaxVarsOp`, `QuantizedBiasAddOp` and `RequantizeOp`.
- The fix was released in TensorFlow versions 2.7.4, 2.8.3, 2.9.2, and 2.10.0.
- The provided code snippet demonstrates the vulnerability, by passing `x_min` as a tensor with shape `[0]` and `x_max` as a tensor with shape `[]`. The vulnerability requires x_min to be non-scalar.
- The vulnerability is rated as "low" severity.