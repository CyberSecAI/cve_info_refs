=== Content from github.com_c584661e_20250114_195607.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2Fd66e1d568275e6a2947de97dca7a102a211e01ce)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2Fd66e1d568275e6a2947de97dca7a102a211e01ce)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fcommit_fragments%2Frepo_layout&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  827](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Commit

[Permalink](/tensorflow/tensorflow/commit/d66e1d568275e6a2947de97dca7a102a211e01ce)

This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.

Fix tensor shape overflow in FusedResizeAndPadConv2D.

[Browse files](/tensorflow/tensorflow/tree/d66e1d568275e6a2947de97dca7a102a211e01ce)
Browse the repository at this point in the history

```
Replaced TensorShape constructor by Factory method with status.

PiperOrigin-RevId: 477742686
```

* Loading branch information

[![@cantonios](https://avatars.githubusercontent.com/u/2538739?s=40&v=4)](/cantonios) [![@tensorflower-gardener](https://avatars.githubusercontent.com/u/17151892?s=40&v=4)](/tensorflower-gardener)

[cantonios](/tensorflow/tensorflow/commits?author=cantonios "View all commits by cantonios")
authored and
[tensorflower-gardener](/tensorflow/tensorflow/commits?author=tensorflower-gardener "View all commits by tensorflower-gardener")
committed
Sep 29, 2022

1 parent
[0baf76b](/tensorflow/tensorflow/commit/0baf76b4238c9a6ea486117c5562ae1dcf62c302)

commit d66e1d5

 Show file tree

 Hide file tree

Showing
**3 changed files**
with
**34 additions**
and
**4 deletions**.

* Whitespace
* Ignore whitespace

* Split
* Unified

* tensorflow

  + core

    - kernels

      * tensorflow/core/kernels/conv\_ops\_fused\_image\_transform.cc
        [conv\_ops\_fused\_image\_transform.cc](#diff-de8a0244f71ef8d7d591f6bbb6658dbfce90f9c45371701738afe8fe8bdc6c1f)
    - ops

      * tensorflow/core/ops/nn\_ops.cc
        [nn\_ops.cc](#diff-a627d3023fc1feb448548f4bc94c11ffd2cc2514a4b36d11bd94e2efbf2525d6)
  + python/kernel\_tests/nn\_ops

    - tensorflow/python/kernel\_tests/nn\_ops/conv\_ops\_test.py
      [conv\_ops\_test.py](#diff-79dd3e176f32748dfaa862633ab52813e2beaf2ecd4756bfe2b5ad9726c6db3b)

## There are no files selected for viewing

7 changes: 5 additions & 2 deletions

7
[tensorflow/core/kernels/conv\_ops\_fused\_image\_transform.cc](#diff-de8a0244f71ef8d7d591f6bbb6658dbfce90f9c45371701738afe8fe8bdc6c1f "tensorflow/core/kernels/conv_ops_fused_image_transform.cc")

Show comments

[View file](/tensorflow/tensorflow/blob/d66e1d568275e6a2947de97dca7a102a211e01ce/tensorflow/core/kernels/conv_ops_fused_image_transform.cc)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -667,8 +667,11 @@ class FusedResizeConv2DUsingGemmOp : public OpKernel { |
|  |  | st.height\_scale = 1.0f; |
|  |  | st.width\_scale = 1.0f; |
|  |  | } |
|  |  | TensorShape resized\_shape( |
|  |  | {input.dim\_size(0), st.out\_height, st.out\_width, input.dim\_size(3)}); |
|  |  | TensorShape resized\_shape; |
|  |  | OP\_REQUIRES\_OK(context, TensorShape::BuildTensorShape( |
|  |  | {input.dim\_size(0), st.out\_height, st.out\_width, |
|  |  | input.dim\_size(3)}, |
|  |  | &resized\_shape)); |
|  |  | int paddings\_index; |
|  |  | int filter\_index; |
|  |  | if (DoResize) { |
| Expand Down | |  |

4 changes: 2 additions & 2 deletions

4
[tensorflow/core/ops/nn\_ops.cc](#diff-a627d3023fc1feb448548f4bc94c11ffd2cc2514a4b36d11bd94e2efbf2525d6 "tensorflow/core/ops/nn_ops.cc")

Show comments

[View file](/tensorflow/tensorflow/blob/d66e1d568275e6a2947de97dca7a102a211e01ce/tensorflow/core/ops/nn_ops.cc)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -581,7 +581,7 @@ REGISTER\_OP("FusedResizeAndPadConv2D") |
|  |  | .Attr("strides: list(int)") |
|  |  | .Attr(GetPaddingAttrString()) |
|  |  | .SetShapeFn([](InferenceContext\* c) { |
|  |  | return CommonFusedConvCalculations(c, true /\* has\_resize \*/); |
|  |  | return CommonFusedConvCalculations(c, /\*has\_resize=\*/true); |
|  |  | }); |
|  |  |  |
|  |  | REGISTER\_OP("FusedPadConv2D") |
| Expand All | | @@ -594,7 +594,7 @@ REGISTER\_OP("FusedPadConv2D") |
|  |  | .Attr("strides: list(int)") |
|  |  | .Attr(GetPaddingAttrString()) |
|  |  | .SetShapeFn([](InferenceContext\* c) { |
|  |  | return CommonFusedConvCalculations(c, false /\* has\_resize \*/); |
|  |  | return CommonFusedConvCalculations(c, /\*has\_resize=\*/false); |
|  |  | }); |
|  |  |  |
|  |  | // -------------------------------------------------------------------------- |
| Expand Down | |  |

27 changes: 27 additions & 0 deletions

27
[tensorflow/python/kernel\_tests/nn\_ops/conv\_ops\_test.py](#diff-79dd3e176f32748dfaa862633ab52813e2beaf2ecd4756bfe2b5ad9726c6db3b "tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py")

Show comments

[View file](/tensorflow/tensorflow/blob/d66e1d568275e6a2947de97dca7a102a211e01ce/tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -3429,6 +3429,33 @@ def testAddWithSameSrcAndAddTensorBuffer(self): |
|  |  | np.rint(expected\_output), |
|  |  | self.evaluate(add).reshape(-1)) |
|  |  |  |
|  |  | # Fused resize and pad conv. |
|  |  | @test\_util.run\_in\_graph\_and\_eager\_modes() |
|  |  | def testResizeAndPadLargeResize(self): |
|  |  | with self.assertRaisesRegex((ValueError, errors\_impl.InvalidArgumentError), |
|  |  | "Encountered overflow"): |
|  |  | mode = "REFLECT" |
|  |  | strides = [1, 1, 1, 1] |
|  |  | padding = "SAME" |
|  |  | resize\_align\_corners = False |
|  |  | tensor = constant\_op.constant( |
|  |  | 147, shape=[3, 3, 1, 4], dtype=dtypes.float32) |
|  |  | size = constant\_op.constant([1879048192, 1879048192], dtype=dtypes.int32) |
|  |  | paddings = constant\_op.constant([[0, 0], [0, 0], [0, 0], [0, 0]], |
|  |  | dtype=dtypes.int32) |
|  |  | kernel = constant\_op.constant( |
|  |  | 123, shape=[1, 3, 4, 1], dtype=dtypes.float32) |
|  |  | self.evaluate( |
|  |  | gen\_nn\_ops.fused\_resize\_and\_pad\_conv2d( |
|  |  | input=tensor, |
|  |  | size=size, |
|  |  | paddings=paddings, |
|  |  | filter=kernel, |
|  |  | mode=mode, |
|  |  | strides=strides, |
|  |  | padding=padding, |
|  |  | resize\_align\_corners=resize\_align\_corners)) |
|  |  |  |
|  |  |  |
|  |  | if \_\_name\_\_ == "\_\_main\_\_": |
|  |  | for index, (input\_size\_, filter\_size\_, output\_size\_, stride\_, |
| Expand Down | |  |

Toggle all file notes
Toggle all file annotations

### 0 comments on commit `d66e1d5`

Please
[sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2Fd66e1d568275e6a2947de97dca7a102a211e01ce) to comment.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_f75fd02a_20250114_195605.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Fmaster%2Ftensorflow%2Fcore%2Fkernels%2Fconv_ops_fused_image_transform.cc)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Fmaster%2Ftensorflow%2Fcore%2Fkernels%2Fconv_ops_fused_image_transform.cc)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  827](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Files

 master
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/master)
2. /[tensorflow](/tensorflow/tensorflow/tree/master/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/master/tensorflow/core)
4. /[kernels](/tensorflow/tensorflow/tree/master/tensorflow/core/kernels)
/
# conv\_ops\_fused\_image\_transform.cc

Copy path Blame  Blame
## Latest commit

## History

[History](/tensorflow/tensorflow/commits/master/tensorflow/core/kernels/conv_ops_fused_image_transform.cc)908 lines (845 loc) · 41.3 KB master
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/master)
2. /[tensorflow](/tensorflow/tensorflow/tree/master/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/master/tensorflow/core)
4. /[kernels](/tensorflow/tensorflow/tree/master/tensorflow/core/kernels)
/
# conv\_ops\_fused\_image\_transform.cc

Top
## File metadata and controls

* Code
* Blame

908 lines (845 loc) · 41.3 KB[Raw](https://github.com/tensorflow/tensorflow/raw/refs/heads/master/tensorflow/core/kernels/conv_ops_fused_image_transform.cc)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908/\* Copyright 2018 The TensorFlow Authors. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");you may not use this file except in compliance with the License.You may obtain a copy of the License at
 http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.==============================================================================\*/
// Implements convolution operations with image transformations (resize and// mirror padding) baked into the processing, to optimize latency and memory// usage.
#define EIGEN\_USE\_THREADS
#include <string>#include <vector>
#include "tensorflow/core/framework/bounds\_check.h"#include "tensorflow/core/framework/kernel\_shape\_util.h"#include "tensorflow/core/framework/numeric\_op.h"#include "tensorflow/core/framework/op\_kernel.h"#include "tensorflow/core/framework/register\_types.h"#include "tensorflow/core/framework/resource\_mgr.h"#include "tensorflow/core/framework/tensor.h"#include "tensorflow/core/framework/tensor\_shape.h"#include "tensorflow/core/framework/tensor\_slice.h"#include "tensorflow/core/kernels/conv\_2d.h"#include "tensorflow/core/kernels/conv\_ops.h"#include "tensorflow/core/kernels/gemm\_functors.h"#include "tensorflow/core/kernels/ops\_util.h"#include "tensorflow/core/lib/core/threadpool.h"#include "tensorflow/core/util/image\_resizer\_state.h"#include "tensorflow/core/util/mirror\_pad\_mode.h"#include "tensorflow/core/util/padding.h"#include "tensorflow/core/util/tensor\_format.h"
namespace tensorflow {namespace {
// We don't want to allocate a buffer to hold all the patches if the size is// going to be extremely large, so break it into chunks if it's bigger than// a limit. Each chunk will be processed serially, so we can refill the// buffer for the next chunk and reuse it, keeping maximum memory size down.// In this case, we've picked 16 megabytes as a reasonable limit for Android and// other platforms using Eigen, and 1MB for iOS devices, from experimentation.#if defined(\_\_APPLE\_\_) && defined(IS\_MOBILE\_PLATFORM)const size\_t kMaxChunkSize = (1 \* 1024 \* 1024);#elseconst size\_t kMaxChunkSize = (16 \* 1024 \* 1024);#endifconst size\_t kResizeCacheSize = (8 \* 1024 \* 1024);
// Lookup method used when resizing.enum SamplingMode { BILINEAR = 0, NEAREST = 1,};
// Simple utility function used by FusedConv to multithread basic workloads. To// use it, pass begin and end values for the full workload and a std::function// that receives a subset of that through the begin and end values for each// worker's task. The division of the full workload into worker tasks is handled// by the multithreading logic. Here's an example of how to use it:// std::vector<float> my\_vector(100);// ...// FusedConvParallelFor(context, 0, 100,// [&my\_vector](int64 task\_begin, int64 task\_end) {// for (int64 current = task\_begin; current != task\_end; ++current) {// my\_vector[current] \*= 10.0f;// }// });void FusedConvParallelFor( OpKernelContext\* context, int64\_t begin, int64\_t end, const std::function<void(int64\_t, int64\_t)>& task\_function) {// On iOS, the thread management imposes a very big performance penalty, so// just call the function directly with no multithreading.#if defined(\_\_APPLE\_\_) && defined(IS\_MOBILE\_PLATFORM) task\_function(begin, end);#else auto& worker\_threads = \*(context->device()->tensorflow\_cpu\_worker\_threads()); thread::ThreadPool\* thread\_pool = worker\_threads.workers; const int64\_t total\_elements = end - begin; // This is a bit of an arbitrary number, but was found to work well for // typical models we've been profiling on various devices. const int64\_t element\_cost = 10000000; thread\_pool->ParallelFor( total\_elements, element\_cost, [begin, task\_function](int64\_t begin\_offset, int64\_t end\_offset) { const int64\_t task\_begin = begin + begin\_offset; const int64\_t task\_end = begin + end\_offset; task\_function(task\_begin, task\_end); });#endif}
// Holds the state needed for the resizing subtasks.template <class T1>struct ResizeTaskParameters { ResizeTaskParameters() : st(false, false) {}
 int cache\_height; T1\* resize\_cache; int cache\_line\_width; int input\_width; int input\_depth; int top\_padding; int pad\_offset; int64\_t resized\_height; ImageResizerState st; const T1\* input\_batch\_start; int64\_t cache\_start\_x; int64\_t cache\_end\_x; int left\_padding; int64\_t resized\_width; int64\_t padded\_width; int64\_t padded\_height;};
template <class T1>struct PerCacheLineParameters { PerCacheLineParameters() {} PerCacheLineParameters(const PerCacheLineParameters<T1>& other) : cache\_line\_start(other.cache\_line\_start), input\_top\_row\_start(other.input\_top\_row\_start), input\_bottom\_row\_start(other.input\_bottom\_row\_start), y\_lerp(other.y\_lerp) {}
 T1\* cache\_line\_start; const T1\* input\_top\_row\_start; const T1\* input\_bottom\_row\_start; T1 y\_lerp;};
// Helper class to simplify bilinear filteringtemplate <class T1>struct SampleRect { EIGEN\_ALWAYS\_INLINE SampleRect(const T1\* in\_top\_left, const T1\* in\_top\_right, const T1\* in\_bottom\_left, const T1\* in\_bottom\_right) : top\_left(in\_top\_left), top\_right(in\_top\_right), bottom\_left(in\_bottom\_left), bottom\_right(in\_bottom\_right) {}
 EIGEN\_ALWAYS\_INLINE T1 BilinearSample(int channel, T1 x\_lerp, T1 y\_lerp) const { const T1 top = top\_left[channel] + (top\_right[channel] - top\_left[channel]) \* x\_lerp; const T1 bottom = bottom\_left[channel] + (bottom\_right[channel] - bottom\_left[channel]) \* x\_lerp; return top + (bottom - top) \* y\_lerp; }
 const T1\* top\_left; const T1\* top\_right; const T1\* bottom\_left; const T1\* bottom\_right;};
// Calculates parameters which remain constant through a resize cache row.template <class T1>EIGEN\_ALWAYS\_INLINE PerCacheLineParameters<T1> CalculatePerCacheLineParameters( int64\_t cache\_height, int64\_t cache\_y, T1\* resize\_cache, int64\_t cache\_line\_width, int64\_t input\_width, int64\_t input\_depth, int64\_t top\_padding, int64\_t pad\_offset, int64\_t resized\_height, const ImageResizerState& st, const T1\* input\_batch\_start) { PerCacheLineParameters<T1> result; // The cache is organized so that the real y values of the resized image map // onto the actual cache values through a modulo scheme. This means that as we // progress downwards through the image, we keep reusing a small cache and so // keep memory usage down. int64\_t cache\_index\_y; if (cache\_y < 0) { cache\_index\_y = cache\_height + (cache\_y % cache\_height); } else { cache\_index\_y = cache\_y % cache\_height; } result.cache\_line\_start = resize\_cache + (cache\_index\_y \* cache\_line\_width \* input\_depth); // This part is implementing the mirror padding that happens before resizing. float in\_y = (cache\_y - top\_padding); if (in\_y < 0) { in\_y = -(in\_y + 1.0f - pad\_offset); } else if (in\_y >= resized\_height) { in\_y = (resized\_height \* 2.0f) - (in\_y + 1.0f + pad\_offset); } // Here's where to do the actual resize. in\_y \*= st.height\_scale; const int64\_t top\_y\_index = static\_cast<int64\_t>(std::floor(in\_y)); const int64\_t bottom\_y\_index = std::min(static\_cast<int64\_t>(std::ceil(in\_y)), (st.in\_height - 1)); // Lerp is used for bilinear filtering when that's needed. result.y\_lerp = static\_cast<T1>(in\_y - top\_y\_index); // Which rows of the original input image to pull the values from. result.input\_top\_row\_start = input\_batch\_start + (top\_y\_index \* input\_width \* input\_depth); result.input\_bottom\_row\_start = input\_batch\_start + (bottom\_y\_index \* input\_width \* input\_depth); return result;}
template <class T1>struct PerCachePixelParameters { PerCachePixelParameters() {} PerCachePixelParameters(const PerCachePixelParameters<T1>& other) : cache\_line\_pixel(other.cache\_line\_pixel), left\_x\_index(other.left\_x\_index), right\_x\_index(other.right\_x\_index), x\_lerp(other.x\_lerp) {}
 T1\* cache\_line\_pixel; int64\_t left\_x\_index; int64\_t right\_x\_index; T1 x\_lerp;};
// Pulls out common parameters used for every resized pixel.template <class T1>EIGEN\_ALWAYS\_INLINE PerCachePixelParameters<T1>CalculatePerCachePixelParameters(int64\_t cache\_x, int64\_t cache\_start\_x, T1\* cache\_line\_start, int64\_t input\_depth, int64\_t left\_padding, int64\_t pad\_offset, int64\_t resized\_width, const ImageResizerState& st) { PerCachePixelParameters<T1> result; // Figure out where we're going to store the results of our transform. const int cache\_index\_x = cache\_x - cache\_start\_x; result.cache\_line\_pixel = cache\_line\_start + (cache\_index\_x \* input\_depth); // Implement mirror padding by flipping in\_x if it's off the edge. float in\_x = (cache\_x - left\_padding); if (in\_x < 0) { in\_x = -(in\_x + 1.0f - pad\_offset); } else if (in\_x >= resized\_width) { in\_x = (resized\_width \* 2.0f) - (in\_x + 1.0f + pad\_offset); } // Resize the x parameters. in\_x \*= st.width\_scale; // Get the x coordinates for the left and right pixels to pull from. result.left\_x\_index = static\_cast<int64\_t>(std::floor(in\_x)); result.right\_x\_index = std::min(static\_cast<int64\_t>(std::ceil(in\_x)), (st.in\_width - 1)); // This x\_lerp is used to blend pixels in bilinear filtering. result.x\_lerp = static\_cast<T1>(in\_x - result.left\_x\_index); return result;}
// Combines bilinear resizing and mirror padding into the im2col transformation// stage of convolution.template <class T1, class T2, class T3, class TGemmFunctor, SamplingMode SampleMode>class FusedResizeAndPadConvFunctor { public: void operator()(OpKernelContext\* context, const Tensor& input, int input\_batches, int resized\_height, int resized\_width, int padded\_height, int padded\_width, int input\_depth, const T2\* filter\_data, int filter\_height, int filter\_width, int filter\_count, int stride\_rows, int stride\_cols, Padding padding, T3\* output\_data, int output\_height, int output\_width, const ImageResizerState& st, int top\_padding, int bottom\_padding, int left\_padding, int right\_padding, int pad\_offset) { if ((input\_batches <= 0) || (padded\_width <= 0) || (padded\_height <= 0) || (input\_depth <= 0)) { LOG(WARNING) << "Conv2D was called with bad input dimensions: " << input\_batches << ", " << padded\_height << ", " << padded\_width << ", " << input\_depth; return; } if ((filter\_width <= 0) || (filter\_height <= 0) || (filter\_count <= 0)) { LOG(WARNING) << "Conv2D was called with bad filter dimensions: " << filter\_width << ", " << filter\_height << ", " << filter\_count; return; } if ((output\_width <= 0) || (output\_height <= 0)) { LOG(WARNING) << "Conv2D was called with bad output width or height: " << output\_width << ", " << output\_height; return; } OP\_REQUIRES( context, ((SampleMode == NEAREST) || (SampleMode == BILINEAR)), errors::InvalidArgument("Bad sample mode passed in", SampleMode));
 // These calculations define how the patches will be positioned within the // input image. The actual definitions are quite complex, and rely on the // previously-calculated output size. int filter\_left\_offset; int filter\_top\_offset; if (padding == VALID) { filter\_left\_offset = ((output\_width - 1) \* stride\_cols + filter\_width - padded\_width + 1) / 2; filter\_top\_offset = ((output\_height - 1) \* stride\_rows + filter\_height - padded\_height + 1) / 2; } else { filter\_left\_offset = ((output\_width - 1) \* stride\_cols + filter\_width - padded\_width) / 2; filter\_top\_offset = ((output\_height - 1) \* stride\_rows + filter\_height - padded\_height) / 2; }
 ResizeTaskParameters<T1> task\_params; task\_params.input\_depth = input\_depth; task\_params.top\_padding = top\_padding; task\_params.pad\_offset = pad\_offset; task\_params.resized\_height = resized\_height; task\_params.st = st; task\_params.left\_padding = left\_padding; task\_params.resized\_width = resized\_width; task\_params.padded\_width = padded\_width; task\_params.padded\_height = padded\_height;
 // The im2col buffer has # of patches rows, and # of filters cols. // It's laid out like this, in row major order in memory: // < filter value count > // ^ +---------------------+ // patch | | // count | | // v +---------------------+ // Each patch row contains a filter\_width x filter\_height patch of the // input, with the depth channel as the most contiguous in memory, followed // by the width, then the height. This is the standard memory order in the // image world if it helps to visualize it. const int filter\_value\_count = filter\_width \* filter\_height \* input\_depth;
 OP\_REQUIRES(context, (filter\_value\_count \* sizeof(T1)) <= kMaxChunkSize, errors::InvalidArgument("Im2Col patch too large for buffer")); const size\_t patches\_per\_chunk = kMaxChunkSize / (filter\_value\_count \* sizeof(T1)); // Because memory allocation is very expensive on mobile platforms, try to // allocate a persistent buffer that will be kept around between calls. We // use TensorFlow's resource management to ensure that the memory will be // released when the session is over. Im2ColBufferResource<T1, kMaxChunkSize>\* im2col\_buffer\_resource; std::function<absl::Status(Im2ColBufferResource<T1, kMaxChunkSize>\*\*)> creator = [](Im2ColBufferResource<T1, kMaxChunkSize>\*\* resource) { \*resource = new Im2ColBufferResource<T1, kMaxChunkSize>(); return absl::OkStatus(); }; OP\_REQUIRES\_OK(context, context->resource\_manager()->LookupOrCreate( "Conv2d", "im2col\_buffer", &im2col\_buffer\_resource, creator));
 // Create a resize cache memory buffer that will hold the rows of // transformed and mirror padded input pixels, ready to be copied // into filter patches by im2col. // It's laid out like this, in row major order in memory: // < cache line width > // ^ +--------------------+ // cache | | // height | | // v +--------------------+ // Each cache row contains a cache\_line\_width number of resized pixels, // each with input\_depth channels. The cache height is typically less than // the full height the resized image would be, so it's filled up // incrementally as we progress downwards through the input creating im2col // patches. task\_params.cache\_start\_x = -filter\_left\_offset; task\_params.cache\_end\_x = (((output\_width - 1) \* stride\_cols) - filter\_left\_offset) + filter\_width; task\_params.cache\_line\_width = task\_params.cache\_end\_x - task\_params.cache\_start\_x; task\_params.cache\_height = kResizeCacheSize / (task\_params.cache\_line\_width \* input\_depth); const int needed\_resize\_cache\_count = filter\_height \* task\_params.cache\_line\_width \* input\_depth; OP\_REQUIRES(context, (needed\_resize\_cache\_count \* sizeof(T1)) <= kResizeCacheSize, errors::InvalidArgument("Input too large for resize cache")); Im2ColBufferResource<T1, kResizeCacheSize>\* resize\_cache\_resource; std::function<absl::Status(Im2ColBufferResource<T1, kResizeCacheSize>\*\*)> resize\_creator = [](Im2ColBufferResource<T1, kResizeCacheSize>\*\* resource) { \*resource = new Im2ColBufferResource<T1, kResizeCacheSize>(); return absl::OkStatus(); }; OP\_REQUIRES\_OK(context, context->resource\_manager()->LookupOrCreate( "Conv2d", "resize\_cache", &resize\_cache\_resource, resize\_creator));
 // This means that multiple ops can't be run simultaneously on different // threads, because we have a single shared resource. The platforms this is // aimed at have intra-op parallelism as their focus though, so it shouldn't // be an issue. mutex\_lock lock\_buffer(im2col\_buffer\_resource->mu); core::ScopedUnref unref\_buffer(im2col\_buffer\_resource); T1\* im2col\_buffer = im2col\_buffer\_resource->data;
 // This buffer is used as a fairly heavy-weight cache for the resized and // mirrored inputs to the im2col operation. The problem is that we want to // keep the memory usage down by not rendering the fully resized and padded // input tensor to the convolution into an entire buffer. The first approach // to avoid this was to fold the bilinear filtering and padding spatial // transformations into the im2col lookup itself. This successfully reduced // memory usage, but because im2col can access an individual pixel for many // different patches, the extra overhead of doing the same bilinear lookups // repeatedly became too expensive. // The resize cache is designed to avoid this problem by keeping a // horizontal slice of the resized and padded input to the im2col // precalculated, so that repeated accesses to the same pixel from different // filter patches can just be copied from this cache. It's organized as a // horizontal slice stretching across the whole virtual image, and as high // as the filter window, so that as the patch processing moves across all // the pixels are present, and before a new row of patches is started any // previously calculated rows that are needed are maintained, with new rows // calculated as required. mutex\_lock resize\_lock\_buffer(resize\_cache\_resource->mu); core::ScopedUnref unref\_resized\_cache(resize\_cache\_resource); task\_params.resize\_cache = resize\_cache\_resource->data;
 const T1\* input\_data = input.flat<T1>().data(); const int64\_t input\_height = input.shape().dim\_sizes()[1]; task\_params.input\_width = input.shape().dim\_sizes()[2];
 int end\_cached\_lines = std::numeric\_limits<int>::min();
 for (int batch = 0; batch < input\_batches; ++batch) { task\_params.input\_batch\_start = input\_data + (batch \* input\_height \* task\_params.input\_width \* input\_depth); const int in\_y\_end = ((output\_height \* stride\_rows) - filter\_top\_offset) + filter\_height; for (int out\_y = 0; out\_y < output\_height; ++out\_y) { const int in\_y\_origin = (out\_y \* stride\_rows) - filter\_top\_offset; const int cache\_start\_y = std::max(in\_y\_origin, end\_cached\_lines); const int cache\_end\_y = std::min( in\_y\_end, std::max((in\_y\_origin + task\_params.cache\_height), end\_cached\_lines)); if (end\_cached\_lines < (in\_y\_origin + filter\_height)) { // This call breaks up the work required for calculating the mirror // padding and resizing across multiple threads. FusedConvParallelFor( context, cache\_start\_y, cache\_end\_y, [task\_params](int64\_t task\_cache\_start\_y, int64\_t task\_cache\_end\_y) { // This is a long and confusing function, but it's been laid out // this way to help with performance on some intensive models. // What it's doing is populating a cache of the original input // image, after it's been bilinear resized and had its edges // mirrored. This allows the following im2col code to access the // transformed pixels from this cache, without having to // repeatedly apply the expensive bilinear calculations as the // same pixels are accessed by different patches. // This is most effective when the stride is small and the // filter size is large, since that's when pixels are reused // most frequently as patches overlap. for (int cache\_y = task\_cache\_start\_y; cache\_y < task\_cache\_end\_y; ++cache\_y) { // We organize the cache as a series of rows, each containing // all the transformed pixels for a given line in the image. // This cache is big enough to hold at least a filter's height // worth of rows, but typically more, limited by the size of // the cache buffer. // We don't allocate an entire image's worth of rows though, // because we're trying to keep memory usage down, so as we // progress downwards through the im2col we periodically // refresh the cache so that the next lines that are needed // for that operation are always present. // Work out the parameters that remain constant across the // row we're calculating. PerCacheLineParameters<T1> line\_params( CalculatePerCacheLineParameters<T1>( task\_params.cache\_height, cache\_y, task\_params.resize\_cache, task\_params.cache\_line\_width, task\_params.input\_width, task\_params.input\_depth, task\_params.top\_padding, task\_params.pad\_offset, task\_params.resized\_height, task\_params.st, task\_params.input\_batch\_start)); // Iterate through the resize cache row we're filling in. for (int cache\_x = task\_params.cache\_start\_x; cache\_x < task\_params.cache\_end\_x; ++cache\_x) { // Figure out what we need for the cache pixel we're // populating. PerCachePixelParameters<T1> pixel\_params( CalculatePerCachePixelParameters<T1>( cache\_x, task\_params.cache\_start\_x, line\_params.cache\_line\_start, task\_params.input\_depth, task\_params.left\_padding, task\_params.pad\_offset, task\_params.resized\_width, task\_params.st)); // If the access is off the left, right, top, or bottom of // the resized image, the conv padding means we should set // it to zero. if ((cache\_x < 0) || (cache\_x >= task\_params.padded\_width) || (cache\_y < 0) || (cache\_y >= task\_params.padded\_height)) { std::fill\_n(pixel\_params.cache\_line\_pixel, task\_params.input\_depth, T1(0)); } else { // There are two different sampling strategies for // resizing. When using nearest, we can just do a // straight copy of the pixel closest to our sample point, // but bilinear requires a more complex calculation. if (SampleMode == NEAREST) { const T1\* input\_top\_left\_pixel = line\_params.input\_top\_row\_start + (pixel\_params.left\_x\_index \* task\_params.input\_depth);
 std::copy\_n(input\_top\_left\_pixel, task\_params.input\_depth, pixel\_params.cache\_line\_pixel); } else { const SampleRect<T1> rect( line\_params.input\_top\_row\_start + (pixel\_params.left\_x\_index \* task\_params.input\_depth), line\_params.input\_top\_row\_start + (pixel\_params.right\_x\_index \* task\_params.input\_depth), line\_params.input\_bottom\_row\_start + (pixel\_params.left\_x\_index \* task\_params.input\_depth), line\_params.input\_bottom\_row\_start + (pixel\_params.right\_x\_index \* task\_params.input\_depth)); for (int in\_channel = 0; in\_channel < task\_params.input\_depth; ++in\_channel) { pixel\_params.cache\_line\_pixel[in\_channel] = rect.BilinearSample(in\_channel, pixel\_params.x\_lerp, line\_params.y\_lerp); } } } } } }); end\_cached\_lines = cache\_end\_y; } for (int out\_x = 0; out\_x < output\_width; ++out\_x) { const int in\_x\_origin = (out\_x \* stride\_cols) - filter\_left\_offset; const int patch\_index = (batch \* output\_width \* output\_height) + (out\_y \* output\_width) + out\_x; const int patch\_index\_within\_chunk = patch\_index % patches\_per\_chunk; T1\* im2col\_patch\_start = im2col\_buffer + (patch\_index\_within\_chunk \* filter\_value\_count); for (int filter\_y = 0; filter\_y < filter\_height; ++filter\_y) { T1\* im2col\_row\_start = im2col\_patch\_start + (filter\_y \* filter\_width \* task\_params.input\_depth); const int conv\_in\_y = in\_y\_origin + filter\_y; int cache\_index\_y; if (conv\_in\_y < 0) { cache\_index\_y = task\_params.cache\_height + (conv\_in\_y % task\_params.cache\_height); } else { cache\_index\_y = conv\_in\_y % task\_params.cache\_height; } T1\* cache\_line\_start = task\_params.resize\_cache + (cache\_index\_y \* task\_params.cache\_line\_width \* task\_params.input\_depth); T1\* cache\_filter\_row\_start = cache\_line\_start + ((in\_x\_origin - task\_params.cache\_start\_x) \* task\_params.input\_depth); std::copy\_n(cache\_filter\_row\_start, (filter\_width \* task\_params.input\_depth), im2col\_row\_start); } const bool is\_last\_in\_chunk = (patch\_index\_within\_chunk == (patches\_per\_chunk - 1)); const bool is\_last\_overall = ((batch == (input\_batches - 1)) && (out\_y == (output\_height - 1)) && (out\_x == (output\_width - 1))); if (is\_last\_in\_chunk || is\_last\_overall) { // Now we've assembled a set of image patches into a matrix, apply // a GEMM matrix multiply of the patches as rows, times the filter // weights in columns, to get partial results in the output // matrix. const int how\_many\_patches = patch\_index\_within\_chunk + 1; const int m = how\_many\_patches; const int n = filter\_count; const int k = filter\_value\_count; const int lda = filter\_value\_count; const int ldb = filter\_count; const int ldc = filter\_count; const size\_t start\_patch\_index = patch\_index - (how\_many\_patches - 1); T3\* chunk\_output\_data = output\_data + (start\_patch\_index \* filter\_count); TGemmFunctor gemm\_functor; gemm\_functor(context, m, n, k, im2col\_buffer, lda, filter\_data, ldb, chunk\_output\_data, ldc); } } } } }};
} // namespace
// Implements a version of convolution with bilinear resizing and mirror padding// included.template <class T, class TConvFunctor, bool DoResize>class FusedResizeConv2DUsingGemmOp : public OpKernel { public: explicit FusedResizeConv2DUsingGemmOp(OpKernelConstruction\* context) : OpKernel(context) { if (DoResize) { OP\_REQUIRES\_OK(context, context->GetAttr("resize\_align\_corners", &align\_corners\_)); } MirrorPadMode mode; OP\_REQUIRES\_OK(context, context->GetAttr("mode", &mode));
 switch (mode) { case MirrorPadMode::SYMMETRIC: { offset\_ = 0; break; } case MirrorPadMode::REFLECT: { offset\_ = 1; break; } default: OP\_REQUIRES(context, false, errors::InvalidArgument( "mode must be either REFLECT or SYMMETRIC.")); } OP\_REQUIRES\_OK(context, context->GetAttr("strides", &strides\_)); OP\_REQUIRES(context, strides\_.size() == 4, errors::InvalidArgument("Sliding window strides field must " "specify 4 dimensions")); const int64\_t stride\_n = GetTensorDim(strides\_, FORMAT\_NHWC, 'N'); const int64\_t stride\_c = GetTensorDim(strides\_, FORMAT\_NHWC, 'C'); OP\_REQUIRES( context, stride\_n == 1 && stride\_c == 1, errors::InvalidArgument("Current implementation does not yet support " "strides in the batch and depth dimensions.")); OP\_REQUIRES\_OK(context, context->GetAttr("padding", &padding\_)); }
 void Compute(OpKernelContext\* context) override { // Input tensor is of the following dimensions: // [ batch, in\_rows, in\_cols, in\_depth ] const Tensor& input = context->input(0); OP\_REQUIRES(context, (input.shape().num\_elements() > 0), errors::InvalidArgument("Input tensor can't be empty"));
 ImageResizerState st(false, false); if (DoResize) { st = ImageResizerState(align\_corners\_, false); st.ValidateAndCalculateOutputSize(context); if (!context->status().ok()) return; } else { // Set up the resize parameters to do no scaling at all. st.batch\_size = input.dim\_size(0); st.out\_height = input.dim\_size(1); st.out\_width = input.dim\_size(2); st.in\_height = input.dim\_size(1); st.in\_width = input.dim\_size(2); st.channels = input.dim\_size(3); st.height\_scale = 1.0f; st.width\_scale = 1.0f; } TensorShape resized\_shape; OP\_REQUIRES\_OK(context, TensorShape::BuildTensorShape( {input.dim\_size(0), st.out\_height, st.out\_width, input.dim\_size(3)}, &resized\_shape)); int paddings\_index; int filter\_index; if (DoResize) { paddings\_index = 2; filter\_index = 3; } else { paddings\_index = 1; filter\_index = 2; } const Tensor& paddings = context->input(paddings\_index);
 const int dims = resized\_shape.dims(); OP\_REQUIRES( context, TensorShapeUtils::IsMatrix(paddings.shape()) && paddings.dim\_size(1) == 2, errors::InvalidArgument("paddings must be a matrix with 2 columns: ", paddings.shape().DebugString())); OP\_REQUIRES( context, dims == paddings.dim\_size(0), errors::InvalidArgument( "The first dimension of paddings must be the rank of inputs: ", dims, " ", paddings.shape().DebugString(), " ", resized\_shape.DebugString())); OP\_REQUIRES( context, dims == paddings.dim\_size(0), errors::InvalidArgument( "The first dimension of paddings must be the rank of inputs: ", dims, " ", paddings.shape().DebugString(), " ", resized\_shape.DebugString()));
 OP\_REQUIRES( context, dims == 4, errors::InvalidArgument( "Fused mirror padding only supports four-dimensional inputs, but ", dims, " requested"));
 // Compute the shape of the output tensor, and allocate it. TensorShape padded\_shape; TTypes<int32>::ConstMatrix paddings\_matrix = paddings.matrix<int32>(); for (int d = 0; d < dims; ++d) { const int32\_t before = paddings\_matrix(d, 0); // Pad before existing elements. const int32\_t after = paddings\_matrix(d, 1); // Pad after existing elements. OP\_REQUIRES(context, before >= 0 && after >= 0, errors::InvalidArgument( "paddings must be non-negative: ", before, " ", after)); if (offset\_ == 0) { // SYMMETRIC mode. OP\_REQUIRES( context, before <= resized\_shape.dim\_size(d) && after <= resized\_shape.dim\_size(d), errors::InvalidArgument("paddings must be no greater " "than the dimension size: ", before, ", ", after, " greater than ", resized\_shape.dim\_size(d))); } else if (offset\_ == 1) { // REFLECT mode. OP\_REQUIRES( context, before < resized\_shape.dim\_size(d) && after < resized\_shape.dim\_size(d), errors::InvalidArgument("paddings must be less than" " the dimension size: ", before, ", ", after, " not less than ", resized\_shape.dim\_size(d))); } OP\_REQUIRES\_OK(context, padded\_shape.AddDimWithStatus( before + resized\_shape.dim\_size(d) + after)); }
 OP\_REQUIRES( context, ((paddings\_matrix(0, 0) == 0) && (paddings\_matrix(0, 1) == 0)), errors::InvalidArgument( "Fused mirror padding only support spatial padding, not batches: ", paddings.DebugString())); OP\_REQUIRES( context, ((paddings\_matrix(3, 0) == 0) && (paddings\_matrix(3, 1) == 0)), errors::InvalidArgument( "Fused mirror padding only support spatial padding, not channels: ", paddings.DebugString())); const int32\_t top\_padding = paddings\_matrix(1, 0); const int32\_t bottom\_padding = paddings\_matrix(1, 1); const int32\_t left\_padding = paddings\_matrix(2, 0); const int32\_t right\_padding = paddings\_matrix(2, 1);
 // Input filter is of the following dimensions: // [ filter\_rows, filter\_cols, in\_depth, out\_depth] const Tensor& filter = context->input(filter\_index);
 // For 2D convolution, there should be 4 dimensions. OP\_REQUIRES(context, padded\_shape.dims() == 4, errors::InvalidArgument("input must be 4-dimensional", padded\_shape.DebugString())); OP\_REQUIRES(context, filter.dims() == 4, errors::InvalidArgument("filter must be 4-dimensional: ", filter.shape().DebugString()));
 // We only check the first three dims, since the depth is accessed as an // int64 below. for (int i = 0; i < 3; i++) { OP\_REQUIRES( context, FastBoundsCheck(filter.dim\_size(i), std::numeric\_limits<int>::max()), errors::InvalidArgument("filter too large")); }
 // The last dimension for input is in\_depth. It must be the same as the // filter's in\_depth. const int64\_t in\_depth = padded\_shape.dim\_size(3); OP\_REQUIRES(context, in\_depth == filter.dim\_size(2), errors::InvalidArgument( "input and filter must have the same depth: ", in\_depth, " vs ", filter.dim\_size(2)));
 // The last dimension for filter is out\_depth. const int out\_depth = static\_cast<int>(filter.dim\_size(3));
 // The second dimension for input is rows/height. // The first dimension for filter is rows/height. const int64\_t padded\_rows\_raw = padded\_shape.dim\_size(1); OP\_REQUIRES( context, FastBoundsCheck(padded\_rows\_raw, std::numeric\_limits<int>::max()), errors::InvalidArgument("Input rows too large")); const int padded\_rows = static\_cast<int>(padded\_rows\_raw); const int filter\_rows = static\_cast<int>(filter.dim\_size(0)); const int resized\_rows = static\_cast<int>(resized\_shape.dim\_size(1));
 // The third dimension for input is columns/width. // The second dimension for filter is columns/width. const int64\_t padded\_cols\_raw = padded\_shape.dim\_size(2); OP\_REQUIRES( context, FastBoundsCheck(padded\_cols\_raw, std::numeric\_limits<int>::max()), errors::InvalidArgument("Input cols too large")); const int padded\_cols = static\_cast<int>(padded\_cols\_raw); const int filter\_cols = static\_cast<int>(filter.dim\_size(1)); const int resized\_cols = static\_cast<int>(resized\_shape.dim\_size(2));
 // The first dimension for input is batch. const int64\_t batch\_raw = padded\_shape.dim\_size(0); OP\_REQUIRES(context, FastBoundsCheck(batch\_raw, std::numeric\_limits<int>::max()), errors::InvalidArgument("batch is too large")); const int batch = static\_cast<int>(batch\_raw);
 // For now we take the stride from the second and third dimensions only (we // do not support striding on the batch or depth dimension). const int stride\_rows = GetTensorDim(strides\_, FORMAT\_NHWC, 'H'); const int stride\_cols = GetTensorDim(strides\_, FORMAT\_NHWC, 'W');
 int64\_t out\_rows = 0, out\_cols = 0, pad\_rows = 0, pad\_cols = 0; OP\_REQUIRES\_OK(context, GetWindowedOutputSize( padded\_rows, filter\_rows, /\*dilation\_rate=\*/1, stride\_rows, padding\_, &out\_rows, &pad\_rows)); OP\_REQUIRES\_OK(context, GetWindowedOutputSize( padded\_cols, filter\_cols, /\*dilation\_rate=\*/1, stride\_cols, padding\_, &out\_cols, &pad\_cols)); TensorShape out\_shape; OP\_REQUIRES\_OK(context, ShapeFromFormatWithStatus(FORMAT\_NHWC, batch, out\_rows, out\_cols, out\_depth, &out\_shape)); OP\_REQUIRES(context, (out\_shape.num\_elements() > 0), errors::InvalidArgument("Output tensor can't be empty"));
 // Output tensor is of the following dimensions: // [ in\_batch, out\_rows, out\_cols, out\_depth ] Tensor\* output = nullptr; OP\_REQUIRES\_OK(context, context->allocate\_output(0, out\_shape, &output));
 VLOG(2) << "FusedConv2D: " << name() << ", in\_depth = " << in\_depth << ", padded\_cols = " << padded\_cols << ", resized\_cols = " << resized\_cols << ", filter\_cols = " << filter\_cols << ", padded\_rows = " << padded\_rows << ", resized\_rows = " << resized\_rows << ", filter\_rows = " << filter\_rows << ", stride\_rows = " << stride\_rows << ", stride\_cols = " << stride\_cols << ", out\_depth = " << out\_depth << ", DoResize=" << DoResize;
 // If there is nothing to compute, return. if (out\_shape.num\_elements() == 0) { return; } TConvFunctor conv\_functor; conv\_functor(context, input, batch, resized\_rows, resized\_cols, padded\_rows, padded\_cols, in\_depth, filter.flat<T>().data(), filter\_rows, filter\_cols, out\_depth, stride\_rows, stride\_cols, padding\_, output->flat<T>().data(), out\_rows, out\_cols, st, top\_padding, bottom\_padding, left\_padding, right\_padding, offset\_); }
 private: std::vector<int32> strides\_; Padding padding\_; bool align\_corners\_; int offset\_;
 FusedResizeConv2DUsingGemmOp(const FusedResizeConv2DUsingGemmOp&) = delete; void operator=(const FusedResizeConv2DUsingGemmOp&) = delete;};
#define REGISTER\_FUSED(T) \ REGISTER\_KERNEL\_BUILDER( \ Name("FusedResizeAndPadConv2D") \ .Device(DEVICE\_CPU) \ .TypeConstraint<T>("T"), \ FusedResizeConv2DUsingGemmOp< \ T, \ FusedResizeAndPadConvFunctor<T, T, T, FastGemmFunctor<T, T, T>, \ BILINEAR>, \ true>);
TF\_CALL\_half(REGISTER\_FUSED);TF\_CALL\_float(REGISTER\_FUSED);TF\_CALL\_double(REGISTER\_FUSED);
#define REGISTER\_PAD\_ONLY\_FUSED(T) \ REGISTER\_KERNEL\_BUILDER( \ Name("FusedPadConv2D").Device(DEVICE\_CPU).TypeConstraint<T>("T"), \ FusedResizeConv2DUsingGemmOp< \ T, \ FusedResizeAndPadConvFunctor<T, T, T, FastGemmFunctor<T, T, T>, \ NEAREST>, \ false>);
TF\_CALL\_half(REGISTER\_PAD\_ONLY\_FUSED);TF\_CALL\_float(REGISTER\_PAD\_ONLY\_FUSED);TF\_CALL\_double(REGISTER\_PAD\_ONLY\_FUSED);TF\_CALL\_bfloat16(REGISTER\_PAD\_ONLY\_FUSED);
} // namespace tensorflow

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_1db2b5c4_20250114_195608.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fsecurity%2Fadvisories%2FGHSA-762h-vpvw-3rcx)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fsecurity%2Fadvisories%2FGHSA-762h-vpvw-3rcx)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Frepos%2Fadvisories%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  827](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

# Overflow in `FusedResizeAndPadConv2D`

Low

[pak-laura](/pak-laura)
published
GHSA-762h-vpvw-3rcx
Nov 18, 2022

## Package

pip

tensorflow, tensorflow-cpu, tensorflow-gpu
([pip](/advisories?query=ecosystem%3Apip))

## Affected versions

< 2.11.0

## Patched versions

2.7.4, 2.8.1, 2.9.1, 2.10.0

## Description

### Impact

When [`tf.raw_ops.FusedResizeAndPadConv2D`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/conv_ops_fused_image_transform.cc) is given a large tensor shape, it overflows.

```
import tensorflow as tf

mode = "REFLECT"
strides = [1, 1, 1, 1]
padding = "SAME"
resize_align_corners = False
input = tf.constant(147, shape=[3,3,1,1], dtype=tf.float16)
size = tf.constant([1879048192,1879048192], shape=[2], dtype=tf.int32)
paddings = tf.constant([3,4], shape=[2], dtype=tf.int32)
filter = tf.constant(123, shape=[1,3,4,1], dtype=tf.float16)
tf.raw_ops.FusedResizeAndPadConv2D(input=input, size=size, paddings=paddings, filter=filter, mode=mode, strides=strides, padding=padding, resize_align_corners=resize_align_corners)
```
### Patches

We have patched the issue in GitHub commit [d66e1d568275e6a2947de97dca7a102a211e01ce](https://github.com/tensorflow/tensorflow/commit/d66e1d568275e6a2947de97dca7a102a211e01ce).

The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1, 2.9.3, and TensorFlow 2.8.4, as these are also affected and still in supported range.

### For more information

Please consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.

### Attribution

This vulnerability has been reported by Neophytos Christou from the Secure Systems Lab (SSL) at Brown University.

### Severity

Low

### CVE ID

CVE-2022-41885

### Weaknesses

No CWEs

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.


