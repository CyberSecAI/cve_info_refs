=== Content from github.com_2703801c_20250115_093405.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fsecurity%2Fadvisories%2FGHSA-w58w-79xv-6vcj)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fsecurity%2Fadvisories%2FGHSA-w58w-79xv-6vcj)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Frepos%2Fadvisories%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  826](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

# OOB seg fault in `DynamicStitch` due to missing validation

Low

[pak-laura](/pak-laura)
published
GHSA-w58w-79xv-6vcj
Nov 18, 2022

## Package

pip

tensorflow, tensorflow-cpu, tensorflow-gpu
([pip](/advisories?query=ecosystem%3Apip))

## Affected versions

2.10.0

## Patched versions

2.10.1, 2.11.0

## Description

### Impact

[`tf.raw_ops.DynamicStitch`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/dynamic_stitch_op.cc) specifies input sizes when it is [registered](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/data_flow_ops.cc).

```
REGISTER_OP("DynamicStitch")
    .Input("indices: N * int32")
    .Input("data: N * T")
    .Output("merged: T")
    .Attr("N : int >= 1")
    .Attr("T : type")
    .SetShapeFn(DynamicStitchShapeFunction);
```

When it receives a differing number of inputs, such as when it is called with an `indices` size 1 and a `data` size 2, it will crash.

```
import tensorflow as tf

# indices = 1*[tf.random.uniform([1,2], dtype=tf.dtypes.int32, maxval=100)]
indices = [tf.constant([[0, 1]]),]

# data = 2*[tf.random.uniform([1,2], dtype=tf.dtypes.float32, maxval=100)]
data = [tf.constant([[5, 6]]), tf.constant([[7, 8]])]

tf.raw_ops.DynamicStitch(
    indices=indices,
    data=data)
```
### Patches

We have patched the issue in GitHub commit [f5381e0e10b5a61344109c1b7c174c68110f7629](https://github.com/tensorflow/tensorflow/commit/f5381e0e10b5a61344109c1b7c174c68110f7629).

The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1 as this is also affected.

### For more information

Please consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.

### Attribution

This vulnerability has been reported by Zizhuang Deng of IIE, UCAS

### Severity

Low

### CVE ID

CVE-2022-41883

### Weaknesses

No CWEs

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_153e9169_20250115_093401.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Fmaster%2Ftensorflow%2Fcore%2Fkernels%2Fdynamic_stitch_op.cc)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Fmaster%2Ftensorflow%2Fcore%2Fkernels%2Fdynamic_stitch_op.cc)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  826](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Files

 master
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/master)
2. /[tensorflow](/tensorflow/tensorflow/tree/master/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/master/tensorflow/core)
4. /[kernels](/tensorflow/tensorflow/tree/master/tensorflow/core/kernels)
/
# dynamic\_stitch\_op.cc

Copy path Blame  Blame
## Latest commit

## History

[History](/tensorflow/tensorflow/commits/master/tensorflow/core/kernels/dynamic_stitch_op.cc)410 lines (366 loc) · 16.7 KB master
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/master)
2. /[tensorflow](/tensorflow/tensorflow/tree/master/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/master/tensorflow/core)
4. /[kernels](/tensorflow/tensorflow/tree/master/tensorflow/core/kernels)
/
# dynamic\_stitch\_op.cc

Top
## File metadata and controls

* Code
* Blame

410 lines (366 loc) · 16.7 KB[Raw](https://github.com/tensorflow/tensorflow/raw/refs/heads/master/tensorflow/core/kernels/dynamic_stitch_op.cc)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410/\* Copyright 2015 The TensorFlow Authors. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");you may not use this file except in compliance with the License.You may obtain a copy of the License at
 http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.==============================================================================\*/
// See docs in ../ops/data\_flow\_ops.cc.
#include <algorithm>
#include "tensorflow/core/framework/bounds\_check.h"#include "tensorflow/core/framework/op\_kernel.h"#include "tensorflow/core/framework/register\_types.h"#include "tensorflow/core/framework/tensor.h"#include "tensorflow/core/kernels/fill\_functor.h"#include "tensorflow/core/lib/core/threadpool.h"
#if GOOGLE\_CUDA || TENSORFLOW\_USE\_ROCM#include "tensorflow/core/kernels/gpu\_device\_array.h"#endif // GOOGLE\_CUDA || TENSORFLOW\_USE\_ROCM
#if !defined(PLUGGABLE\_DEVICE\_SUPPORTED\_MACOS) && defined(\_\_APPLE\_\_) && \ !defined(ANDROID) && !defined(\_\_ANDROID\_\_) && \ (!defined(TARGET\_OS\_IOS) || !TARGET\_OS\_IOS)#define PLUGGABLE\_DEVICE\_SUPPORTED\_MACOS 1#endif
namespace tensorflow {
typedef Eigen::ThreadPoolDevice CPUDevice;#if GOOGLE\_CUDA || TENSORFLOW\_USE\_ROCMtypedef Eigen::GpuDevice GPUDevice;#endif // GOOGLE\_CUDA || TENSORFLOW\_USE\_ROCM
template <class T>class DynamicStitchOpImplBase : public OpKernel { public: explicit DynamicStitchOpImplBase(OpKernelConstruction\* c, const string& op\_name) : OpKernel(c) { // Compute expected input signature const DataType dt = DataTypeToEnum<T>::v(); const int n = c->num\_inputs() / 2; DataTypeVector expected; for (int i = 0; i < n; i++) { expected.push\_back(DT\_INT32); } for (int i = 0; i < n; i++) { expected.push\_back(dt); } OP\_REQUIRES\_OK(c, c->MatchSignature(expected, {dt})); OP\_REQUIRES(c, c->num\_inputs() > 0, errors::InvalidArgument(op\_name + ": Must have some inputs")); OP\_REQUIRES(c, c->num\_inputs() % 2 == 0, errors::InvalidArgument( op\_name + ": Must have even number of arguments")); }
 protected: // Check if data0.shape[indices0.dims():] == data1.shape[indices1.dims():] static bool SameExtraShape(const Tensor& data0, const Tensor& indices0, const Tensor& data1, const Tensor& indices1) { const int extra0 = data0.dims() - indices0.dims(); const int extra1 = data1.dims() - indices1.dims(); if (extra0 != extra1) return false; for (int i = 0; i < extra0; i++) { if (data0.dim\_size(indices0.dims() + i) != data1.dim\_size(indices1.dims() + i)) { return false; } } return true; }
 void CheckArgsAndAllocateResult(OpKernelContext\* c, OpInputList\* indices\_inputs, OpInputList\* data\_inputs, int\* first\_dim\_size, int\* data\_elements\_size, Tensor\*\* result\_ptr) { // Find maximum index in the indices vectors OP\_REQUIRES\_OK(c, c->input\_list("indices", indices\_inputs));
 int32\_t max\_index = -1; if (data\_elements\_size) { \*data\_elements\_size = 0; } for (const Tensor& indices : \*indices\_inputs) { if (indices.NumElements() > 0) { Eigen::Tensor<int32, 0, Eigen::RowMajor> m = indices.flat<int32>().maximum(); max\_index = std::max(m(), max\_index); } if (data\_elements\_size) { \*data\_elements\_size += indices.NumElements(); } }
 \*first\_dim\_size = max\_index + 1;
 for (const Tensor& indices : \*indices\_inputs) { auto indices\_vec = indices.flat<int32>();
 for (int i = 0; i < indices\_vec.size(); i++) { int32\_t index = internal::SubtleMustCopy(indices\_vec(i)); OP\_REQUIRES( c, FastBoundsCheck(index, \*first\_dim\_size), errors::InvalidArgument("indices[", i, "] is out of range")); } }
 // Validate that data[i].shape = indices[i].shape + constant OP\_REQUIRES\_OK(c, c->input\_list("data", data\_inputs)); const Tensor& data0 = (\*data\_inputs)[0]; const Tensor& indices0 = (\*indices\_inputs)[0]; for (int input\_num = 0; input\_num < indices\_inputs->size(); input\_num++) { const Tensor& indices = (\*indices\_inputs)[input\_num]; const Tensor& data = (\*data\_inputs)[input\_num]; OP\_REQUIRES( c, TensorShapeUtils::StartsWith(data.shape(), indices.shape()), errors::InvalidArgument("data[", input\_num, "].shape = ", data.shape().DebugString(), " does not start with indices[", input\_num, "].shape = ", indices.shape().DebugString())); OP\_REQUIRES( c, input\_num == 0 || SameExtraShape(data0, indices0, data, indices), errors::InvalidArgument( "Need data[0].shape[", indices0.dims(), ":] = data[", input\_num, "].shape[", indices.dims(), ":], got data[0].shape = ", data0.shape().DebugString(), ", data[", input\_num, "].shape = ", data.shape().DebugString(), ", indices[0].shape = ", indices0.shape().DebugString(), ", indices[", input\_num, "].shape = ", indices.shape().DebugString())); }
 // Allocate result tensor of shape // [\*first\_dim\_size] + data.shape[indices.dims:] TensorShape result\_shape; OP\_REQUIRES\_OK(c, result\_shape.AddDimWithStatus(\*first\_dim\_size)); for (int d = indices0.dims(); d < data0.dims(); d++) { OP\_REQUIRES\_OK(c, result\_shape.AddDimWithStatus(data0.dim\_size(d))); } OP\_REQUIRES\_OK(c, c->allocate\_output(0, result\_shape, result\_ptr)); }};
#if GOOGLE\_CUDA || TENSORFLOW\_USE\_ROCM
template <typename T>void DynamicStitchGPUImpl(const Eigen::GpuDevice& gpu\_device, const int32\_t slice\_size, const int32\_t first\_dim\_size, const GpuDeviceArrayStruct<int>& input\_indices, const GpuDeviceArrayStruct<const T\*>& input\_ptrs, T\* output);#define REGISTER\_GPU(T) \ extern template void DynamicStitchGPUImpl( \ const Eigen::GpuDevice& gpu\_device, const int32 slice\_size, \ const int32 first\_dim\_size, \ const GpuDeviceArrayStruct<int32>& input\_indices, \ const GpuDeviceArrayStruct<const T\*>& input\_ptrs, T\* output);
TF\_CALL\_int32(REGISTER\_GPU);TF\_CALL\_int64(REGISTER\_GPU);TF\_CALL\_GPU\_NUMBER\_TYPES(REGISTER\_GPU);TF\_CALL\_COMPLEX\_TYPES(REGISTER\_GPU);#undef REGISTER\_GPU
template <class T>class DynamicStitchOpGPU : public DynamicStitchOpImplBase<T> { public: explicit DynamicStitchOpGPU(OpKernelConstruction\* c) : DynamicStitchOpImplBase<T>(c, "DynamicStitchOp") {}
 void Compute(OpKernelContext\* c) override { OpInputList indices\_inputs; OpInputList data\_inputs; int first\_dim\_size; int data\_elements\_size; Tensor\* merged = nullptr; this->CheckArgsAndAllocateResult(c, &indices\_inputs, &data\_inputs, &first\_dim\_size, &data\_elements\_size, &merged); if (!c->status().ok()) { // Avoid segmentation faults if merged cannot be allocated and an error is // passed back in the context. return; }
 if (first\_dim\_size > 0) { // because the collision requirements, we have to deal with // collision first before send data to gpu kernel. // TODO(ekelsen): Instead of doing a serial scan on the CPU to pick the // last of duplicated indices, it could instead be done of the GPU // implicitly using atomics to make sure the last index is the final // write. const int slice\_size = merged->flat\_outer\_dims<T>().dimension(1); GpuDeviceArrayOnHost<int32> indices\_flat(c, first\_dim\_size); GpuDeviceArrayOnHost<const T\*> data\_flat(c, data\_elements\_size); OP\_REQUIRES\_OK(c, indices\_flat.Init()); OP\_REQUIRES\_OK(c, data\_flat.Init()); // initialize the indices\_flat (-1 represents missing indices) for (int i = 0; i < first\_dim\_size; ++i) { indices\_flat.Set(i, -1); }
 // data\_flat index int32\_t idx = 0; // sum of indices\_inputs[i].NumElements() for compute indices\_flat value. int32\_t base\_size = 0; for (int i = 0; i < indices\_inputs.size(); ++i) { auto indices\_vec = indices\_inputs[i].flat<int32>(); auto data\_ptr\_base = data\_inputs[i].template flat<T>().data(); for (int j = 0; j < indices\_vec.size(); ++j) { // indices\_flat's indices represent the indices of output. // indices\_flat's values represent the indices of input\_data where the // data located. indices\_flat.Set(indices\_vec(j), base\_size + j); data\_flat.Set( idx, const\_cast<T\*>(reinterpret\_cast<const T\*>(data\_ptr\_base) + j \* slice\_size)); ++idx; } base\_size += indices\_vec.size(); } OP\_REQUIRES\_OK(c, indices\_flat.Finalize()); OP\_REQUIRES\_OK(c, data\_flat.Finalize());
 auto merged\_flat = merged->template flat<T>(); functor::SetZeroFunctor<GPUDevice, T> f; f(c->eigen\_device<GPUDevice>(), merged\_flat); auto output = merged\_flat.data(); DynamicStitchGPUImpl<T>(c->eigen\_gpu\_device(), slice\_size, first\_dim\_size, indices\_flat.data(), data\_flat.data(), output); } }};
#endif // GOOGLE\_CUDA || TENSORFLOW\_USE\_ROCM
template <class T, bool Parallel>class DynamicStitchOpImplCPU : public DynamicStitchOpImplBase<T> { public: explicit DynamicStitchOpImplCPU(OpKernelConstruction\* c) : DynamicStitchOpImplBase<T>( c, (Parallel ? "ParallelDynamicStitchOp" : "DynamicStitchOp")) {}
 void Compute(OpKernelContext\* c) override { OpInputList indices\_inputs; OpInputList data\_inputs; int first\_dim\_size; Tensor\* merged = nullptr; this->CheckArgsAndAllocateResult(c, &indices\_inputs, &data\_inputs, &first\_dim\_size, nullptr, &merged); if (!c->status().ok()) { // Avoid segmentation faults if merged cannot be allocated and an error is // passed back in the context. return; }
 if (first\_dim\_size > 0) { functor::SetZeroFunctor<CPUDevice, T> f; f(c->eigen\_device<CPUDevice>(), merged->template flat<T>()); auto merged\_flat = merged->flat\_outer\_dims<T>(); // slice\_size must not be stored as int for cases of tensors over 2GB. const auto slice\_size = merged\_flat.dimension(1); const size\_t slice\_bytes = slice\_size \* sizeof(T); auto OnInputNumber = [&](int input\_num) { const Tensor& indices = indices\_inputs[input\_num]; auto indices\_vec = indices.flat<int32>(); const Tensor& data = data\_inputs[input\_num]; auto data\_flat = data.shaped<T, 2>({indices\_vec.dimension(0), slice\_size});
 if (DataTypeCanUseMemcpy(DataTypeToEnum<T>::v())) { T\* merged\_base = merged\_flat.data(); const T\* data\_base = data\_flat.data(); for (int i = 0; i < indices\_vec.size(); i++) { int32\_t index = internal::SubtleMustCopy(indices\_vec(i)); memcpy(merged\_base + index \* slice\_size, data\_base + i \* slice\_size, slice\_bytes); } } else { Eigen::DSizes<Eigen::DenseIndex, 2> sizes(1, slice\_size); for (int i = 0; i < indices\_vec.size(); i++) { // Copy slice data[i] to merged[indices[i]] Eigen::DSizes<Eigen::DenseIndex, 2> data\_indices(i, 0); int32\_t index = internal::SubtleMustCopy(indices\_vec(i)); Eigen::DSizes<Eigen::DenseIndex, 2> merged\_indices(index, 0); merged\_flat.slice(merged\_indices, sizes) = data\_flat.slice(data\_indices, sizes); } } }; if (Parallel && c->device()->tensorflow\_cpu\_worker\_threads()->num\_threads > 1) { auto thread\_pool = c->device()->tensorflow\_cpu\_worker\_threads()->workers; size\_t total\_indices\_size = 0; for (int input\_num = 0; input\_num < indices\_inputs.size(); ++input\_num) { total\_indices\_size += indices\_inputs[input\_num].NumElements(); } const double avg\_indices\_size = static\_cast<double>(total\_indices\_size) / indices\_inputs.size(); auto bytes\_processed = slice\_bytes \* avg\_indices\_size; auto LoopBody = [&](int first, int last) { for (int input\_num = first; input\_num < last; ++input\_num) { OnInputNumber(input\_num); } }; thread\_pool->ParallelFor(indices\_inputs.size(), bytes\_processed, LoopBody); } else { for (int input\_num = 0; input\_num < indices\_inputs.size(); input\_num++) { OnInputNumber(input\_num); } } } }};
// Using inheritance rather than a typedef so that these classes might have more// functionality later.
template <typename T>struct DynamicStitchOpCPU : DynamicStitchOpImplCPU<T, false> { using DynamicStitchOpImplCPU<T, false>::DynamicStitchOpImplCPU;};
template <typename T>struct ParallelDynamicStitchOpCPU : DynamicStitchOpImplCPU<T, true> { using DynamicStitchOpImplCPU<T, true>::DynamicStitchOpImplCPU;};
#define REGISTER\_DYNAMIC\_STITCH(type) \ REGISTER\_KERNEL\_BUILDER(Name("DynamicStitch") \ .Device(DEVICE\_CPU) \ .TypeConstraint<type>("T") \ .HostMemory("indices"), \ DynamicStitchOpCPU<type>) \ REGISTER\_KERNEL\_BUILDER(Name("ParallelDynamicStitch") \ .Device(DEVICE\_CPU) \ .TypeConstraint<type>("T") \ .HostMemory("indices"), \ ParallelDynamicStitchOpCPU<type>)
TF\_CALL\_POD\_STRING\_TYPES(REGISTER\_DYNAMIC\_STITCH);TF\_CALL\_variant(REGISTER\_DYNAMIC\_STITCH);TF\_CALL\_QUANTIZED\_TYPES(REGISTER\_DYNAMIC\_STITCH);#undef REGISTER\_DYNAMIC\_STITCH
#define REGISTER\_PARALLEL\_DYNAMIC\_STITCH(type) \ REGISTER\_KERNEL\_BUILDER(Name("ParallelDynamicStitch") \ .Device(DEVICE\_DEFAULT) \ .TypeConstraint<type>("T") \ .HostMemory("indices") \ .HostMemory("data") \ .HostMemory("merged"), \ ParallelDynamicStitchOpCPU<type>)
TF\_CALL\_int32(REGISTER\_PARALLEL\_DYNAMIC\_STITCH);TF\_CALL\_int64(REGISTER\_PARALLEL\_DYNAMIC\_STITCH);TF\_CALL\_GPU\_NUMBER\_TYPES(REGISTER\_PARALLEL\_DYNAMIC\_STITCH);TF\_CALL\_COMPLEX\_TYPES(REGISTER\_PARALLEL\_DYNAMIC\_STITCH);#undef REGISTER\_PARALLEL\_DYNAMIC\_STITCH
#if GOOGLE\_CUDA || TENSORFLOW\_USE\_ROCM#define REGISTER\_DYNAMIC\_STITCH\_GPU(type) \ REGISTER\_KERNEL\_BUILDER(Name("DynamicStitch") \ .Device(DEVICE\_GPU) \ .TypeConstraint<type>("T") \ .HostMemory("indices"), \ DynamicStitchOpGPU<type>)
TF\_CALL\_int32(REGISTER\_DYNAMIC\_STITCH\_GPU);TF\_CALL\_int64(REGISTER\_DYNAMIC\_STITCH\_GPU);TF\_CALL\_GPU\_NUMBER\_TYPES(REGISTER\_DYNAMIC\_STITCH\_GPU);TF\_CALL\_COMPLEX\_TYPES(REGISTER\_DYNAMIC\_STITCH\_GPU);#undef REGISTER\_DYNAMIC\_STITCH\_GPU#endif // GOOGLE\_CUDA || TENSORFLOW\_USE\_ROCM
#if defined(PLUGGABLE\_DEVICE\_SUPPORTED\_MACOS)#define REGISTER\_DYNAMIC\_STITCH\_DEFAULT\_DEVICE(type) \ REGISTER\_KERNEL\_BUILDER(Name("DynamicStitch") \ .Device(DEVICE\_DEFAULT) \ .TypeConstraint<type>("T") \ .HostMemory("indices") \ .HostMemory("data") \ .HostMemory("merged"), \ DynamicStitchOpCPU<type>)
TF\_CALL\_int32(REGISTER\_DYNAMIC\_STITCH\_DEFAULT\_DEVICE);TF\_CALL\_int64(REGISTER\_DYNAMIC\_STITCH\_DEFAULT\_DEVICE);TF\_CALL\_GPU\_NUMBER\_TYPES(REGISTER\_DYNAMIC\_STITCH\_DEFAULT\_DEVICE);TF\_CALL\_COMPLEX\_TYPES(REGISTER\_DYNAMIC\_STITCH\_DEFAULT\_DEVICE);#undef REGISTER\_DYNAMIC\_STITCH\_DEFAULT\_DEVICE#endif
} // namespace tensorflow

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_c4722308_20250115_093405.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2Ff5381e0e10b5a61344109c1b7c174c68110f7629)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2Ff5381e0e10b5a61344109c1b7c174c68110f7629)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fcommit_fragments%2Frepo_layout&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  826](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Commit

[Permalink](/tensorflow/tensorflow/commit/f5381e0e10b5a61344109c1b7c174c68110f7629)

This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.

Fix OOB error when op input sizes do not match.

[Browse files](/tensorflow/tensorflow/tree/f5381e0e10b5a61344109c1b7c174c68110f7629)
Browse the repository at this point in the history

```
In cases where op input sizes are specified as in
```
REGISTER_OP("DynamicStitch")
    .Input("indices: N * int32")
    .Input("data: N * T")
    .Output("merged: T")
    .Attr("N : int >= 1")
    .Attr("T : type")
    .SetShapeFn(DynamicStitchShapeFunction);
```
if differing number of inputs are provided (e.g. 3 for `indices` and 4 for `data`)
we can get a crash in the executor when parsing the inputs, even before the kernel
called.  Here we avoid this by checking the return code for the argument id and
exit early.

PiperOrigin-RevId: 478068540
```

* Loading branch information

[![@cantonios](https://avatars.githubusercontent.com/u/2538739?s=40&v=4)](/cantonios) [![@tensorflower-gardener](https://avatars.githubusercontent.com/u/17151892?s=40&v=4)](/tensorflower-gardener)

[cantonios](/tensorflow/tensorflow/commits?author=cantonios "View all commits by cantonios")
authored and
[tensorflower-gardener](/tensorflow/tensorflow/commits?author=tensorflower-gardener "View all commits by tensorflower-gardener")
committed
Sep 30, 2022

1 parent
[7e89804](/tensorflow/tensorflow/commit/7e8980426d43416f9135ef335f8f895064eba3ba)

commit f5381e0

 Show file tree

 Hide file tree

Showing
**2 changed files**
with
**28 additions**
and
**0 deletions**.

* Whitespace
* Ignore whitespace

* Split
* Unified

* tensorflow

  + core/common\_runtime/eager

    - tensorflow/core/common\_runtime/eager/execute.cc
      [execute.cc](#diff-ba6ea5a9ca5f90005c085b72a9d26bc9ab05fab759b222b51cb6e3f45bf9824d)
  + python/kernel\_tests/data\_structures

    - tensorflow/python/kernel\_tests/data\_structures/dynamic\_stitch\_op\_test.py
      [dynamic\_stitch\_op\_test.py](#diff-3980ed1162f46fb9a89b276871a608d544a92d41298c414548805d8973348381)

## There are no files selected for viewing

4 changes: 4 additions & 0 deletions

4
[tensorflow/core/common\_runtime/eager/execute.cc](#diff-ba6ea5a9ca5f90005c085b72a9d26bc9ab05fab759b222b51cb6e3f45bf9824d "tensorflow/core/common_runtime/eager/execute.cc")

Show comments

[View file](/tensorflow/tensorflow/blob/f5381e0e10b5a61344109c1b7c174c68110f7629/tensorflow/core/common_runtime/eager/execute.cc)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -313,6 +313,10 @@ bool IsHostMemoryArg(const EagerOperation& op, const NodeDef\* node\_def, |
|  |  | const auto& host\_memory\_args = kernel\_def->host\_memory\_arg(); |
|  |  | const OpDef& op\_def = OpRegistry::Global()->LookUp(op.Name())->op\_def; |
|  |  | const int arg\_id = OpPortIdToArgId(\*node\_def, op\_def.input\_arg(), port\_id); |
|  |  | // Fail if argument ID not found. |
|  |  | if (arg\_id < 0) { |
|  |  | return false; |
|  |  | } |
|  |  | return std::find(host\_memory\_args.begin(), host\_memory\_args.end(), |
|  |  | op\_def.input\_arg(arg\_id).name()) != host\_memory\_args.end(); |
|  |  | } |
| Expand Down | |  |

24 changes: 24 additions & 0 deletions

24
[tensorflow/python/kernel\_tests/data\_structures/dynamic\_stitch\_op\_test.py](#diff-3980ed1162f46fb9a89b276871a608d544a92d41298c414548805d8973348381 "tensorflow/python/kernel_tests/data_structures/dynamic_stitch_op_test.py")

Show comments

[View file](/tensorflow/tensorflow/blob/f5381e0e10b5a61344109c1b7c174c68110f7629/tensorflow/python/kernel_tests/data_structures/dynamic_stitch_op_test.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -18,6 +18,7 @@ |
|  |  |  |
|  |  | from tensorflow.python.framework import constant\_op |
|  |  | from tensorflow.python.framework import dtypes |
|  |  | from tensorflow.python.framework import errors |
|  |  | from tensorflow.python.framework import test\_util |
|  |  | from tensorflow.python.ops import array\_ops |
|  |  | from tensorflow.python.ops import data\_flow\_ops |
| Expand Down  Expand Up | | @@ -308,6 +309,29 @@ def testHigherRankGPU(self): |
|  |  | for datum, grad in zip(data, self.evaluate(grads[3:])): |
|  |  | self.assertAllEqual(7.0 \* self.evaluate(datum), grad) |
|  |  |  |
|  |  | @test\_util.run\_in\_graph\_and\_eager\_modes |
|  |  | def testMismatchedDataAndIndexListSizes(self): |
|  |  | indices = [ |
|  |  | constant\_op.constant([2]), |
|  |  | constant\_op.constant([1]), |
|  |  | constant\_op.constant([0]), |
|  |  | constant\_op.constant([3]), |
|  |  | ] |
|  |  | data = [ |
|  |  | constant\_op.constant([1.0]), |
|  |  | constant\_op.constant([2.0]), |
|  |  | constant\_op.constant([3.0]), |
|  |  | constant\_op.constant([4.0]) |
|  |  | ] |
|  |  | with self.assertRaisesRegex( |
|  |  | (ValueError, errors.InvalidArgumentError), |
|  |  | "expected inputs .\* do not match|List argument .\* must match"): |
|  |  | self.evaluate(data\_flow\_ops.dynamic\_stitch(indices[0:2], data)) |
|  |  |  |
|  |  | with self.assertRaisesRegex( |
|  |  | (ValueError, errors.InvalidArgumentError), |
|  |  | "expected inputs .\* do not match|List argument .\* must match"): |
|  |  | self.evaluate(data\_flow\_ops.dynamic\_stitch(indices, data[0:2])) |
|  |  |  |
|  |  | if \_\_name\_\_ == "\_\_main\_\_": |
|  |  | test.main() |

Toggle all file notes
Toggle all file annotations

### 0 comments on commit `f5381e0`

Please
[sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fcommit%2Ff5381e0e10b5a61344109c1b7c174c68110f7629) to comment.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_5c96a01a_20250115_093404.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Fmaster%2Ftensorflow%2Fcore%2Fops%2Fdata_flow_ops.cc)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Fmaster%2Ftensorflow%2Fcore%2Fops%2Fdata_flow_ops.cc)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  826](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Files

 master
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/master)
2. /[tensorflow](/tensorflow/tensorflow/tree/master/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/master/tensorflow/core)
4. /[ops](/tensorflow/tensorflow/tree/master/tensorflow/core/ops)
/
# data\_flow\_ops.cc

Copy path Blame  Blame
## Latest commit

## History

[History](/tensorflow/tensorflow/commits/master/tensorflow/core/ops/data_flow_ops.cc)1464 lines (1329 loc) · 48.5 KB master
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/master)
2. /[tensorflow](/tensorflow/tensorflow/tree/master/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/master/tensorflow/core)
4. /[ops](/tensorflow/tensorflow/tree/master/tensorflow/core/ops)
/
# data\_flow\_ops.cc

Top
## File metadata and controls

* Code
* Blame

1464 lines (1329 loc) · 48.5 KB[Raw](https://github.com/tensorflow/tensorflow/raw/refs/heads/master/tensorflow/core/ops/data_flow_ops.cc)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000/\* Copyright 2015 The TensorFlow Authors. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");you may not use this file except in compliance with the License.You may obtain a copy of the License at
 http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.==============================================================================\*/
#include "tensorflow/core/framework/common\_shape\_fns.h"#include "tensorflow/core/framework/op.h"#include "tensorflow/core/framework/op\_def\_builder.h"#include "tensorflow/core/framework/shape\_inference.h"
namespace tensorflow {
using shape\_inference::DimensionHandle;using shape\_inference::InferenceContext;using shape\_inference::ShapeHandle;
namespace {
absl::Status DequeueManyV2Shape(InferenceContext\* c, ShapeHandle n\_shape) { auto\* t = c->input\_handle\_shapes\_and\_types(0); if (t != nullptr && t->size() == c->num\_outputs()) { for (int i = 0; i < c->num\_outputs(); ++i) { ShapeHandle combined\_shape; TF\_RETURN\_IF\_ERROR( c->Concatenate(n\_shape, (\*t)[i].shape, &combined\_shape)); c->set\_output(i, combined\_shape); } return absl::OkStatus(); } else { return shape\_inference::UnknownShape(c); }}
} // namespace
// --------------------------------------------------------------------------
REGISTER\_OP("DynamicPartition") .Input("data: T") .Input("partitions: int32") .Output("outputs: num\_partitions \* T") .Attr("num\_partitions: int") .Attr("T: type") .SetShapeFn([](InferenceContext\* c) { int64\_t num\_partitions; TF\_RETURN\_IF\_ERROR(c->GetAttr("num\_partitions", &num\_partitions));
 ShapeHandle data\_shape = c->input(0); ShapeHandle partitions\_shape = c->input(1);
 if (!c->RankKnown(partitions\_shape)) { return shape\_inference::UnknownShape(c); }
 const int64\_t rank = c->Rank(partitions\_shape);
 // data shape must start with partitions\_shape ShapeHandle unused; TF\_RETURN\_IF\_ERROR( c->MergePrefix(data\_shape, partitions\_shape, &unused, &unused));
 // The partition shape is dynamic in the 0th dimension, and matches // data\_shape in the remaining dimensions. ShapeHandle unknown\_dim0 = c->MakeShape({c->UnknownDim()});
 ShapeHandle data\_suffix\_shape; TF\_RETURN\_IF\_ERROR(c->Subshape(data\_shape, rank, &data\_suffix\_shape)); ShapeHandle result\_shape; TF\_RETURN\_IF\_ERROR( c->Concatenate(unknown\_dim0, data\_suffix\_shape, &result\_shape));
 for (int i = 0; i < c->num\_outputs(); ++i) { c->set\_output(i, result\_shape); }
 return absl::OkStatus(); });
namespace {
absl::Status DynamicStitchShapeFunction(InferenceContext\* c) { int32\_t num\_partitions; TF\_RETURN\_IF\_ERROR(c->GetAttr("N", &num\_partitions));
 bool all\_indices\_constant = true; int32\_t max\_index = -1; ShapeHandle extra\_shape = c->UnknownShape(); for (int i = 0; i < num\_partitions; ++i) { const Tensor\* indices\_t = c->input\_tensor(i); if (indices\_t == nullptr) { all\_indices\_constant = false; }
 ShapeHandle indices\_shape = c->input(i); ShapeHandle data\_shape = c->input(i + num\_partitions); if (!c->RankKnown(indices\_shape)) { continue; } const int64\_t indices\_rank = c->Rank(indices\_shape);
 // Assert that data\_shape starts with indices\_shape. ShapeHandle unused; TF\_RETURN\_IF\_ERROR( c->MergePrefix(data\_shape, indices\_shape, &unused, &unused));
 // The rest belongs to output. ShapeHandle rest; TF\_RETURN\_IF\_ERROR(c->Subshape(data\_shape, indices\_rank, &rest)); TF\_RETURN\_IF\_ERROR(c->Merge(extra\_shape, rest, &extra\_shape));
 if (indices\_t != nullptr) { // The length is based on the highest index from flattened indices. const int32\* indices = indices\_t->flat<int32>().data(); int64\_t count = indices\_t->NumElements(); for (int64\_t i = 0; i < count; ++i) { if (indices[i] > max\_index) { max\_index = indices[i]; } } } }
 ShapeHandle output\_shape = c->Vector( all\_indices\_constant ? c->MakeDim(max\_index + 1) : c->UnknownDim()); TF\_RETURN\_IF\_ERROR(c->Concatenate(output\_shape, extra\_shape, &output\_shape)); c->set\_output(0, output\_shape); return absl::OkStatus();}
} // namespace
REGISTER\_OP("DynamicStitch") .Input("indices: N \* int32") .Input("data: N \* T") .Output("merged: T") .Attr("N : int >= 1") .Attr("T : type") .SetShapeFn(DynamicStitchShapeFunction);
REGISTER\_OP("ParallelDynamicStitch") .Input("indices: N \* int32") .Input("data: N \* T") .Output("merged: T") .Attr("N : int >= 1") .Attr("T : type") .SetShapeFn(DynamicStitchShapeFunction);
// --------------------------------------------------------------------------
namespace {absl::Status TwoElementVectorInputsAndScalarOutputs(InferenceContext\* c) { ShapeHandle handle; DimensionHandle unused\_handle; for (int i = 0; i < c->num\_inputs(); ++i) { TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(i), 1, &handle)); TF\_RETURN\_IF\_ERROR(c->WithValue(c->Dim(handle, 0), 2, &unused\_handle)); } for (int i = 0; i < c->num\_outputs(); ++i) { c->set\_output(i, c->Scalar()); } return absl::OkStatus();}
absl::Status TwoElementOutput(InferenceContext\* c) { c->set\_output(0, c->Vector(2)); return absl::OkStatus();}} // namespace
REGISTER\_OP("RandomShuffleQueue") .Output("handle: Ref(string)") .Attr("component\_types: list(type) >= 1") .Attr("shapes: list(shape) >= 0 = []") .Attr("capacity: int = -1") .Attr("min\_after\_dequeue: int = 0") .Attr("seed: int = 0") .Attr("seed2: int = 0") .Attr("container: string = ''") .Attr("shared\_name: string = ''") .SetIsStateful() .SetShapeFn(TwoElementOutput);
REGISTER\_OP("RandomShuffleQueueV2") .Output("handle: resource") .Attr("component\_types: list(type) >= 1") .Attr("shapes: list(shape) >= 0 = []") .Attr("capacity: int = -1") .Attr("min\_after\_dequeue: int = 0") .Attr("seed: int = 0") .Attr("seed2: int = 0") .Attr("container: string = ''") .Attr("shared\_name: string = ''") .SetIsStateful() .SetShapeFn(shape\_inference::ScalarShape);
REGISTER\_OP("FIFOQueue") .Output("handle: Ref(string)") .Attr("component\_types: list(type) >= 1") .Attr("shapes: list(shape) >= 0 = []") .Attr("capacity: int = -1") .Attr("container: string = ''") .Attr("shared\_name: string = ''") .SetIsStateful() .SetShapeFn(TwoElementOutput);
REGISTER\_OP("FIFOQueueV2") .Output("handle: resource") .Attr("component\_types: list(type) >= 1") .Attr("shapes: list(shape) >= 0 = []") .Attr("capacity: int = -1") .Attr("container: string = ''") .Attr("shared\_name: string = ''") .SetIsStateful() .SetShapeFn(shape\_inference::ScalarShape);
REGISTER\_OP("PaddingFIFOQueue") .Output("handle: Ref(string)") .Attr("component\_types: list(type) >= 1") .Attr("shapes: list(shape) >= 0 = []") .Attr("capacity: int = -1") .Attr("container: string = ''") .Attr("shared\_name: string = ''") .SetIsStateful() .SetShapeFn(TwoElementOutput);
REGISTER\_OP("PaddingFIFOQueueV2") .Output("handle: resource") .Attr("component\_types: list(type) >= 1") .Attr("shapes: list(shape) >= 0 = []") .Attr("capacity: int = -1") .Attr("container: string = ''") .Attr("shared\_name: string = ''") .SetIsStateful() .SetShapeFn(shape\_inference::ScalarShape);
REGISTER\_OP("PriorityQueue") .Output("handle: Ref(string)") .Attr("component\_types: list(type) >= 0 = []") .Attr("shapes: list(shape) >= 0") .Attr("capacity: int = -1") .Attr("container: string = ''") .Attr("shared\_name: string = ''") .SetIsStateful() .SetShapeFn(TwoElementOutput);
REGISTER\_OP("PriorityQueueV2") .Output("handle: resource") .Attr("component\_types: list(type) >= 0 = []") .Attr("shapes: list(shape) >= 0") .Attr("capacity: int = -1") .Attr("container: string = ''") .Attr("shared\_name: string = ''") .SetIsStateful() .SetShapeFn(shape\_inference::ScalarShape);
REGISTER\_OP("FakeQueue") .Input("resource: resource") .Output("handle: Ref(string)") .SetIsStateful() .SetShapeFn(TwoElementOutput);
REGISTER\_OP("QueueEnqueue") .Input("handle: Ref(string)") .Input("components: Tcomponents") .Attr("Tcomponents: list(type) >= 1") .Attr("timeout\_ms: int = -1") .SetShapeFn(shape\_inference::UnknownShape);
REGISTER\_OP("QueueEnqueueV2") .Input("handle: resource") .Input("components: Tcomponents") .Attr("Tcomponents: list(type) >= 1") .Attr("timeout\_ms: int = -1") .SetShapeFn(shape\_inference::UnknownShape);
REGISTER\_OP("QueueEnqueueMany") .Input("handle: Ref(string)") .Input("components: Tcomponents") .Attr("Tcomponents: list(type) >= 1") .Attr("timeout\_ms: int = -1") .SetShapeFn(shape\_inference::UnknownShape);
REGISTER\_OP("QueueEnqueueManyV2") .Input("handle: resource") .Input("components: Tcomponents") .Attr("Tcomponents: list(type) >= 1") .Attr("timeout\_ms: int = -1") .SetShapeFn(shape\_inference::UnknownShape);
REGISTER\_OP("QueueDequeue") .Input("handle: Ref(string)") .Output("components: component\_types") .Attr("component\_types: list(type) >= 1") .Attr("timeout\_ms: int = -1") .SetShapeFn(shape\_inference::UnknownShape);
REGISTER\_OP("QueueDequeueV2") .Input("handle: resource") .Output("components: component\_types") .Attr("component\_types: list(type) >= 1") .Attr("timeout\_ms: int = -1") .SetShapeFn([](InferenceContext\* c) { auto\* t = c->input\_handle\_shapes\_and\_types(0); if (t != nullptr && t->size() == c->num\_outputs()) { for (int i = 0; i < c->num\_outputs(); ++i) { c->set\_output(i, (\*t)[i].shape); } return absl::OkStatus(); } else { return shape\_inference::UnknownShape(c); } });
REGISTER\_OP("QueueDequeueMany") .Input("handle: Ref(string)") .Input("n: int32") .Output("components: component\_types") .Attr("component\_types: list(type) >= 1") .Attr("timeout\_ms: int = -1") .SetShapeFn(shape\_inference::UnknownShape);
REGISTER\_OP("QueueDequeueManyV2") .Input("handle: resource") .Input("n: int32") .Output("components: component\_types") .Attr("component\_types: list(type) >= 1") .Attr("timeout\_ms: int = -1") .SetShapeFn([](InferenceContext\* c) { ShapeHandle n\_shape; if (c->input\_tensor(1) == nullptr) { n\_shape = c->Vector(InferenceContext::kUnknownDim); } else { const int32\_t n = c->input\_tensor(1)->scalar<int32>()(); if (n < 0) { return errors::InvalidArgument("Input 'n' must be >= 0, but is ", n); } n\_shape = c->Vector(n); } return DequeueManyV2Shape(c, n\_shape); });
REGISTER\_OP("QueueDequeueUpTo") .Input("handle: Ref(string)") .Input("n: int32") .Output("components: component\_types") .Attr("component\_types: list(type) >= 1") .Attr("timeout\_ms: int = -1") .SetShapeFn(shape\_inference::UnknownShape);
REGISTER\_OP("QueueDequeueUpToV2") .Input("handle: resource") .Input("n: int32") .Output("components: component\_types") .Attr("component\_types: list(type) >= 1") .Attr("timeout\_ms: int = -1") .SetShapeFn([](InferenceContext\* c) { return DequeueManyV2Shape(c, c->Vector(InferenceContext::kUnknownDim)); });
REGISTER\_OP("QueueClose") .Input("handle: Ref(string)") .SetShapeFn(TwoElementVectorInputsAndScalarOutputs) .Attr("cancel\_pending\_enqueues: bool = false");
REGISTER\_OP("QueueCloseV2") .Input("handle: resource") .SetShapeFn(shape\_inference::NoOutputs) .Attr("cancel\_pending\_enqueues: bool = false");
REGISTER\_OP("QueueIsClosed") .Input("handle: Ref(string)") .Output("is\_closed: bool") .SetShapeFn(shape\_inference::ScalarShape);
REGISTER\_OP("QueueIsClosedV2") .Input("handle: resource") .Output("is\_closed: bool") .SetShapeFn(shape\_inference::ScalarShape);
REGISTER\_OP("QueueSize") .Input("handle: Ref(string)") .Output("size: int32") .SetShapeFn(TwoElementVectorInputsAndScalarOutputs);
REGISTER\_OP("QueueSizeV2") .Input("handle: resource") .Output("size: int32") .SetShapeFn(shape\_inference::UnchangedShape);
// --------------------------------------------------------------------------
REGISTER\_OP("AccumulatorNumAccumulated") .Input("handle: Ref(string)") .Output("num\_accumulated: int32") .SetShapeFn(shape\_inference::ScalarShape);
REGISTER\_OP("AccumulatorSetGlobalStep") .Input("handle: Ref(string)") .Input("new\_global\_step: int64") .SetShapeFn([](InferenceContext\* c) { ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 0, &unused)); return absl::OkStatus(); });
REGISTER\_OP("ConditionalAccumulator") .Output("handle: Ref(string)") .Attr("dtype: numbertype") .Attr("shape: shape") .Attr("container: string = ''") .Attr("shared\_name: string = ''") .Attr("reduction\_type: { 'MEAN', 'SUM' } = 'MEAN' ") .SetIsStateful() .SetShapeFn([](InferenceContext\* c) { c->set\_output(0, c->Vector(2)); return absl::OkStatus(); });
REGISTER\_OP("AccumulatorApplyGradient") .Input("handle: Ref(string)") .Input("local\_step: int64") .Input("gradient: dtype") .Attr("dtype: numbertype") .SetShapeFn([](InferenceContext\* c) { ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 0, &unused)); return absl::OkStatus(); });
REGISTER\_OP("AccumulatorTakeGradient") .Input("handle: Ref(string)") .Input("num\_required: int32") .Output("average: dtype") .SetShapeFn([](InferenceContext\* c) { ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 0, &unused)); // Shape of output is the shape of the accumulator referenced // by 'handle', but which is not available here, so we lose // shape information. return shape\_inference::UnknownShape(c); }) .Attr("dtype: numbertype");
// -----------------V2 accumulators that use resource -------------------------
REGISTER\_OP("ResourceAccumulatorNumAccumulated") .Input("handle: resource") .Output("num\_accumulated: int32") .SetShapeFn(shape\_inference::ScalarShape);
REGISTER\_OP("ResourceAccumulatorSetGlobalStep") .Input("handle: resource") .Input("new\_global\_step: int64") .SetShapeFn([](InferenceContext\* c) { ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 0, &unused)); return absl::OkStatus(); });
REGISTER\_OP("ResourceConditionalAccumulator") .Output("handle: resource") .Attr("dtype: numbertype") .Attr("shape: shape") .Attr("container: string = ''") .Attr("shared\_name: string = ''") .Attr("reduction\_type: { 'MEAN', 'SUM' } = 'MEAN' ") .SetIsStateful() .SetShapeFn([](InferenceContext\* c) { c->set\_output(0, c->Vector(2)); return absl::OkStatus(); });
REGISTER\_OP("ResourceAccumulatorApplyGradient") .Input("handle: resource") .Input("local\_step: int64") .Input("gradient: dtype") .Attr("dtype: numbertype") .SetShapeFn([](InferenceContext\* c) { ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 0, &unused)); return absl::OkStatus(); });
REGISTER\_OP("ResourceAccumulatorTakeGradient") .Input("handle: resource") .Input("num\_required: int32") .Output("average: dtype") .SetShapeFn([](InferenceContext\* c) { ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 0, &unused)); // Shape of output is the shape of the accumulator referenced // by 'handle', but which is not available here, so we lose // shape information. return shape\_inference::UnknownShape(c); }) .Attr("dtype: numbertype");
// TODO(nponomareva): change these all to use resources.REGISTER\_OP("SparseConditionalAccumulator") .Output("handle: Ref(string)") .Attr("dtype: numbertype") .Attr("shape: shape") .Attr("container: string = ''") .Attr("shared\_name: string = ''") .Attr("reduction\_type: { 'MEAN', 'SUM' } = 'MEAN' ") .SetIsStateful() .SetShapeFn([](InferenceContext\* c) { c->set\_output(0, c->Vector(2)); return absl::OkStatus(); });
REGISTER\_OP("SparseAccumulatorApplyGradient") .Input("handle: Ref(string)") .Input("local\_step: int64") .Input("gradient\_indices: int64") .Input("gradient\_values: dtype") .Input("gradient\_shape: int64") .Attr("dtype: numbertype") .Attr("has\_known\_shape: bool") .SetShapeFn([](InferenceContext\* c) { ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 0, &unused)); return absl::OkStatus(); });
REGISTER\_OP("SparseAccumulatorTakeGradient") .Input("handle: Ref(string)") .Input("num\_required: int32") .Output("indices: int64") .Output("values: dtype") .Output("shape: int64") .Attr("dtype: numbertype") .SetShapeFn([](InferenceContext\* c) { ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 0, &unused)); // Shape of output is the shape of the accumulator referenced // by 'handle', but which is not available here, so we lose // shape information. return shape\_inference::UnknownShape(c); });
// --------------------------------------------------------------------------
REGISTER\_OP("StackV2") .Input("max\_size: int32") .Output("handle: resource") .Attr("elem\_type: type") .Attr("stack\_name: string = ''") .SetIsStateful() .SetShapeFn(TwoElementOutput);
REGISTER\_OP("StackPushV2") .Input("handle: resource") .Input("elem: T") .Output("output: T") .Attr("T: type") .Attr("swap\_memory: bool = false") .SetShapeFn([](shape\_inference::InferenceContext\* c) { c->set\_output(0, c->input(1)); return absl::OkStatus(); });
REGISTER\_OP("StackPopV2") .Input("handle: resource") .Output("elem: elem\_type") .Attr("elem\_type: type") .SetShapeFn(shape\_inference::UnknownShape);
REGISTER\_OP("StackCloseV2") .Input("handle: resource") .SetShapeFn(TwoElementVectorInputsAndScalarOutputs);
// Deprecated ref-typed variants of stack.
REGISTER\_OP("Stack") .Output("handle: Ref(string)") .Attr("elem\_type: type") .Attr("stack\_name: string = ''") .SetIsStateful() .SetShapeFn(TwoElementOutput);
REGISTER\_OP("StackPush") .Input("handle: Ref(string)") .Input("elem: T") .Output("output: T") .Attr("T: type") .Attr("swap\_memory: bool = false") .SetShapeFn([](shape\_inference::InferenceContext\* c) { c->set\_output(0, c->input(1)); return absl::OkStatus(); });
REGISTER\_OP("StackPop") .Input("handle: Ref(string)") .Output("elem: elem\_type") .Attr("elem\_type: type") .SetShapeFn(shape\_inference::UnknownShape);
REGISTER\_OP("StackClose") .Input("handle: Ref(string)") .SetShapeFn(TwoElementVectorInputsAndScalarOutputs);
// --------------------------------------------------------------------------
REGISTER\_OP("TensorArrayV3") .Input("size: int32") .Attr("dtype: type") .Attr("element\_shape: shape = { unknown\_rank: true }") .Attr("dynamic\_size: bool = false") .Attr("clear\_after\_read: bool = true") .Attr("identical\_element\_shapes: bool = false") .Attr("tensor\_array\_name: string = ''") .Output("handle: resource") .Output("flow: float") .SetIsStateful() .SetShapeFn([](InferenceContext\* c) { ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 0, &unused)); c->set\_output(0, c->Vector(2)); c->set\_output(1, c->Scalar()); bool identical\_shapes; TF\_RETURN\_IF\_ERROR( c->GetAttr("identical\_element\_shapes", &identical\_shapes)); DataType t; TF\_RETURN\_IF\_ERROR(c->GetAttr("dtype", &t)); PartialTensorShape p; TF\_RETURN\_IF\_ERROR(c->GetAttr("element\_shape", &p)); ShapeHandle s; TF\_RETURN\_IF\_ERROR(c->MakeShapeFromPartialTensorShape(p, &s)); if (c->FullyDefined(s) || identical\_shapes) { c->set\_output\_handle\_shapes\_and\_types( 0, std::vector<shape\_inference::ShapeAndType>{{s, t}}); } return absl::OkStatus(); });
REGISTER\_OP("TensorArrayGradV3") .Input("handle: resource") .Input("flow\_in: float") .Output("grad\_handle: resource") .Output("flow\_out: float") .Attr("source: string") .SetIsStateful() .SetShapeFn([](InferenceContext\* c) { ShapeHandle handle; DimensionHandle unused\_dim; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 1, &handle)); TF\_RETURN\_IF\_ERROR(c->WithValue(c->Dim(handle, 0), 2, &unused\_dim)); c->set\_output(0, c->Vector(2)); c->set\_output(1, c->Scalar()); if (c->input\_handle\_shapes\_and\_types(0)) { c->set\_output\_handle\_shapes\_and\_types( 0, \*c->input\_handle\_shapes\_and\_types(0)); } return absl::OkStatus(); });
REGISTER\_OP("TensorArrayGradWithShape") .Input("handle: resource") .Input("flow\_in: float") .Input("shape\_to\_prepend: int32") .Output("grad\_handle: resource") .Output("flow\_out: float") .Attr("source: string") .SetIsStateful() .SetShapeFn([](InferenceContext\* c) { ShapeHandle handle; DimensionHandle unused\_dim; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 1, &handle)); TF\_RETURN\_IF\_ERROR(c->WithValue(c->Dim(handle, 0), 2, &unused\_dim)); c->set\_output(0, c->Vector(2)); c->set\_output(1, c->Scalar()); auto\* shape\_and\_type = c->input\_handle\_shapes\_and\_types(0); if (shape\_and\_type) { auto input\_shape = (\*shape\_and\_type)[0].shape; auto dtype = (\*shape\_and\_type)[0].dtype; // Note that shape\_to\_preped is a rank 1 Tensor representing a shape. // The size of dimension 0 is the number of dimensions we need to add to // output shape. int64\_t prepend\_rank = c->Value(c->Dim(c->input(2), 0)); if (c->RankKnown(input\_shape) && prepend\_rank != InferenceContext::kUnknownDim) { int32\_t input\_rank = c->Rank(input\_shape); std::vector<DimensionHandle> dims; dims.reserve(prepend\_rank + input\_rank); for (int i = 0; i < prepend\_rank; ++i) { dims.push\_back(c->UnknownDim()); } for (int i = 0; i < input\_rank; ++i) { dims.push\_back(c->Dim(input\_shape, i)); } c->set\_output\_handle\_shapes\_and\_types(0, {{c->MakeShape(dims), dtype}}); } else { c->set\_output\_handle\_shapes\_and\_types(0, {{c->UnknownShape(), dtype}}); } } return absl::OkStatus(); });
REGISTER\_OP("TensorArrayWriteV3") .Input("handle: resource") .Input("index: int32") .Input("value: T") .Input("flow\_in: float") .Output("flow\_out: float") .Attr("T: type") .SetShapeFn([](InferenceContext\* c) { ShapeHandle handle; DimensionHandle unused\_dim; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 1, &handle)); TF\_RETURN\_IF\_ERROR(c->WithValue(c->Dim(handle, 0), 2, &unused\_dim));
 ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 0, &unused)); TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(3), 0, &unused));
 auto\* handle\_data = c->input\_handle\_shapes\_and\_types(0); if (handle\_data != nullptr && !handle\_data->empty()) { shape\_inference::ShapeAndType shape\_and\_type = (\*handle\_data)[0]; ShapeHandle value\_shape = c->input(2); TF\_RETURN\_IF\_ERROR( c->Merge(shape\_and\_type.shape, value\_shape, &unused)); }
 return shape\_inference::ScalarShape(c); });
REGISTER\_OP("TensorArrayReadV3") .Input("handle: resource") .Input("index: int32") .Input("flow\_in: float") .Output("value: dtype") .Attr("dtype: type") .SetShapeFn([](InferenceContext\* c) { ShapeHandle handle; DimensionHandle unused\_dim; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 1, &handle)); TF\_RETURN\_IF\_ERROR(c->WithValue(c->Dim(handle, 0), 2, &unused\_dim)); ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 0, &unused)); TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(2), 0, &unused)); auto shapes = c->input\_handle\_shapes\_and\_types(0); if (shapes != nullptr && !shapes->empty()) { ShapeHandle tensor\_shape = shapes->at(0).shape; c->set\_output(0, tensor\_shape); return absl::OkStatus(); } else { return shape\_inference::UnknownShape(c); } });
REGISTER\_OP("TensorArrayGatherV3") .Input("handle: resource") .Input("indices: int32") .Input("flow\_in: float") .Output("value: dtype") .Attr("dtype: type") .Attr("element\_shape: shape = { unknown\_rank: true }") .SetShapeFn([](InferenceContext\* c) { ShapeHandle indices; ShapeHandle unused; DimensionHandle unused\_dim; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 1, &unused)); TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 1, &indices)); TF\_RETURN\_IF\_ERROR(c->WithValue(c->Dim(c->input(0), 0), 2, &unused\_dim)); TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(2), 0, &unused)); auto shapes = c->input\_handle\_shapes\_and\_types(0); if (shapes != nullptr && !shapes->empty()) { ShapeHandle tensor\_shape = shapes->at(0).shape; ShapeHandle output\_shape; TF\_RETURN\_IF\_ERROR( c->Concatenate(indices, tensor\_shape, &output\_shape)); c->set\_output(0, output\_shape); return absl::OkStatus(); } else { PartialTensorShape p; TF\_RETURN\_IF\_ERROR(c->GetAttr("element\_shape", &p)); ShapeHandle s; TF\_RETURN\_IF\_ERROR(c->MakeShapeFromPartialTensorShape(p, &s)); ShapeHandle output\_shape; TF\_RETURN\_IF\_ERROR(c->Concatenate(indices, s, &output\_shape)); c->set\_output(0, output\_shape); return absl::OkStatus(); } });
REGISTER\_OP("TensorArrayScatterV3") .Input("handle: resource") .Input("indices: int32") .Input("value: T") .Input("flow\_in: float") .Output("flow\_out: float") .Attr("T: type") .SetShapeFn([](InferenceContext\* c) { ShapeHandle indices; ShapeHandle unused; DimensionHandle unused\_dim; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 1, &unused)); TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 1, &indices)); TF\_RETURN\_IF\_ERROR(c->WithValue(c->Dim(c->input(0), 0), 2, &unused\_dim)); TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(3), 0, &unused)); ShapeHandle value\_shape; // Assert that the length of the indices tensor is equal to the first // dimension of the value tensor. TF\_RETURN\_IF\_ERROR( c->MergePrefix(c->input(2), indices, &value\_shape, &indices)); auto shapes = c->input\_handle\_shapes\_and\_types(0); if (shapes != nullptr && !shapes->empty()) { ShapeHandle tensor\_shape = shapes->at(0).shape; ShapeHandle fed\_shape; TF\_RETURN\_IF\_ERROR(c->Subshape(value\_shape, 1, &fed\_shape)); TF\_RETURN\_IF\_ERROR(c->Merge(tensor\_shape, fed\_shape, &fed\_shape)); } return shape\_inference::ScalarShape(c); });
REGISTER\_OP("TensorArrayConcatV3") .Input("handle: resource") .Input("flow\_in: float") .Output("value: dtype") .Output("lengths: int64") .Attr("dtype: type") .Attr("element\_shape\_except0: shape = { unknown\_rank: true }") .SetShapeFn([](InferenceContext\* c) { ShapeHandle handle; DimensionHandle unused\_dim; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 1, &handle)); TF\_RETURN\_IF\_ERROR(c->WithValue(c->Dim(handle, 0), 2, &unused\_dim)); ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 0, &unused)); c->set\_output(0, c->UnknownShape()); c->set\_output(1, c->Vector(c->UnknownDim())); return absl::OkStatus(); });
REGISTER\_OP("TensorArraySplitV3") .Input("handle: resource") .Input("value: T") .Input("lengths: int64") .Input("flow\_in: float") .Output("flow\_out: float") .Attr("T: type") .SetShapeFn([](InferenceContext\* c) { ShapeHandle handle; DimensionHandle unused\_dim; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 1, &handle)); TF\_RETURN\_IF\_ERROR(c->WithValue(c->Dim(handle, 0), 2, &unused\_dim)); ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(2), 1, &unused)); TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(3), 0, &unused)); return shape\_inference::ScalarShape(c); });
REGISTER\_OP("TensorArraySizeV3") .Input("handle: resource") .Input("flow\_in: float") .Output("size: int32") .SetShapeFn([](InferenceContext\* c) { ShapeHandle handle; DimensionHandle unused\_dim; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 1, &handle)); TF\_RETURN\_IF\_ERROR(c->WithValue(c->Dim(handle, 0), 2, &unused\_dim)); return shape\_inference::ScalarShape(c); });
REGISTER\_OP("TensorArrayCloseV3") .Input("handle: resource") .SetShapeFn([](InferenceContext\* c) { ShapeHandle handle; DimensionHandle unused\_dim; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 1, &handle)); TF\_RETURN\_IF\_ERROR(c->WithValue(c->Dim(handle, 0), 2, &unused\_dim)); return absl::OkStatus(); });
// --------------------------------------------------------------------------
// Deprecated TensorArray methods
REGISTER\_OP("TensorArray") .Input("size: int32") .Attr("dtype: type") .Attr("dynamic\_size: bool = false") .Attr("clear\_after\_read: bool = true") .Attr("tensor\_array\_name: string = ''") .Attr("element\_shape: shape = { unknown\_rank: true }") .Output("handle: Ref(string)") .SetIsStateful() .SetShapeFn(shape\_inference::UnknownShape) .Deprecated(16, "Use TensorArrayV3");REGISTER\_OP("TensorArrayV2") .Input("size: int32") .Attr("dtype: type") .Attr("element\_shape: shape = { unknown\_rank: true }") .Attr("dynamic\_size: bool = false") .Attr("clear\_after\_read: bool = true") .Attr("tensor\_array\_name: string = ''") .Output("handle: string") .SetIsStateful() .SetShapeFn([](InferenceContext\* c) { ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 0, &unused)); c->set\_output(0, c->Vector(2)); return absl::OkStatus(); }) .Deprecated(26, "Use TensorArrayV3");REGISTER\_OP("TensorArrayGrad") .Input("handle: string") .Input("flow\_in: float") .Output("grad\_handle: Ref(string)") .Attr("source: string") .SetIsStateful() .SetShapeFn(shape\_inference::UnknownShape) .Deprecated(16, "Use TensorArrayGradV3");REGISTER\_OP("TensorArrayGradV2") .Input("handle: string") .Input("flow\_in: float") .Output("grad\_handle: string") .Attr("source: string") .SetIsStateful() .SetShapeFn([](InferenceContext\* c) { ShapeHandle handle; DimensionHandle unused\_dim; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 1, &handle)); TF\_RETURN\_IF\_ERROR(c->WithValue(c->Dim(handle, 0), 2, &unused\_dim)); c->set\_output(0, c->Vector(2)); return absl::OkStatus(); }) .Deprecated(26, "Use TensorArrayGradV3");REGISTER\_OP("TensorArrayWrite") .Input("handle: Ref(string)") .Input("index: int32") .Input("value: T") .Input("flow\_in: float") .Output("flow\_out: float") .Attr("T: type") .SetShapeFn(shape\_inference::UnknownShape) .Deprecated(16, "Use TensorArrayWriteV3");REGISTER\_OP("TensorArrayWriteV2") .Input("handle: string") .Input("index: int32") .Input("value: T") .Input("flow\_in: float") .Output("flow\_out: float") .Attr("T: type") .SetShapeFn([](InferenceContext\* c) { ShapeHandle handle; DimensionHandle unused\_dim; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 1, &handle)); TF\_RETURN\_IF\_ERROR(c->WithValue(c->Dim(handle, 0), 2, &unused\_dim));
 ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 0, &unused)); TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(3), 0, &unused)); return shape\_inference::ScalarShape(c); }) .Deprecated(26, "Use TensorArrayWriteV3");REGISTER\_OP("TensorArrayRead") .Input("handle: Ref(string)") .Input("index: int32") .Input("flow\_in: float") .Output("value: dtype") .Attr("dtype: type") .SetShapeFn(shape\_inference::UnknownShape) .Deprecated(16, "Use TensorArrayReadV3");REGISTER\_OP("TensorArrayReadV2") .Input("handle: string") .Input("index: int32") .Input("flow\_in: float") .Output("value: dtype") .Attr("dtype: type") .SetShapeFn([](InferenceContext\* c) { ShapeHandle handle; DimensionHandle unused\_dim; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(0), 1, &handle)); TF\_RETURN\_IF\_ERROR(c->WithValue(c->Dim(handle, 0), 2, &unused\_dim)); ShapeHandle unused; TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(1), 0, &unused)); TF\_RETURN\_IF\_ERROR(c->WithRank(c->input(2), 0, &unused)); return shape\_inference::UnknownShape(c); }) .Deprecated(26, "Use TensorArrayReadV3");REGISTER\_OP("TensorArrayPack") .Input("handle: Ref(string)") .Input("flow\_in: float") .Output("value: dtype") .Attr("dtype: type") .Attr("element\_shape: shape = { unknown\_rank: true }")[View remainder of file in raw view](https://github.com/tensorflow/tensorflow/raw/refs/heads/master/tensorflow/core/ops/data_flow_ops.cc)

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.


