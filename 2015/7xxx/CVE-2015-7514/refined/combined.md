=== Content from review.openstack.org_75bf421a_20250126_043918.html ===




=== Content from www.openwall.com_44d1a5fd_20250125_000124.html ===


| [Openwall](/) * [Products](/)   + [Openwall GNU/\*/Linux   *server OS*](/Owl/)+ [Linux Kernel Runtime Guard](/lkrg/)+ [John the Ripper   *password cracker*](/john/)         - [Free & Open Source for any platform](/john/)- [in the cloud](/john/cloud/)- [Pro for Linux](/john/pro/linux/)- [Pro for macOS](/john/pro/macosx/)+ [Wordlists   *for password cracking*](/wordlists/)+ [passwdqc   *policy enforcement*](/passwdqc/)             - [Free & Open Source for Unix](/passwdqc/)- [Pro for Windows (Active Directory)](/passwdqc/windows/)+ [yescrypt   *KDF & password hashing*](/yescrypt/)+ [yespower   *Proof-of-Work (PoW)*](/yespower/)+ [crypt\_blowfish   *password hashing*](/crypt/)+ [phpass   *ditto in PHP*](/phpass/)+ [tcb   *better password shadowing*](/tcb/)+ [Pluggable Authentication Modules](/pam/)+ [scanlogd   *port scan detector*](/scanlogd/)+ [popa3d   *tiny POP3 daemon*](/popa3d/)+ [blists   *web interface to mailing lists*](/blists/)+ [msulogin   *single user mode login*](/msulogin/)+ [php\_mt\_seed   *mt\_rand() cracker*](/php_mt_seed/)* [Services](/services/)* Publications       + [Articles](/articles/)+ [Presentations](/presentations/)* Resources         + [Mailing lists](/lists/)+ [Community wiki](https://openwall.info/wiki/)+ [Source code repositories (GitHub)](https://github.com/openwall)+ [Source code repositories (CVSweb)](https://cvsweb.openwall.com)+ [File archive & mirrors](/mirrors/)+ [How to verify digital signatures](/signatures/)+ [OVE IDs](/ove/)* [What's new](/news) | |
| --- | --- |

| | [Hash Suite - Windows password security audit tool. GUI, reports in PDF.](https://hashsuite.openwall.net) | | --- | |
| --- | --- |

[[<prev]](3) [[next>]](5) [[day]](.) [[month]](..) [[year]](../..) [[list]](../../..)
```

Message-ID: <56606D42.7070205@gmail.com>
Date: Thu, 3 Dec 2015 08:26:42 -0800
From: Devananda van der Veen <devananda.vdv@...il.com>
To: oss-security@...ts.openwall.com
Subject: OpenStack Ironic does not honor clean steps (CVE-2015-7514)

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

===========================================
OpenStack Ironic does not honor clean steps
===========================================

:Date: December 03, 2015
:CVE: CVE-2015-7514

Affects
~~~~~~~
- - Ironic: >= 4.2.0, <= 4.2.1

Description
~~~~~~~~~~~
Brad Morgan from Rackspace reported a vulnerability in Ironic. To
prevent user data leak, Ironic is expected to "clean" a server after
use, however that is transparently not happening. Previous tenant's data
may be left behind on the disk and may be available to new users. All
Ironic setups are affected.

Patches
~~~~~~~
- - <https://review.openstack.org/#/c/253001> (Liberty)
- - <https://review.openstack.org/#/c/252993> (Mitaka)

Credits
~~~~~~~
- - Brad Morgan from Rackspace (CVE-2015-7514)

References
~~~~~~~~~~
- - <https://bugs.launchpad.net/bugs/1517277>
- - <http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-7514>

Notes
~~~~~
- - This fix will be included in a future 4.2.2 release.
- - This fix will be included in a future 4.3 release.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1

iEYEARECAAYFAlZgbUIACgkQhFvuBniJg6cbxwCgl9eepjJWbkWXsZsPDjhN/bDR
rCkAoOLlZYGgItR7LirG4u6uvDaljOby
=rXfP
-----END PGP SIGNATURE-----

```

[Powered by blists](https://www.openwall.com/blists/) - [more mailing lists](https://lists.openwall.net)

Please check out the
[Open Source Software Security Wiki](https://oss-security.openwall.org/wiki/), which is counterpart to this
[mailing list](https://oss-security.openwall.org/wiki/mailing-lists/oss-security).

Confused about [mailing lists](/lists/) and their use?
[Read about mailing lists on Wikipedia](https://en.wikipedia.org/wiki/Electronic_mailing_list)
and check out these
[guidelines on proper formatting of your messages](https://www.complang.tuwien.ac.at/anton/mail-news-errors.html).



=== Content from access.redhat.com_ee04f62c_20250126_043920.html ===


[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

**We're sorry but cve-details doesn't work properly without JavaScript enabled. Please enable it to continue.**

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2025 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from review.openstack.org_ee5879ed_20250126_043919.html ===




=== Content from bugs.launchpad.net_1af482b2_20250126_043917.html ===

[Log in / Register](https://bugs.launchpad.net/ironic/%2Bbug/1517277/%2Blogin)

[![](https://launchpadlibrarian.net/294367848/Ironic_mascot_color_64x64.png)](https://launchpad.net/ironic)

## [Ironic](https://launchpad.net/ironic)

* [Overview](https://launchpad.net/ironic)
* [Code](https://code.launchpad.net/ironic)
* [Bugs](https://bugs.launchpad.net/ironic)
* [Blueprints](https://blueprints.launchpad.net/ironic)
* [Translations](https://translations.launchpad.net/ironic)
* [Answers](https://answers.launchpad.net/ironic)

# Clean steps don't actually run (CVE-2015-7514)

Bug #1517277 reported by
[Jim Rollenhagen](https://launchpad.net/~jim-rollenhagen)
on 2015-11-18

[12](/%2Bhelp-bugs/bug-heat.html)

This bug affects 1 person

| Affects | | Status | Importance | Assigned to | Milestone |
| --- | --- | --- | --- | --- | --- |
|  | [Ironic](https://bugs.launchpad.net/ironic) | Fix Released | Critical | [aeva black](https://launchpad.net/~tenbrae) |  |
|  | [Liberty](https://bugs.launchpad.net/ironic/liberty) | Fix Released | Critical | [Jim Rollenhagen](https://launchpad.net/~jim-rollenhagen) |  |
|  | [OpenStack Security Advisory](https://bugs.launchpad.net/ossa) | Won't Fix | Undecided | Unassigned |  |

### Bug Description

In playing with the latest code, it seems that ironic just drops all clean steps it's getting from the agent.

Since devstack drops the priority on erase\_devices so it doesn't run, I added a clean step to the agent, and ran through cleaning.

stack@jim-devstack:~/ironic-python-agent$ git diff

diff --git a/ironic\_python\_agent/hardware.py b/ironic\_python\_agent/hardware.py

index d755f8c..7590959 100644

--- a/ironic\_python\_agent/hardware.py

+++ b/ironic\_python\_agent/hardware.py

@@ -230,6 +230,9 @@ class HardwareManager(object):

         """

         raise errors.IncompatibleHardwareMethodError

+ def test\_devstack(self, node, ports):

+ return 'hi devstack!'

+

     def erase\_devices(self, node, ports):

         """Erase any device that holds user data.

@@ -305,6 +308,13 @@ class HardwareManager(object):

                 'interface': 'deploy',

                 'reboot\_requested': False,

                 'abortable': True

+ },

+ {

+ 'step': 'test\_devstack',

+ 'priority': 20,

+ 'interface': 'deploy',

+ 'reboot\_requested': False,

+ 'abortable': True

             }

         ]

This results in the following logs, indicating that Ironic never attempted to run the new clean step:

2015-11-18 01:19:09.669 DEBUG oslo\_concurrency.lockutils [req-9b9df105-4fdb-4461-8d07-7298f48ac261 None None] Lock "conductor\_w

orker\_spawn" released by "ironic.conductor.manager.\_spawn\_worker" :: held 0.000s from (pid=27761) inner /usr/local/lib/python2.

7/dist-packages/oslo\_concurrency/lockutils.py:265

2015-11-18 01:19:09.670 DEBUG ironic.drivers.modules.agent\_base\_vendor [-] Heartbeat from 795a5722-22ad-4537-b17c-fcea5f7dc125,

 last heartbeat at None. from (pid=27761) heartbeat /opt/stack/ironic/ironic/drivers/modules/agent\_base\_vendor.py:316

2015-11-18 01:19:09.681 DEBUG ironic.drivers.modules.agent\_base\_vendor [-] Node 795a5722-22ad-4537-b17c-fcea5f7dc125 just boote

d to start cleaning. from (pid=27761) heartbeat /opt/stack/ironic/ironic/drivers/modules/agent\_base\_vendor.py:356

2015-11-18 01:19:09.684 DEBUG ironic.drivers.modules.agent\_client [-] Executing agent command clean.get\_clean\_steps for node 79

5a5722-22ad-4537-b17c-fcea5f7dc125 from (pid=27761) \_command /opt/stack/ironic/ironic/drivers/modules/agent\_client.py:69

2015-11-18 01:19:09.945 DEBUG ironic.drivers.modules.agent\_client [-] Agent command clean.get\_clean\_steps for node 795a5722-22a

d-4537-b17c-fcea5f7dc125 returned result {u'clean\_steps': {u'GenericHardwareManager': [{u'priority': 10, u'interface': u'deploy

', u'step': u'erase\_devices', u'abortable': True, u'reboot\_requested': False}, {u'priority': 20, u'interface': u'deploy', u'ste

p': u'test\_devstack', u'abortable': True, u'reboot\_requested': False}]}, u'hardware\_manager\_version': {u'generic\_hardware\_manag

er': u'1.0'}}, error None, HTTP status code 200 from (pid=27761) \_command /opt/stack/ironic/ironic/drivers/modules/agent\_client

.py:93

2015-11-18 01:19:09.965 DEBUG ironic.drivers.modules.agent\_base\_vendor [-] Sending RPC to conductor to resume cleaning for node

 795a5722-22ad-4537-b17c-fcea5f7dc125 from (pid=27761) notify\_conductor\_resume\_clean /opt/stack/ironic/ironic/drivers/modules/a

gent\_base\_vendor.py:211

2015-11-18 01:19:09.973 DEBUG ironic.conductor.task\_manager [-] Successfully released exclusive lock for calling vendor passthr

u on node 795a5722-22ad-4537-b17c-fcea5f7dc125 (lock was held 0.31 sec) from (pid=27761) release\_resources /opt/stack/ironic/ir

onic/conductor/task\_manager.py:311

2015-11-18 01:19:09.976 DEBUG ironic.conductor.manager [req-9b9df105-4fdb-4461-8d07-7298f48ac261 None None] RPC continue\_node\_c

lean called for node 795a5722-22ad-4537-b17c-fcea5f7dc125. from (pid=27761) continue\_node\_clean /opt/stack/ironic/ironic/conduc

tor/manager.py:885

2015-11-18 01:19:09.978 DEBUG ironic.conductor.task\_manager [req-9b9df105-4fdb-4461-8d07-7298f48ac261 None None] Attempting to

get exclusive lock on node 795a5722-22ad-4537-b17c-fcea5f7dc125 (for node cleaning) from (pid=27761) \_\_init\_\_ /opt/stack/ironic

/ironic/conductor/task\_manager.py:201

2015-11-18 01:19:09.989 DEBUG ironic.conductor.task\_manager [req-9b9df105-4fdb-4461-8d07-7298f48ac261 None None] Node 795a5722-

22ad-4537-b17c-fcea5f7dc125 successfully reserved for node cleaning (took 0.01 seconds) from (pid=27761) reserve\_node /opt/stac

k/ironic/ironic/conductor/task\_manager.py:239

2015-11-18 01:19:09.992 DEBUG ironic.common.states [req-9b9df105-4fdb-4461-8d07-7298f48ac261 None None] Exiting old state 'clea

n wait' in response to event 'resume' from (pid=27761) on\_exit /opt/stack/ironic/ironic/common/states.py:199

2015-11-18 01:19:09.992 DEBUG ironic.common.states [req-9b9df105-4fdb-4461-8d07-7298f48ac261 None None] Entering new state 'cle

aning' in response to event 'resume' from (pid=27761) on\_enter /opt/stack/ironic/ironic/common/states.py:205

2015-11-18 01:19:09.999 DEBUG oslo\_concurrency.lockutils [req-9b9df105-4fdb-4461-8d07-7298f48ac261 None None] Lock "conductor\_w

orker\_spawn" acquired by "ironic.conductor.manager.\_spawn\_worker" :: waited 0.000s from (pid=27761) inner /usr/local/lib/python

2.7/dist-packages/oslo\_concurrency/lockutils.py:253

2015-11-18 01:19:10.001 DEBUG oslo\_concurrency.lockutils [req-9b9df105-4fdb-4461-8d07-7298f48ac261 None None] Lock "conductor\_w

orker\_spawn" released by "ironic.conductor.manager.\_spawn\_worker" :: held 0.001s from (pid=27761) inner /usr/local/lib/python2.

7/dist-packages/oslo\_concurrency/lockutils.py:265

2015-11-18 01:19:10.001 INFO ironic.conductor.manager [-] Executing cleaning on node 795a5722-22ad-4537-b17c-fcea5f7dc125, rema

ining steps: []

Tracking this down further, it appears that at first boot, this conditional is true: <https://github.com/openstack/ironic/blob/7ec5a06c3ca55c97a84c3659f7d206be998877b6/ironic/conductor/manager.py#L848-L849>

Causing that method to return an empty list of clean steps.

This was released in 4.2.0 so will also need a backport.

## CVE References

* [2015-7514](/bugs/cve/2015-7514 "OpenStack Ironic 4.2.0 through 4.2.1 ...")

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jim Rollenhagen (jim-rollenhagen)](https://launchpad.net/~jim-rollenhagen) wrote on 2015-11-18: |  |  | [#1](/ironic/%2Bbug/1517277/comments/1) |
| --- | --- | --- | --- |

Need to figure out how to validate this in the gate so it doesn't happen again. Add the same dummy clean step and check logs to see if it ran?

Need to figure out how to validate this in the gate so it doesn't happen again. Add the same dummy clean step and check logs to see if it ran?

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jim Rollenhagen (jim-rollenhagen)](https://launchpad.net/~jim-rollenhagen) wrote on 2015-11-18: |  |  | [#2](/ironic/%2Bbug/1517277/comments/2) |
| --- | --- | --- | --- |

Suggested fix, need to test in more detail and add unit tests:

stack@jim-devstack:~/ironic$ git diff

diff --git a/ironic/conductor/manager.py b/ironic/conductor/manager.py

index 4e639c9..76b1065 100644

--- a/ironic/conductor/manager.py

+++ b/ironic/conductor/manager.py

@@ -845,10 +845,11 @@ class ConductorManager(periodic\_task.PeriodicTasks):

"""

         node = task.node

+ next\_steps = node.driver\_internal\_info.get('clean\_steps', [])

         if not node.clean\_step:

- return []

+ # first time through, return all steps

+ return next\_steps

- next\_steps = node.driver\_internal\_info.get('clean\_steps', [])

         try:

             # Trim off the last clean step (now finished) and

             # all previous steps

Suggested fix, need to test in more detail and add unit tests:
stack@jim-devstack:~/ironic$ git diff
diff --git a/ironic/conductor/manager.py b/ironic/conductor/manager.py
index 4e639c9..76b1065 100644
--- a/ironic/conductor/manager.py
+++ b/ironic/conductor/manager.py
@@ -845,10 +845,11 @@ class ConductorManager(periodic\_task.PeriodicTasks):
"""
node = task.node
+ next\_steps = node.driver\_internal\_info.get('clean\_steps', [])
if not node.clean\_step:
- return []
+ # first time through, return all steps
+ return next\_steps
- next\_steps = node.driver\_internal\_info.get('clean\_steps', [])
try:
# Trim off the last clean step (now finished) and
# all previous steps

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jim Rollenhagen (jim-rollenhagen)](https://launchpad.net/~jim-rollenhagen) wrote on 2015-11-18: |  |  | [#3](/ironic/%2Bbug/1517277/comments/3) |
| --- | --- | --- | --- |

Patch with unit tests included

Patch with unit tests included

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jim Rollenhagen (jim-rollenhagen)](https://launchpad.net/~jim-rollenhagen) wrote on 2015-11-18: |  |  | [#4](/ironic/%2Bbug/1517277/comments/4) |
| --- | --- | --- | --- |

[Download full text](https://bugs.launchpad.net/ironic/%2Bbug/1517277/comments/4/%2Bdownload) (12.0 KiB)

The patch also applies cleanly to stable/liberty. Logs with the patch applied:

2015-11-18 03:54:36.294 INFO ironic.conductor.manager [-] Executing cleaning on node 795a5722-22ad-4537-b17c-fcea5f7dc125, remaining steps: [{u'priority': 20, u'interface': u'deploy', u'step': u'test\_devstack', u'abortable': True, u'reboot\_requested': False}, {u'priority': 10, u'interface': u'deploy', u'step': u'erase\_devices', u'abortable': True, u'reboot\_requested': False}]

2015-11-18 03:54:36.300 INFO ironic.conductor.manager [-] Executing {u'priority': 20, u'interface': u'deploy', u'step': u'test\_devstack', u'abortable': True, u'reboot\_requested': False} on node 795a5722-22ad-4537-b17c-fcea5f7dc125

2015-11-18 03:54:36.304 DEBUG ironic.drivers.modules.agent\_client [-] Executing agent command clean.execute\_clean\_step for node 795a5722-22ad-4537-b17c-fcea5f7dc125 from (pid=17795) \_command /opt/stack/ironic/ironic/drivers/modules/agent\_client.py:69

2015-11-18 03:54:36.447 DEBUG ironic.drivers.modules.agent\_client [-] Agent command clean.execute\_clean\_step for node 795a5722-22ad-4537-b17c-fcea5f7dc125 returned result None, error None, HTTP status code 200 from (pid=17795) \_command /opt/stack/ironic/ironic/drivers/modules/agent\_client.py:93

2015-11-18 03:54:36.447 INFO ironic.conductor.manager [-] Clean step {u'priority': 20, u'interface': u'deploy', u'step': u'test\_devstack', u'abortable': True, u'reboot\_requested': False} on node 795a5722-22ad-4537-b17c-fcea5f7dc125 being executed asynchronously, waiting for driver.

2015-11-18 03:54:36.448 DEBUG ironic.common.states [-] Exiting old state 'cleaning' in response to event 'wait' from (pid=17795) on\_exit /opt/stack/ironic/ironic/common/states.py:199

2015-11-18 03:54:36.448 DEBUG ironic.common.states [-] Entering new state 'clean wait' in response to event 'wait' from (pid=17795) on\_enter /opt/stack/ironic/ironic/common/states.py:205

2015-11-18 03:54:36.460 DEBUG ironic.conductor.task\_manager [-] Successfully released exclusive lock for node cleaning on node 795a5722-22ad-4537-b17c-fcea5f7dc125 (lock was held 0.18 sec) from (pid=17795) release\_resources /opt/stack/ironic/ironic/conductor/task\_manager.py:311

2015-11-18 03:54:36.501 DEBUG oslo\_messaging.\_drivers.amqpdriver [-] received message msg\_id: d14e31a90b6d404da8ad5a066f0f1861 reply to reply\_b48c2415999f4ac1845b4f36e08cb180 from (pid=17795) \_\_call\_\_ /usr/local/lib/python2.7/dist-packages/oslo\_messaging/\_drivers/amqpdriver.py:193

2015-11-18 03:54:36.502 DEBUG ironic.conductor.manager [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] RPC vendor\_passthru called for node 795a5722-22ad-4537-b17c-fcea5f7dc125. from (pid=17795) vendor\_passthru /opt/stack/ironic/ironic/conductor/manager.py:491

2015-11-18 03:54:36.503 DEBUG ironic.conductor.task\_manager [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] Attempting to get exclusive lock on node 795a5722-22ad-4537-b17c-fcea5f7dc125 (for calling vendor passthru) from (pid=17795) \_\_init\_\_ /opt/stack/ironic/ironic/conductor/task\_manager.py:201

2015-11-18 03:54:36.512 DEBUG ironic.conductor.task\_manager [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] Node 795a5722-22ad-4537-b17c-fcea5f7dc125 successfully reserved for c...

The patch also applies cleanly to stable/liberty. Logs with the patch applied:
2015-11-18 03:54:36.294 INFO ironic.conductor.manager [-] Executing cleaning on node 795a5722-22ad-4537-b17c-fcea5f7dc125, remaining steps: [{u'priority': 20, u'interface': u'deploy', u'step': u'test\_devstack', u'abortable': True, u'reboot\_requested': False}, {u'priority': 10, u'interface': u'deploy', u'step': u'erase\_devices', u'abortable': True, u'reboot\_requested': False}]
2015-11-18 03:54:36.300 INFO ironic.conductor.manager [-] Executing {u'priority': 20, u'interface': u'deploy', u'step': u'test\_devstack', u'abortable': True, u'reboot\_requested': False} on node 795a5722-22ad-4537-b17c-fcea5f7dc125
2015-11-18 03:54:36.304 DEBUG ironic.drivers.modules.agent\_client [-] Executing agent command clean.execute\_clean\_step for node 795a5722-22ad-4537-b17c-fcea5f7dc125 from (pid=17795) \_command /opt/stack/ironic/ironic/drivers/modules/agent\_client.py:69
2015-11-18 03:54:36.447 DEBUG ironic.drivers.modules.agent\_client [-] Agent command clean.execute\_clean\_step for node 795a5722-22ad-4537-b17c-fcea5f7dc125 returned result None, error None, HTTP status code 200 from (pid=17795) \_command /opt/stack/ironic/ironic/drivers/modules/agent\_client.py:93
2015-11-18 03:54:36.447 INFO ironic.conductor.manager [-] Clean step {u'priority': 20, u'interface': u'deploy', u'step': u'test\_devstack', u'abortable': True, u'reboot\_requested': False} on node 795a5722-22ad-4537-b17c-fcea5f7dc125 being executed asynchronously, waiting for driver.
2015-11-18 03:54:36.448 DEBUG ironic.common.states [-] Exiting old state 'cleaning' in response to event 'wait' from (pid=17795) on\_exit /opt/stack/ironic/ironic/common/states.py:199
2015-11-18 03:54:36.448 DEBUG ironic.common.states [-] Entering new state 'clean wait' in response to event 'wait' from (pid=17795) on\_enter /opt/stack/ironic/ironic/common/states.py:205
2015-11-18 03:54:36.460 DEBUG ironic.conductor.task\_manager [-] Successfully released exclusive lock for node cleaning on node 795a5722-22ad-4537-b17c-fcea5f7dc125 (lock was held 0.18 sec) from (pid=17795) release\_resources /opt/stack/ironic/ironic/conductor/task\_manager.py:311
2015-11-18 03:54:36.501 DEBUG oslo\_messaging.\_drivers.amqpdriver [-] received message msg\_id: d14e31a90b6d404da8ad5a066f0f1861 reply to reply\_b48c2415999f4ac1845b4f36e08cb180 from (pid=17795) \_\_call\_\_ /usr/local/lib/python2.7/dist-packages/oslo\_messaging/\_drivers/amqpdriver.py:193
2015-11-18 03:54:36.502 DEBUG ironic.conductor.manager [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] RPC vendor\_passthru called for node 795a5722-22ad-4537-b17c-fcea5f7dc125. from (pid=17795) vendor\_passthru /opt/stack/ironic/ironic/conductor/manager.py:491
2015-11-18 03:54:36.503 DEBUG ironic.conductor.task\_manager [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] Attempting to get exclusive lock on node 795a5722-22ad-4537-b17c-fcea5f7dc125 (for calling vendor passthru) from (pid=17795) \_\_init\_\_ /opt/stack/ironic/ironic/conductor/task\_manager.py:201
2015-11-18 03:54:36.512 DEBUG ironic.conductor.task\_manager [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] Node 795a5722-22ad-4537-b17c-fcea5f7dc125 successfully reserved for calling vendor passthru (took 0.01 seconds) from (pid=17795) reserve\_node /opt/stack/ironic/ironic/conductor/task\_manager.py:239
2015-11-18 03:54:36.516 DEBUG oslo\_concurrency.lockutils [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] Lock "conductor\_worker\_spawn" acquired by "ironic.conductor.manager.\_spawn\_worker" :: waited 0.000s from (pid=17795) inner /usr/local/lib/python2.7/dist-packages/oslo\_concurrency/lockutils.py:253
2015-11-18 03:54:36.516 DEBUG oslo\_concurrency.lockutils [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] Lock "conductor\_worker\_spawn" released by "ironic.conductor.manager.\_spawn\_worker" :: held 0.000s from (pid=17795) inner /usr/local/lib/python2.7/dist-packages/oslo\_concurrency/lockutils.py:265
2015-11-18 03:54:36.517 DEBUG ironic.drivers.modules.agent\_base\_vendor [-] Heartbeat from 795a5722-22ad-4537-b17c-fcea5f7dc125, last heartbeat at 1447818876. from (pid=17795) heartbeat /opt/stack/ironic/ironic/drivers/modules/agent\_base\_vendor.py:321
2015-11-18 03:54:36.524 DEBUG oslo\_messaging.\_drivers.amqpdriver [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] sending reply msg\_id: d14e31a90b6d404da8ad5a066f0f1861 reply queue: reply\_b48c2415999f4ac1845b4f36e08cb180 from (pid=17795) \_send\_reply /usr/local/lib/python2.7/dist-packages/oslo\_messaging/\_drivers/amqpdriver.py:79
2015-11-18 03:54:36.531 DEBUG ironic.drivers.modules.agent\_client [-] Fetching status of agent commands for node 795a5722-22ad-4537-b17c-fcea5f7dc125 from (pid=17795) get\_commands\_status /opt/stack/ironic/ironic/drivers/modules/agent\_client.py:98
2015-11-18 03:54:36.644 DEBUG ironic.drivers.modules.agent\_client [-] Status of agent commands for node 795a5722-22ad-4537-b17c-fcea5f7dc125: get\_clean\_steps: result "{u'clean\_steps': {u'GenericHardwareManager': [{u'priority': 10, u'interface': u'deploy', u'step': u'erase\_devices', u'abortable': True, u'reboot\_requested': False}, {u'priority': 20, u'interface': u'deploy', u'step': u'test\_devstack', u'abortable': True, u'reboot\_requested': False}]}, u'hardware\_manager\_version': {u'generic\_hardware\_manager': u'1.0'}}", error "None"; execute\_clean\_step: result "{u'clean\_step': {u'priority': 20, u'interface': u'deploy', u'step': u'test\_devstack', u'abortable': True, u'reboot\_requested': False}, u'clean\_result': u'hi devstack!'}", error "None" from (pid=17795) get\_commands\_status /opt/stack/ironic/ironic/drivers/modules/agent\_client.py:107
2015-11-18 03:54:36.645 DEBUG ironic.drivers.modules.agent\_base\_vendor [-] Cleaning command status for node 795a5722-22ad-4537-b17c-fcea5f7dc125 on step {u'priority': 20, u'interface': u'deploy', u'step': u'test\_devstack', u'abortable': True, u'reboot\_requested': False}: {u'command\_error': None, u'command\_status': u'SUCCEEDED', u'command\_params': {u'node': {u'target\_power\_state': None, u'target\_provision\_state': u'available', u'last\_error': None, u'updated\_at': u'2015-11-18T03:54:36.000000', u'maintenance\_reason': None, u'chassis\_id': 1, u'provision\_state': u'cleaning', u'clean\_step': {u'priority': 20, u'interface': u'deploy', u'step': u'test\_devstack', u'abortable': True, u'reboot\_requested': False}, u'id': 2, u'uuid': u'795a5722-22ad-4537-b17c-fcea5f7dc125', u'console\_enabled': False, u'extra': {}, u'raid\_config': {}, u'provision\_updated\_at': u'2015-11-18T03:54:36.000000', u'maintenance': False, u'target\_raid\_config': {}, u'conductor\_affinity': None, u'inspection\_started\_at': None, u'inspection\_finished\_at': None, u'power\_state': u'power on', u'driver': u'agent\_ssh', u'reservation': u'jim-devstack', u'properties': {u'memory\_mb': 1024, u'cpu\_arch': u'x86\_64', u'local\_gb': 10, u'cpus': 1}, u'instance\_uuid': None, u'name': u'node-1', u'driver\_info': {u'ssh\_port': 22, u'ssh\_username': u'stack', u'deploy\_kernel': u'a5c4ce14-4d6e-4e7d-9235-c55ba845fd10', u'deploy\_ramdisk': u'aa726045-c77c-436c-8a76-ec687daeceaa', u'ssh\_virt\_type': u'virsh', u'ssh\_address': u'104.239.168.65', u'ssh\_key\_filename': u'/opt/stack/data/ironic/ssh\_keys/ironic\_key'}, u'created\_at': u'2015-11-18T01:11:03.000000', u'driver\_internal\_info': {u'agent\_url': u'http://10.1.0.7:9999', u'agent\_erase\_devices\_iterations': 1, u'agent\_last\_heartbeat': 1447818876, u'clean\_steps': [{u'priority': 20, u'interface': u'deploy', u'step': u'test\_devstack', u'abortable': True, u'reboot\_requested': False}, {u'priority': 10, u'interface': u'deploy', u'step': u'erase\_devices', u'abortable': True, u'reboot\_requested': False}], u'hardware\_manager\_version': {u'generic\_hardware\_manager': u'1.0'}}, u'instance\_info': {u'deploy\_key': u'8BE8XBQDSIL66CAEP6S47ATBJAZNYHSI'}}, u'step': {u'priority': 20, u'interface': u'deploy', u'step': u'test\_devstack', u'abortable': True, u'reboot\_requested': False}, u'ports': [{u'uuid': u'7949ab2d-301c-4af0-a7c5-8d0b66d265d1', u'extra': {u'vif\_port\_id': u'313ab317-f534-4bf2-b1d3-01ed9c29e048'}, u'created\_at': u'2015-11-18T01:11:03.000000', u'updated\_at': u'2015-11-18T03:49:43.000000', u'node\_id': 2, u'address': u'52:54:00:52:7b:8a', u'id': 2}], u'clean\_version': {u'generic\_hardware\_manager': u'1.0'}}, u'command\_result': {u'clean\_step': {u'priority': 20, u'interface': u'deploy', u'step': u'test\_devstack', u'abortable': True, u'reboot\_requested': False}, u'clean\_result': u'hi devstack!'}, u'id': u'9dc0a4cf-3667-457d-8960-25f279c91a3e', u'command\_name': u'execute\_clean\_step'} from (pid=17795) continue\_cleaning /opt/stack/ironic/ironic/drivers/modules/agent\_base\_vendor.py:239
2015-11-18 03:54:36.645 INFO ironic.drivers.modules.agent\_base\_vendor [-] Agent on node 795a5722-22ad-4537-b17c-fcea5f7dc125 returned cleaning command success, moving to next clean step
2015-11-18 03:54:36.645 DEBUG ironic.drivers.modules.agent\_base\_vendor [-] Sending RPC to conductor to resume cleaning for node 795a5722-22ad-4537-b17c-fcea5f7dc125 from (pid=17795) \_notify\_conductor\_resume\_clean /opt/stack/ironic/ironic/drivers/modules/agent\_base\_vendor.py:216
2015-11-18 03:54:36.656 DEBUG ironic.conductor.task\_manager [-] Successfully released exclusive lock for calling vendor passthru on node 795a5722-22ad-4537-b17c-fcea5f7dc125 (lock was held 0.14 sec) from (pid=17795) release\_resources /opt/stack/ironic/ironic/conductor/task\_manager.py:311
2015-11-18 03:54:36.657 DEBUG oslo\_messaging.\_drivers.amqpdriver [-] CAST unique\_id: cb6a8ee1bbfc4f3a87cc8576bf600e52 exchange 'ironic' topic 'ironic.conductor\_manager.jim-devstack' from (pid=17795) \_send /usr/local/lib/python2.7/dist-packages/oslo\_messaging/\_drivers/amqpdriver.py:448
2015-11-18 03:54:36.659 DEBUG oslo\_messaging.\_drivers.amqpdriver [-] received message unique\_id: cb6a8ee1bbfc4f3a87cc8576bf600e52 from (pid=17795) \_\_call\_\_ /usr/local/lib/python2.7/dist-packages/oslo\_messaging/\_drivers/amqpdriver.py:195
2015-11-18 03:54:36.659 DEBUG ironic.conductor.manager [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] RPC continue\_node\_clean called for node 795a5722-22ad-4537-b17c-fcea5f7dc125. from (pid=17795) continue\_node\_clean /opt/stack/ironic/ironic/conductor/manager.py:881
2015-11-18 03:54:36.660 DEBUG ironic.conductor.task\_manager [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] Attempting to get exclusive lock on node 795a5722-22ad-4537-b17c-fcea5f7dc125 (for node cleaning) from (pid=17795) \_\_init\_\_ /opt/stack/ironic/ironic/conductor/task\_manager.py:201
2015-11-18 03:54:36.667 DEBUG ironic.conductor.task\_manager [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] Node 795a5722-22ad-4537-b17c-fcea5f7dc125 successfully reserved for node cleaning (took 0.01 seconds) from (pid=17795) reserve\_node /opt/stack/ironic/ironic/conductor/task\_manager.py:239
2015-11-18 03:54:36.671 DEBUG ironic.common.states [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] Exiting old state 'clean wait' in response to event 'resume' from (pid=17795) on\_exit /opt/stack/ironic/ironic/common/states.py:199
2015-11-18 03:54:36.671 DEBUG ironic.common.states [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] Entering new state 'cleaning' in response to event 'resume' from (pid=17795) on\_enter /opt/stack/ironic/ironic/common/states.py:205
2015-11-18 03:54:36.678 DEBUG oslo\_concurrency.lockutils [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] Lock "conductor\_worker\_spawn" acquired by "ironic.conductor.manager.\_spawn\_worker" :: waited 0.000s from (pid=17795) inner /usr/local/lib/python2.7/dist-packages/oslo\_concurrency/lockutils.py:253
2015-11-18 03:54:36.679 DEBUG oslo\_concurrency.lockutils [req-51e72e4c-69a7-4225-b21e-d8db3e85b65a None None] Lock "conductor\_worker\_spawn" released by "ironic.conductor.manager.\_spawn\_worker" :: held 0.000s from (pid=17795) inner /usr/local/lib/python2.7/dist-packages/oslo\_concurrency/lockutils.py:265
2015-11-18 03:54:36.679 INFO ironic.conductor.manager [-] Executing cleaning on node 795a5722-22ad-4537-b17c-fcea5f7dc125, remaining steps: [{u'priority': 10, u'interface': u'deploy', u'step': u'erase\_devices', u'abortable': True, u'reboot\_requested': False}]
2015-11-18 03:54:36.686 INFO ironic.conductor.manager [-] Executing {u'priority': 10, u'interface': u'deploy', u'step': u'erase\_devices', u'abortable': True, u'reboot\_requested': False} on node 795a5722-22ad-4537-b17c-fcea5f7dc125

[Jim Rollenhagen (jim-rollenhagen)](https://launchpad.net/~jim-rollenhagen)
on 2015-11-18

| Changed in ironic: | |
| --- | --- |
| **importance**: | Undecided → Critical |
| **status**: | New → Confirmed |
| **no longer affects**: | ironic/trunk |

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Grant Murphy (gmurphy)](https://launchpad.net/~gmurphy) wrote on 2015-11-18: |  |  | [#5](/ironic/%2Bbug/1517277/comments/5) |
| --- | --- | --- | --- |

Did you mean to mark this as a security issue?

Did you mean to mark this as a security issue?

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jim Rollenhagen (jim-rollenhagen)](https://launchpad.net/~jim-rollenhagen) wrote on 2015-11-18: |  |  | [#6](/ironic/%2Bbug/1517277/comments/6) |
| --- | --- | --- | --- |

@Grant very much yes. The issue here is that Ironic is expected to "clean" a server when a tenant is done, however that is transparently not happening.

@Grant very much yes. The issue here is that Ironic is expected to "clean" a server when a tenant is done, however that is transparently not happening.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jim Rollenhagen (jim-rollenhagen)](https://launchpad.net/~jim-rollenhagen) wrote on 2015-11-18: |  |  | [#7](/ironic/%2Bbug/1517277/comments/7) |
| --- | --- | --- | --- |

Sorry, submitted too early. This means a previous tenant's data could be left behind on the disk.

Sorry, submitted too early. This means a previous tenant's data could be left behind on the disk.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Grant Murphy (gmurphy)](https://launchpad.net/~gmurphy) wrote on 2015-11-18: |  |  | [#8](/ironic/%2Bbug/1517277/comments/8) |
| --- | --- | --- | --- |

Thanks for clarifying! Was just trying to figure out if an OSSA was needed here.

Ironic doesn't seem to currently have the vulnerability:managed tag in openstack/governance.

(See - <http://governance.openstack.org/reference/tags/vulnerability_managed.html>)

We will most likely need to look into that if a security advisory is required here. I'll add a OSSA task to the bug in assist the VMT with tracking.

Thanks for clarifying! Was just trying to figure out if an OSSA was needed here.
Ironic doesn't seem to currently have the vulnerability:managed tag in openstack/governance.
(See - http://governance.openstack.org/reference/tags/vulnerability\_managed.html)
We will most likely need to look into that if a security advisory is required here. I'll add a OSSA task to the bug in assist the VMT with tracking.

| Changed in ossa: | |
| --- | --- |
| **status**: | New → Incomplete |

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jim Rollenhagen (jim-rollenhagen)](https://launchpad.net/~jim-rollenhagen) wrote on 2015-11-18: |  |  | [#9](/ironic/%2Bbug/1517277/comments/9) |
| --- | --- | --- | --- |

Hrm, we've had help from the VMT in the past (before that tag was a thing), not sure why we didn't get that tag. I'll look into that at some point. Thanks Grant!

Hrm, we've had help from the VMT in the past (before that tag was a thing), not sure why we didn't get that tag. I'll look into that at some point. Thanks Grant!

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [aeva black (tenbrae)](https://launchpad.net/~tenbrae) wrote on 2015-11-19: |  |  | [#10](/ironic/%2Bbug/1517277/comments/10) |
| --- | --- | --- | --- |

I have confirmed the issue as Jim describes in my bifrost-based lab. Even with cleaning enabled, Ironic does not erase the servers' disks during instance deletion. If, after instance deletion, I manually turn that server on, I can confirm that it still has an OS and all user data is present.

I have also confirmed the patch corrects this behaviour. After applying the patch on top of trunk and deleting an instance, Ironic logs the clean\_steps appropriately and the server no longer has any data or operating system on its disks.

I have confirmed the issue as Jim describes in my bifrost-based lab. Even with cleaning enabled, Ironic does not erase the servers' disks during instance deletion. If, after instance deletion, I manually turn that server on, I can confirm that it still has an OS and all user data is present.
I have also confirmed the patch corrects this behaviour. After applying the patch on top of trunk and deleting an instance, Ironic logs the clean\_steps appropriately and the server no longer has any data or operating system on its disks.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [aeva black (tenbrae)](https://launchpad.net/~tenbrae) wrote on 2015-11-19: |  |  | [#11](/ironic/%2Bbug/1517277/comments/11) |
| --- | --- | --- | --- |

confirmed the fix also works on stable/liberty

confirmed the fix also works on stable/liberty

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Lucas Alvares Gomes (lucasagomes)](https://launchpad.net/~lucasagomes) wrote on 2015-11-20: |  |  | [#12](/ironic/%2Bbug/1517277/comments/12) |
| --- | --- | --- | --- |

Hi,

I can confirm the issue as well. I've enabled cleaning and the clean step was just skipped.

I also can confirm that if I apply the patch and only enable the "erase\_devices" clean step this works as expected.

However, I wanted to test some different scenarios with in-band and out-of-band cleaning steps and cleaning seems to be stuck when there's more than one clean step enabled after I applied the patch. I've created a very simple clean step that all it does is to create a file under "/tmp" in the RAID interface for the agent\_ssh driver (that interface is enabled by default for that driver). So when I run, I can see cleaning being executed and then once it moves to the new step Ironic executes it (I can see the file under /tmp) but Ironic never finishes the clean process, here's the current output of node-show and the file created [1].

And here's the diff of the @Jim's patch applied + the new in-band clean step [2]

[1] <http://fpaste.org/292697/48015718/> (password: ironic123)

[2] <http://fpaste.org/292695/01541214/> (password: ironic123)

@Deva, @Jim, can you guys confirm if the patch works when there's more than one clean step enabled?

Hi,
I can confirm the issue as well. I've enabled cleaning and the clean step was just skipped.
I also can confirm that if I apply the patch and only enable the "erase\_devices" clean step this works as expected.
However, I wanted to test some different scenarios with in-band and out-of-band cleaning steps and cleaning seems to be stuck when there's more than one clean step enabled after I applied the patch. I've created a very simple clean step that all it does is to create a file under "/tmp" in the RAID interface for the agent\_ssh driver (that interface is enabled by default for that driver). So when I run, I can see cleaning being executed and then once it moves to the new step Ironic executes it (I can see the file under /tmp) but Ironic never finishes the clean process, here's the current output of node-show and the file created [1].
And here's the diff of the @Jim's patch applied + the new in-band clean step [2]
[1] http://fpaste.org/292697/48015718/ (password: ironic123)
[2] http://fpaste.org/292695/01541214/ (password: ironic123)
@Deva, @Jim, can you guys confirm if the patch works when there's more than one clean step enabled?

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Lucas Alvares Gomes (lucasagomes)](https://launchpad.net/~lucasagomes) wrote on 2015-11-20: |  |  | [#13](/ironic/%2Bbug/1517277/comments/13) |
| --- | --- | --- | --- |

More info... Turns out it was my mistake. The fact that I was returning states.CLEANWAIT in that out-of-band clean step was what was causing it to hang.

So, I ran it again removing that return and everything went fine.

Thanks @Jim for the fix.

More info... Turns out it was my mistake. The fact that I was returning states.CLEANWAIT in that out-of-band clean step was what was causing it to hang.
So, I ran it again removing that return and everything went fine.
Thanks @Jim for the fix.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Tristan Cacqueray (tristan-cacqueray)](https://launchpad.net/~tristan-cacqueray) wrote on 2015-11-23: |  |  | [#14](/ironic/%2Bbug/1517277/comments/14) |
| --- | --- | --- | --- |

Does this bug also reproduces before 4.2.0 ?

Also, can you attach properly formated patch (see <https://security.openstack.org/#how-to-propose-and-review-a-security-patch> ) ?

While the Ironic vmt support tag is being worked on, here is an impact description draft that could be use to request a CVE. Please make sure it is accurate:

Title: Ironic does not honor clean steps

Reporter: Jim Rollenhagen (Rackspace)

Products: Ironic

Affects: >= 4.2.0, <= 4.2.1

Description:

Jim Rollenhagen from Rackspace reported a vulnerability in Ironic. To prevent user data leak, Ironic is expected to "clean" a server after use, however that is transparently not happening. Previous tenant's data may be left behind on the disk and may be available to new users. All Ironic setup are affected.

Does this bug also reproduces before 4.2.0 ?
Also, can you attach properly formated patch (see https://security.openstack.org/#how-to-propose-and-review-a-security-patch ) ?
While the Ironic vmt support tag is being worked on, here is an impact description draft that could be use to request a CVE. Please make sure it is accurate:
Title: Ironic does not honor clean steps
Reporter: Jim Rollenhagen (Rackspace)
Products: Ironic
Affects: >= 4.2.0, <= 4.2.1
Description:
Jim Rollenhagen from Rackspace reported a vulnerability in Ironic. To prevent user data leak, Ironic is expected to "clean" a server after use, however that is transparently not happening. Previous tenant's data may be left behind on the disk and may be available to new users. All Ironic setup are affected.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jim Rollenhagen (jim-rollenhagen)](https://launchpad.net/~jim-rollenhagen) wrote on 2015-11-23: |  |  | [#15](/ironic/%2Bbug/1517277/comments/15) |
| --- | --- | --- | --- |

* [bug\_1517277.patch](https://bugs.launchpad.net/ironic/%2Bbug/1517277/%2Battachment/4524342/%2Bfiles/bug_1517277.patch)
  [Edit](/ironic/%2Bbug/1517277/%2Battachment/4524342)
  (3.6 KiB,
  text/plain)

Uploaded a new version of the patch, rebased on master, with proper patch formatting. Also added reno-style release note.

Uploaded a new version of the patch, rebased on master, with proper patch formatting. Also added reno-style release note.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jim Rollenhagen (jim-rollenhagen)](https://launchpad.net/~jim-rollenhagen) wrote on 2015-11-23: |  |  | [#16](/ironic/%2Bbug/1517277/comments/16) |
| --- | --- | --- | --- |

Thanks Tristan, uploaded a new patch. That description looks good to me, with the exception that "setup" should be "setups".

We'd like to get this out ASAP - would y'all have the bandwidth to push through the OSSA/CVE process while the VMT support tag is being worked on? Or should I do some of that work?

Thanks Tristan, uploaded a new patch. That description looks good to me, with the exception that "setup" should be "setups".
We'd like to get this out ASAP - would y'all have the bandwidth to push through the OSSA/CVE process while the VMT support tag is being worked on? Or should I do some of that work?

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jim Rollenhagen (jim-rollenhagen)](https://launchpad.net/~jim-rollenhagen) wrote on 2015-11-23: |  |  | [#17](/ironic/%2Bbug/1517277/comments/17) |
| --- | --- | --- | --- |

One more thing - Brad Morgan (also from Rackspace) originally reported this bug, he should get the credit for it. :)

One more thing - Brad Morgan (also from Rackspace) originally reported this bug, he should get the credit for it. :)

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Tristan Cacqueray (tristan-cacqueray)](https://launchpad.net/~tristan-cacqueray) wrote on 2015-11-23: |  |  | [#18](/ironic/%2Bbug/1517277/comments/18) |
| --- | --- | --- | --- |

Thank for the impact description review, I've requested a CVE with it.

Can you please also attach the backport to stable/liberty branch ? (the last patch doesn't apply with "git am")

Since Ironic doesn't have the tag yet, I would prefer if you did the disclosure. (this step: <https://security.openstack.org/vmt-process.html#embargoed-disclosure> )

You can reuse the following template: <https://security.openstack.org/vmt-process.html#downstream-stakeholders-notification-email-private-issues>

So the next step is to get someone to approve the proposed patch.

Thank for the impact description review, I've requested a CVE with it.
Can you please also attach the backport to stable/liberty branch ? (the last patch doesn't apply with "git am")
Since Ironic doesn't have the tag yet, I would prefer if you did the disclosure. (this step: https://security.openstack.org/vmt-process.html#embargoed-disclosure )
You can reuse the following template: https://security.openstack.org/vmt-process.html#downstream-stakeholders-notification-email-private-issues
So the next step is to get someone to approve the proposed patch.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Tristan Cacqueray (tristan-cacqueray)](https://launchpad.net/~tristan-cacqueray) wrote on 2015-11-23: |  |  | [#19](/ironic/%2Bbug/1517277/comments/19) |
| --- | --- | --- | --- |

Updated impact description:

Title: Ironic does not honor clean steps

Reporter: Brad Morgan (Rackspace)

Products: Ironic

Affects: >= 4.2.0, <= 4.2.1

Description:

Grad Morgan from Rackspace reported a vulnerability in Ironic. To prevent user data leak, Ironic is expected to "clean" a server after use, however that is transparently not happening. Previous tenant's data may be left behind on the disk and may be available to new users. All Ironic setups are affected.

Updated impact description:
Title: Ironic does not honor clean steps
Reporter: Brad Morgan (Rackspace)
Products: Ironic
Affects: >= 4.2.0, <= 4.2.1
Description:
Grad Morgan from Rackspace reported a vulnerability in Ironic. To prevent user data leak, Ironic is expected to "clean" a server after use, however that is transparently not happening. Previous tenant's data may be left behind on the disk and may be available to new users. All Ironic setups are affected.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jeremy Stanley (fungi)](https://launchpad.net/~fungi) wrote on 2015-11-24: |  |  | [#20](/ironic/%2Bbug/1517277/comments/20) |
| --- | --- | --- | --- |

Tristan's updated impact description in comment 19 looks good to me.

Tristan's updated impact description in comment 19 looks good to me.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jim Rollenhagen (jim-rollenhagen)](https://launchpad.net/~jim-rollenhagen) wrote on 2015-11-24: |  |  | [#21](/ironic/%2Bbug/1517277/comments/21) |
| --- | --- | --- | --- |

* [liberty\_bug\_1517277.patch](https://bugs.launchpad.net/ironic/%2Bbug/1517277/%2Battachment/4524361/%2Bfiles/liberty_bug_1517277.patch)
  [Edit](/ironic/%2Bbug/1517277/%2Battachment/4524361)
  (3.6 KiB,
  text/plain)

Liberty patch attached.

Liberty patch attached.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Jim Rollenhagen (jim-rollenhagen)](https://launchpad.net/~jim-rollenhagen) wrote on 2015-11-24: |  |  | [#22](/ironic/%2Bbug/1517277/comments/22) |
| --- | --- | --- | --- |

Tristan, almost good to go. s/Grad/Brad/ :)

I've pinged Deva and Lucas to review the new patches.

As an FYI, I'll do a 4.2.2 release immediately after the stable/liberty patch lands.

I'm happy to send the email, if I'm given a list of addresses to send it to. I'd prefer if the VMT or deva sent the email as I'm sure my GPG keys are not as well-trusted. Here's a draft with a proposed disclosure date:

This is an advance warning of a vulnerability discovered in OpenStack,

to give you, as downstream stakeholders, a chance to coordinate the

release of fixes and reduce the vulnerability window. Please treat the

following information as confidential until the proposed public

disclosure date.

Title: Ironic does not honor clean steps

Reporter: Brad Morgan (Rackspace)

Products: Ironic

Affects: >= 4.2.0, <= 4.2.1

Description:

Grad Morgan from Rackspace reported a vulnerability in Ironic. To prevent user data leak, Ironic is expected to "clean" a server after use, however that is transparently not happening. Previous tenant's data may be left behind on the disk and may be available to new users. All Ironic setups are affected.

Proposed patch:

See attached patches. Unless a flaw is discovered in them, these patches

will be merged to the stable/liberty and master branches on the public disclosure date.

CVE: $CVE

Proposed public disclosure date/time:

December 1, 2015, 1500UTC

Please do not make the issue public (or release public patches) before

this coordinated embargo date.

Tristan, almost good to go. s/Grad/Brad/ :)
I've pinged Deva and Lucas to review the new patches.
As an FYI, I'll do a 4.2.2 release immediately after the stable/liberty patch lands.
I'm happy to send the email, if I'm given a list of addresses to send it to. I'd prefer if the VMT or deva sent the email as I'm sure my GPG keys are not as well-trusted. Here's a draft with a proposed disclosure date:
This is an advance warning of a vulnerability discovered in OpenStack,
to give you, as downstream stakeholders, a chance to coordinate the
release of fixes and reduce the vulnerability window. Please treat the
following information as confidential until the proposed public
disclosure date.
Title: Ironic does not honor clean steps
Reporter: Brad Morgan (Rackspace)
Products: Ironic
Affects: >= 4.2.0, <= 4.2.1
Description:
Grad Morgan from Rackspace reported a vulnerability in Ironic. To prevent user data leak, Ironic is expected to "clean" a server after use, however that is transparently not happening. Previous tenant's data may be left behind on the disk and may be available to new users. All Ironic setups are affected.
Proposed patch:
See attached patches. Unless a flaw is discovered in them, these patches
will be merged to the stable/liberty and master branches on the public disclosure date.
CVE: $CVE
Proposed public disclosure date/time:
December 1, 2015, 1500UTC
Please do not make the issue public (or release public patches) before
this coordinated embargo date.

[Tristan Cacqueray (tristan-cacqueray)](https://launchpad.net/~tristan-cacqueray)
on 2015-11-24

| **summary**: | - Clean steps don't actually run+ Clean steps don't actually run (CVE-2015-7514) |
| --- | --- |

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [aeva black (tenbrae)](https://launchpad.net/~tenbrae) wrote on 2015-11-24: |  |  | [#23](/ironic/%2Bbug/1517277/comments/23) |
| --- | --- | --- | --- |

Patches look good to me. I've confirmed they apply cleanly on master and stable/liberty.

Aside from the latest comment still indicating that "Grad Morgan" found the issue (instead of Brad) this looks fine to my non-VMT-experienced eyes.

I'm happy to sign and send the email, but I, too, do not know who all the downstream stakeholders are.

Patches look good to me. I've confirmed they apply cleanly on master and stable/liberty.
Aside from the latest comment still indicating that "Grad Morgan" found the issue (instead of Brad) this looks fine to my non-VMT-experienced eyes.
I'm happy to sign and send the email, but I, too, do not know who all the downstream stakeholders are.

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Tristan Cacqueray (tristan-cacqueray)](https://launchpad.net/~tristan-cacqueray) wrote on 2015-11-25: |  |  | [#24](/ironic/%2Bbug/1517277/comments/24) |
| --- | --- | --- | --- |

Thanks Devananda for sending the notification.

The public disclosure date is:

December 3, 2015, 1500UTC

Thanks Devananda for sending the notification.
The public disclosure date is:
December 3, 2015, 1500UTC

| Changed in ossa: | |
| --- | --- |
| **status**: | Incomplete → Fix Committed |

[Jim Rollenhagen (jim-rollenhagen)](https://launchpad.net/~jim-rollenhagen)
on 2015-12-03

| **information type**: | Private Security → Public |
| --- | --- |

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [OpenStack Infra (hudson-openstack)](https://launchpad.net/~hudson-openstack) wrote on 2015-12-03:  [**Fix proposed to ironic (stable/liberty)**](/ironic/%2Bbug/1517277/comments/25) |  |  | [#25](/ironic/%2Bbug/1517277/comments/25) |
| --- | --- | --- | --- |

Fix proposed to branch: stable/liberty

Review: <https://review.openstack.org/253001>

Fix proposed to branch: stable/liberty
Review: https://review.openstack.org/253001

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [OpenStack Infra (hudson-openstack)](https://launchpad.net/~hudson-openstack) wrote on 2015-12-03:  [**Change abandoned on ironic (stable/liberty)**](/ironic/%2Bbug/1517277/comments/26) |  |  | [#26](/ironic/%2Bbug/1517277/comments/26) |
| --- | --- | --- | --- |

Change abandoned by Jim Rollenhagen (<email address hidden>) on branch: stable/liberty

Review: <https://review.openstack.org/252994>

Reason: I screwed up change-id, new patch is here <https://review.openstack.org/#/c/253001/>

Change abandoned by Jim Rollenhagen (jim@jimrollenhagen.com) on branch: stable/liberty
Review: https://review.openstack.org/252994
Reason: I screwed up change-id, new patch is here https://review.openstack.org/#/c/253001/

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Tristan Cacqueray (tristan-cacqueray)](https://launchpad.net/~tristan-cacqueray) wrote on 2015-12-03: |  |  | [#27](/ironic/%2Bbug/1517277/comments/27) |
| --- | --- | --- | --- |

Master patch is: <https://review.openstack.org/#/c/252993/>

Advisory is out, I removed the ossa task now.

Thanks everyone!

Master patch is: https://review.openstack.org/#/c/252993/
Advisory is out, I removed the ossa task now.
Thanks everyone!

| Changed in ossa: | |
| --- | --- |
| **status**: | Fix Committed → Won't Fix |

[OpenStack Infra (hudson-openstack)](https://launchpad.net/~hudson-openstack)
on 2015-12-03

| Changed in ironic: | |
| --- | --- |
| **assignee**: | nobody → Devananda van der Veen (devananda) |
| **status**: | Confirmed → In Progress |

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [OpenStack Infra (hudson-openstack)](https://launchpad.net/~hudson-openstack) wrote on 2015-12-03:  [**Fix merged to ironic (stable/liberty)**](/ironic/%2Bbug/1517277/comments/28) |  |  | [#28](/ironic/%2Bbug/1517277/comments/28) |
| --- | --- | --- | --- |

Reviewed: <https://review.openstack.org/253001>

Committed: <https://git.openstack.org/cgit/openstack/ironic/commit/?id=6eb970b71cb6ae629b733ced84917d9db5afc78a>

Submitter: Jenkins

Branch: stable/liberty

commit 6eb970b71cb6ae629b733ced84917d9db5afc78a

Author: Jim Rollenhagen <email address hidden>

Date: Mon Nov 23 22:40:19 2015 +0000

Fix bug where clean steps do not run

A bug was introduced during Liberty where Ironic transparently

    ignores all clean steps and finishes cleaning. This is caused

    by \_get\_node\_next\_clean\_steps returning an empty list when

    cleaning has just started. Fix this method to return the full

    list of clean steps when cleaning begins.

This may leave previous tenants' data on disk and available to future

    tenants. Deployers should apply this patch (or upgrade to a new release

    with this patch) ASAP.

Closes-Bug: #1517277

    (cherry picked from commit 1c700e6d62ad299e3fc9023e30b98d51408e49e1)

Change-Id: If815f81d7e668244f0d434d4e2933e8f41946107

Reviewed: https://review.openstack.org/253001
Committed: https://git.openstack.org/cgit/openstack/ironic/commit/?id=6eb970b71cb6ae629b733ced84917d9db5afc78a
Submitter: Jenkins
Branch: stable/liberty
commit 6eb970b71cb6ae629b733ced84917d9db5afc78a
Author: Jim Rollenhagen <jim@jimrollenhagen.com>
Date: Mon Nov 23 22:40:19 2015 +0000
Fix bug where clean steps do not run
A bug was introduced during Liberty where Ironic transparently
ignores all clean steps and finishes cleaning. This is caused
by \_get\_node\_next\_clean\_steps returning an empty list when
cleaning has just started. Fix this method to return the full
list of clean steps when cleaning begins.
This may leave previous tenants' data on disk and available to future
tenants. Deployers should apply this patch (or upgrade to a new release
with this patch) ASAP.
Closes-Bug: #1517277
(cherry picked from commit 1c700e6d62ad299e3fc9023e30b98d51408e49e1)
Change-Id: If815f81d7e668244f0d434d4e2933e8f41946107

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [OpenStack Infra (hudson-openstack)](https://launchpad.net/~hudson-openstack) wrote on 2015-12-04:  [**Fix merged to ironic (master)**](/ironic/%2Bbug/1517277/comments/29) |  |  | [#29](/ironic/%2Bbug/1517277/comments/29) |
| --- | --- | --- | --- |

Reviewed: <https://review.openstack.org/252993>

Committed: <https://git.openstack.org/cgit/openstack/ironic/commit/?id=bf518cd5407296e32e26686fc6e99be8f71e5731>

Submitter: Jenkins

Branch: master

commit bf518cd5407296e32e26686fc6e99be8f71e5731

Author: Jim Rollenhagen <email address hidden>

Date: Mon Nov 23 22:40:19 2015 +0000

Fix bug where clean steps do not run

A bug was introduced during Liberty where Ironic transparently

    ignores all clean steps and finishes cleaning. This is caused

    by \_get\_node\_next\_clean\_steps returning an empty list when

    cleaning has just started. Fix this method to return the full

    list of clean steps when cleaning begins.

This may leave previous tenants' data on disk and available to future

    tenants. Deployers should apply this patch (or upgrade to a new release

    with this patch) ASAP.

Depends-On: Id15cf6cc49122b08e557e44871b31a8c0d20b55d

Change-Id: If815f81d7e668244f0d434d4e2933e8f41946107

    Closes-Bug: #1517277

Reviewed: https://review.openstack.org/252993
Committed: https://git.openstack.org/cgit/openstack/ironic/commit/?id=bf518cd5407296e32e26686fc6e99be8f71e5731
Submitter: Jenkins
Branch: master
commit bf518cd5407296e32e26686fc6e99be8f71e5731
Author: Jim Rollenhagen <jim@jimrollenhagen.com>
Date: Mon Nov 23 22:40:19 2015 +0000
Fix bug where clean steps do not run
A bug was introduced during Liberty where Ironic transparently
ignores all clean steps and finishes cleaning. This is caused
by \_get\_node\_next\_clean\_steps returning an empty list when
cleaning has just started. Fix this method to return the full
list of clean steps when cleaning begins.
This may leave previous tenants' data on disk and available to future
tenants. Deployers should apply this patch (or upgrade to a new release
with this patch) ASAP.
Depends-On: Id15cf6cc49122b08e557e44871b31a8c0d20b55d
Change-Id: If815f81d7e668244f0d434d4e2933e8f41946107
Closes-Bug: #1517277

| Changed in ironic: | |
| --- | --- |
| **status**: | In Progress → Fix Committed |

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Doug Hellmann (doug-hellmann)](https://launchpad.net/~doug-hellmann) wrote on 2015-12-04:  [**Fix included in openstack/ironic 4.2.2**](/ironic/%2Bbug/1517277/comments/30) |  |  | [#30](/ironic/%2Bbug/1517277/comments/30) |
| --- | --- | --- | --- |

This issue was fixed in the openstack/ironic 4.2.2 release.

This issue was fixed in the openstack/ironic 4.2.2 release.

| Changed in ironic: | |
| --- | --- |
| **status**: | Fix Committed → Fix Released |

Revision history for this message
![](/+icing/build/overlay/assets/skins/sam/images/close.gif)

| [Doug Hellmann (doug-hellmann)](https://launchpad.net/~doug-hellmann) wrote on 2015-12-07:  [**Fix included in openstack/ironic 4.3.0**](/ironic/%2Bbug/1517277/comments/31) |  |  | [#31](/ironic/%2Bbug/1517277/comments/31) |
| --- | --- | --- | --- |

This issue was fixed in the openstack/ironic 4.3.0 release.

This issue was fixed in the openstack/ironic 4.3.0 release.

[See full activity log](https://bugs.launchpad.net/ironic/%2Bbug/1517277/%2Bactivity)

To post a comment you must [log in](%2Blogin?comments=all).

* [Report a bug](/ironic/%2Bfilebug)

This report contains
**Public**
information

Everyone can see this information.

You are
[not directly subscribed to this bug's notifications.](/ironic/%2Bbug/1517277/%2Bsubscribe)

Subscribing...

* [Edit bug mail](https://bugs.launchpad.net/ironic/%2Bbug/1517277/%2Bsubscriptions "View and change your subscriptions to this bug")

## Other bug subscribers

[Subscribe someone else](https://bugs.launchpad.net/ironic/%2Bbug/1517277/%2Baddsubscriber "Launchpad will email that person whenever this bugs changes")

## Patches

* [bug\_1517277.patch](https://bugs.launchpad.net/ironic/%2Bbug/1517277/%2Battachment/4524342/%2Bfiles/bug_1517277.patch)
  [Edit](/ironic/%2Bbug/1517277/%2Battachment/4524342 "Change patch details")
* [liberty\_bug\_1517277.patch](https://bugs.launchpad.net/ironic/%2Bbug/1517277/%2Battachment/4524361/%2Bfiles/liberty_bug_1517277.patch)
  [Edit](/ironic/%2Bbug/1517277/%2Battachment/4524361 "Change patch details")

* [Add patch](/ironic/%2Bbug/1517277/%2Baddcomment?field.patch=on)

## Remote bug watches

Bug watches keep track of this bug in other bug trackers.

[![Launchpad](/@@/launchpad-footer-logo.svg)](https://launchpad.net/)
 •
[Take the tour](https://launchpad.net/%2Btour)
 •
[Read the guide](https://help.launchpad.net/)

© 2004
[Canonical Ltd.](http://canonical.com/)
 •
[Terms of use](https://launchpad.net/legal)
 •
[Data privacy](https://www.ubuntu.com/legal/dataprivacy)
 •
[Contact Launchpad Support](/feedback)
 •
[Blog](http://blog.launchpad.net/)
 •
[Careers](https://canonical.com/careers)
 •
[System status](https://ubuntu.social/%40launchpadstatus)
 •
4d55102
([Get the code!](https://dev.launchpad.net/))



=== Content from bugzilla.redhat.com_c6e35c78_20250125_000126.html ===


* Login
  + Log in using an SSO provider:- [Fedora Account System](saml2_login.cgi?idp=Fedora%20Account%20System&target=show_bug.cgi%3Fid%3D1285809)
    - [Red Hat Associate](saml2_login.cgi?idp=Red%20Hat%20Associate&target=show_bug.cgi%3Fid%3D1285809)
    - [Red Hat Customer](saml2_login.cgi?idp=Red%20Hat%20Customer&target=show_bug.cgi%3Fid%3D1285809)+ Login using a Red Hat Bugzilla account
  + Forgot Password
  + [Create an Account](createaccount.cgi)

Red Hat Bugzilla – Bug 1285809

* [Home](./)
* [New](enter_bug.cgi)
* Search
  + [Simple Search](query.cgi?format=specific)
  + [Advanced Search](query.cgi?format=advanced)
* My Links
  + [Browse](describecomponents.cgi)
  + [Requests](request.cgi)
  + Reports
  + Current State
    - [Search](query.cgi)
    - [Tabular reports](query.cgi?format=report-table)
    - [Graphical reports](query.cgi?format=report-graph)
    - [Duplicates](duplicates.cgi)
  + Other Reports
    - [User Changes](https://bugzilla.redhat.com/page.cgi?id=user_activity.html)
  + Plotly Reports
    - [Bug Status](https://bugzilla.redhat.com/page.cgi?id=bug_status.html)
    - [Bug Severity](https://bugzilla.redhat.com/page.cgi?id=bug_severity.html)
    - [Non-Defaults](https://bugzilla.redhat.com/page.cgi?id=non_defaults.html)
* [Product Dashboard](page.cgi?id=productdashboard.html)

- Help
  * [Page Help!](docs/en/html/using/understanding.html)
  * [Bug Writing Guidelines](page.cgi?id=bug-writing.html)
  * [What's new](page.cgi?id=whats-new.html)
  * [Browser Support Policy](https://access.redhat.com/help/browsers)
  * [5.0.4.rh103 Release notes](page.cgi?id=release-notes.html)
  * [FAQ](page.cgi?id=faq.html)
  * [Guides index](docs/en/html/index.html)
  * [User guide](docs/en/html/using/index.html)
  * [Web Services](docs/en/html/integrating/api/Bugzilla/WebService/Bug.html)
  * [Contact](page.cgi?id=redhat/contact.html)
  * [Legal](page.cgi?id=terms-conditions.html)
- [[?]](page.cgi?id=quicksearch.html "Quicksearch Help")

This site requires JavaScript to be enabled to function correctly, please enable it.

[**Bug 1285809**](show_bug.cgi?id=1285809)
(CVE-2015-7514)
- [CVE-2015-7514](https://access.redhat.com/security/cve/CVE-2015-7514) openstack-ironic: Ironic does not honor clean steps

[Summary:](page.cgi?id=fields.html#short_desc "The bug summary is a short sentence which succinctly describes what the bug is about.")
CVE-2015-7514 openstack-ironic: Ironic does not honor clean steps

| | [Keywords](describekeywords.cgi): | Security | | --- | --- | | [Status](page.cgi?id=fields.html#bug_status): | CLOSED CURRENTRELEASE | | [Alias:](page.cgi?id=fields.html#alias "A short, unique name assigned to a bug in order to assist with looking it up and referring to it in other places in Bugzilla.") | CVE-2015-7514 | | [Product:](describecomponents.cgi "Bugs are categorised into Products and Components. Select a Classification to narrow down this list.") | Security Response | | [Classification:](page.cgi?id=fields.html#classification "Bugs are categorised into Classifications, Products and Components. classifications is the top-level categorisation.") | Other | | [Component:](describecomponents.cgi?product=Security Response "Components are second-level categories; each belongs to a particular Product. Select a Product to narrow down this list.") | vulnerability | | [Sub Component:](page.cgi?id=fields.html#rh_sub_components "The sub component of a specific component") | --- | | [Version:](page.cgi?id=fields.html#version "The version field defines the version of the software the bug was found in.") | unspecified | | [Hardware:](page.cgi?id=fields.html#rep_platform "The hardware platform the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | All | | [OS:](page.cgi?id=fields.html#op_sys "The operating system the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | Linux | | [Priority:](page.cgi?id=fields.html#priority) | medium | | [Severity:](page.cgi?id=fields.html#bug_severity) | medium | | [Target Milestone:](page.cgi?id=fields.html#target_milestone "The Target Milestone field is used to define when the engineer the bug is assigned to expects to fix it.") | --- | | [Assignee:](page.cgi?id=fields.html#assigned_to "The person in charge of resolving the bug.") | Red Hat Product Security | | [QA Contact:](page.cgi?id=fields.html#qa_contact "The person responsible for confirming this bug if it is unconfirmed, and for verifying the fix once the bug has been resolved.") | Toure Dunnon | | [Docs Contact:](page.cgi?id=fields.html#docs_contact "The person responsible for documenting once the bug has been resolved.") |  | | [URL:](page.cgi?id=fields.html#bug_file_loc "Bugs can have a URL associated with them - for example, a pointer to a web site where the problem is seen.") |  | | [Whiteboard:](page.cgi?id=fields.html#status_whiteboard "Each bug has a free-form single line text entry box for adding tags and status information.") |  | | [Depends On:](page.cgi?id=fields.html#dependson "The bugs listed here must be resolved before this bug can be resolved.") | [1299675](show_bug.cgi?id=1299675) [1299676](show_bug.cgi?id=1299676) | | [Blocks:](page.cgi?id=fields.html#blocked "This bug must be resolved before the bugs listed in this field can be resolved.") | [1285811](show_bug.cgi?id=1285811) | | TreeView+ | [depends on](buglist.cgi?bug_id=1285809&bug_id_type=anddependson&format=tvp) / [blocked](buglist.cgi?bug_id=1285809&bug_id_type=andblocked&format=tvp&tvp_dir=blocked) |  | |  | | [Reported:](page.cgi?id=fields.html#reporter) | 2015-11-26 14:09 UTC by Martin Prpič | | --- | --- | | [Modified:](page.cgi?id=fields.html#modified) | 2023-05-12 11:03 UTC ([History](show_activity.cgi?id=1285809)) | | [CC List:](page.cgi?id=fields.html#cclist) | 22 users (show)  abaron aortega apevec ayoung chrisw dallan dtantsur gkotton gmollett jschluet lhh lmartins lpeer markmc mburns rbryant rhel-osp-director-maint sclewis security-response-team srevivo tdecacqu tdunnon | | Fixed In Version: |  | | | Doc Type: | Bug Fix | | | Doc Text: |  | | | Clone Of: |  | | | Environment: |  | | | Last Closed: | 2016-06-20 04:08:36 UTC | | | Embargoed: |  | | |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| --- | | |

| | Attachments | [(Terms of Use)](page.cgi?id=terms-conditions.html) | | | --- | --- | --- | | [**CVE-2015-7514-master-mitaka.patch**](attachment.cgi?id=1099283 "View the content of the attachment") (3.61 KB, text/plain)  [2015-11-26 14:13 UTC](#attach_1099283 "Go to the comment associated with the attachment"), Martin Prpič | *no flags* | [Details](attachment.cgi?id=1099283&action=edit) | | [**CVE-2015-7514-stable-liberty.patch**](attachment.cgi?id=1099284 "View the content of the attachment") (3.59 KB, text/plain)  [2015-11-26 14:13 UTC](#attach_1099284 "Go to the comment associated with the attachment"), Martin Prpič | *no flags* | [Details](attachment.cgi?id=1099284&action=edit) | | [View All](attachment.cgi?bugid=1285809&action=viewall) | | | |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |

| [Description](show_bug.cgi?id=1285809#c0)  Martin Prpič    2015-11-26 14:09:36 UTC  ``` A flaw was reported in Ironic:  Brad Morgan from Rackspace reported a vulnerability in Ironic. To prevent user data leak, Ironic is expected to "clean" a server after use, however that is transparently not happening. Previous tenant's data may be left behind on the disk and may be available to new users. All Ironic setups are affected.  This flaw is reported to affect versions >= 4.2.0 and <= 4.2.1.  Acknowledgements:  Red Hat would like to thank the OpenStack project for reporting this issue. Upstream acknowledges Brad Morgan from Rackspace as the original reporter.   ```  [Comment 1](show_bug.cgi?id=1285809#c1)  Martin Prpič    2015-11-26 14:13:15 UTC  ``` Created [attachment 1099283](attachment.cgi?id=1099283 "CVE-2015-7514-master-mitaka.patch") [[details]](attachment.cgi?id=1099283&action=edit "CVE-2015-7514-master-mitaka.patch") CVE-2015-7514-master-mitaka.patch   ```  [Comment 2](show_bug.cgi?id=1285809#c2)  Martin Prpič    2015-11-26 14:13:21 UTC  ``` Created [attachment 1099284](attachment.cgi?id=1099284 "CVE-2015-7514-stable-liberty.patch") [[details]](attachment.cgi?id=1099284&action=edit "CVE-2015-7514-stable-liberty.patch") CVE-2015-7514-stable-liberty.patch   ```  [Comment 3](show_bug.cgi?id=1285809#c3)  Adam Mariš    2015-12-03 17:30:16 UTC  ``` Public via:  <http://seclists.org/oss-sec/2015/q4/426>   ``` |  |
| --- | --- |

---

| Note You need to [log in](show_bug.cgi?id=1285809&GoAheadAndLogIn=1) before you can comment on or make changes to this bug. |
| --- |

---

[Privacy](page.cgi?id=redhat/privacy.html)
[Contact](page.cgi?id=redhat/contact.html)
[FAQ](page.cgi?id=faq.html)
[Legal](page.cgi?id=terms-conditions.html)


