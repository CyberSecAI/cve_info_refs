=== Content from bugzilla.mozilla.org_f5d81ed0_20250125_100301.html ===


![](/static/v20250114.1/extensions/BMO/web/images/moz-fav-one-color-white-rgb.svg)

* [Mozilla Home](https://www.mozilla.org/)
* [Privacy](https://www.mozilla.org/privacy/websites/)
* [Cookies](https://www.mozilla.org/privacy/websites/#cookies)
* [Legal](https://www.mozilla.org/about/legal/)
# [Bugzilla](https://bugzilla.mozilla.org/home "Go to home page")

[Quick Search Tips](/page.cgi?id=quicksearch.html)
[Advanced Search](/query.cgi?format=advanced)

* [Browse](/describecomponents.cgi "Browse bugs by component")
* [Advanced Search](/query.cgi?format=advanced "Search bugs using various criteria")
* [New Bug](/enter_bug.cgi "File a new bug")

* [Reports](/report.cgi)
* [Documentation](https://bmo.readthedocs.io/en/latest/)

* [Log In](/index.cgi?GoAheadAndLogIn=1)

   Log In with GitHub

  or

  Remember me

  [Create an Account](/createaccount.cgi)
  ·
  [Forgot Password](/index.cgi?GoAheadAndLogIn=1#forgot)

* [Browse](/describecomponents.cgi "Browse bugs by component")
* [Advanced Search](/query.cgi?format=advanced "Search bugs using various criteria")
* [New Bug](/enter_bug.cgi "File a new bug")
* [Reports](/report.cgi)
* [Documentation](https://bmo.readthedocs.io/en/latest/)

Please enable JavaScript in your browser to use all the features on this site.

Copy Summary▾

* Markdown
* Markdown (bug number)
* Plain Text
* HTML

View ▾

* Reset Sections
* Expand All Sections
* Collapse All Sections
* History
* [JSON](/rest/bug/453403)
* [XML](/show_bug.cgi?ctype=xml&id=453403)

Closed
[Bug 453403](/show_bug.cgi?id=453403)

Opened 16 years ago
Closed 16 years ago

# add DNS pre-fetching to Necko and Firefox

\*
[Summary:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#short_desc)

add DNS pre-fetching to Necko and Firefox

## Categories

### (Core :: Networking, enhancement)

[Product:](/describecomponents.cgi?product=Core)

Core
▾

Core
Shared components used by Firefox and other Mozilla software, including handling of Web content; Gecko, HTML, CSS, layout, DOM, scripts, images, networking, etc. Issues with web page layout probably go here, while Firefox user interface issues belong in the [Firefox](https://bugzilla.mozilla.org/describecomponents.cgi?product=Firefox) product. ([More info](https://wiki.mozilla.org/Modules/All#Core))
[See Open Bugs in This Product](/buglist.cgi?product=Core&bug_status=__open__)
[File New Bug in This Product](/enter_bug.cgi?product=Core)
Watch This Product

[Component:](/describecomponents.cgi?product=Core&component=Networking#Networking)

Networking
▾

Core :: Networking
For bugs in Mozilla's modular networking library (aka "Netlib" or "Necko".) The networking library supplies the software interface that Mozilla uses to access physical transports (e.g. the Internet and local drives), perform URL resolutions, and handle a variety of networking protocols.

Examples of appropriate bugs: URLs with backslash not fetched; URLs starting with a single slash turn into http:///; Cannot access authenticated FTP site.

[See Open Bugs in This Component](/buglist.cgi?product=Core&component=Networking&bug_status=__open__)
[Recently Fixed Bugs in This Component](/buglist.cgi?product=Core&component=Networking&chfield=resolution&chfieldfrom=-6m&chfieldvalue=FIXED&bug_status=__closed__)
[File New Bug in This Component](/enter_bug.cgi?product=Core&component=Networking)
Watch This Component

[Version:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#version)

Trunk

[Platform:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#rep_platform)

All

All

[Type:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#bug_type)

enhancement

[Priority:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#priority)

*Not set*

[Severity:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#bug_severity)

normal

Points:

---

## Tracking

### ()

[Status:](https://wiki.mozilla.org/BMO/UserGuide/BugStatuses)

RESOLVED
FIXED

[Status:](https://wiki.mozilla.org/BMO/UserGuide/BugStatuses)

RESOLVED

FIXED

Mark as Assigned

[Milestone:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#target_milestone)

mozilla1.9.1b2

Iteration:

---

[Project Flags:](https://wiki.mozilla.org/BMO/UserGuide#Project_Flags)

| Webcompat Priority | --- |
| --- | --- |
| a11y-review | --- |
| Webcompat Score | --- |
| Performance Impact | --- |
| Accessibility Severity | --- |

[Tracking Flags:](https://wiki.mozilla.org/BMO/UserGuide#Tracking_Flags)

|  | Tracking | Status |
| --- | --- | --- |
| relnote-firefox |  | --- |
| thunderbird\_esr115 | --- | --- |
| thunderbird\_esr128 | --- | --- |
| firefox-esr115 | --- | --- |
| firefox-esr128 | --- | --- |
| firefox134 | --- | --- |
| firefox135 | --- | --- |
| firefox136 | --- | --- |

## People

### (Reporter: asa, Assigned: mcmanus)

[Assignee:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#assigned_to)

![](https://secure.gravatar.com/avatar/2b0de973c803f192309b00777c594202?d=mm&size=40)  [mcmanus](/user_profile?user_id=32546)

[Assignee:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#assigned_to)

Reset Assignee to default

[Mentors:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#bug_mentor)

---

[QA Contact:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#qa_contact)

Reset QA Contact to default

[Reporter:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#reporter)

![](https://secure.gravatar.com/avatar/4c29696cb5fe35b184e1221706f87874?d=mm&size=40)  [asa](/user_profile?user_id=5003)

[Triage Owner:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#triage_owner)

![](https://secure.gravatar.com/avatar/608e04ebca94be52b05c003d51d43e07?d=mm&size=40)  [kershaw](/user_profile?user_id=505624)

[CC:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#cc)

54 people

## References

[Depends on:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#dependson)

[459724](/show_bug.cgi?id=459724 "RESOLVED FIXED - DNS: page reload should set bypass cache flag"), [463215](/show_bug.cgi?id=463215 "RESOLVED WORKSFORME - Browser intermittently stalls/hangs for long periods resolving hostnames - Looking up <hostname> in status bar"), [463263](/show_bug.cgi?id=463263 "RESOLVED FIXED - leaking nsHostResolver a lot on multiple platforms from unrelated checkins"), [464838](/show_bug.cgi?id=464838 "RESOLVED FIXED - Tp3 regression on 2008-11-11"), [467648](/show_bug.cgi?id=467648 "RESOLVED FIXED - nsHTMLDNSPrefetch leak"), [475603](/show_bug.cgi?id=475603 "VERIFIED INVALID - Lots of timeouts for DNS requests with Netgear Router WGR614, and stylesheet/css rendering problems"), [486127](/show_bug.cgi?id=486127 "RESOLVED FIXED - Seamonkey/Thunderbird send DNS queries when viewing mail, could be used to verify existence of mail accounts"), [488162](/show_bug.cgi?id=488162 "RESOLVED FIXED - DNS prefetch leaks information because it doesn't honour network.proxy.socks_remote_dns"), [492196](/show_bug.cgi?id=492196 "RESOLVED FIXED - Make DNS-Prefetching subject to user-defined policies")

[Blocks:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#blocks)

[437953](/show_bug.cgi?id=437953 "VERIFIED FIXED - Better network performance")

Dependency [tree](/showdependencytree.cgi?id=453403&hide_resolved=1)
/ [graph](/showdependencygraph.cgi?id=453403)

[Regressions:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#regresses)

---

[Regressed by:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#regressed_by)

---

[Duplicates:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#duplicates)

[220942](/show_bug.cgi?id=220942 "RESOLVED DUPLICATE - DNS: pre-resolving hostnames found on a page")

[URL:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#bug_file_loc)

[See Also:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#see_also)

---

## Details

### (Keywords: fixed1.9.1, perf)

[Alias:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#alias)

---

[Keywords:](/describekeywords.cgi)

[fixed1.9.1](/buglist.cgi?keywords=fixed1.9.1&resolution=---),
[perf](/buglist.cgi?keywords=perf&resolution=---)

[Whiteboard:](https://wiki.mozilla.org/BMO/UserGuide/Whiteboard)

---

QA Whiteboard:

---

Has STR:

---

Change Request:

---

[Votes:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#votes)

6

Bug Flags:

| [pavlov](/user_profile?user_id=5756) | [wanted1.9.1](#a1167461_5756 "16 years ago") | + |
| --- | --- | --- |
| [pavlov](/user_profile?user_id=5756) | wanted1.9.1 | + |
| --- | --- | --- |
| [bzbarsky](/user_profile?user_id=20209) | [in-testsuite](#c68 "16 years ago") | ? |
| --- | --- | --- |
| [bzbarsky](/user_profile?user_id=20209) | in-testsuite | ? |
| --- | --- | --- |
|  | behind-pref |  |
| --- | --- | --- |
|  | firefox-backlog |  |
|  | sec-bounty | ? |
|  | sec-bounty-hof |  |
|  | in-qa-testsuite |  | | |
|  | qe-verify |  |

## Crash Data

Signature:

*None*

## Security

### (public)

This bug is publicly visible.

## User Story

## Attachments

### (2 files, 8 obsolete files)

| [dns prefetch patch mentioned in comment 8](/attachment.cgi?id=338419)  [16 years ago](#c9)  [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)   27.98 KB, patch |  | [Details](/attachment.cgi?id=338419&action=edit) | [Diff](/attachment.cgi?id=338419&action=diff) | [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=338419) |
| --- | --- | --- |
| [version 3 of patch](/attachment.cgi?id=342476)  [16 years ago](#c23)  [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)   38.84 KB, patch |  | [Details](/attachment.cgi?id=342476&action=edit) | [Diff](/attachment.cgi?id=342476&action=diff) | [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=342476) |
| [version 4 of patch](/attachment.cgi?id=343153)  [16 years ago](#c24)  [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)   50.13 KB, patch |  | [Details](/attachment.cgi?id=343153&action=edit) | [Diff](/attachment.cgi?id=343153&action=diff) | [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=343153) |
| [version 5 of patch](/attachment.cgi?id=344475)  [16 years ago](#c25)  [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)   49.44 KB, patch | bzbarsky : [review-](#c26 "16 years ago") | [Details](/attachment.cgi?id=344475&action=edit) | [Diff](/attachment.cgi?id=344475&action=diff) | [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=344475) |
| [version 6 of patch](/attachment.cgi?id=345527)  [16 years ago](#c28)  [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)   53.73 KB, patch | bzbarsky : [review+](#c29 "16 years ago")  bzbarsky : [superreview+](#c29 "16 years ago") | [Details](/attachment.cgi?id=345527&action=edit) | [Diff](/attachment.cgi?id=345527&action=diff) | [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=345527) |
| [version 7 of patch](/attachment.cgi?id=345727)  [16 years ago](#c30)  [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)   56.89 KB, patch |  | [Details](/attachment.cgi?id=345727&action=edit) | [Diff](/attachment.cgi?id=345727&action=diff) | [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=345727) |
| [version 8 of patch](/attachment.cgi?id=346134)  [16 years ago](#c36)  [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)   56.84 KB, patch | bzbarsky : [review+](#a5345441_20209 "16 years ago")  bzbarsky : [superreview+](#a5345441_20209 "16 years ago") | [Details](/attachment.cgi?id=346134&action=edit) | [Diff](/attachment.cgi?id=346134&action=diff) | [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=346134) |
| [Additional patch to fix shutdown nsHostResolver leak](/attachment.cgi?id=346274)  [16 years ago](#c38)  [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209)   1.08 KB, patch |  | [Details](/attachment.cgi?id=346274&action=edit) | [Diff](/attachment.cgi?id=346274&action=diff) | [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=346274) |
| [version 9 of patch](/attachment.cgi?id=346958)  [16 years ago](#c59)  [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)   43.32 KB, patch | bzbarsky : [review+](#c60 "16 years ago") | [Details](/attachment.cgi?id=346958&action=edit) | [Diff](/attachment.cgi?id=346958&action=diff) | [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=346958) |
| [version 10 of patch](/attachment.cgi?id=346976)  [16 years ago](#c61)  [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)   43.44 KB, patch | beltzner : [approval1.9.1b2+](#c64 "16 years ago") | [Details](/attachment.cgi?id=346976&action=edit) | [Diff](/attachment.cgi?id=346976&action=diff) | [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=346976) |

Show Obsolete

Bottom ↓
Tags ▾

* Reset

Timeline ▾

* Reset
* Collapse All
* Expand All
* Comments Only

|  | [Asa Dotzler [:asa]](/user_profile?user_id=5003)  Reporter |  |
| --- | --- | --- |
| [Description](/show_bug.cgi?id=453403#c0)• 16 years ago |
|  | |

Not sure what it actually does but Google's Chrome beta has a "enable DNS pre-fetching" preferences and if it's what I think it is, we should do something like that.
I figure we could either pre-fetch DNS for all links, visible links (in the viewport,) or links that get a mouse hover for some millisecond count.

|  | [Stuart Parmenter](/user_profile?user_id=5756) |  |
| --- | --- | --- |
| [Comment 1](/show_bug.cgi?id=453403#c1)• 16 years ago |
|  | |

blake/pat: is this something we could do as part of the speculative loading and any idea what the effect here would be if we were to lazily lookup dns for all the links on a page?

|  | [Mike Shaver (:shaver emeritus)](/user_profile?user_id=422) |  |
| --- | --- | --- |
| [Comment 2](/show_bug.cgi?id=453403#c2)• 16 years ago |
|  | |

I don't think you want to do it lazily; we already do DNS lookups as lazily as we can, and you want to do them more eagerly here.
Might be some privacy concerns, so we should have an about:config to turn it off, but just kicking off a DNS poke for every link as we construct the page might be sufficient.

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 3](/show_bug.cgi?id=453403#c3)• 16 years ago |
|  | |

I think this is probably a fabulous idea, I wish I had suggested it - especially for mobile where the RTT of the lookup is so high.
prefetching things has a mixed track record - but this is a perfect candidate: low bandwidth, low cpu, low state.. and in high latency envs a significant payback.
personally, I wouldn't overlap this with the speculative loader bug. If it is overlapped it would be a significant expansion of that scope which right now only deals with resources we are pretty sure we are loading (they are speculative in the sense that js or something similar may undo that decision), whereas I would think in this case we would want to do the async DNS resolution of every link we see.
definitely worth prototyping and measuring the results.

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a35555_32546)• 16 years ago |

Blocks: [437953](/show_bug.cgi?id=437953 "VERIFIED FIXED - Better network performance")

|  | [Jesse Ruderman](/user_profile?user_id=11608) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a62001_11608)• 16 years ago |

Severity: normal → enhancementKeywords: [perf](/buglist.cgi?keywords=perf&resolution=---)

|  | [benc](/user_profile?user_id=16246) |  |
| --- | --- | --- |
| [Comment 4](/show_bug.cgi?id=453403#c4)• 16 years ago |
|  | |

This needs to be reviewed from a network security standpoint before it is implemented. There are a variety of concerns when you load and keep DNS data. In the past, the cache implementation was very short, the goal was to prevent the page loads from being excessively "bursty". We also went through misguided phases where people loaded DNS info forever. There are trade offs both ways.
The underlying problem is we don't have a lot of ways of supporting DNS TTL when we cache. This is due to the fact we don't really USE dns, we typically call libraries that implement resolvers, and for reasons I don't understand, those libraries don't support exposing TTLs to applications, even in this modern day and age.
The other factor to keep in mind is that many modern OS's actually implement DNS caching as well, (which might be part of the argument for not augmenting the libraries w/ TTL support). In fact, I don't know if anyone has really done a sit down w/ a logging DNS server and packet tracer to see if the existing DNS caching scheme helps much on the current tier 1 platforms.
If you are talking about a "necko should work great everywhere" approach, then you really gotta start looking at the event model and counting packets on real systems.

|  | [Vladimir Vukicevic [:vlad] [:vladv] (needinfo me, slow to respond)](/user_profile?user_id=24534) |  |
| --- | --- | --- |
| [Comment 5](/show_bug.cgi?id=453403#c5)• 16 years ago |
|  | |

I would guess the plan for this was to just use the normal OS DNS cache -- that is, just make a normal DNS lookup request, not implement everything ourselves. Given that, there should be no security concerns over any that might be present due to whatever way the OS does dns lookups and caching anyway.

|  | [Mark Finkle (:mfinkle) (use needinfo?)](/user_profile?user_id=252194) |  |
| --- | --- | --- |
| [Comment 6](/show_bug.cgi?id=453403#c6)• 16 years ago |
|  | |

related to ideas in [bug 220942](/show_bug.cgi?id=220942 "RESOLVED DUPLICATE - DNS: pre-resolving hostnames found on a page")?

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 7](/show_bug.cgi?id=453403#c7)• 16 years ago |
|  | |

re: the OS cache comments in [comment 5](/show_bug.cgi?id=453403#c5 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox") and 6. the gnu libc resolver code does not contain a cache. Each call to getaddrinfo() results in a network round trip. Some folks run "ncsd" locally to accomplish this, but it does not seem standard.
from experiments - OS X does seem to have a operating system cache. I cannot say regarding windows.
For mobile, where glibc is a common resolver and the network round trip time is exorbitant (think 750 - 1000ms) some kind of cache to resolve the "bursts of duplicates", like we currently have, is critical.
I did a spot check using a large page: <http://planet.mozilla.org/> - when I did the test that page needed to resolve 134 hostnames in order to render. Only 23 of them were unique, so the cache saved 111 network lookups.
The current default timeout is 1 minute. In order to gain the most benefit of this (migrating between adjacent pages) I might argue for upping it to 3 or so, but nothing bigger than that in order to not violate any high-availability expectations service providers might have. Even within that constraint I expect this strategy can be quite effective.
We might conditionally compile the cache off on OS's known to have their own caches, but the heart of the pre-fetching would be unchanged - it is just a matter of who is managing the cache that is being speculatively loaded.

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 8](/show_bug.cgi?id=453403#c8)• 16 years ago |
|  | |

I will attach, shortly, a proof of concept patch for DNS prefetching. Read on to the end of this comment and you will see it demonstrates not only the expected benefit, but an unexpected one too.
The patch implements speculative resolution of anchor href's and img src's at the time they are bound to the DOM.
The DNS service is expanded from one class of service into three. The three are high, medium, and low. medium and low are used for pre-fetching and can be disabled via a preference ("network.dns.disablePrefetch"). All previous DNS uses are mapped to the high class of service, images are looked up with medium (see below) and hrefs are looked up with low. Servicing is done with strict priortiy. A request which is originally queued in a low class of service may be upgraded if a new query comes along for it at a higher class before it has actually been de-queued.
The DNS service has always allowed up to 8 threads to be used. That is unchanged. If the pool grows up to 6 or more threads, those threads are used exclusively for high priority items (i.e. non prefetches) - ensuring that high priority requests will never be blocked behind just speculative lookups.
Previously, if the DNS service expanded beyond one thread it very aggressively pruned itself back down at the first opportunity. With the increased load of prefetching that pattern results in excessive creation and destruction of threads. Not only is there OS overhead in doing so, but when using the thread for DNS resolution for the first time libc must initialize the resolver (res\_init), which involves opening and parsing files such as /etc/resolv.conf and /etc/hosts which is certainly something that we don't want to do over and over. The patch softens this behavior some by applying the same soft-timeout logic to all of the initialized threads (which are still created in a dynamically growing pool) instead of just the first one.
Resolving hostnames in img urls just before loading them (literally the line before LoadImage()) sounds like a waste. However it turns out to have a significant benefit as the actual load may take a while to be executed due to limits on the number of parallel HTTP connections.
Running the DNS lookup in parallel with the other loads blocking the image load makes a lot of sense - it is a low bandwidth but potentially high latency operation that nicely overlaps. When the image's turn does come up in the HTTP queue it benefits from a warm DNS cache when starting the transfer.
This has the neat effect of using DNS prefetching to improve page load times on the first page view, not just the subsequent pages in a link-chain.
As I mentioned in [comment 7](/show_bug.cgi?id=453403#c7 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox"), I ran a set of tests using planet.mozilla.org. (I also did these tests with cnn.com - the results where similar but less dramatic as cnn is a smaller page). I did the test both in a broadband environment, and over a simulated wireless edge network. (54/160 kbit, 770ms latency)
23 unique DNS lookups are needed to render the planet page (as of the time I did the tests anyhow). With the prefetch patches applied 16 of the 23 lookups were improved on the edge tests and 22 of the 23 on the broadband tests. By improved I mean when the HTTP transaction requested the lookup the name was either already in the cache or the request for it had already gone out on the network. Requests that were just sitting in the queue don't count as improved.
This does translate into improved page load time for a page with lots of images in a high latency environment. Loading the initial planet page on the mobile network improved over 4% with just this change, even while absorbing the overhead of looking up dozens of extra other hostnames in order to warm the cache for the next click! This is a nice unexpected bonus and the overhead is really not that onerous.
On broadband the savings are less impressive because the lookups cost so much less - I saved about 15ms on the page load (.1%). The savings should actually be a bit better than that on broadband because the cache of my recursive resolver was full for this test and I did not emulate a lag to reach it on the broadband test as I did for the edge test. Treating it as a LAN (<1ms of latency) instead of as broadband (maybe 70ms of latency) under estimates the benefit of the patch in that scenario. Whether or not the recursive resolver is warm in reality depends on whom it is being shared with and how popular the site is - it will vary widely.
The CNN tests showed improvement too - but less so. It had 35 names, 16 of them unique. Prefetching improved 7 of the 16 on broadband and 5 of the 16 on edge. The CNN tests don't muck up the HTTP queues quite as much, so the opportunity for getting ahead of the image load isn't as strong. The page load times improved marginally as well.
Of course the main goal was in eliminating some latency when going from page A to page B, where B is in a different hostname than A. My edge tests showed the page load time of page B improving by 800ms, which is what we expect.

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 9](/show_bug.cgi?id=453403#c9)• 16 years ago |
|  | |

Attached patch

[dns prefetch patch mentioned in comment 8](attachment.cgi?id=338419&action=diff) (obsolete)
— [Details](attachment.cgi?id=338419&action=edit)
— [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=338419)

|  | [Jo Hermans](/user_profile?user_id=29552) |  |
| --- | --- | --- |
| [Comment 10](/show_bug.cgi?id=453403#c10)• 16 years ago |
|  | |

You can see the windows cache with this command :
ipconfig /displaydns
and flush it with
ipconfig /flushdns
<<http://planet.mozilla.org/>> uses 18 elements in a normal Firefox 3 without the patch
See also [bug 208312](/show_bug.cgi?id=208312 "RESOLVED FIXED - DNS: negative (NXDOMAIN) cache") : DNS: negative (NXDOMAIN) cache

|  | [Stuart Parmenter](/user_profile?user_id=5756) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a1167461_5756)• 16 years ago |

Flags: wanted1.9.1+

|  | [John Mellor (Jomel)](/user_profile?user_id=163841) |  |
| --- | --- | --- |
| [Comment 11](/show_bug.cgi?id=453403#c11)• 16 years ago |
|  | |

Google blogged about this FYI: <http://blog.chromium.org/2008/09/dns-prefetching-or-pre-resolving.html>

|  | [Jo Hermans](/user_profile?user_id=29552) |  |
| --- | --- | --- |
| [Comment 12](/show_bug.cgi?id=453403#c12)• 16 years ago |
|  | |

more documentation : <http://dev.chromium.org/developers/design-documents/dns-prefetching>

|  | [Ryan VanderMeulen [:RyanVM]](/user_profile?user_id=75935) |  |
| --- | --- | --- |
| [Comment 13](/show_bug.cgi?id=453403#c13)• 16 years ago |
|  | |

Out of curiosity, what happens to those affected by [bug 306922](/show_bug.cgi?id=306922 "RESOLVED DUPLICATE - Firefox Locks up System on DNS lookup failure when using proxy.") when this lands? Are we going to see random UI lockups while Fx is doing background DNS lookups?

|  | [(not currently active) Ted Mielczarek](/user_profile?user_id=39022) |  |
| --- | --- | --- |
| [Comment 14](/show_bug.cgi?id=453403#c14)• 16 years ago |
|  | |

Patrick: is this patch ready for review, or are you waiting on something else?Assignee: nobody → mcmanus

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a2553730_32546)• 16 years ago |

[Attachment #338419](/attachment.cgi?id=338419&action=edit "dns prefetch patch mentioned in comment 8") -
Flags: review?(cbiesinger)

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 15](/show_bug.cgi?id=453403#c15)• 16 years ago |
|  | |

I guess it has received all the feedback it is going to get without a review flag, so I have added that now.

|  | [Stuart Parmenter](/user_profile?user_id=5756) |  |
| --- | --- | --- |
| [Comment 16](/show_bug.cgi?id=453403#c16)• 16 years ago |
|  | |

Comment on [attachment 338419](/attachment.cgi?id=338419 "dns prefetch patch mentioned in comment 8") [[details]](/attachment.cgi?id=338419&action=edit "dns prefetch patch mentioned in comment 8") [[diff]](/attachment.cgi?id=338419&action=diff "dns prefetch patch mentioned in comment 8") [[review]](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=338419)
dns prefetch patch mentioned in [comment 8](/show_bug.cgi?id=453403#c8 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox")
bz, can you review this?
[Attachment #338419](/attachment.cgi?id=338419&action=edit "dns prefetch patch mentioned in comment 8") -
Flags: review?(cbiesinger) → review?(bzbarsky)

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 17](/show_bug.cgi?id=453403#c17)• 16 years ago |
|  | |

I can try, though I'm not very familiar with this code. Then again, probably no one is, other than Darin. ccing biesi just in case, though.
Some questions off the top of my head just skimming this:
1) Why are we manually doing DNS cache stuff from image code instead of just
building that into the HTTP code and making use of existing request
priorities? I can see how we might need this for anchors, since we're not
actually starting a load there, but the image thing doesn't seem like it
would work as well as something that also covers scripts, stylesheets, etc.
To be honest, I'm not really even sure why this helps; don't we just go and
start resolving from under here anyway once we open the HTTP channel?
2) What's the performance impact from the nsHTMLAnchorElement change? That's
typically very perf-sensitive code, and pages often have a \_lot\_ of links on
them... I haven't read the guts of the prefetch code yet, so maybe this is
not a problem because we coalesce well? If there is any impact at all, it
would make more sense to do the prefetches more lazily, though I guess they
only help if you click a link within the dns cache timeout span?
3) As written, this is going to regress [bug 223861](/show_bug.cgi?id=223861 "VERIFIED FIXED - default value of network.dnsCacheExpiration should be reduced") (just from a quick look at
the CVS blame here). I'm not happy doing that without at least better data
akin to that in [bug 162871 comment 84](/show_bug.cgi?id=162871#c84 "RESOLVED FIXED - DNS: problems with new DNS cache (\"pinning\" forever)").
4) Do we want something akin to chromium's https thing here?
5) Do we want some way for sites to opt out like chromium does?

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 18](/show_bug.cgi?id=453403#c18)• 16 years ago |
|  | |

(In reply to [comment #17](/show_bug.cgi?id=453403#c17 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox"))
> I can try, though I'm not very familiar with this code. Then again, probably
> no one is, other than Darin. ccing biesi just in case, though.
>
> Some questions off the top of my head just skimming this:
>
> 1) Why are we manually doing DNS cache stuff from image code instead of just
> building that into the HTTP code and making use of existing request
> priorities?
the HTTP request priorities are not really relevant as far as I can tell - the image dns prefetch is of lower priority than the image dns fetch associated with the http get regardless of the http priorities. I never want the speculative cache thing to tie up the resolver system and create a wait for "I just clicked on it" events.
While it would be nice to put this in the http layer, it needs semantic understanding that this is something that should have its dns prefetched - which is why it is explicitly hung off anchor href's and imgs now. We could add a generic interface for http for things that are being fetched "very soon" like images, but you'd still need a different path for the anchors which we aren't as sure are going to be retrieved.
> I can see how we might need this for anchors, since we're not
> actually starting a load there, but the image thing doesn't seem like it
> would work as well as something that also covers scripts, stylesheets, etc.
> To be honest, I'm not really even sure why this helps; don't we just go and
> start resolving from under here anyway once we open the HTTP channel?
This is one of the cool and counter intuitive things about this patch. It works because opening the HTTP channel might be a significant amount of time away from identifying the channel hostname. This is because there are limits on the number of channels which are easily bumped into and this code essentially allows the dns resolution of images to "queue jump" for only the DNS portion of the transaction.
Normally queue jumping is evil behavior, but in this case it really works out well. The DNS transaction is, compared to the HTTP transactions, extremely low bandwidth and dominated by latency. Because it is low bandwdith (1 packet each way) it really does not meaningfully interfere with existing transfers, and its high latency property allows it to essentially overlap for free with the HTTP transfer.. when the image HTTP request does go to open its channel it sees a cache hit.
This manifests itself most strongly in mobile where latencies are very high and the http channel pool is more likely to backup for a long time due to bandwidth constraints.
I did make some measurement of this phenomenon that I mention in [comment 8](/show_bug.cgi?id=453403#c8 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox"). One of the tests needed to do 23 unique DNS lookups for images and with this change 16 of them were either already completed or already under way when the HTTP channel code asked for the name leading to a significant reduction in wait time.
>
> 2) What's the performance impact from the nsHTMLAnchorElement change? That's
> typically very perf-sensitive code, and pages often have a \_lot\_ of links on
> them... I haven't read the guts of the prefetch code yet, so maybe this is
> not a problem because we coalesce well? If there is any impact at all, it
> would make more sense to do the prefetches more lazily, though I guess they
> only help if you click a link within the dns cache timeout span?
>
As I noted, I did a bunch of measurements - and the faster the network the less of a beneift (to the point of their being no perceived benefit) - but I didn't note anything getting slower.
But there are a million points of view on what to measure. I'm happy to look into any particular scenario you are suspicious about.
The code is completely fire and forget wrt nsHTMLAnchorElement - it just puts an entry in the queue and moves on. It never even gets called back - the payoff is in the form of a cache hit later. So I do not suspect this will be a big deal for it.
> 3) As written, this is going to regress [bug 223861](/show_bug.cgi?id=223861 "VERIFIED FIXED - default value of network.dnsCacheExpiration should be reduced") (just from a quick look at
> the CVS blame here). I'm not happy doing that without at least better data
> akin to that in [bug 162871 comment 84](/show_bug.cgi?id=162871#c84 "RESOLVED FIXED - DNS: problems with new DNS cache (\"pinning\" forever)").
>
223861 lowers the default cache time from 300 to 60. This patch raises it to 180.
The spectrum is a tradeoff of course. I inched the limit up because the likelyhood of a payoff also increased - the cache is now a richer object and to make use of it on inter-page clicks some "think time" needs to be accounted for.
It can return to 60 at the unknown cost of lower cache hit rates. I first thought a median page-time-spent metric would be interesting here but I think any median or average would really obscure the large number "click.. click.. click" sequences that typically lead up to a "lets read this in full" kind of page.
As for site ttls, my experience is that the Akamai default of 5 minutes is becoming pretty common for folks doing dynamic dns. Content providers have come to understand that DNS latency is part of their performance and some minimal caching can be their friend.. Services like keynote have helped drive this home.. this is borne out some by rechecking the data listed in [bug 162871](/show_bug.cgi?id=162871 "RESOLVED FIXED - DNS: problems with new DNS cache (\"pinning\" forever)") and comparing it to today - everything has stayed the same or gotten more generous.
old today
amazon 60 60
cnn 215 3600
imbd 60 60
google 118 300
Roll into this that the firefox cache has always had the potential to be over the ttl even with ttls of at least 60. At 60 (the minimum in the data set), it is quite possible for firefox to pick up a 59 second old entry from its local caching resolver and then hold onto it for another 60 seconds - doubling the nameserver allowed validity period. That's life, and life would be a heck of a lot better if getaddrinfo() gave some TTL and age information.
> 4) Do we want something akin to chromium's https thing here?
> 5) Do we want some way for sites to opt out like chromium does?
Yes, I have come to believe it would be good to be pretty compatible with chromium where those ideas make sense.
So I'll make the following changes:
\* lookups derived from https fetches will be tied to a second configuration property (anded with the existing one) that will default to false
\* honor x-dns-prefetch-control in both the response headers and meta to opt out of a particular page
\* implement link rel="dns-prefetch" though I am dubious of its value

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 19](/show_bug.cgi?id=453403#c19)• 16 years ago |
|  | |

OK, so would it make sense to start prefetch at AsyncOpen() time (from inside necko) as opposed to from the image loader? I'm still not sure why it's better for images to jump the queue but for scripts not to do so (esp. given that the latter have a lot more impact on pageload). And it's pretty common to have ad scripts on web pages that come from all sorts of servers, as I recall.
> I'm happy to look into any particular scenario you are suspicious about.
Typical broadband (cable/dsl) network, page that's just a list of 3-4 hundred links, measuring total load time. This is actually a good approximation of some pages out there.
I wouldn't be too surprised if there is no perf impact, given your description.
> this is borne out some by rechecking the data listed in [bug 162871](/show_bug.cgi?id=162871 "RESOLVED FIXED - DNS: problems with new DNS cache (\"pinning\" forever)")
That's exactly the data I was looking for. I'm probably ok with the 180 thing given that, though it would be good to get darin to comment. Want to just bounce him an e-mail?
I don't think we should worry about rel="dns-prefetch" for now. Unlike the opt-out changes, this one wouldn't break sites if not done, just enhance the ones that make special changes even more if it is done. We can land without it and do it as a followup if we decide we want to (and I'm not entirely convinced we do, just as you are not).

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 20](/show_bug.cgi?id=453403#c20)• 16 years ago |
|  | |

For what it's worth we had an existing bug on this: [bug 220942](/show_bug.cgi?id=220942 "RESOLVED DUPLICATE - DNS: pre-resolving hostnames found on a page"). Might be worth reading through the comments there too.

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 22](/show_bug.cgi?id=453403#c22)• 16 years ago |
|  | |

An interesting bit in the chromium dns prefetch design document, they give
meta http-equiv="x-dns-prefetch-control" value="on"
as an example of a meta element.
I presume that the value attribute should really be a content attribute - that is how it is normally done with http-equiv, right? So I am presuming its just a thinko in the chromium doc..

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 23](/show_bug.cgi?id=453403#c23)• 16 years ago |
|  | |

Attached patch

[version 3 of patch](attachment.cgi?id=342476&action=diff) (obsolete)
— [Details](attachment.cgi?id=342476&action=edit)
— [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=342476)

A new revision of the patch, which incorporates the above feedback.
The changes:
\* lookups are no longer triggered from imglib for img elements. Instead they are triggered in http::AsyncOpen() which should bring the "early lookup" benefits to js, css, etc as well
\* prefetching is not done by default from an https based document, as per chromium. can be overriden with new pref
\* implement x-dns-prefetch-control, both "on" and "off" in both response header and meta contexts..
\* implement link rel="dns-prefetch" for explicit lookups
[Attachment #338419](/attachment.cgi?id=338419&action=edit "dns prefetch patch mentioned in comment 8") -
Attachment is obsolete: true
[Attachment #342476](/attachment.cgi?id=342476&action=edit "version 3 of patch") -
Flags: review?(bzbarsky)
[Attachment #338419](/attachment.cgi?id=338419&action=edit "dns prefetch patch mentioned in comment 8") -
Flags: review?(bzbarsky)

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 24](/show_bug.cgi?id=453403#c24)• 16 years ago |
|  | |

Attached patch

[version 4 of patch](attachment.cgi?id=343153&action=diff) (obsolete)
— [Details](attachment.cgi?id=343153&action=edit)
— [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=343153)

Two changes from rev 3
\* a bug with the idl part of the patch
\* v3 contained code for a problem I found with normalizing the flags used in the DNS cache.. I broke out this code and attached that patch to [bug 459724](/show_bug.cgi?id=459724 "RESOLVED FIXED - DNS: page reload should set bypass cache flag") (which also uses DNS flags and needs this code)
This patch now depends on the "Fix normalization of flags in DNS cache" attachment in [bug 459724](/show_bug.cgi?id=459724 "RESOLVED FIXED - DNS: page reload should set bypass cache flag") in order to work.
[Attachment #342476](/attachment.cgi?id=342476&action=edit "version 3 of patch") -
Attachment is obsolete: true
[Attachment #343153](/attachment.cgi?id=343153&action=edit "version 4 of patch") -
Flags: review?(bzbarsky)
[Attachment #342476](/attachment.cgi?id=342476&action=edit "version 3 of patch") -
Flags: review?(bzbarsky)

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 25](/show_bug.cgi?id=453403#c25)• 16 years ago |
|  | |

Attached patch

[version 5 of patch](attachment.cgi?id=344475&action=diff) (obsolete)
— [Details](attachment.cgi?id=344475&action=edit)
— [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=344475)

simply removes an entanglement with 459724 that doesnt belong in this patch
[Attachment #343153](/attachment.cgi?id=343153&action=edit "version 4 of patch") -
Attachment is obsolete: true
[Attachment #344475](/attachment.cgi?id=344475&action=edit "version 5 of patch") -
Flags: review?(bzbarsky)
[Attachment #343153](/attachment.cgi?id=343153&action=edit "version 4 of patch") -
Flags: review?(bzbarsky)

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 26](/show_bug.cgi?id=453403#c26)• 16 years ago |
|  | |

Comment on [attachment 344475](/attachment.cgi?id=344475 "version 5 of patch") [[details]](/attachment.cgi?id=344475&action=edit "version 5 of patch") [[diff]](/attachment.cgi?id=344475&action=diff "version 5 of patch") [[review]](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=344475)
version 5 of patch
>+++ b/content/base/src/nsContentSink.cpp
>+nsContentSink::PrefetchDNS(const nsAString &aHref)
>+ if (StringBeginsWith(aHref, NS\_LITERAL\_STRING("//"))) {
>+ hostname = aHref;
>+ hostname.Cut (0,2);
hostname = Substring(aHref, 2)
>+ nsHTMLDNSPrefetch \*prefetch = new nsHTMLDNSPrefetch (hostname, mDocument);
This part should imo look more like this:
nsRefPtr<nsHTMLDNSPrefetch> prefetch = new nsHTMLDNSPrefetch(...);
if (prefetch) {
prefetch->PrefetchLow();
}
(no manual delete on reference counted object). Also, no space before the '(' in the constructor call.
>+++ b/content/base/src/nsContentSink.h
>+ void PrefetchDNS(const nsAString &aHref);
This should probably document that aHref might not actually be a URI but might rather be a "//hostname" kind of thing.
>+++ b/content/html/content/src/nsHTMLAnchorElement.cpp
>+nsHTMLAnchorElement::PrefetchDNS()
>+{
>+ nsAutoString hostname;
>+ nsresult rv;
>+
>+ rv = GetHostname (hostname);
>+ if (NS\_FAILED(rv) || hostname.IsEmpty())
>+ return;
>+
>+ nsHTMLDNSPrefetch \*prefetch = new nsHTMLDNSPrefetch (hostname, GetOwnerDoc());
That's a pretty suboptimal way of doing things. If you trace through this code, it creates an nsIURI for the href, gets its spec, creates another nsIURI from the spec, and then gets its hostname.
It's probably better to call GetHrefURI() here and then use the nsIURI version of prefetch.
And the same comments as in the sink in terms of the actual construction/destruction pattern. Let refcounting actually work for you. ;)
>@@ -191,30 +212,32 @@ nsHTMLAnchorElement::GetDraggable(PRBool
>+
> nsresult
> nsHTMLAnchorElement::BindToTree(nsIDocument\* aDocument, nsIContent\* aParent,
Nix that whitespace change?
>+++ b/content/html/content/src/nsHTMLDNSPrefetch.cpp
The licence block seems to be missing the "The Original Code is" paragraph and more importantly the paragraph that lists initial developer (Mozilla Corporation in this case) and copyright date.
>+/\* -\*- Mode: C++; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -\*- \*/
>+/\* vim:set tw=80 expandtab softtabstop=2 ts=2 sw=2: \*/
Those modelines are inconsitent. You probably want s/4/2/ in the emacs modeline (and reindent accordingly), since content code typically does 2-space indent.
>+nsHTMLDNSPrefetch::nsHTMLDNSPrefetch(nsAString &hostname, nsIDocument \*aDocument)
>+ mAllowed = IsAllowed(aDocument);
>+ mHostnamePtr = new NS\_ConvertUTF16toUTF8 (hostname);
Why not just have mHostname be an nsCString (not a pointer) and use CopyUTF16toUTF8 here?
>+nsHTMLDNSPrefetch::nsHTMLDNSPrefetch(nsIURI \*aURI, nsIDocument \*aDocument)
>+ mHostnamePtr = new nsCString();
>+ aURI->GetHost(\*mHostnamePtr);
And then here you could just GetAsciiHost(mHostname) (or GetHost as you do, but DNS will end up having to do the converstion to ACE for IDN hostnames in that case; if we're going to use this nsIURI for anything else at least it will already have the ASCII-ified version cached)..
>+nsHTMLDNSPrefetch::IsSecureBaseContext (nsIDocument \*aDocument)
>+ if (aDocument != nsnull)
Can we just require the callers to alwys pass in a document (and assert that in the constructor)?
Also (and this applies to all the methods), nix the space before '('.
>+nsHTMLDNSPrefetch::IsAllowed (nsIDocument \*aDocument)
>+ if (IsSecureBaseContext(aDocument))
>+ {
Module style is usually to put the curly for an 'if' at the end of the if line.
>+ if (nsContentUtils::GetBoolPref("network.dns.disablePrefetchFromHTTPS", PR\_TRUE))
Do we really want to hit the pref service on every single link in an SSL page? This seems like a good use case for nsContentUtils::AddBoolPrefVarCache (which is underdocumented, I know) called from a method run at module startup with a static PRBool to store the current state. The only word of warning there is that AddBoolPrefVarCache will default to false on first call if not set, and since you want a default of true you'll need a manual GetBoolPref call there too (at module startup).
>+ rv = PR\_FALSE;
Why even keep track of rv? If it's false here, we'll return false, so just do an early return.
>+ if (rv && (aDocument != nsnull))
Again, I think we should just require a non-null document.
>+ // checks if x-dns-prefetch-control HTTP response header is set to override default
>+ // may also be set by meta tag
s/if/whether the/. And please capitalize sentence beginning and punctuate sentence ends?
>+ nsAutoString control;
>+ aDocument->GetHeaderData(nsGkAtoms::headerDNSPrefetchControl, control);
So for what it's worth, this might be a little slow... we can see how it goes. In general, the link stuff could be a Tp hazard; we should watch out for that when we land. It might be better to just add an API on nsIDocument exposing this boolean value (updated by SetHeaderData) instead of recomputing it on every single link.
>+ if (rv && control.LowerCaseEqualsLiteral ("off"))
We know rv is true here.
I hate to ask this... but what does chromium do if the value is neither "on" or "off"? Does it treat that as "on" or "off"? We should do the same (and ask them to update their docs accordingly).
One thing probably worth checking in this code is that the document has a window. I see no reason to do DNS prefetch in XMLHttpRequest result documents, for example.
>+nsHTMLDNSPrefetch::Prefetch(PRUint16 flags)
>+ nsCOMPtr<nsIDNSService> dns = do\_GetService(kDNSServiceCID, &rv);
This is another possible source of performance impact to watch out for. We might want to cache this service somewhere (nsContentUtils, say).
>+ // this reference is dropped at the end of Prefetch and ensures the object
>+ // cannot be deleted by another thread (initiated from AsyncResolve())
>+ // while this function is running
>+ NS\_ADDREF\_THIS();
>+
>+ // this reference will be dropped by OnLookupComplete()
>+ NS\_ADDREF\_THIS();
OK. So if we have the callers hold a strong ref while calling Prefetch() (as they should per XPCOM rules), can we nix both of these self-addrefs (and the selfrelease in OnLookupComplete())? Certainly the DNS service will hold a reference to us until it calls OnLookupComplete().
>+++ b/content/html/content/src/nsHTMLDNSPrefetch.h
>+/\* -\*- Mode: C++; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -\*- \*/
>+/\* vim:set tw=80 expandtab softtabstop=2 ts=2 sw=2: \*/
Again, these don't match; should use 2 throughout. And again, the license block is missing pieces.
>+#include "nsIDNSRecord.h"
Do we really need that header? Would a forward-declaration do the trick?
>+#include "nsIDNSService.h"
Same here. Seems like we only need that type in the .cpp, not here.
>+#include "nsICancelable.h"
This can probably also be a forward-declaration: see below.
>+public:
>+ NS\_DECL\_ISUPPORTS
>+ NS\_DECL\_NSIDNSLISTENER
Fix indent?
>+ // The aDocument parameter is the context requesting the prefetch - under
>+ // certain circumstances (e.g. headers, or security context) associated with
>+ // the context the prefetch will not be performed. nsnull is acceptable and
>+ // always allows prefetches
As I said, I don't think there's a good reason to allow a null document.
>+ // call one of the following methods, and the class is self destructing if they
>+ // return NS\_OK
I don't think there's a need to describe a special ownership model; this should just work like any other refcounted object.
>+ nsCOMPtr<nsICancelable> mOutstanding;
We don't use this for anything. Why bother storing it? Could just put it in a stack nsCOMPtr when we call asyncResolve, and then let it go out of scope.
>+++ b/content/html/document/src/nsHTMLContentSink.cpp
This part looks fine, but do we want to do the prefetch in XHTML too? If so, we need to adjust the XML sink...
>+++ b/netwerk/base/public/nsNetError.h
>+#define NS\_ERROR\_SERVICE\_FULL \
NS\_ERROR\_DNS\_LOOKUP\_QUEUE\_FULL seems clearer... Unless we think this error code will be used for other things, but then the comment needs fixing.
>+ NS\_ERROR\_GENERATE\_FAILURE(NS\_ERROR\_MODULE\_NETWORK, 31)
That gives it the same value as NS\_ERROR\_REDIRECT\_LOOP. I'd prefer a unique value here.
>+++ b/netwerk/base/src/nsDNSPrefetch.cpp
>+/\* -\*- Mode: C++; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -\*- \*/
>+/\* vim:set tw=80 expandtab softtabstop=2 ts=2 sw=2: \*/
Again, mismatch in the modelines and missing parts in the license.
In necko, I think 4-space indent is standard, so that's what this file should use and what the modelins should declare.
A lot of the nsHTMLDNSPrefetch comments apply here and in the header for this class as well, especially the GetAsciiHost thing, since in most cases the URI here will in fact have the ascii host cached.
Is it worth trying to reduce the code duplication by having a virtual method for whether the prefetch is allowed and having the content class subclass this one? If so, I'm ok with that as a followup patch, in the interests of getting this landed.
>+++ b/netwerk/base/src/nsDNSPrefetch.h
>+/\* -\*- Mode: C++; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -\*- \*/
>+/\* vim:set tw=80 expandtab softtabstop=2 ts=2 sw=2: \*/
Usual thing with modelines and license.
>+++ b/netwerk/dns/public/nsIDNSService.idl
>+ /\*\*
>+ \* if set, the query is given lower priority
>+ \*/
>+ const unsigned long RESOLVE\_PRIORITY\_MEDIUM = (1 << 2);
>+ const unsigned long RESOLVE\_PRIORITY\_LOW = (1 << 3);
What happens if both are set? Probably we should document that we treat it as PRIORITY\_MEDIUM in that case, if that's what we do.
>+
> };
Weird whitespace there. Take it out?
>+++ b/netwerk/dns/src/nsHostResolver.cpp
>+#define MAX\_NON\_PRIORITY 150
MAX\_NON\_PRIORITY\_REQUESTS maybe?
>+// we dont want to be spinning new threads and redoing res\_init() all the time in the new thread
"don't", and please do the whole punctuation/capitalization thing?
Maybe document where this '4' number for NumIdleThreads comes from? And what NumIdleThreads means? Shouldn't it be called something more like MAX\_IDLE\_THREADS or some such?
>+static PRUint32 LongIdleTimeout = 300; // for threads 1 -> numidlethreads
>+static PRUint32 ShortIdleTimeout = 60; // for threads numidlethreads+1 -> MAX\_RESOLVER\_THREADS
Those are in seconds, right? Document that? Or really, why not store these in interval units so we don't have to keep calling PR\_SecondsToInterval all the time?
Also, add a PR\_STATIC\_ASSERT(MAX\_RESOLVER\_THREADS > NumIdleThreads), since we seem to be assuming that?
And NumIdleThreads in those comments, right?
> nsHostResolver::nsHostResolver(PRUint32 maxCacheEntries,
>+ , mHaveIdleThread(0)
So mHaveIdleThread is clearly a counter of some sort now, right? What's it really counting? It should get renamed accordingly... Perhaps mNumIdleThreads?
>+ int i = 0, j;
|i| is only really needed to set .id on the mResolverID[n], right? That .id seems to be unused; can we just drop it? Or am I missing something?
>@@ -368,28 +391,31 @@ nsHostResolver::Shutdown()
>+ MoveCList(mHighQ, pendingQ);
>+ MoveCList(mMediumQ, pendingQ);
>+ MoveCList(mLowQ, pendingQ);
That doesn't look right, since as far as I can tell MoveCList fails if the target PRCList is not empty (and it should probably assert that its target is in fact empty, or be rewritten to allow "appending" a PRCList to the target).
>@@ -441,17 +467,17 @@ nsHostResolver::ResolveHost(const char
>-
>+
Please lose the whitespace change?
>@@ -479,26 +505,48 @@ nsHostResolver::ResolveHost(const char
>+ else if ((mPendingCount >= MAX\_NON\_PRIORITY) &&
>+ (flags & (RES\_PRIORITY\_LOW | RES\_PRIORITY\_MEDIUM)) &&
>+ (!he->rec->resolving)) {
Drop the extra parens from around the first and third parts of the '&&', please.
> if (!he->rec->resolving) {
>+
> he->rec->flags = flags;
Why add the blank line?
>+ // consider the case where we are on a pending queue of
>+ // lower priority than the request is being made at.
>+ // in that case we should upgrade queues
Punctuation + capitalization? Same in other comments in this bit here.
>+ if ((!(flags & (RES\_PRIORITY\_LOW | RES\_PRIORITY\_MEDIUM))) &&
>+ (he->rec->flags & (RES\_PRIORITY\_LOW | RES\_PRIORITY\_MEDIUM))) {
>+ // move from (low|med) to high
>+ MoveQueue(he->rec, mHighQ);
>+ } else if ((flags & RES\_PRIORITY\_MEDIUM) &&
>+ (he->rec->flags & RES\_PRIORITY\_LOW)) {
>+ // move from low to med
>+ MoveQueue(he->rec, mMediumQ);
Do we need to update he->rec->flags somewhere there to indicate that it's on a different queue now?
> nsHostResolver::IssueLookup(nsHostRecord \*rec)
>+ if ((rec->flags & (RES\_PRIORITY\_LOW | RES\_PRIORITY\_MEDIUM)) == 0)
OK, so I think we could use some static inline functions like:
static inline PRBool IsHighPriority(nsHostRecord \*rec);
static inline PRBool IsMediumPriority(nsHostRecord \*rec);
static inline PRBool IsLowPriority(nsHostRecord \*rec);
I think that would make a lot of this code much more readable. If we want, we can make the function take flags instead of rec, so in ResolveHost we can use the same functions on the incoming flags too. Or we could even have functions that take both, with the nsHostRecord ones calling the flags ones on rec->flags.
>+ else if (((!(rec->flags & (RES\_PRIORITY\_LOW | RES\_PRIORITY\_MEDIUM))) && (mThreadCount < MAX\_RESOLVER\_THREADS)) ||
>+ ((rec->flags & (RES\_PRIORITY\_LOW | RES\_PRIORITY\_MEDIUM)) && (mThreadCount < NumIdleThreads))) {
If NumIdleThreads < MAX\_RESOLVER\_THREADS (which we're asserting statically, right?) this looks equivalent to:
else if (mThreadCount < NumIdleThreads ||
(IsHighPriority(rec) && mThreadCount < MAX\_RESOLVER\_THREADS)) {
and this way of writing it seems a lot more readable.
>+ mResolverID + mThreadCount++,
This would be a lot clearer if mResolverID were named mResolverThreadInfoArr or some such....
That said, I'm not sure I follow this. Say we get three requests in rapid succession and spin up three threads to handle them (numbered 0, 1, 2). Thread 1 finishes its lookup and then waits a bit and then exits. Now mThreadCount is 2. If we then go to spin up another thread, we'll point it to slot 2 in the array.
Now if the first 2 items in the array are supposed to be any-request-goes while the third is high-priority-only, after we spin up the new thread we'll have two high-priority-only threads and only one any-request-goes. Or am I missing something?
>- 0);
>+ 256 \* 1024); // 256KB stack is plenty
Is there a reason for that change?
>+nsHostResolver::MoveQueue(nsHostRecord \*aRec, PRCList &aDestQ)
Is there a reason this is a member method? Seems like it could just be static, or certainly a static class method.
>+ NS\_ASSERTION (aRec->onQueue, "Moving Host Record Not Currently Queued");
Nix the space before '('
>+ return;
No need for that.
>+nsHostResolver::GetHostToLookup(nsHostRecord \*\*result, struct nsHostResolverID \*aID)
>+ do {
Why not |while (!mShutdown)|? We could assert that if mShutdown is false and we're here then all the queues are empty, so it should be equivalent to your code, but without the extra break in the loop....
>+++ b/netwerk/dns/src/nsHostResolver.h
>+#define MAX\_RESOLVER\_THREADS\_ANY 5
MAX\_RESOLVER\_THREADS\_ANY\_REQUESTS, perhaps?
>+#define MAX\_RESOLVER\_THREADS\_HIGH 3
MAX\_RESOLVER\_THREADS\_HIGH\_PRIORITY\_REQUESTS\_ONLY? Or too long?
>+ PRBool onQueue; /\* true if pending and on the queue (not yet given to getaddrinfo())\*/
How many nsHostRecord()s do we have in-flight at once, and how long do they live for? Would it make sense to use PRPackedBool, or should we just not worry about this?
>+ // nsHostResolverID \* is passed to the ThreadFunc
>+ struct nsHostResolverID
>+ {
>+ nsHostResolver \*self;
>+ PRUint32 id;
>+ PRBool onlyHighPriority;
>+ } mResolverID[MAX\_RESOLVER\_THREADS];
So the thing is, this isn't really an ID. This is more of a nsHostResolverThreadInfo or some such, no? Also, the |id| member seems to be unused.
>+ PRCList mHighQ;
>+ PRCList mMediumQ;
>+ PRCList mLowQ;
Fix the indent?
>+++ b/netwerk/protocol/http/src/nsHttpChannel.cpp
>+ nsDNSPrefetch \*prefetch = new nsDNSPrefetch (mURI);
Same comments as for HTML about using nsRefPtr, etc.
This looks like great stuff; let's beat the issues out and get this landed. ;)
[Attachment #344475](/attachment.cgi?id=344475&action=edit "version 5 of patch") -
Flags: review?(bzbarsky) → review-

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 27](/show_bug.cgi?id=453403#c27)• 16 years ago |
|  | |

One other thought. For anchors, it seems a bit wasteful to create the URI object and create the HTMLDNSPrefetch object just to bail out because prefetch is not allowed. So maybe a better split there is a separate IsDNSPrefetchAllowed check (either on nsIDocument or on nsContentUtils and taking an nsIDocument arg) and if it succeeds just using the necko nsDNSPrefetch?

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 28](/show_bug.cgi?id=453403#c28)• 16 years ago |
|  | |

Attached patch

[version 6 of patch](attachment.cgi?id=345527&action=diff) (obsolete)
— [Details](attachment.cgi?id=345527&action=edit)
— [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=345527)

Boris, thank you for the extensive comments in 26. I believe I had everything in there that is appropriate to do so with this update. It is made much stronger with your help.
I didn't note until now your [comment 27](/show_bug.cgi?id=453403#c27 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox"). Let me know if you think that should block this - my opinion is that these details should remain abstracted inside the prefetch class.
[Attachment #344475](/attachment.cgi?id=344475&action=edit "version 5 of patch") -
Attachment is obsolete: true
[Attachment #345527](/attachment.cgi?id=345527&action=edit "version 6 of patch") -
Flags: review?(bzbarsky)

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 29](/show_bug.cgi?id=453403#c29)• 16 years ago |
|  | |

Comment on [attachment 345527](/attachment.cgi?id=345527 "version 6 of patch") [[details]](/attachment.cgi?id=345527&action=edit "version 6 of patch") [[diff]](/attachment.cgi?id=345527&action=diff "version 6 of patch") [[review]](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=345527)
version 6 of patch
>+++ b/content/html/content/src/nsHTMLAnchorElement.cpp
>+nsHTMLAnchorElement::PrefetchDNS()
>+ nsRefPtr<nsHTMLDNSPrefetch> prefetch = new nsHTMLDNSPrefetch(hrefURI, GetOwnerDoc());
Please wrap to 80 cols?
>+++ b/content/html/content/src/nsHTMLDNSPrefetch.cpp
>+ // This would be better done with a static constructor method, but those cannot
>+ // be portably used within mozilla.
What you probably want to do is to just make initialization here a class static method and run it from nsLayoutStatics::Initialize. Sorry I wasn't more clear about that.
>+nsHTMLDNSPrefetch::IsSecureBaseContext (nsIDocument \*aDocument)
>+ if (scheme.EqualsLiteral("https"))
>+ return PR\_TRUE;
>+ return PR\_FALSE;
return scheme.EqualsLiteral("https");
>+nsHTMLDNSPrefetch::IsAllowed (nsIDocument \*aDocument)
>+ if (IsSecureBaseContext(aDocument)) {
>+ if (GetDisablePrefetchHTTPSPref())
This would be more readable with a && in my opinion.
>+static nsIDNSService \*sDNSService = nsnull;
We never release this, so we'd leak it... Probably best to just set it up in nsLayoutStatics::Initialize and release it in nsLayoutStatics::Shutdown. Then in Prefetch just null-check sDNSService. Or we could cache it in nsContentUtils with other services, like I said in the original review. Either way, but we need to make sure to release at shutdown.
>+nsHTMLDNSPrefetch::Prefetch(PRUint16 flags)
>+ nsresult rv;
>+
>+ rv = dns->AsyncResolve(mHostname, flags, this, nsnull,
>+ getter\_AddRefs(tmpOutstanding));
>+ return rv;
Just |return dns->.....|
>+class nsHTMLDNSPrefetch : public nsIDNSListener
>+ // the context the prefetch will not be performed. The nsDNSPrefetch class
>+ // does not require an nsIDocument.
I'm not sure we want that last sentence there.
>+++ b/netwerk/base/src/nsDNSPrefetch.cpp
>+static nsIDNSService \*sDNSService = nsnull;
Again, we're not releasing this. nsNetShutdown might be an ok place to do that.
>+ nsresult rv;
>+
>+ rv = dns->AsyncResolve(mHostname, flags, this, nsnull,
>+ getter\_AddRefs(tmpOutstanding));
>+ return rv;
Again, just |return dns->....|
>+++ b/netwerk/dns/src/nsHostResolver.cpp
>+// Use a persistent thread pool inorder to avoid spinning up new threads all the time.
"in order"
>+// go first to an idle thread, if that cannot be found and there are less than MAX\_RESOLVER\_THREADS
'.' after "thread", please. And s/less/fewer/
>+// currently in the pool a new threads
"thread"
>+// there are less than HighThreadThreshold currently outstanding. If a thread cannot be
s/less/fewer/
Please fix the shutdown leaks and the minor nits, and this looks great. Just keep an eye out on Tp!
[Attachment #345527](/attachment.cgi?id=345527&action=edit "version 6 of patch") -
Flags: superreview+
[Attachment #345527](/attachment.cgi?id=345527&action=edit "version 6 of patch") -
Flags: review?(bzbarsky)
[Attachment #345527](/attachment.cgi?id=345527&action=edit "version 6 of patch") -
Flags: review+

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 30](/show_bug.cgi?id=453403#c30)• 16 years ago |
|  | |

Attached patch

[version 7 of patch](attachment.cgi?id=345727&action=diff) (obsolete)
— [Details](attachment.cgi?id=345727&action=edit)
— [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=345727)

I believe this addresses everything from [comment 29](/show_bug.cgi?id=453403#c29 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox").
[Attachment #345527](/attachment.cgi?id=345527&action=edit "version 6 of patch") -
Attachment is obsolete: true

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 31](/show_bug.cgi?id=453403#c31)• 16 years ago |
|  | |

please note when checking in from [comment 24](/show_bug.cgi?id=453403#c24 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox"):
This patch now depends on the "Fix normalization of flags in DNS cache"
attachment in [bug 459724](/show_bug.cgi?id=459724 "RESOLVED FIXED - DNS: page reload should set bypass cache flag") in order to work correctly.Depends on: [459724](/show_bug.cgi?id=459724 "RESOLVED FIXED - DNS: page reload should set bypass cache flag")

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 32](/show_bug.cgi?id=453403#c32)• 16 years ago |
|  | |

Comment on [attachment 345727](/attachment.cgi?id=345727 "version 7 of patch") [[details]](/attachment.cgi?id=345727&action=edit "version 7 of patch") [[diff]](/attachment.cgi?id=345727&action=diff "version 7 of patch") [[review]](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=345727)
version 7 of patch
This is almost all good stuff, but please use a static raw pointer with manual NS\_RELEASE when cleaning up (and NS\_ADDREF if needed when setting, e.g. in the necko nsDNSPrefetch code) instead of a static nsCOMPtr...

|  | [Christian :Biesinger (don't email me, ping me on IRC)](/user_profile?user_id=15661) |  |
| --- | --- | --- |
| [Comment 33](/show_bug.cgi?id=453403#c33)• 16 years ago |
|  | |

Comment on [attachment 345727](/attachment.cgi?id=345727 "version 7 of patch") [[details]](/attachment.cgi?id=345727&action=edit "version 7 of patch") [[diff]](/attachment.cgi?id=345727&action=diff "version 7 of patch") [[review]](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=345727)
version 7 of patch
+nsDNSPrefetch::nsDNSPrefetch(nsAString &hostname)
+{
+ CopyUTF16toUTF8(hostname, mHostname);
why are you using UTF-16 hostnames in necko? In fact this constructor doesn't seem to be called at all.
@@ -3981,16 +3982,23 @@ nsHttpChannel::AsyncOpen(nsIStreamListen
+ // Start a DNS lookup very early in case the real open is queued the DNS can
+ // happen in parallel.
+ nsRefPtr<nsDNSPrefetch> prefetch = new nsDNSPrefetch(mURI);
Doesn't the queuing mean that we are currently processing another load to the same host, meaning that the host should already be cached from that? What advantage does this additional prefetch have?

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 34](/show_bug.cgi?id=453403#c34)• 16 years ago |
|  | |

(In reply to [comment #32](/show_bug.cgi?id=453403#c32 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox"))
> (From update of [attachment 345727](/attachment.cgi?id=345727 "version 7 of patch") [[details]](/attachment.cgi?id=345727&action=edit "version 7 of patch") [[diff]](/attachment.cgi?id=345727&action=diff "version 7 of patch") [[review]](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=345727))
> This is almost all good stuff, but please use a static raw pointer with manual
> NS\_RELEASE when cleaning up (and NS\_ADDREF if needed when setting, e.g. in the
> necko nsDNSPrefetch code) instead of a static nsCOMPtr...
hi - I've made this change and it will be reflected in v8 of the patch (to be posted tonight), but can you help me understand the difference/advantage? Thanks.

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 35](/show_bug.cgi?id=453403#c35)• 16 years ago |
|  | |

Christian, thanks for the comments!
(In reply to [comment #33](/show_bug.cgi?id=453403#c33 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox"))
> (From update of [attachment 345727](/attachment.cgi?id=345727 "version 7 of patch") [[details]](/attachment.cgi?id=345727&action=edit "version 7 of patch") [[diff]](/attachment.cgi?id=345727&action=diff "version 7 of patch") [[review]](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=345727))
> +nsDNSPrefetch::nsDNSPrefetch(nsAString &hostname)
> +{
this isn't used in the necko part, as you note, so I've removed it in v8.
> @@ -3981,16 +3982,23 @@ nsHttpChannel::AsyncOpen(nsIStreamListen
> + // Start a DNS lookup very early in case the real open is queued the DNS
> can
> + // happen in parallel.
> + nsRefPtr<nsDNSPrefetch> prefetch = new nsDNSPrefetch(mURI);
>
> Doesn't the queuing mean that we are currently processing another load to the
> same host, meaning that the host should already be cached from that?
not necessarily - there are configurable quotas on the total number of streams that can be created at one time, seperate from the per host quota. (usually 6 in total I think). In my testing it isn't unusual to hit the limit on sites that embed a lot of content by reference. (blogs, aggregators, youtube, photos, counters, analytics, jscript libraries, etc.) Realistically all it takes is references to 3 different hosts.

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 36](/show_bug.cgi?id=453403#c36)• 16 years ago |
|  | |

Attached patch

[version 8 of patch](attachment.cgi?id=346134&action=diff) (obsolete)
— [Details](attachment.cgi?id=346134&action=edit)
— [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=346134)

[Attachment #345727](/attachment.cgi?id=345727&action=edit "version 7 of patch") -
Attachment is obsolete: true
[Attachment #346134](/attachment.cgi?id=346134&action=edit "version 8 of patch") -
Flags: review?(bzbarsky)

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 37](/show_bug.cgi?id=453403#c37)• 16 years ago |
|  | |

> but can you help me understand the difference/advantage?
Just a matter of static nsCOMPtrs confusing leak-detection tools, mostly (and the whole portability guideline thing about static objects with constructors/destructors, which nsCOMPtr has).

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a5345441_20209)• 16 years ago |

[Attachment #346134](/attachment.cgi?id=346134&action=edit "version 8 of patch") -
Flags: superreview+
[Attachment #346134](/attachment.cgi?id=346134&action=edit "version 8 of patch") -
Flags: review?(bzbarsky)
[Attachment #346134](/attachment.cgi?id=346134&action=edit "version 8 of patch") -
Flags: review+

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a5345489_20209)• 16 years ago |

Keywords: [checkin-needed](/buglist.cgi?keywords=checkin-needed&resolution=---)

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 38](/show_bug.cgi?id=453403#c38)• 16 years ago |
|  | |

Attached patch

[Additional patch to fix shutdown nsHostResolver leak](attachment.cgi?id=346274&action=diff)
— [Details](attachment.cgi?id=346274&action=edit)
— [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=346274)

Leak tests on tinderbox caught this. We need to wake up all the worker threads on shutdown so they can exit, and we were only waking up one.

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 39](/show_bug.cgi?id=453403#c39)• 16 years ago |
|  | |

Pushed changeset e8fd3f4c52b6 for the main patch and changeset 19b3caf108d1 for the leak fix.Status: NEW → RESOLVEDClosed: 16 years agoResolution: --- → FIXED

|  | [Bill Gianopoulos [:WG9s]](/user_profile?user_id=104622) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a5478785_104622)• 16 years ago |

Depends on: [463215](/show_bug.cgi?id=463215 "RESOLVED WORKSFORME - Browser intermittently stalls/hangs for long periods resolving hostnames - Looking up <hostname> in status bar")

|  | [(not currently active) Ted Mielczarek](/user_profile?user_id=39022) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a5479534_39022)• 16 years ago |

Keywords: [checkin-needed](/buglist.cgi?keywords=checkin-needed&resolution=---)

|  | [Justin Dolske [:Dolske]](/user_profile?user_id=27780) |  |
| --- | --- | --- |
| [Comment 40](/show_bug.cgi?id=453403#c40)• 16 years ago |
|  | |

Backed out due to leaks (see [bug 463263](/show_bug.cgi?id=463263 "RESOLVED FIXED - leaking nsHostResolver a lot on multiple platforms from unrelated checkins")).Status: RESOLVED → REOPENEDResolution: FIXED → ---

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 41](/show_bug.cgi?id=453403#c41)• 16 years ago |
|  | |

So from the leak logs it looks like we were managing to leak a nsDNSAsyncRequest. Everything else that was leaked would be held by one of those.

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 42](/show_bug.cgi?id=453403#c42)• 16 years ago |
|  | |

Actually, scratch that. nsDNSAsyncRequest doesn't hold an nsHostRecord, but losing nsHostRecords could certainly cause us to leak their callbacks, which are nsDNSAsyncRequests.

|  | [Bill Gianopoulos [:WG9s]](/user_profile?user_id=104622) |  |
| --- | --- | --- |
| [Comment 43](/show_bug.cgi?id=453403#c43)• 16 years ago |
|  | |

I have verified the checkins from this bug as causing the regression noted in [bug 463215](/show_bug.cgi?id=463215 "RESOLVED WORKSFORME - Browser intermittently stalls/hangs for long periods resolving hostnames - Looking up <hostname> in status bar").

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a5520962_20209)• 16 years ago |

Depends on: [463263](/show_bug.cgi?id=463263 "RESOLVED FIXED - leaking nsHostResolver a lot on multiple platforms from unrelated checkins")

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 44](/show_bug.cgi?id=453403#c44)• 16 years ago |
|  | |

I agree we must be losing nsHostRecords somehow, but sadly I get a clean leak report when I run the same test tinderbox does. Of course I am still looking at it and 463215.

|  | [Bill Gianopoulos [:WG9s]](/user_profile?user_id=104622) |  |
| --- | --- | --- |
| [Comment 45](/show_bug.cgi?id=453403#c45)• 16 years ago |
|  | |

(In reply to [comment #44](/show_bug.cgi?id=453403#c44 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox"))
> I agree we must be losing nsHostRecords somehow, but sadly I get a clean leak
> report when I run the same test tinderbox does. Of course I am still looking at
> it and 463215.
When looking at 463215, please note that we now have a report of the same type of issue with No proxy selected rather than auto-detect. Evidently I just did not run long enough yesterday with no proxy set to see the issue, probably because I changed back to auto-detect in order to isolate the regression cause.

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 46](/show_bug.cgi?id=453403#c46)• 16 years ago |
|  | |

Tinderbox didn't hit the leak reliably either; just "often". :( There's almost certainly some sort of timing issue involved...

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 47](/show_bug.cgi?id=453403#c47)• 16 years ago |
|  | |

I have been able to make the leak happen a couple of times now. My data set is too small to be sure, but it appears to be leaking outstanding requests during shutdown.. (or maybe ones that are being added during shutdown..)

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 48](/show_bug.cgi?id=453403#c48)• 16 years ago |
|  | |

We shouldn't be adding requests during shutdown, I would think: we have an mShutdown check in nsHostResolver::ResolveHost.

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 49](/show_bug.cgi?id=453403#c49)• 16 years ago |
|  | |

I think this whole leak is innocuous.
resolver::shutdown() is called which wakes up anybody in the thread pool after setting the shutdown flag and then, after cleaning up a few other things, exits. Shutdown() is synchronous, but the other thread exits are not, and they hold references to the resolver.
That leaves a race between the firefox shutdown/leak code and the pool threads getting scheduled and running to completion. The pool thread could take a fair chunk of time if it is blocked on getaddrinfo() which is why I can reproduce this easily if I add a network delay getting to my name server.
spinning on while(mthreadcount) at the end of shutdown reliably fixes the leak. We probably want to join the threads for a real fix.
interestingly, this is not a result of my patch - but the asynchronous nature of the prefetch code brings it to light in what is otherwise a synchronous test.
My only hesitation on doing joins or the spin is that the time it takes to shutdown is going to be bound by the operating system timing out PR\_GetAddrInfoByName(). The fx isn't really interruptible or configurable, and some OS's might give it a very long time indeed.
I suppose we could spin with an upper bound of a couple seconds..
none of this has anything to do with 463215.

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 50](/show_bug.cgi?id=453403#c50)• 16 years ago |
|  | |

Hmm. Benjamin, is there anything specific we should be doing with the worker threads to make shutdown leak logging happy? Given [comment 49](/show_bug.cgi?id=453403#c49 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox"), the "spin-or-join with timeout" approach sounds good to me, but if there's something better I'd love to know.

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 51](/show_bug.cgi?id=453403#c51)• 16 years ago |
|  | |

fyi: this is the patch I would propose (I'll roll them all together into one attachment) if Benjamin doesn't have a silver bullet.
diff --git a/netwerk/dns/src/nsHostResolver.cpp b/netwerk/dns/src/nsHostResolver.cpp
--- a/netwerk/dns/src/nsHostResolver.cpp
+++ b/netwerk/dns/src/nsHostResolver.cpp
@@ -444,16 +444,25 @@ nsHostResolver::Shutdown()
PRCList \*node = evictionQ.next;
while (node != &evictionQ) {
nsHostRecord \*rec = static\_cast<nsHostRecord \*>(node);
node = node->next;
NS\_RELEASE(rec);
}
}
+ // Logically join the outstanding worker threads with a timeout.
+ // Use this approach instead of PR\_JoinThread() because that does
+ // not allow a timeout which may be necessary for a responsive
+ // shutdown if the thread is blocked on a very slow DNS resolution.
+
+ PRIntervalTime delay = PR\_MillisecondsToInterval(25);
+ PRIntervalTime stopTime = PR\_IntervalNow() + PR\_SecondsToInterval(2);
+ while (mThreadCount && PR\_IntervalNow() < stopTime)
+ PR\_Sleep(delay);
}
static inline PRBool
IsHighPriority(PRUint16 flags)
{
return !(flags & (nsHostResolver::RES\_PRIORITY\_LOW | nsHostResolver::RES\_PRIORITY\_MEDIUM));
}

|  | [Benjamin Smedberg](/user_profile?user_id=7044) |  |
| --- | --- | --- |
| [Comment 52](/show_bug.cgi?id=453403#c52)• 16 years ago |
|  | |

The normal/correct behavior is that all XPCOM threads must be joined before or during the xpcom-shutdown-threads global observer notification.
At some point we specifically decided to absolve the DNS lookup thread(s) from this responsibility because PR\_GetAddrInfoByName was uninterruptably blocking. We cannot delay shutdown for any significant amount of time. This meant, IIRC, that the DNS threads couldn't participate in XPCOM.

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 53](/show_bug.cgi?id=453403#c53)• 16 years ago |
|  | |

Unfortunately, the DNS threads effectively hold owning references to nsHostRecord objects (or more precisely the objects are not released until the lookup is done). That's the problem we're having here...

|  | [Benjamin Smedberg](/user_profile?user_id=7044) |  |
| --- | --- | --- |
| [Comment 54](/show_bug.cgi?id=453403#c54)• 16 years ago |
|  | |

We could perhaps use the magic shutdown flag differently to abandon, so that we can simply abandon the worker thread by having the main thread do cleanup for the abandoned worker thread. I can try to do this, if you file a separate bug. The big problem is that you have to avoid referencing mLock after the thread has been abandoned, which sounds like it would introduce a race condition. Anyone know if it's ok to intentionally leak a PRLock?

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 55](/show_bug.cgi?id=453403#c55)• 16 years ago |
|  | |

let me know if I'm reading the situation wrong.
What I see is that the DNS code has always violated, with absolution, the edict to join those threads at shutdown. Furthermore, spinning/blocking there just adds delay and isn't really desirable (I agree). However, with the prefetch code the test harness now sees an always existing race between shutdown and the leak detection code. There isn't any race that produces an actual leak - just the detection of it. Nonetheless the leak detection code is important.
I'm going to post a patch that splits the baby. The patch will spin-with-timeout in the shutdown code in debug mode only (which I believe is a pre-req for the leack check code) so we can get reasonable reports but in non-debug builds we will just do the shutdown async as always. I'll also file a follwon bug to see if this can be disentangled as per [comment 54](/show_bug.cgi?id=453403#c54 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox").

|  | [Benjamin Smedberg](/user_profile?user_id=7044) |  |
| --- | --- | --- |
| [Comment 56](/show_bug.cgi?id=453403#c56)• 16 years ago |
|  | |

This could be an actual leak, though not a serious one: it's quite possible for the application to terminate before the worker thread which is performing a DNS resolution returns.
The debug-only spin thing makes me slightly uncomfortable, but not enough to seriously object. The other alternative would be to stop leak-checking nsHostRecord, which is probably worse.

|  | [(not currently active) Ted Mielczarek](/user_profile?user_id=39022) |  |
| --- | --- | --- |
| [Comment 57](/show_bug.cgi?id=453403#c57)• 16 years ago |
|  | |

Note that the refcount leak checking code is available in non-debug builds. The leaks that this patch was backed out for (in mochitest) run on non-debug builds.

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 58](/show_bug.cgi?id=453403#c58)• 16 years ago |
|  | |

Yeah; we should condition the spinning on NS\_BUILD\_REFCNT\_LOGGING, not DEBUG.

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 59](/show_bug.cgi?id=453403#c59)• 16 years ago |
|  | |

Attached patch

[version 9 of patch](attachment.cgi?id=346958&action=diff) (obsolete)
— [Details](attachment.cgi?id=346958&action=edit)
— [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=346958)

Boris - thanks for the pointer to NS\_BUILD\_REFCNT\_LOGGING, I was having trouble finding that symbol.
This patch should apply to moz-central and it contains:
\* most of v8 (which was backed out)
\* the PR\_NotifyAllCondVar change attached to this bug (which was backed out)
\* the wait-for-thread-exit code in shutdown(), which should help the leak detection tool
\* fixes for the problem reported in 463215 - primarily the 'high-priority-only' threads were not being created. Based on this evidence, I also tilted the pool a little towards high-only threads (which could cause queueing in the prefetch requests, but leaves more slots for click driven lookups.)
Note that v8 contained 4 new files and those were not backed out of hg (they were just removed from the Makefile). v9 does not readd them and requires no changes to them.
[Attachment #346134](/attachment.cgi?id=346134&action=edit "version 8 of patch") -
Attachment is obsolete: true
[Attachment #346958](/attachment.cgi?id=346958&action=edit "version 9 of patch") -
Flags: review?(bzbarsky)

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 60](/show_bug.cgi?id=453403#c60)• 16 years ago |
|  | |

Comment on [attachment 346958](/attachment.cgi?id=346958 "version 9 of patch") [[details]](/attachment.cgi?id=346958&action=edit "version 9 of patch") [[diff]](/attachment.cgi?id=346958&action=diff "version 9 of patch") [[review]](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=346958)
version 9 of patch
Add a brief comment about it being ok to read mThreadCount outside the lock there because the worst that will happen if we race on it is that we'll wait an extra 25ms?
[Attachment #346958](/attachment.cgi?id=346958&action=edit "version 9 of patch") -
Flags: review?(bzbarsky) → review+

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 61](/show_bug.cgi?id=453403#c61)• 16 years ago |
|  | |

Attached patch

[version 10 of patch](attachment.cgi?id=346976&action=diff)
— [Details](attachment.cgi?id=346976&action=edit)
— [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=346976)

version 9 with an updated comment as per comment. Think it is checkin-ready?
[Attachment #346958](/attachment.cgi?id=346958&action=edit "version 9 of patch") -
Attachment is obsolete: true

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 62](/show_bug.cgi?id=453403#c62)• 16 years ago |
|  | |

The follow-on bug, regarding joining the threads, is 463724.

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 63](/show_bug.cgi?id=453403#c63)• 16 years ago |
|  | |

Comment on [attachment 346976](/attachment.cgi?id=346976 "version 10 of patch") [[details]](/attachment.cgi?id=346976&action=edit "version 10 of patch") [[diff]](/attachment.cgi?id=346976&action=diff "version 10 of patch") [[review]](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=346976)
version 10 of patch
Yeah, this is ready to go. It would be great to get beta baking for this!
[Attachment #346976](/attachment.cgi?id=346976&action=edit "version 10 of patch") -
Flags: approval1.9.1b2?

|  | [Mike Beltzner [:beltzner, not reading bugmail]](/user_profile?user_id=137548) |  |
| --- | --- | --- |
| [Comment 64](/show_bug.cgi?id=453403#c64)• 16 years ago |
|  | |

Comment on [attachment 346976](/attachment.cgi?id=346976 "version 10 of patch") [[details]](/attachment.cgi?id=346976&action=edit "version 10 of patch") [[diff]](/attachment.cgi?id=346976&action=diff "version 10 of patch") [[review]](/page.cgi?id=splinter.html&ignore=&bug=453403&attachment=346976)
version 10 of patch
a=beltzner; feels like a big (and risky) change so watch closely for regressions. You're getting approval because the potential benefit to responsiveness is also pretty big :)
[Attachment #346976](/attachment.cgi?id=346976&action=edit "version 10 of patch") -
Flags: approval1.9.1b2? → approval1.9.1b2+

|  | [Damon Sicore (:damons)](/user_profile?user_id=269330) |  |
| --- | --- | --- |
| [Comment 65](/show_bug.cgi?id=453403#c65)• 16 years ago |
|  | |

Has this landed?

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 66](/show_bug.cgi?id=453403#c66)• 16 years ago |
|  | |

Not yet. Tree's been closed ever since it got a= due to orange.

|  | [Damon Sicore (:damons)](/user_profile?user_id=269330) |  |
| --- | --- | --- |
| [Comment 67](/show_bug.cgi?id=453403#c67)• 16 years ago |
|  | |

Should probably get it in the queue: <https://wiki.mozilla.org/1.9.1_beta_2_checkins>

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 68](/show_bug.cgi?id=453403#c68)• 16 years ago |
|  | |

Pushed changeset 0496b58bb9f8 with that latest diff.Status: REOPENED → RESOLVEDClosed: 16 years ago → 16 years agoFlags: in-testsuite?Resolution: --- → FIXED

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 69](/show_bug.cgi?id=453403#c69)• 16 years ago |
|  | |

So this seems to have caused a small (2-3%) Tp3 regression at least on Mac and Linux.... (well, that or one of the other changes I pushed, but this one is the most likely culprit of the set).

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)  Assignee |  |
| --- | --- | --- |
| [Comment 70](/show_bug.cgi?id=453403#c70)• 16 years ago |
|  | |

I'm not familiar with how to run tp3 - any pointers are appreciated.
<https://wiki.mozilla.org/Perfomatic/Test_Name_Mappings> describes tp3 as "iframe-based pageload test embedded into Talos; loads content via local proxy server.".. If that's accurate it is only going to measure overhead for this feature (there is no upside when the proxy server is doing the DNS), but that doesn't mean we can't work on any overhead.
is tp3 measuring cpu time or elapsed time?

|  | [David Baron :dbaron: (⌚️UTC-4, no longer working on Mozilla)](/user_profile?user_id=3881) |  |
| --- | --- | --- |
| [Comment 71](/show_bug.cgi?id=453403#c71)• 16 years ago |
|  | |

The primary number (the one we're looking at) is a measure of elapsed time.

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 72](/show_bug.cgi?id=453403#c72)• 16 years ago |
|  | |

Not sure how one runs tp3 locally... I can't seem to find anything about it (or talos, for that matter) at [https://wiki.mozilla.org/Performance:Tinderbox\_Tests](https://wiki.mozilla.org/Performance%3ATinderbox_Tests)
Alice, is there a way Patrick can run Tp3 with the tinderbox pageset locally?

|  | [Shawn Wilsher :sdwilsh](/user_profile?user_id=233280) |  |
| --- | --- | --- |
| [Comment 73](/show_bug.cgi?id=453403#c73)• 16 years ago |
|  | |

You'll likely want to run standalone talos:
<https://wiki.mozilla.org/StandaloneTalos>
Note: the pageset is different however (we cannot publish our pageset for legal reasons if I recall correctly)

|  | [Vladimir Vukicevic [:vlad] [:vladv] (needinfo me, slow to respond)](/user_profile?user_id=24534) |  |
| --- | --- | --- |
| [Comment 74](/show_bug.cgi?id=453403#c74)• 16 years ago |
|  | |

I put a little xul app that can run Tp and reftests at <http://people.mozilla.com/~vladimir/misc/testtool.zip> ; though if you have a build with --enable-tests you can just run with the right command line options yourself (-help, it's the -tp option). The full talos script uses this for all the work, though it also sets up a local http server as well.

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a6214562_20209)• 16 years ago |

Depends on: [464838](/show_bug.cgi?id=464838 "RESOLVED FIXED - Tp3 regression on 2008-11-11")

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 75](/show_bug.cgi?id=453403#c75)• 16 years ago |
|  | |

I filed [bug 464838](/show_bug.cgi?id=464838 "RESOLVED FIXED - Tp3 regression on 2008-11-11") on investigating the Tp regression here.

|  | [Jesse Ruderman](/user_profile?user_id=11608) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a7841967_11608)• 16 years ago |

Depends on: [467648](/show_bug.cgi?id=467648 "RESOLVED FIXED - nsHTMLDNSPrefetch leak")

|  | [Henrik Skupin [:whimboo][⌚️UTC+2]](/user_profile?user_id=76551) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a12683582_76551)• 16 years ago |

Keywords: [fixed1.9.1](/buglist.cgi?keywords=fixed1.9.1&resolution=---)Target Milestone: --- → mozilla1.9.1b2

|  | [Henrik Skupin [:whimboo][⌚️UTC+2]](/user_profile?user_id=76551) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a12687751_76551)• 16 years ago |

Depends on: [475603](/show_bug.cgi?id=475603 "VERIFIED INVALID - Lots of timeouts for DNS requests with Netgear Router WGR614, and stylesheet/css rendering problems")

|  | [jag (Peter Annema)](/user_profile?user_id=29582) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a19233833_29582)• 16 years ago |

Depends on: [488162](/show_bug.cgi?id=488162 "RESOLVED FIXED - DNS prefetch leaks information because it doesn't honour network.proxy.socks_remote_dns")

|  | [TheRave](/user_profile?user_id=344472) |  |
| --- | --- | --- |
| [Comment 76](/show_bug.cgi?id=453403#c76)• 16 years ago |
|  | |

Can somebody of the devs here have a look at the following thread in mozillazine forum? It seems to we have a problem with this bugfix.
<http://forums.mozillazine.org/viewtopic.php?f=23&t=1150335&start=15>

|  | [Karsten Düsterloh](/user_profile?user_id=34346) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a20348320_34346)• 16 years ago |

Depends on: [486127](/show_bug.cgi?id=486127 "RESOLVED FIXED - Seamonkey/Thunderbird send DNS queries when viewing mail, could be used to verify existence of mail accounts")

|  | [Karsten Düsterloh](/user_profile?user_id=34346) |  |
| --- | --- | --- |
| [Comment 77](/show_bug.cgi?id=453403#c77)• 16 years ago |
|  | |

Did \*anyone\* give a thought about the security implications of this?
\*Any\* local HTML document on trunk now causes a DNS query, thus it's \*extremely\* easy to track who's reading a specific doc just by adding some unique URL in it - the reader doesn't even need to click the URL to be tracked!
That's just mad or utterly broken...

|  | [Karsten Düsterloh](/user_profile?user_id=34346) |  |
| --- | --- | --- |
| [Comment 78](/show_bug.cgi?id=453403#c78)• 16 years ago |
|  | |

(In reply to [comment #77](/show_bug.cgi?id=453403#c77 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox"))
> \*Any\* local HTML document
... containing a mere HTML link, e.g.
<html><body>
<a href="<http://what.about.sub.domains.in.html.urls/I.wonder>">No need to click me!</a>
</body></html>

|  | [Shawn Wilsher :sdwilsh](/user_profile?user_id=233280) |  |
| --- | --- | --- |
| [Comment 79](/show_bug.cgi?id=453403#c79)• 16 years ago |
|  | |

(In reply to [comment #77](/show_bug.cgi?id=453403#c77 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox"))
> Did \*anyone\* give a thought about the security implications of this?
> \*Any\* local HTML document on trunk now causes a DNS query, thus it's
> \*extremely\* easy to track who's reading a specific doc just by adding some
> unique URL in it - the reader doesn't even need to click the URL to be tracked!
> That's just mad or utterly broken...
That's only true if the dns server that you use is owned by the website in question. A DNS lookup doesn't go to the server of the site for a link...

|  | [Mike Shaver (:shaver emeritus)](/user_profile?user_id=422) |  |
| --- | --- | --- |
| [Comment 80](/show_bug.cgi?id=453403#c80)• 16 years ago |
|  | |

(In reply to [comment #77](/show_bug.cgi?id=453403#c77 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox"))
> Did \*anyone\* give a thought about the security implications of this?
> \*Any\* local HTML document on trunk now causes a DNS query, thus it's
> \*extremely\* easy to track who's reading a specific doc just by adding some
> unique URL in it
You mean by putting an <img> or <script> or <link rel="many choices"> in it? Yeah, long-standing problem, but not what this bug is about.
DNS resolution only helps if you can log queries and associate them back against the originating source, which latter is typically pretty challenging, AFAICT.

|  | [Karsten Düsterloh](/user_profile?user_id=34346) |  |
| --- | --- | --- |
| [Comment 81](/show_bug.cgi?id=453403#c81)• 16 years ago |
|  | |

> That's only true if the dns server that you use is owned by the website in
> question. A DNS lookup doesn't go to the server of the site for a link...
Trackable by the DNS provider of the linked domain, not of the website where the link appears.
> DNS resolution only helps if you can log queries and associate them back
> against the originating source, which latter is typically pretty challenging,
> AFAICT.
Pretty challenging?!
- set up your own DNS server for your domain
- create unique, not yet used DNS entries for each user you want to track and you are able to get to see certain webpages (e.g. by sending him a spam mail, see [bug 488162](/show_bug.cgi?id=488162 "RESOLVED FIXED - DNS prefetch leaks information because it doesn't honour network.proxy.socks_remote_dns"))
=> You won't get \*all\* hits of the DNS resolution attempt, but you'll get the \*first\* one for sure, since the new DNS record needs to find its way to the caches.

|  | [Bruno 'Aqualon' Escherl](/user_profile?user_id=88429) |  |
| --- | --- | --- |
| [Comment 82](/show_bug.cgi?id=453403#c82)• 16 years ago |
|  | |

Another problem could be with plans in Germany to log every attempt to access websites on a blacklist with child pornography by using DNS bypasses to a stop page. If the provider logs that you made an DNS query for a forbidden webpage, it could result in a house search by the police, even if you never clicked on it.

|  | [Vladimir Vukicevic [:vlad] [:vladv] (needinfo me, slow to respond)](/user_profile?user_id=24534) |  |
| --- | --- | --- |
| [Comment 83](/show_bug.cgi?id=453403#c83)• 16 years ago |
|  | |

As Mike said in [comment #80](/show_bug.cgi?id=453403#c80 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox"), malicious web pages can already force a DNS lookup and even a HTTP request by using an <img> or <script> or <link> tag to any arbitrary site. Those requests would just show up nicely in their http logs, along with the dns request; if someone had malicious intent, why would they bother to go the complicated and fragile route of setting up dns and hoping that dns prefetching hits their site, when they can just put in an img tag?
Regardless, this bug is not the place for this discussion -- I'd suggest either mozillazine or posting to one of the mozilla newsgroups.

|  | [James May [:fowl2]](/user_profile?user_id=317549) |  |
| --- | --- | --- |
| [Comment 84](/show_bug.cgi?id=453403#c84)• 16 years ago |
|  | |

Would it be possible to plug this in to the same system that allows extensions like ad block plus to veto requests?

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 85](/show_bug.cgi?id=453403#c85)• 16 years ago |
|  | |

There would be a performance cost, but maybe. File a bug, please, and request blocking if you think it needs to happen for 1.9.1?

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209) |  |
| --- | --- | --- |
| [Comment 86](/show_bug.cgi?id=453403#c86)• 16 years ago |
|  | |

Oh, and [comment 76](/show_bug.cgi?id=453403#c76 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox") also needs a separate bug, with blocking requested on it and marked as blocking this bug.

|  | [TheRave](/user_profile?user_id=344472) |  |
| --- | --- | --- |
| [Comment 87](/show_bug.cgi?id=453403#c87)• 16 years ago |
|  | |

For [comment 76](/show_bug.cgi?id=453403#c76 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox") i have opened the [bug 491140](/show_bug.cgi?id=491140 "VERIFIED INVALID - DNS pre-fetching (bug 453403) freezing Windows XP in Jetico Firewall").

|  | [Karsten Düsterloh](/user_profile?user_id=34346) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=453403#a21466487_34346)• 16 years ago |

Depends on: [492196](/show_bug.cgi?id=492196 "RESOLVED FIXED - Make DNS-Prefetching subject to user-defined policies")
You need to [log in](/show_bug.cgi?id=453403&GoAheadAndLogIn=1)
before you can comment on or make changes to this bug.

Top ↑

## Attachment

Hide Details

### General

Creator:  [Patrick McManus [:mcmanus]](/user_profile?user_id=32546)

Created:
Updated:
Size:

### Description

### File Name

### Content Type

Raw
Diff
Splinter Review



=== Content from bugzilla.mozilla.org_179368f1_20250125_100303.html ===


![](/static/v20250114.1/extensions/BMO/web/images/moz-fav-one-color-white-rgb.svg)

* [Mozilla Home](https://www.mozilla.org/)
* [Privacy](https://www.mozilla.org/privacy/websites/)
* [Cookies](https://www.mozilla.org/privacy/websites/#cookies)
* [Legal](https://www.mozilla.org/about/legal/)
# [Bugzilla](https://bugzilla.mozilla.org/home "Go to home page")

[Quick Search Tips](/page.cgi?id=quicksearch.html)
[Advanced Search](/query.cgi?format=advanced)

* [Browse](/describecomponents.cgi "Browse bugs by component")
* [Advanced Search](/query.cgi?format=advanced "Search bugs using various criteria")
* [New Bug](/enter_bug.cgi "File a new bug")

* [Reports](/report.cgi)
* [Documentation](https://bmo.readthedocs.io/en/latest/)

* [Log In](/index.cgi?GoAheadAndLogIn=1)

   Log In with GitHub

  or

  Remember me

  [Create an Account](/createaccount.cgi)
  ·
  [Forgot Password](/index.cgi?GoAheadAndLogIn=1#forgot)

* [Browse](/describecomponents.cgi "Browse bugs by component")
* [Advanced Search](/query.cgi?format=advanced "Search bugs using various criteria")
* [New Bug](/enter_bug.cgi "File a new bug")
* [Reports](/report.cgi)
* [Documentation](https://bmo.readthedocs.io/en/latest/)

Please enable JavaScript in your browser to use all the features on this site.

Copy Summary▾

* Markdown
* Markdown (bug number)
* Plain Text
* HTML

View ▾

* Reset Sections
* Expand All Sections
* Collapse All Sections
* History
* [JSON](/rest/bug/492196)
* [XML](/show_bug.cgi?ctype=xml&id=492196)

Closed
[Bug 492196](/show_bug.cgi?id=492196)

Opened 16 years ago
Closed 16 years ago

# Make DNS-Prefetching subject to user-defined policies

\*
[Summary:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#short_desc)

Make DNS-Prefetching subject to user-defined policies

## Categories

### (Core :: Networking, defect)

[Product:](/describecomponents.cgi?product=Core)

Core
▾

Core
Shared components used by Firefox and other Mozilla software, including handling of Web content; Gecko, HTML, CSS, layout, DOM, scripts, images, networking, etc. Issues with web page layout probably go here, while Firefox user interface issues belong in the [Firefox](https://bugzilla.mozilla.org/describecomponents.cgi?product=Firefox) product. ([More info](https://wiki.mozilla.org/Modules/All#Core))
[See Open Bugs in This Product](/buglist.cgi?product=Core&bug_status=__open__)
[File New Bug in This Product](/enter_bug.cgi?product=Core)
Watch This Product

[Component:](/describecomponents.cgi?product=Core&component=Networking#Networking)

Networking
▾

Core :: Networking
For bugs in Mozilla's modular networking library (aka "Netlib" or "Necko".) The networking library supplies the software interface that Mozilla uses to access physical transports (e.g. the Internet and local drives), perform URL resolutions, and handle a variety of networking protocols.

Examples of appropriate bugs: URLs with backslash not fetched; URLs starting with a single slash turn into http:///; Cannot access authenticated FTP site.

[See Open Bugs in This Component](/buglist.cgi?product=Core&component=Networking&bug_status=__open__)
[Recently Fixed Bugs in This Component](/buglist.cgi?product=Core&component=Networking&chfield=resolution&chfieldfrom=-6m&chfieldvalue=FIXED&bug_status=__closed__)
[File New Bug in This Component](/enter_bug.cgi?product=Core&component=Networking)
Watch This Component

[Version:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#version)

Trunk

[Platform:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#rep_platform)

x86

All

[Type:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#bug_type)

defect

[Priority:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#priority)

*Not set*

[Severity:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#bug_severity)

major

Points:

---

## Tracking

### ()

[Status:](https://wiki.mozilla.org/BMO/UserGuide/BugStatuses)

RESOLVED
FIXED

[Status:](https://wiki.mozilla.org/BMO/UserGuide/BugStatuses)

RESOLVED

FIXED

Mark as Assigned

[Milestone:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#target_milestone)

---

Iteration:

---

[Project Flags:](https://wiki.mozilla.org/BMO/UserGuide#Project_Flags)

| Webcompat Priority | --- |
| --- | --- |
| a11y-review | --- |
| Webcompat Score | --- |
| Performance Impact | --- |
| Accessibility Severity | --- |

[Tracking Flags:](https://wiki.mozilla.org/BMO/UserGuide#Tracking_Flags)

|  | Tracking | Status |
| --- | --- | --- |
| relnote-firefox |  | --- |
| thunderbird\_esr115 | --- | --- |
| thunderbird\_esr128 | --- | --- |
| firefox-esr115 | --- | --- |
| firefox-esr128 | --- | --- |
| firefox134 | --- | --- |
| firefox135 | --- | --- |
| firefox136 | --- | --- |

## People

### (Reporter: mnyromyr, Assigned: bzbarsky)

[Assignee:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#assigned_to)

![](extensions/Gravatar/web/default.jpg)  [bzbarsky](/user_profile?user_id=20209)

[Assignee:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#assigned_to)

Reset Assignee to default

[Mentors:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#bug_mentor)

---

[QA Contact:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#qa_contact)

Reset QA Contact to default

[Reporter:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#reporter)

![](https://secure.gravatar.com/avatar/b4e3e00188e65c716b400131f56ac0f0?d=mm&size=40)  [mnyromyr](/user_profile?user_id=34346)

[Triage Owner:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#triage_owner)

![](https://secure.gravatar.com/avatar/608e04ebca94be52b05c003d51d43e07?d=mm&size=40)  [kershaw](/user_profile?user_id=505624)

[CC:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#cc)

24 people

## References

[Depends on:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#dependson)

[493467](/show_bug.cgi?id=493467 "RESOLVED FIXED - preserve allowDNSPrefetch and allowAuth and test for completeness")

[Blocks:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#blocks)

[486127](/show_bug.cgi?id=486127 "RESOLVED FIXED - Seamonkey/Thunderbird send DNS queries when viewing mail, could be used to verify existence of mail accounts"), [545407](/show_bug.cgi?id=545407 "RESOLVED FIXED - Remove code that disables DNS pre-fetching for APP_TYPE_MAIL/EDITOR docshells")

[453403](/show_bug.cgi?id=453403 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox")

Dependency [tree](/showdependencytree.cgi?id=492196&hide_resolved=1)
/ [graph](/showdependencygraph.cgi?id=492196)

[Regressions:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#regresses)

---

[Regressed by:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#regressed_by)

---

[URL:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#bug_file_loc)

[See Also:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#see_also)

---

## Details

### (Keywords: fixed1.9.1, privacy, regression, Whiteboard: [tb3needs])

[Alias:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#alias)

---

[Keywords:](/describekeywords.cgi)

[fixed1.9.1](/buglist.cgi?keywords=fixed1.9.1&resolution=---),
[privacy](/buglist.cgi?keywords=privacy&resolution=---),
[regression](/buglist.cgi?keywords=regression&resolution=---)

[Whiteboard:](https://wiki.mozilla.org/BMO/UserGuide/Whiteboard)

[tb3needs]

QA Whiteboard:

---

Has STR:

---

Change Request:

---

[Votes:](https://wiki.mozilla.org/BMO/UserGuide/BugFields#votes)

0

Bug Flags:

| [jst](/user_profile?user_id=12352) | [blocking1.9.1](#c5 "16 years ago") | + |
| --- | --- | --- |
| [jst](/user_profile?user_id=12352) | blocking1.9.1 | + |
| --- | --- | --- |
|  | behind-pref |  |
| --- | --- | --- |
|  | firefox-backlog |  |
|  | sec-bounty | ? |
|  | sec-bounty-hof |  |
|  | in-qa-testsuite |  | | |
|  | in-testsuite |  |
|  | qe-verify |  |

## Crash Data

Signature:

*None*

## Security

### (public)

This bug is publicly visible.

## User Story

## Attachments

### (2 files)

| [Proposed fix](/attachment.cgi?id=377824)  [16 years ago](#c16)  [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209)   19.04 KB, patch | jst : [review+](#c18 "16 years ago")  jst : [superreview+](#c18 "16 years ago") | [Details](/attachment.cgi?id=377824&action=edit) | [Diff](/attachment.cgi?id=377824&action=diff) | [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=492196&attachment=377824) |
| --- | --- | --- |
| [1.9.1 version (same, but with an extra interface instead of changing nsIDocShell)](/attachment.cgi?id=377828)  [16 years ago](#c17)  [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209)   21.20 KB, patch | jst : [review+](#a623684_12352 "16 years ago")  jst : [superreview+](#a623684_12352 "16 years ago") | [Details](/attachment.cgi?id=377828&action=edit) | [Diff](/attachment.cgi?id=377828&action=diff) | [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=492196&attachment=377828) |

Bottom ↓
Tags ▾

* Reset

Timeline ▾

* Reset
* Collapse All
* Expand All
* Comments Only

|  | [Karsten Düsterloh](/user_profile?user_id=34346)  Reporter |  |
| --- | --- | --- |
| [Description](/show_bug.cgi?id=492196#c0)• 16 years ago |
|  | |

[Bug 453403](/show_bug.cgi?id=453403 "RESOLVED FIXED - add DNS pre-fetching to Necko and Firefox") implemented DNS prefetching in Necko, which has severe security implications:
Local HTML pages will generate DNS queries even if other remote content is disabled, e.g. for mere <a href="...">!
This gets even more creepy if we take into account that SeaMonkey and Thunderbird render \_all\_ messages (even plaintext ones) as HTML documents in a <browser> element. Thus reading a plaintext(!) message will already make you acknowledge the existence of this account (e.g. by using one-time subdomain entries), because even in plaintext mode links are rendered as clickable items.
Until now, there was a commonly agreed assumption that reading local HTML without remote \*content\* will keep your privacy intact. This promise is broken now.
While you can turn off the prefetching entirely by using network.dns.disablePrefetch, this is no real option for SeaMonkey (although maybe for TB), because you can't seriously apply one single setting to public websurfing, viewing local HTML documents in the browser and reading mail all alike without affecting user experience.
We could even work around the mail case by trying to produce certain markup, but that is rather band-aiding than fixing the real issue. And, of course, this will not help a bit when viewing local HTML documents in the browser...Flags: blocking1.9.2?Flags: blocking1.9.1?

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209)  Assignee |  |
| --- | --- | --- |
| [Comment 1](/show_bug.cgi?id=492196#c1)• 16 years ago |
|  | |

We don't actually need user-defined policies, here? What we need is a way to disable DNS prefetch on a per-document basis. Whether this is done via a setting on the docshell or via content policy or some other mechanism is something to decide on during implementation. Now that the prefetch is done after document load completes, maybe a content policy check would sorta work, except the content policy API is completely inappropriate here (e.g. we have no URI we plan to load).
This is a serious problem for any Gecko-based app that's not a pure web browser, and I should have caught it in review... I think this needs to block 1.9.1.Assignee: nobody → mcmanus

|  | [Magnus Melin [:mkmelin]](/user_profile?user_id=101158) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=492196#a18065_101158)• 16 years ago |

Keywords: [privacy](/buglist.cgi?keywords=privacy&resolution=---)

|  | [Mark Banner (:standard8)](/user_profile?user_id=112088) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=492196#a20303_112088)• 16 years ago |

Whiteboard: [tb3needs]

|  | [Karsten Düsterloh](/user_profile?user_id=34346)  Reporter |  |
| --- | --- | --- |
| [Comment 2](/show_bug.cgi?id=492196#c2)• 16 years ago |
|  | |

> We don't actually need user-defined policies, here? What we need is a way to
> disable DNS prefetch on a per-document basis.
My Necko foo ist not particularly strong, so please correct my wording where necessary. :)

|  | [neil@parkwaycc.co.uk](/user_profile?user_id=14006) |  |
| --- | --- | --- |
| [Comment 3](/show_bug.cgi?id=492196#c3)• 16 years ago |
|  | |

Is per-document strong enough? For example, suppose I send an email containing <iframe src=data:text/html,%3Ba%20href=<http://unique.evil.com%3D>> ?

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209)  Assignee |  |
| --- | --- | --- |
| [Comment 4](/show_bug.cgi?id=492196#c4)• 16 years ago |
|  | |

Presumably the disabling would need to inherit to child documents, like other docshell settings.
As for [comment 2](/show_bug.cgi?id=492196#c2 "RESOLVED FIXED - Make DNS-Prefetching subject to user-defined policies"), the point is that we don't need either something users can easily set or something that can be set on a per-site basis, as far as I can tell. Something set on the docshell tree root level should be fine.

|  | [Johnny Stenback (:jst)](/user_profile?user_id=12352) |  |
| --- | --- | --- |
| [Comment 5](/show_bug.cgi?id=492196#c5)• 16 years ago |
|  | |

Yeah, blocking, but yeah, this is an issue only for some non-Firefox apps.Flags: blocking1.9.1? → blocking1.9.1+

|  | [Jason Duell](/user_profile?user_id=334931) |  |
| --- | --- | --- |
| [Comment 6](/show_bug.cgi?id=492196#c6)• 16 years ago |
|  | |

Boris, who's the right person to work on this? Patrick McManus has touched the DNS code recently, but from your comments it sounds like the code might be more in docshell. I'm guessing the right way to proceed to is to have Patrick or someone else add a necko "don't prefetch DNS for this" API, and then someone else might be the right person to do the docshell work.

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209)  Assignee |  |
| --- | --- | --- |
| [Comment 7](/show_bug.cgi?id=492196#c7)• 16 years ago |
|  | |

Patrick is almost certainly the right person to work on this... There's no reason not to learn a bit about the docshell code if you're doing necko work (and in fact, it's a good idea).

|  | [Karsten Düsterloh](/user_profile?user_id=34346)  Reporter |  |
| --- | --- | --- |
| [Comment 8](/show_bug.cgi?id=492196#c8)• 16 years ago |
|  | |

(In reply to [comment #5](/show_bug.cgi?id=492196#c5 "RESOLVED FIXED - Make DNS-Prefetching subject to user-defined policies"))
> Yeah, blocking, but yeah, this is an issue only for some non-Firefox apps.
Wrong.
Watching a local HTML file with any <a href="link"> in it will result in a DNS query. Of course you can turn off DNS prefetching entirely, but you can't distinguish between wanted prefetching (web) and unwanted ones (local).

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209)  Assignee |  |
| --- | --- | --- |
| [Comment 9](/show_bug.cgi?id=492196#c9)• 16 years ago |
|  | |

Hold on. Which problems are we trying to solve? The local file case needs a totally different solution, in general, than the mail case. Or rather, the local file solution (pluggable per-origin behavior of some sort) would also solve the mail case, maybe, but the best solution for the mail case will NOT solve your local file issue, almost certainly.
Given that you can't have "other remote content" disabled without an extension for local file pages, I don't think we necessarily need to worry about that case. That same extension can disable DNS prefetch (yes, you get a performance penalty, but you already have a major performance penalty from the extension's existence; globally disabling DNS prefetch may well be a smaller penalty than running a bunch of JS for every single link on the page).
So I think we should focus on the mail-and-such case here, myself.

|  | [Karsten Düsterloh](/user_profile?user_id=34346)  Reporter |  |
| --- | --- | --- |
| [Comment 10](/show_bug.cgi?id=492196#c10)• 16 years ago |
|  | |

(In reply to [comment #9](/show_bug.cgi?id=492196#c9 "RESOLVED FIXED - Make DNS-Prefetching subject to user-defined policies"))
> So I think we should focus on the mail-and-such case here, myself.
Yes, sure. I just want to avoid the notion that DNS prefetching issues are "just" a problem of "some non-Firefox apps".

|  | [Johnny Stenback (:jst)](/user_profile?user_id=12352) |  |
| --- | --- | --- |
| [Comment 11](/show_bug.cgi?id=492196#c11)• 16 years ago |
|  | |

Patrick, do you think you'll have time to look into this before the end of the week?

|  | [James May [:fowl2]](/user_profile?user_id=317549) |  |
| --- | --- | --- |
| [Comment 12](/show_bug.cgi?id=492196#c12)• 16 years ago |
|  | |

Would this be "plugged in" to the content policy system?
Then Adblock, etc could filter requests DNS too, or is that another bug?

|  | [Patrick McManus [:mcmanus]](/user_profile?user_id=32546) |  |
| --- | --- | --- |
| [Comment 13](/show_bug.cgi?id=492196#c13)• 16 years ago |
|  | |

(In reply to [comment #11](/show_bug.cgi?id=492196#c11 "RESOLVED FIXED - Make DNS-Prefetching subject to user-defined policies"))
> Patrick, do you think you'll have time to look into this before the end of the
> week?
Sorry, fraid not. Someone else should probably look at it.

|  | [Johnny Stenback (:jst)](/user_profile?user_id=12352) |  |
| --- | --- | --- |
| [Comment 14](/show_bug.cgi?id=492196#c14)• 16 years ago |
|  | |

Thanks for letting me know, Patrick. Boris said he can look at this, reassigning.Assignee: mcmanus → bzbarsky

|  | [Damon Sicore (:damons)](/user_profile?user_id=269330) |  |
| --- | --- | --- |
| [Comment 15](/show_bug.cgi?id=492196#c15)• 16 years ago |
|  | |

Boris, you think you are going to be able to make the freeze date of Wed, May 20th here? Just want to make sure we're being realistic, and if you haven't started on this one yet, it makes me worry. Thoughts?

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209)  Assignee |  |
| --- | --- | --- |
| [Comment 16](/show_bug.cgi?id=492196#c16)• 16 years ago |
|  | |

Attached patch

[Proposed fix](attachment.cgi?id=377824&action=diff)
— [Details](attachment.cgi?id=377824&action=edit)
— [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=492196&attachment=377824)

A few things going on here.
1) Add a boolean member on documents that indicates whether prefetch is allowed
for that document. This defaults to true.
2) Set this member to false if the document gets a window and the docshell is
not allowing prefetch, if the document has an HTTP header or equivalent
META tag disallowing prefetch, or if the "no DNS prefetch from secure" pref
is set and the document gets a principal that has no URI or has an https
URI. This makes document.write from https do the right thing no matter
what we do with the document URI, for example. The code corresponding to
all this in nsHTMLDNSPrefetch goes away.
3) Docshell defaults to allowing prefetch and exposes an nsIDocShell API to
change this. It also defaults to disallowing prefetch if someone sets the
app type to mail or editor. This should immediately fix the issues
thunderbird and seamonkey have, I would think.
4) nsWebBrowser defaults to NOT allowing prefetch, since those APIs are
frozen, but adds a way to enable it via nsIWebBrowserSetup. If this flies,
I'll file a bug on Cammino to enable it on their end.
I revved the docshell iid, but the other interface changes shouldn't need IID revs, I would think. The nsIDocument one is debatable; if desired I can put this member all the way at the end of the nsIDocument members, in which case it will certainly be ok.
I can't think of a sane way to test this automatically, but I did verify via printfs that I get DNS prefetch in Firefox with this patch, but that if I flip the default value in docshell that stops happening....
[Attachment #377824](/attachment.cgi?id=377824&action=edit "Proposed fix") -
Flags: superreview?(jst)
[Attachment #377824](/attachment.cgi?id=377824&action=edit "Proposed fix") -
Flags: review?(jst)

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209)  Assignee |  |
| --- | --- | --- |
| [Comment 17](/show_bug.cgi?id=492196#c17)• 16 years ago |
|  | |

Attached patch

[1.9.1 version (same, but with an extra interface instead of changing nsIDocShell)](attachment.cgi?id=377828&action=diff)
— [Details](attachment.cgi?id=377828&action=edit)
— [Splinter Review](/page.cgi?id=splinter.html&ignore=&bug=492196&attachment=377828)

[Attachment #377828](/attachment.cgi?id=377828&action=edit "1.9.1 version (same, but with an extra interface instead of changing nsIDocShell)") -
Flags: superreview?(jst)
[Attachment #377828](/attachment.cgi?id=377828&action=edit "1.9.1 version (same, but with an extra interface instead of changing nsIDocShell)") -
Flags: review?(jst)

|  | [Johnny Stenback (:jst)](/user_profile?user_id=12352) |  |
| --- | --- | --- |
| [Comment 18](/show_bug.cgi?id=492196#c18)• 16 years ago |
|  | |

Comment on [attachment 377824](/attachment.cgi?id=377824 "Proposed fix") [[details]](/attachment.cgi?id=377824&action=edit "Proposed fix") [[diff]](/attachment.cgi?id=377824&action=diff "Proposed fix") [[review]](/page.cgi?id=splinter.html&ignore=&bug=492196&attachment=377824)
Proposed fix
Looks good. r+sr=jst
[Attachment #377824](/attachment.cgi?id=377824&action=edit "Proposed fix") -
Flags: superreview?(jst)
[Attachment #377824](/attachment.cgi?id=377824&action=edit "Proposed fix") -
Flags: superreview+
[Attachment #377824](/attachment.cgi?id=377824&action=edit "Proposed fix") -
Flags: review?(jst)
[Attachment #377824](/attachment.cgi?id=377824&action=edit "Proposed fix") -
Flags: review+

|  | [Johnny Stenback (:jst)](/user_profile?user_id=12352) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=492196#a623684_12352)• 16 years ago |

[Attachment #377828](/attachment.cgi?id=377828&action=edit "1.9.1 version (same, but with an extra interface instead of changing nsIDocShell)") -
Flags: superreview?(jst)
[Attachment #377828](/attachment.cgi?id=377828&action=edit "1.9.1 version (same, but with an extra interface instead of changing nsIDocShell)") -
Flags: superreview+
[Attachment #377828](/attachment.cgi?id=377828&action=edit "1.9.1 version (same, but with an extra interface instead of changing nsIDocShell)") -
Flags: review?(jst)
[Attachment #377828](/attachment.cgi?id=377828&action=edit "1.9.1 version (same, but with an extra interface instead of changing nsIDocShell)") -
Flags: review+

|  | [Johnny Stenback (:jst)](/user_profile?user_id=12352) |  |
| --- | --- | --- |
| [Comment 19](/show_bug.cgi?id=492196#c19)• 16 years ago |
|  | |

Comment on [attachment 377828](/attachment.cgi?id=377828 "1.9.1 version (same, but with an extra interface instead of changing nsIDocShell)") [[details]](/attachment.cgi?id=377828&action=edit "1.9.1 version (same, but with an extra interface instead of changing nsIDocShell)") [[diff]](/attachment.cgi?id=377828&action=diff "1.9.1 version (same, but with an extra interface instead of changing nsIDocShell)") [[review]](/page.cgi?id=splinter.html&ignore=&bug=492196&attachment=377828)
1.9.1 version (same, but with an extra interface instead of changing nsIDocShell)
r+sr=jst for this one too, but do we really care about not changing interfaces for 1.9.1 already? Was that decided, if so, I missed it. And have we really kept any such claims?

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209)  Assignee |  |
| --- | --- | --- |
| [Comment 20](/show_bug.cgi?id=492196#c20)• 16 years ago |
|  | |

We promised compat after b4, and we have in fact been keeping it.

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209)  Assignee |  |
| --- | --- | --- |
| [Comment 21](/show_bug.cgi?id=492196#c21)• 16 years ago |
|  | |

Pushed <http://hg.mozilla.org/mozilla-central/rev/cab8d8a075da>Status: NEW → RESOLVEDClosed: 16 years agoResolution: --- → FIXED

|  | [Simon Bünzli](/user_profile?user_id=160571) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=492196#a697491_160571)• 16 years ago |

Blocks: [493467](/show_bug.cgi?id=493467 "RESOLVED FIXED - preserve allowDNSPrefetch and allowAuth and test for completeness")

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209)  Assignee |  |
| --- | --- | --- |
| [Comment 22](/show_bug.cgi?id=492196#c22)• 16 years ago |
|  | |

Pushed <http://hg.mozilla.org/releases/mozilla-1.9.1/rev/1cd394f39075>
Filed [bug 493474](/show_bug.cgi?id=493474 "RESOLVED FIXED - Consider enabling DNS prefetch in camino") on camino.Keywords: [fixed1.9.1](/buglist.cgi?keywords=fixed1.9.1&resolution=---)

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209)  Assignee |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=492196#a726562_20209)• 16 years ago |

No longer blocks: [493467](/show_bug.cgi?id=493467 "RESOLVED FIXED - preserve allowDNSPrefetch and allowAuth and test for completeness")Depends on: [493467](/show_bug.cgi?id=493467 "RESOLVED FIXED - preserve allowDNSPrefetch and allowAuth and test for completeness")

|  | [Benjamin Smedberg](/user_profile?user_id=7044) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=492196#a6388385_7044)• 16 years ago |

Flags: blocking1.9.2?

|  | [Owen Marshall (Not reading bugmail)](/user_profile?user_id=42076) |  |
| --- | --- | --- |
| [Comment 23](/show_bug.cgi?id=492196#c23)• 15 years ago |
|  | |

[Bug 544745](/show_bug.cgi?id=544745 "RESOLVED FIXED - DNS Prefetch security issue: Information leak") indicates that DNS prefetching is still occurring for messages on Thunderbird 3.0.1 as well as TB3.1 beta.
I'm not up on my BMO QA: should we dupe that one over to here and reopen this bug, or just leave that as a separate bug?

|  | [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209)  Assignee |  |
| --- | --- | --- |
| [Comment 24](/show_bug.cgi?id=492196#c24)• 15 years ago |
|  | |

Separate bug, please, especially given [bug 486127 comment 15](/show_bug.cgi?id=486127#c15 "RESOLVED FIXED - Seamonkey/Thunderbird send DNS queries when viewing mail, could be used to verify existence of mail accounts").

|  | [Mark Banner (:standard8)](/user_profile?user_id=112088) |  |
| --- | --- | --- |
| [Updated](/show_bug.cgi?id=492196#a23932761_112088)• 15 years ago |

Blocks: [545407](/show_bug.cgi?id=545407 "RESOLVED FIXED - Remove code that disables DNS pre-fetching for APP_TYPE_MAIL/EDITOR docshells")
You need to [log in](/show_bug.cgi?id=492196&GoAheadAndLogIn=1)
before you can comment on or make changes to this bug.

Top ↑

## Attachment

Hide Details

### General

Creator:  [Boris Zbarsky [:bzbarsky]](/user_profile?user_id=20209)

Created:
Updated:
Size:

### Description

### File Name

### Content Type

Raw
Diff
Splinter Review


