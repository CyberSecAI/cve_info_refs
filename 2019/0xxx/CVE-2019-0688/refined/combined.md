=== Content from portal.msrc.microsoft.com_b36e7a81_20250120_233210.html ===
You need to enable JavaScript to run this app.

=== Content from arxiv.org_6928d18e_20250120_233208.html ===
9
1
0
2

t
c
O
7
2

]

R
C
.
s
c
[

2
v
8
7
4
0
1
.
6
0
9
1
:
v
i
X
r
a

From IP ID to Device ID and KASLR Bypass (Extended Version)∗

Amit Klein
Bar-Ilan University

Benny Pinkas
Bar-Ilan University

Abstract

IP headers include a 16-bit ID ﬁeld. Our work examines the
generation of this ﬁeld in Windows (versions 8 and higher),
Linux and Android, and shows that the IP ID ﬁeld enables re-
mote servers to assign a unique ID to each device and thus be
able to identify subsequent transmissions sent from that de-
vice. This identiﬁcation works across all browsers and over
network changes. In modern Linux and Android versions,
this ﬁeld leaks a kernel address, thus we also break KASLR.
Our work includes reverse-engineering of the Windows IP
ID generation code, and a cryptanalysis of this code and of
the Linux kernel IP ID generation code. It provides practical
techniques to partially extract the key used by each of these
algorithms, overcoming different implementation issues, and
observing that this key can identify individual devices. We
deployed a demo (for Windows) showing that key extraction
and machine ﬁngerprinting works in the wild, and tested it
from networks around the world.

1 Introduction

Online browser-based user tracking is prevalent. Tracking is
used to identify users and track them across many sessions
and websites on the Internet. Tracking is often performed in
order to personalize advertisements or for surveillance pur-
poses. It can either be done by sites that are visited by users,
or by third-party companies which track users across multi-
ple web sites and applications. [2] speciﬁcally lists motiva-
tions for web-based ﬁngerprinting as “fraud detection, pro-
tection against account hijacking, anti-bot and anti-scraping
services, enterprise security management, protection against
DDOS attacks, real-time targeted marketing, campaign mea-
surement, reaching customers across devices, and limiting
number of access to services”.
Tracking methods Existing tracking mechanisms are usu-
ally based on either tagging or ﬁngerprinting. With tagging,
the tracking party stores at the user’s device some informa-
tion, such as a cookie, which can later be tracked. Modern
web standards and norms, however, enable users to opt-out
from tagging. Furthermore, tagging is often speciﬁc for one
application or browser, and therefore a tag that was stored in
one browser cannot be identiﬁed when the user is using a dif-
ferent browser on the same machine, or when the user uses

∗This is an extended version of a paper that will be published in Usenix

Security 2019.

the private browsing feature of the browser. Fingerprinting
is implemented by having the tracking party measure fea-
tures of the user’s machine (for example the set of installed
fonts). Corporates, however, often install a single “golden
image” (standard set of software packages) on many iden-
tical (hardware-wise) machines, and therefore it is hard to
obtain ﬁngerprints that distinguish among such machines.

In this work we present a new tracking mechanism which
is based on extracting data used by the IP ID generator (see
Section 1.1). It is the ﬁrst tracking technique that is able to
simultaneously (a) cross the private browsing boundary (i.e.
compute the same tracking ID for a private mode tab/window
of a browser as for a regular tab/window of the browser);
(b) work across different browsers; (c) address the “golden
image” problem; and (d) work across multiple networks; all
this while maintaining a very good coverage of the platforms
involved. To our knowledge, no other tracking method (or
a combination of several tracking techniques) achieves all
these goals simultaneously. Moreover, the Windows variant
of this technique also survives Windows shutdown+startup
(but not restart).

Our techniques are realistic: for Windows we only need
to have control over 8-30 IP addresses (in 3-13 class B net-
works), and for Linux/Android, we only need to control 300-
400 IP addresses (can be in a single class B network). The
Windows technique was successfully tested in the wild.

1.1

Introduction to IP ID

The IP ID ﬁeld is a 16 bit IP header ﬁeld, deﬁned in RFC
791 [22]. It is used to facilitate de-fragmentation, by mark-
ing IP fragments that belong to the same IP datagram. The
IP protocol assembles fragments into a datagram based on
the fragment source IP, destination IP, protocol (e.g. TCP or
UDP) and IP ID. Thus, it is desirable to ensure that given the
same source address, destination address and protocol, the
IP ID does not repeat itself in short time intervals. Simulta-
neously, the IP ID should not be predictable (across different
destination IP addresses) since “[IP ID] predictability allows
trafﬁc analysis, idle scanning, and even packet injection in
speciﬁc cases” [53].

Designing an IP ID generation algorithm that meets both
requirements is not straightforward. Since IPv4 was stan-
dardized, several schemes have emerged:

• Global counter – This approach was used in the early
IPv4 days due to its simplicity and its non-repetition

period of 65536 global packets. However it is extremely
predictable and thus insecure, hence abandoned.

• Counter/bucket based algorithms – This family of algo-
rithms, suggested by RFC 7739 [18, Section 5.3],1 is
the focus of our work. It uses a table of counters, and
a hash function that maps a combination of a source
IP address, destination IP address, key and sometimes
other elements into an index of an entry in the table. IP
ID is generated by choosing the counter pointed to by
the hash function, possibly adding to it an offset (which
may depend on the IP endpoints, key, etc.), and ﬁnally
incrementing the counter. The non-repetition period in
this family is 65536 global packets. At the same time,
knowing IP ID values for one pair of source and destina-
tion IP addresses does not reveal anything about the IP
IDs of other endpoints (except those that use the same
bucket) – i.e.
it fulﬁlls the non-predictability require-
ment for almost all other IP destination addresses. This
family of algorithms is, therefore, a trade-off between
security and functionality.

• Searchable queue-based algorithm – This algorithm
maintains a queue of the last several thousand IP IDs
that were used. The algorithm draws random IDs un-
til one is found that is not in the queue. Then this ID
is used as the next IP ID, pushed to the queue, and
the least-recently used value is popped from the queue.
This algorithm ensures high unpredictability, and guar-
antees a non-repetition period as long as the queue.

Windows (version 8 and later) and Linux/Android imple-
ment variants of the counter-based algorithm. MacOS and
iOS implement a searchable queue algorithm.

1.2 Introduction to KASLR

KASLR (Kernel Address Space Layout Randomization [56])
is a security mechanism designed to defeat attack techniques
such as ROP (Return-Oriented Programming [47]) that rely
on the predictability of kernel code addresses. KASLR-
enabled kernels randomize the kernel image load address
during boot, so that kernel code addresses become unpre-
dictable. While, e.g.
in the Linux x64 kernel, the entropy
of the load address is 9 bits, a brute force attack is deemed
irrelevant since each failure usually ends in a system freeze
(“kernel panic”). A typical KASLR bypass enables the at-
tacker to obtain a kernel address (from which, addresses to
useful kernel code gadgets can be calculated as offsets) with-
out de-stabilizing the system.

1.3 Our Approach

source IP address, the destination IP address, and a key K
which is generated when the source machine is restarted and
is never changed afterwards. We run a cryptanalysis attack
which analyzes the IP ID values that are sent by a device and
extracts the key K. This key can then be used to identify
the source device, because subsequent attacks will yield the
same key value (until the device is restarted).

In more detail, IP ID generation in both systems maintains
a table of counters and uses a hash function to choose which
counter is used for each connection. It seems hard to deploy
an attack based on the value of the counter, since each IP ID
might depend on a different counter. Instead, our attack tech-
niques rely on identifying and exploiting collisions which
map two destination IP addresses to the same counter. This
enables us to extract information about the key that caused
the hash values to collide (Linux), or (in Windows) extract
information about the offset of the IP ID from the counter.
These values depend on K and therefore enable us to learn K
and identify the machine.

Our approach does not rely on an a-priori knowledge of
the counter values. Moreover, after we reconstruct K, we
can reconstruct the current counter values (in full or in part)
by sending trafﬁc to specially chosen IP addresses, obtaining
their IP ID values and with the knowledge of K, work back
the counter values that were used to generate them.
Linux/Android KASLR bypass Support
for network
namespaces (part of container technology) was introduced in
Linux kernel 4.1. With this change, the key K was extended
to include 32 bits of a kernel address (the address of the net
structure for the current namespace). Thus, reconstructing
K also reveals 32 bits of a kernel address, which sufﬁces to
reconstruct the full address and be able to bypass KASLR.2
Conclusion In general, our work demonstrates that the us-
age of a non-cryptographic algorithm for the generation of
attacker observable values such as IP ID, may be a security
vulnerability even if the values themselves are not security-
sensitive. This is due to an attacker’s ability to extract the
key used by the algorithm generating the values, and use this
key to track or attack the system.

1.4 Advantages of our Technique

Tracking machines based on the key that is used for generat-
ing the IP ID has multiple advantages:

Browser Privacy Mode: Since our technique exploits the
behavior of the IP packet generator, it is not affected if the
browser runs in privacy mode.

Cross-Browser: Since our technique exploits the behav-
ior of the IP packet generator, it yields the same device

The IP ID generation mechanisms in Windows and in Linux
(UDP only) both compute the IP ID as a function of the

1While RFC 7739 focuses on IPv6, its proposed algorithms and discus-

sions are also applicable to IPv4.

2Through our IP ID attack we were also able to achieve partial KASLR
bypass, and a partial list of loaded drivers, with regards to Windows 10
RedStone 4. This attack was based on an additional initialization bug in
Windows. However, that bug was repaired in the October 2018 security
update and the corresponding KASLR bypass is not effective anymore.

ID regardless of the browser used. It should be noted that
browsers (like Tor browser) that relay transport protocols
through other servers are not affected by our technique.

Network change: Tracking works across different net-
works since our technique uses bits of K as a device ID, and
K does not depend on the device’s IP address or network.

The “Golden Image” Challenge: Since each device gen-
erates its own key K in a random fashion at O/S restart, even
devices with identical software and hardware will most likely
have different K values and thus different device IDs.

Not easily turned off: IP ID generation is built into the
kernel, and cannot be modiﬁed or switched off by the user.
Furthermore, the Windows attack can use simple HTTP traf-
ﬁc. The Linux/Android attack requires WebRTC which can-
not be turned off for mobile Chrome and Firefox.

VPN resistant: The device ID remains the same when the

device uses an IP-layer VPN.

Windows shutdown+startup vs.

restart: The Fast
Startup feature of Windows 8 and later,3 which is enabled
by default, saves the kernel to disk on shutdown, and reloads
it from disk on system startup. Therefore, K is not re-
initialized on startup, and keeps its pre-shutdown value. This
means that the tracking technique for Windows survives sys-
tem shutdown+startup. On restart, in contrast, the kernel is
initialized from scratch, and a new value for K is generated,
i.e. the old device ID is no longer in effect.

Scalability: Our technique can support billions of devices
(Windows, Linux, newer Androids), as the device ID is
random, and thus ID collisions are only expected due to the
birthday paradox. Thus the probability of a single device not
to have a unique ID is very low.

It should be noted that in the Linux/Android case, due
to the use of 300-400 IP addresses, the need to “dwell” on
the page for 8-9 seconds, and (in newer Android devices)
the excessive attack time, there are use cases in which the
technique may be considered invasive and/or inapplicable.

1.5 Additional Contributions

In addition to the cross-browser tracking technique for
Windows and Linux, our work introduces multiple additional
contributions.

With respect to Windows, we also show
• The ﬁrst full public documentation of the IP ID gen-
eration algorithm in Windows 8 and later versions, ob-
tained via reverse-engineering of the relevant parts of
Windows kernel tcpip.sys driver.

• Cryptanalysis of said algorithm, resulting in a practi-
cal technique to extract 40-45 bits of its key. This anal-
ysis is applicable to all Windows 8 and later operating
systems.

3https://blogs.msdn.microsoft.com/olivnie/2012/12/14/

windows-8-fast-boot

• A scaled down demo implementation of the Windows
tracking technique, using only 15 IP addresses (+2 IP
addresses for veriﬁcation) and providing a 40-bit device
ID for a ﬁeld experiment. We provide results from an
extensive in-the-wild experiment spanning 75 networks
in 18 countries, demonstrating the practicality and ap-
plicability of the technique, and also demonstrating that
IP IDs are rarely modiﬁed in transit.

With respect to Linux/Android, in addition to a cross-
browser tracking technique we also show a full kernel ad-
dress disclosure (KASLR bypass), based on revealing a ker-
nel address which is in the .data segment of the kernel im-
age.

We disclosed the vulnerabilities to Microsoft and Linux.
Microsoft ﬁxed the issue in Windows April 2019 Security
Update (CVE-2019-0688).45 Linux ﬁxed the kernel ad-
dress disclosure (CVE-2019-10639) together with partially
addressing the key-based tracking technique (by extending
the key to 64 bits) in a patch6 applied to Linux kernel ver-
sions 5.1-rc4, 5.0.8, 4.19.35, 4.14.112, 4.9.169 and 4.4.179.
For 3.18.139 and 3.16.67, Linux applied a patch7 we devel-
oped, that extends the key to 64 bits. The key-based tracking
technique (CVE-2019-10638) is fully addressed in a patch,8
part of kernel versions 5.2-rc1, 5.1.7, 5.0.21, 4.19.48 and
4.14.124.

2 The Setting

We assume that device tracking is carried out over the web,
using an HTML snippet (which can be embedded by a 3rd
party site/page). The snippet forces the browser to send TCP
or UDP trafﬁc (one packet per destination IP sufﬁces) to
multiple IP addresses under the tracker’s control (8-30 ad-
dresses for Windows, 300-400 for Linux/Android). Ideally,
such transmission would be rapid. In our experiments, this
can be done in few seconds or less.

4https://portal.msrc.microsoft.com/en-US/

security-guidance/advisory/CVE-2019-0688

5The old (vulnerable) logic is still available for Windows 10 versions
below 1903 via a registry setting: if during system startup, the registry key
HKLM\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters
contains a value named EnableToeplitzHashForIPID of type DWORD
with data 0x00000001, then the Toeplitz-based logic is used to generate
the IP ID. By default, this value is absent, hence the new (ﬁxed) logic is
used. This registry ﬂag is not in effect for Windows 10 versions 1903 and
above.

6“netns:

for
(https://github.com/torvalds/linux/commit/
355b98553789b646ed97ad801a619ff898471b92)

entropy

provide

pure

net_hash_mix()”

7“inet:

update
standards”

the

ID

IP
algorithm to
(https://git.kernel.org/pub/scm/

generation

higher
linux/kernel/git/stable/linux.git/commit/?id=
55f0fc7a02de8f12757f4937143d8d5091b2e40b)

8“inet: switch IP ID generator to siphash” (https://git.kernel.

org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/
?id=df453700e8d81b1bdafdf684365ee2b9431fb702)

For the Windows attack, the tracker needs to choose the IP
addresses according to some trivial constraints (the Linux IP
addresses are not subject to any constraints). A discussion of
the exact constraints and their trade-offs can be found in the
following sections. At the server side, the tracker collects
the IP ID values sent by the client to each of the IPs, and
computes a device ID consisting of bits of the key in the
device’s kernel data that is used to calculate the IP ID.

Additional scenarios (KASLR bypass and internal IP dis-
closure) for Linux/Android attacks are described in Ap-
pendix G.

3 Related Work

Many tracking techniques were suggested in prior research.
At large, proposals can be categorized by their passive/active
nature. We use the terminology deﬁned in [59]:

• A ﬁngerprinting technique measures properties already
existing in the browser or operating system, collecting a
combination of data that ideally uniquely identiﬁes the
browser/device without altering its state.

• A tagging technique, in contrast, stores data in the
browser/device, which uniquely identiﬁes it. Further
access to the browser can “read” the data and identify
the device.

As described in Section 1, ﬁngerprinting techniques typically
cannot guarantee the uniqueness of the device ID, in partic-
ular with respect to corporate machines cloned from “golden
images”. Tagging techniques store data on the device, and
as such they are more easily monitored and evaded. A com-
prehensive discussion of tracking methods can be found in
Google Chromium’s web page “Technical analysis of client
identiﬁcation mechanisms” [23].

3.1 Fingerprinting

There is a major drawback to ﬁngerprinting techniques,
which is that typically they cannot guarantee the uniqueness
of the device ID. This problem becomes acute when consid-
ering organizations wherein desktops and laptops are cloned
from “golden images”, thus making those devices practi-
cally indistinguishable for passive techniques. (Furthermore,
since ﬁngerprinting techniques are known and understood
nowadays, countermeasures are already deployed against
some of these techniques.) For example, font-based ﬁnger-
printing, User-Agent header ﬁngerprinting, WebGL (canvas)
ﬁngerprinting, browser plugin/extension ﬁngerprinting, and
CPU/GPU performance ﬁngerprinting are all methods that
cannot distinguish between systems that are based on the ex-
act same hardware and software. Recently, [10] improved
the accuracy of some of these techniques, and introduced
new variants, and [58] measured the longevity of various ﬁn-
gerprinting techniques, and found it limited (and provided

suggestions to increase their longevity). However, none of
these works addressed the above fundamental shortcoming.
Below we discuss the few ﬁngerprinting techniques that do
cover the “golden image” scenario:
DNS-based ﬁngerprinting methods: [3] suggests using the
DNS resolver IP address as a ﬁngerprint. However, in an
enterprise (or an ISP, or a campus), multitude of clients use
the same resolver, and as such, this DNS-based ﬁngerprint-
ing method does not contribute toward distinguishing among
these clients.
Clock skew: [31] describes how to remotely measure an
endpoint’s TCP timestamp clock skew. However, nowadays
the risk of enabling TCP timestamps is well understood, and
in Windows 7 and later, this feature is disabled by default.
[50] describes how to measure the CPU clock skew using
Javascript, however they do not compute a unique ID, but
rather attempt to match a signature of a previous measure-
ment, which, even with 300 devices, resulted in at least 20%
multiple matches.
Using the Javascript Math.random() seed: This attack
([27]) was addressed by browser vendors in 2008-2010 and
is no longer effective.
Ephemeral source ports in outgoing requests: This tech-
nique does not work behind a ﬁrewall/NAT, as oftentimes
the ﬁrewall/NAT replaces the original client source port with
a port from its own pool. Furthermore, the ports are drawn
from a small space (up to 216 values) which leads to colli-
sions, and moreover, it requires constant monitoring to track
devices.
Motion sensors (in mobile devices): it is possible to ﬁn-
gerprint mobile devices in the browser using deviations in
their motion sensors. In general, these techniques are lim-
ited in their coverage to such mobile devices that have the
required motion sensors. According to [8], deviations in the
accelerometer readouts can be used as a ﬁngerprint, but this
requires the mobile device not to move while the measure-
ment takes place. [14] suggests using the accelerometer and
gyroscope, but their calibration process is time consuming,
and the accuracy reported (93%) is insufﬁcient for large scale
deployments.
User action history: Except for DNS (see below), privacy
mode renders this technique ineffective.

3.2 Tagging

In general, tagging methods are a well understood privacy
threat. Therefore, one of the goals of the privacy modes that
are implemented in major browsers is to make the tagging
methods identify a private browsing session as a distinct in-
stance, which has a different tag than that of the “regular”
browser. Private browsing sessions also typically clear their
residual data upon termination and start with an empty set of
data when launched.

A summary of the privacy mode boundary-crossing status

of many tagging techniques appears in [9, Table IV]. As is
depicted in that table, almost all tagging techniques do not
cross the private browsing boundary for most browsers. In
general, nowadays tagging attempts are blocked by the rel-
evant software vendors. For example, Flash cookies do not
cross the privacy mode boundary ([60]), and anyway, Flash
nowadays requires user interaction in order to run.

There are some advanced tagging techniques that are not
covered in [9], and yet do not cross the privacy mode bound-
ary:
TLS-based: The TLS token binding protocol speciﬁcally re-
quires browsers to separate privacy mode tokens from the
regular browser tokens ([45, Section 7.3]). Firefox provides
a separation between the regular browser and privacy mode
with respect to TLS session identiﬁers and session tickets
([42]), and likewise Chrome ([13]). Recently, a similar tech-
nique, using TLS 1.3’s session resumption (and session tick-
ets) was described by [55], but it suffers from the above same
drawbacks.
HSTS-based: HSTS data does not cross the privacy mode
boundary in Chrome[23], Firefox[54] and Safari[54].
HTTPS Public Key Pinning (HPKP): [62] describes a tag-
ging technique based on HPKP. However, HPKP is being
deprecated - it is only supported nowadays by Firefox.
DNS cache ﬁngerprinting/tagging (timing based): A
DNS-based ﬁngerprinting method is proposed in [16], which
can reveal elements of the user’s browsing history. This ﬁn-
gerprinting method could in theory be converted to a tagging
method. However the “read tag” operation is destructive as
it changes the data (the tag).
DNS cache-based tagging: Recent work [29] describes a
tagging technique based on client side caching of resolved
DNS names, where the resolution contains random elements
which provide statistic uniqueness. This technique does not
work across different networks (as clients typically ﬂush
their DNS cache when connecting to a new network), and
its longevity is limited by the TTL cap imposed by resolvers
and stub resolvers.

3.3

IP ID Research

Device tracking via IP ID: Using IP ID is proposed in [6]
(2002) to detect multiple devices behind a NAT, assuming an
IP ID implementation using a global counter. But nowadays
none of the modern operating systems implements IP ID as
a global counter. A similar concept is presented by [43] for
a single destination IP (the DNS resolver) which theoreti-
cally works for devices that have per-IP counter (Windows,
to some extent). However, this technique does not scale be-
yond a few dozen devices, due to IP ID collisions (the IP ID
ﬁeld provides at most 216 values), and requires ongoing ac-
cess to the trafﬁc arriving at the DNS resolver.
Predictable IP ID: The predictability of IP ID may theo-
retically be used in some conditions to track devices. [17]

describes a technique to predict the IP ID of a target, but re-
quires the adversary to have a fully controlled device along-
side it behind the same NAT. Also this technique only han-
dles sequential increments (e.g. not time-based). As such, it
is inapplicable to the more general scenarios handled in this
paper. This technique is then used in [20] to poison DNS
records.
OS Fingerprinting: [61] suggests using IPID = 0 as a ﬁn-
gerprint for some operating systems.
Measuring trafﬁc: [52] samples IP ID values from servers
whose IP ID is a global counter, to estimate their outbound
trafﬁc.
IP ID Algorithm Categorization: [49] provides practical
classiﬁcation of IP ID generation algorithms and measure-
ments in the wild.
Fragmentation attacks: While not directly related to the
properties of the IP ID ﬁeld, it should be noted that attack
techniques abusing fragmentation are known. RFC 1858
[46] lists several such attacks, e.g.
the “tiny frgament” at-
tack and the “overlapping fragement” attack.

Windows IP ID research: In parallel to our research, Ran
Menscher published on Twitter his research on Windows IP
ID [39]. That research reverse-engineered part of the Win-
dows IP ID generation algorithm (without revealing how the
index to the counter array is calculated). The analysis of this
algorithm is based on two assumptions: (1) that the tech-
nique is applied shortly after restart, when the relevant mem-
ory buffer contains zeroes in a large part of its cells; and
(2) that the attacker controls or monitors trafﬁc to pairs of IP
addresses which differ in single, speciﬁc bit position (includ-
ing positions in the left half of the address). Based on these
extreme assumptions, the attacker can extract the key eas-
ily, and use it to expose kernel 31-bit data quantities (though
without learning where in the array this data resides).

The uninitialized memory issue exploited by this attack
was ﬁxed in Microsoft’s October 2018 Security Update [41],
which invalidated assumption (1), rendering Menscher’s at-
tack completely ineffective. Our attack and our demo, on the
other hand, still work against systems that were patched with
this update. Our work has multiple contributions over Men-
scher’s attack: (1) We provide the full details of the IP ID al-
gorithm. (2) Our analysis does not rely on the array data, and
is thus still in effect after applying the October 2018 Security
Update which initializes the array with random data. (3) Our
analysis does not require the extreme requirements on the re-
lations between the addresses of the controlled/monitored IP
addresses. (4) Our kernel data exposure provides positions
of the data, not just data quantities (though our kernel expo-
sure technique, too, was eliminated with the October 2018
Security Update). (5) It should also be noted that unlike our
attack, Menscher’s technique could not be used for tracking,
since as the cell arrays become non-zero when they are in-
cremented, the attack becomes ineffective.

3.4 PRNG seed/key extraction

Our approach involves breaking the random number gen-
erator algorithm used by operating systems to generate the
IP ID value and obtain the seed/key used by the algorithm.
Similar strategies were used to different ends. For example,
[32] broke the PRNG of the Witty worm to obtain the seed,
from which they learned the infection time of the Internet
nodes. [27] broke the Javascript Math.Random() PRNG of
several browsers, obtained the seed and used it as a browser
instance tracking ID. [28] broke the Math.Random() PRNG
of Adobe Flash, obtained the seed and used it to extract the
machine clock speed.

4 Tracking Windows 8 (and Later) Devices

In this section we ﬁrst present the algorithm that is used for
generating the IP ID in Windows 8 (and later) devices. The
input to this algorithm includes a key which is generated at
system restart. We then describe how a remote server can
identify 45 bits of this key. This data enables to remotely
and uniquely identify machines.

4.1

IP ID Generation

IP ID prior to Windows 8
In versions of Microsoft Win-
dows up to and including Windows 7, the IP ID was gener-
ated sequentially and globally. That is, for each outgoing IP
packet, a global counter would be incremented by 1 and the
result (truncated to 16 bits) would be used [43]. These older
Windows versions are out of scope for this paper.

The source code of the algorithm that is used for gener-
ating IP ID values in Windows is not public. However, we
recovered the exact algorithm using reverse engineering, and
veriﬁed its correctness by comparing its output to IP ID val-
ues generated by live Windows systems.
Technical details The algorithm was obtained by reverse-
engineering parts of the tcpip.sys driver of 64-bit Win-
dows 10 RedStone 4 (April 2018 Update, Build 1803). Ap-
parently this algorithm is in use starting with Windows 8
and Windows Server 2012.
It was positively tested with
Windows 8.1 (64-bit), Windows 10 (64-bit), Windows 2012,
Windows 2012 R2 and Windows 2016. The algorithm was
veriﬁed with TCP and UDP over IPv4. The 32 trailing zero
bits used in the calculation of the v variable are hard-wired
in the code. Notice that the code is not speciﬁc to IPv4, and
can be used with IPv6, which is why the key K is deﬁned as
320 bits - more than required to support IPv4.9 For IPv4 pre
RedStone 5, only 106 key bits — K17,...,94 (78 bits), K117,...,31
(15 bits) and K219,...,31 (13 bits) — are used.

Henceforth, the term “IP” is used as a synonym to “IPv4”.
Also, in order to simplify the discussion, it is assumed that

9 Our tracking technique can be probably adapted to IPv6, but since IPv6

is out of scope for this paper, we did not test this.

v is returned modulo 215 even with Windows 10 RedStone 5
(October 2018 Update, Build 1809), i.e. the most signiﬁcant
bit of the IP ID is simply discarded in this case.

Toeplitz hash The IP ID generation is based on the
Toeplitz hash function deﬁned in [21]. Let us ﬁrst deﬁne
the Toeplitz hash, T (K, I), which is a bilinear transformation
from a binary vector K in GF(2)320, and an input which is a
binary string I (where |I| ≤ 289) to the output space GF(2)32.
For a binary vector V , denote by Vi the i-th bit in the vector,
with bit numbering starting from 0. The i-th bit of T (K, I)
(0 ≤ i ≤ 31) is deﬁned as the inner product between I and a
substring of K starting in location i. Namely

T (K, I)i =

|I|−1
(cid:77)

j=0

I j · Ki+ j

(1)

IP ID generation The IP ID generation algorithm itself
uses keys K (tcpip!TcpToeplitzHashKey) which is a 320
bit vector, and K1 and K2 which are 32 bits each. All these
keys are generated once during Windows kernel initialization
(using SystemPrng and BCryptGenRandom).

In addition to these constant keys, the algorithm uses a
dynamic array of M counters, denoted β [0], . . . , β [M − 1],
where M is a power of 2, and is speciﬁcally set to M = 8192.
Algorithm 1 describes how Windows 8 (and later) gener-
ates an IP ID for a packet delivered from IPSRC to IPDST ,
while updating a counter in β .

The algorithm uses the keys, and the source and destina-
tion IP addresses, to pick a random index i for a counter in β ,
and an offset. The algorithm outputs the sum of the counter
β [i] and the offset, and increments the counter.
Notation We use the notation Num(a0, a1, . . . , a31) for the
number represented in binary by the bits ai, namely the num-
ber ∑31
i=0 ai · 231−i. (Network byte order is used throughout
the paper for representing IP addresses as bit vectors, e.g.
127.0.0.1 is 01111111.00000000.00000000.00000001.) For
a vector V = (V0, . . . ,Vn), denote by Vi,..., j the sub-vector
(Vi, . . . ,Vj).
Properties of the Toeplitz hash Our attack uses the fol-
lowing properties of T , which follow from the linearity of
this transformation:

T (K, I||(0, 0, . . . , 0)) = T (K, I)

(2)

Therefore the trailing zeros in the input of T in the compu-
tation of v on line 3 of Algorithm 1, have no effect on the
output. Also,

T (K, I1||I2) = T (K, I1) ⊕ T (K, 0|I1|||I2)

(3)

Therefore it is possible to decompose the second input of T
to two parts, and rephrase the computation as the XOR of
two separate expressions.

Algorithm 1 Windows 8 (and later) IP ID Generation

1: procedure GENERATE-IPID
2:

i ← Num(K2 ⊕ T (K, (IPDST )
v ← β [i] + Num(K1 ⊕ T (K, IPDST ||IPSRC||032)) mod 232
β [i] ← (β [i] + 1) mod 232
return v mod 215

2 −1

|IPDST |

0,...,

) ⊕ T (K, IPSRC)) mod M

3:
4:
5:

4.2 Reconstructing the Key K

To reconstruct the key, the device needs to be measured. The
measurements only take a few seconds, and are thus assumed
to take place from the same network. I.e., the device’s source
IP address, IPSRC, is ﬁxed (though possibly unknown). A
ﬁrst set of measurements directs the client device to J IP ad-
dresses from the same class B network. A second set of mea-
surements directs the client device to G pairs of IP addresses,
each pair in the same class B network, with G different class
B network pairs in the set.

Once the device is measured, the attack proceeds in two
phases. The ﬁrst phase of the attack recovers 30 bits of the
key using the ﬁrst set of measurements. The second phase
of the attack reveals additional 15 bits of the key using the
30 bits recovered in the ﬁrst phase and the second set of
measurements. Overall, the measurements reveal 45 bits of
the key, which sufﬁces to uniquely identify machines from a
large population, with high probability.

Section 4.5 describes how to optimally choose the param-
eters J and G given limits on the number of IP addresses that
are available (L) and the processing time that is allowed (T ).
For L = 30 IP addresses (typical low budget limit), and attack
run time limit of T = 1 seconds on a single Azure B1s ma-
chine (α = 0.001 from Section 5.2), the optimal parameter
values are J = 6, G = 12.

4.3 Extracting Bits of K - Phase 1

Denote by IPg, j, IPIDg, j and β [ig]g, j the values of the des-
tination IP address, the IP ID and β [i] (prior to increment)
respectively, with respect to the j-th packet in the g-th class
B network that is used in the attack ( j and g are counted
0-based). The ﬁrst phase of the attack uses only a single
class B network, and therefore g is set to 0 in this phase.
We thus use the following shorthand notation: IP j = IP0, j,
IPID j = IPID0, j and βg = β [ig]g,0.

A major observation is that only the ﬁrst half of IPDST is
used to calculate i in Algorithm 1. Therefore packets that are
sent to different IP addresses in the same class B network,
have an identical index i into the counter table, and use the
same counter β [i]. Denote the value of i for the g-th class B
network as ig.

If these packets are sent in rapid succession (i.e. when no
other packet is sent in-between with i = ig), then β [ig]g, j =
βg + j mod 232, and therefore the output in line 5 of the

(cid:46) v mod 216 for Windows 10 RedStone 5

algorithm is calculated with β [ig]g, j = βg + j mod 215 (for
simplicity, in Windows 10 RedStone 5, we discard the most
signiﬁcant bit of the IP ID).

We focus in this phase on the ﬁrst class B network, b0,
with J destination IP addresses in it. Note that the offset that
is calculated in line 3 is the difference between the IPID and
the counter β [i0] prior to its increment.

The attack enumerates over the values of the β0 mod 215
counter.10 For each possible value it calculates the differ-
ences between the observed J IPIDs and the corresponding
values of the counter, arriving at the offsets calculated in line
3. By observing pairs of IPIDs, it is possible to identify the
correct value of β0 mod 215 as well as 30 bits of the key.

In more detail, for each possible value of β0 mod 215 the

attack calculates the difference

IPID j − (β0 + j mod 215) mod 215

which, for the right value of the counter should be equal to
the offset that is calculated in line 3. Namely to

Num(K1 ⊕ T (K, IP j||IPSRC||032)) mod 215

value

This
be
T (K, IP j||IPSRC||032))17,...,31.
eq. (3), this expression is simpliﬁed into:

expressed

as
Applying eq.

can

(K1 ⊕
(2) and

(K1 ⊕ T (K, IP j) ⊕ T (K, 032||IPSRC))17,...,31

.

The attack takes two different j values and computes the
XOR of the two corresponding such quantities. This results
in the following expression (where we denote by Vec a rep-
resentation of a number in [0, 232) as a vector in GF(2)32):

(Vec(IPID j − (β0 + j) mod 215)⊕

Vec(IPID j(cid:48)

− (β0 + j(cid:48)) mod 215))17,...,31 =
T (K, IP j ⊕ IP j(cid:48)

)17,...,31

This yields 15 linear equations (i = 17, . . . , 31) on K since

(from eq. (1)):

T (K, IP j ⊕ IP j(cid:48)

)i =

31
(cid:77)

(IP j ⊕ IP j(cid:48)

)m · Ki+m

m=0

10Actually, we show in Appendix C.2 that one bit of this value is canceled
out by the algorithm, and therefore the attack enumerates over only 14 bits.
We ignore this fact for now to simplify the exposition.

Since all IP j belong to the same class B network, IP j ⊕ IP j(cid:48)
always has 0 for its ﬁrst 16 bits, and therefore m can start at
16. Due to obvious linear dependencies, only J − 1 sets of
such equations are useful (e.g. all pairs with j(cid:48) = 0), with a
total of 15(J − 1) linear equations for bits K33, . . . , K62. That
is, for j = 1, . . . , J − 1 and i = 17, . . . , 31, the equations are:

31
(cid:77)

(IP j ⊕ IP0)m · Ki+m =

m=16

(Vec(IPID j − (β0 + j) mod 215) ⊕

Vec(IPID0 − (β0) mod 215))i

(4)

Speeding up the computation using preprocessing The
coefﬁcients of K in eq. (4) are controlled by the server and
are known at setup time. Therefore it is possible to prepro-
cess the computation of Gaussian elimination. Namely, com-
pute a matrix Z that, when multiplied by the observed values,
reveals bits of the key. This preprocessing is important for
efﬁciency, and we describe in Appendix A.1 how it can be
done. Readers who are only interested in the feasibility of
the attack and not in its details can skip that appendix.

Attack summary

1. The tracker needs to control J IP addresses in the same

class B network.

2. During setup time, the tracker calculates, using Gaus-
sian elimination, a matrix Z ∈ GF(2)15(J−1)×15(J−1),
based on the values of these IP addresses.

3. In real time, the tracker gets IP ID values from the de-
vice, from packets sent to the J destination IP addresses
under the tracker’s control.

4. The tracker then guesses 14 bits (β0 mod 214 - the most
signiﬁcant bit of β0 mod 215 cancels itself in eq. (4))
of the counter that is used for these IP addresses, cal-
culates vectors D j ( j = 1, . . . , J − 1), that are deﬁned
as differences of functions of the observed IP IDs (de-
tails in Appendix A.1) and performs a matrix-by-vector
multiplication of Z and the vector (D0, . . . , DJ−1).
For the correct value of β0 mod 214 this computation
results in a vector of 15(J − 1) bits, whose ﬁrst 30 bits
are K33, . . . , K62 and the remaining bits are zero.

5. The attacker identiﬁes the right value of the counter by
comparing to zero the 15(J − 1) − 30 bits starting at po-
sition 31: if 15(J − 1) − 30 (cid:29) 14, this veriﬁcation sta-
tistically guarantees the correctness of the solution (up
to a ﬂipped most signiﬁcant bit in β0 mod 214, see Ap-
pendix C.2.)

Overall this process reveals 30 bits of the key as well as

the value (β0 mod 214).

The attack takes 214 · (15(J − 1))2 bit operations (for enu-
meration over the possible key values and for the matrix-by-
vector multiplication),11 and (15(J − 1))2 memory bits (for
Z). As explained in Section 4.5, we set J = 6 and therefore
this overhead is very small.

The tracker obtains the (correct) value β0 mod 214, which
will be used in the next phase. While it is guaranteed that
the correct K and β0 mod 214 will be found, the algorithm
may emit additional candidates (with incorrect β0 mod 214).
The false positive probability of both phases of the attack is
analyzed in Appendix C.12

4.4 Extracting Bits of K - Phase 2

Given 30 bits of K (K33, . . . , K62) and the value (β0
mod 214), recovered in Phase 1, the attack can be extended
to learn a total of up to 45 key bits (K18, . . . , K62). This is
done in the following way. The offset for IPID0 computed in
line 3 of Algorithm 1 is:

Num(K1 ⊕ T (K, IP0) ⊕ T (K, 032||IPSRC)) mod 215 =

(IPID0 − β0) mod 215

The following equation follows from the previous one:

(K1 ⊕ T (K, 032||IPSRC))17,...,31 = T (K, IP0)17,...,31⊕

Vec(IPID0 − β0 mod 215)17,...,31

The tracker looks at pairs of IP addresses in the remaining
B classes (b1, . . . , bG), each pair in a different class B net-
work. Denote each such pair as (IPg,0, IPg,1), with the order
inside the pair conforming to the order of packet transmis-
sion, and the packets being transmitted in rapid succession.
Substituting the above into the deﬁnition of IPID yields:
IPIDg, j = βg + j + Num( T (K, IP0)17,...,31

⊕ Vec(IPID0 − β0 mod 215)17,...,31
⊕ T (K, IPg, j)17,...,31 ) mod 215

Using the linearity of T , this is simpliﬁed into:
IPIDg, j = βg + j + Num ( T (K, IP0 ⊕ IPg, j)17,...,31 ⊕
Vec(IPID0 − β0 mod 215)17,...,31 ) mod 215

(5)

Let us use the notation

Sg, j = Num ( T (K, IP0 ⊕ IPg, j)17,...,31 ⊕

Vec(IPID0 − β0 mod 215)17,...,31 ) mod 215

11Run time can be improved by conducting the comparison to zero on a
vector-by-vector basis, eliminating on the ﬁrst non-zero value encountered.
This requires an average of 2 · 214(15(J − 1)) bit operations

12Note: Throughout the paper, we assume that rank(C) = 30. This results
in a single key vector per guessed β0 mod 214. We discuss the conditions
on IP0, . . . , IPJ−1 to meet this assumption in Appendix B. If rank(ker(C)) >
0, then each guess of β0 mod 214 yields 2rank(ker(C)) possible keys. Thus
small values of rank(ker(C)) are acceptable.

Then eq. (5) becomes

4.5 Choosing Optimal G and J

IPIDg, j = βg + j + Sg, j mod 215

Subtracting the IPIDs of the two consecutive packets in
the same B class (with j = 0 and j = 1) cancels the value of
the counter βg, and yields:
(IPIDg,1 − IPIDg,0) mod 215 = 1 + Sg,1 − Sg,0 mod 215
(6)
The left side of the equation is observed by the tracker.
The right side can be computed based on β0 mod 215 and
K17, . . . , K62.13 The tracker already knows these values ex-
cept for K18, . . . , K33, and therefore only needs to enumerate
over the 215 possible values of K18, . . . , K32 and eliminate all
values which do not agree with the equation. We discuss this
procedure in depth in Appendix A.2.

Attack summary:

1. The tracker needs to control additional G pairs of IPs

(each pair in its own class B network).

2. Given IP IDs for these pairs, the tracker enumerates
over additional 15 key bits, and then, for each pair of
IP addresses, calculates both sides of eq. (6) and com-
pares them. For this calculation the tracker can choose
K17 and the leftmost bit of β0 mod 215 arbitrarily, as
they will both cancel themselves.

3. In theory, each IP pair should yield a 215 elimination
power for identifying the right key, but see Appendix C
for a more accurate analysis.

4. In the calculation, the leading term (in terms of run
time) is computing T (K, I)17,...,31 (where |I| = 32),
which takes 14|I| bit operations, and is used twice.
Thus, the run-time is roughly 215 · 2 · 14 · 32 bit opera-
tions (there is no multiplication by G since the ﬁrst pair
is likely to eliminate almost all false guesses).

At the end of Phase 2, the tracker obtains:

• A partial key vector (or some candidates) K18, . . . , K62
(45 bits), which is speciﬁc to the device since it was
set during kernel initialization, and does not depend on
IPSRC. These bits serve as a device ID.

• The value

(K1 ⊕ T (K, 032||IPSRC))18,...,31 = T (K, IP0)18,...,31
⊕ Vec(IPID0 − β0 mod 214)18,...,31

This value allows the tracker to calculate (assuming
K18, . . . K62 are known) the value of the counter β [i]
mod 214 for any destination IP address whose IP ID is
known (provided the source IP is IPSRC).14

13As explained in App. A.2, the bit K17 does not affect the computation.
The same holds for the most signiﬁcant bit of β0 mod 215, so knowing β0
mod 214 sufﬁces for the attack.

14This is useful for reconstructing the table β of counters (Appendix D.)

For Windows, we assume budget-oriented constraints,
namely L available IP addresses and T CPU time per mea-
surement. We need to set the number J of IP addresses from
the same class B network to which the client is directed in
the ﬁrst set of measurements, and the number G of pairs of
IP addresses, each pair in the same class B network, used in
the second set of measurements.

Our goal is to optimize for minimum false positives. The
ﬁrst constraint can be expressed as J + 2G ≤ L. As for the
second constraint, the leading term of the time of the attack
run is α · (J!) (Appendix A.3.2), where α expresses the com-
puting platform’s strength. Therefore, we can approximate
the second constraint as α · (J!) ≤ T . Additionally, there
are inherent constraints: J − 1 ≥ 3 to let Phase 1 suggest a
single key candidate to Phase 2 (most of the time), and G ≥ 2
to let Phase 2 provide a single ﬁnal key (most of the time).

Given these constraints, we want to minimize the leading
term in false positives, 2 · 2− G+J−1
(Appendix C), i.e. we
need to maximize G + J. Since we “pay” two IP addresses
for each increment of G and only one IP address for each
increment of J, we should make J as large as possible (as
long as G is valid), so the solution is:

2

J = min(max({J | αJ! ≤ T }), L − 4)

(As stated in Section 4.2, for L = 30, T = 1 sec., and

α = 0.001, the optimal combination is J = 6, G = 12.)

4.6 Practical Considerations

We discuss in Appendix A.3 different issues that appear
when deploying the attack. These issues include ways to
emit the needed trafﬁc from the browser, handling packet
loss and out-of-order packet transmission, handling interfer-
ing packets, and limiting the false-positive and false-negative
error probabilities.

The run time of the key extraction attack is less than a
second even on a very modest machine. The dwell time
(time duration in which the page needs to be loaded in the
browser) is 1-2 seconds for a WebSocket implementation. It
is possible to minimize the dwell time by moving to We-
bRTC (STUN).

Longevity: the device ID is valid until the machine restarts
(mere shutdown+start does not invalidate the device ID due
to Windows’ Fast Start feature). A typical user needs to
restart his/her Windows machine only for some Windows up-
dates, i.e. with a frequency of less than once per month.

The attack is scalable: with 41 bits, the probability of a
device to have a unique ID is very high, even for a billion
device population; false positives are also rare (2.1 × 10−6
– Table 3), and false negatives can be made negligible (Ap-
pendix A.3.4). From resource perspective, the attack uses a
ﬁxed number of servers, RAM/disk and (L = 30) IPs. The

required CPU power is linear in the number of devices mea-
sured per time unit, and in the Windows case is negligible.
Network consumption per test is also negligible (assuming
WebRTC/STUN implementation, a single STUN binding re-
quest is 48 IP level bytes, thus the total network trafﬁc con-
sumed is 48L IP layer bytes in L = 30 packets, i.e. less than
1.5KB at the IP layer.)

4.7 Attack Improvements and Variants

A fast-track identiﬁcation of already-seen keys can be ob-
tained in the following way: Once bits of a key K are ex-
tracted, they will be stored for comparison against future
connections. When a device is to be measured, the tracker
ﬁrst goes through all stored K bit strings, and tests the mea-
sured data for compatibility with each one of them. This
amounts to guessing the bits of β0 one by one, starting
from the least signiﬁcant, and eliminating via eq. (6), using
mod 2n where n is the number of β0 bits guessed so far. The
CPU work per key is thus almost negligible.

The original attack can also be sped up using incremental

evaluation. The details are in Appendix A.5.

4.8 Environment Factors

We demonstrate here that the tracking attack can be deployed
in almost every setting that can be reasonably expected.

HTTPS: In essence, there should be no problem in hav-
ing the snippet use WebSocket over HTTPS (wss:// URL
scheme) for TCP packets.

NAT: Typically NAT (Network Address Translator) de-

vices do not alter IP IDs, and thus do not affect the attack.

Transparent HTTP Proxy / Web Gateway: Such de-
vices may terminate the TCP connection and establish their
own connections (with IP ID from their own network stack)
and thus render our technique completely ineffective. How-
ever, typically these devices do not interfere with HTTPS
(TCP port 443) trafﬁc, and UDP trafﬁc, so these alternatives
can be used by the tracker.

Forward HTTP proxy: When a browser is conﬁgured to
use a forward proxy server, even HTTPS trafﬁc is routed to
it by the browser. However, it may still be the case that UDP
trafﬁc (which is not handled by HTTP forward proxies) can
be used by the technique.

Tor-based browsers and similar browsers: Browsers
that forward TCP trafﬁc to proxy servers (and disallow or
forward UDP requests) are incompatible with the tracking
technique as they do not expose IP header data generated on
the device. Since “Tor transports TCP streams, not IP pack-
ets”,15 this applies to all Tor-based products, such as the Tor
browser and Brave’s “Private Tabs with Tor” and therefore
they are not covered by our technique.

15https://www.torproject.org/docs/faq.html.en#

RemotePhysicalDeviceFingerprinting

Windows Defender Application Guard (WDAG): This
new technology in Windows 10 enables the user to launch the
Edge browser in a virtual environment. While the device ID
in this virtual environment is independent of the device ID of
the main operating system, it is consistent among all WDAG
Edge instances. Furthermore, unlike the “main” Windows
device ID, the WDAG device ID does not change with oper-
ating system restart, hence the WDAG device ID lives longer
than the main Windows device ID. It should be noted that
WDAG is only available for Edge browser in Windows 10
Enterprise/Pro edition, and requires high-end hardware.

IP-Level VPN: We experimented with F-Secure Free-
Dome
(www.f-secure.com/en/web/home_global/
freedome) and PureVPN (www.purevpn.com/). Both
VPNs supported our technique.

IPv6 and IPsec: We do not know whether IPv6 or IPsec
packets use the same IP ID generation mechanism. This re-
quires further research.

Javascript disabled: Tracking can also work when
Javascript (or any client side scripting) is not available, e.g.
with the NoScript browser extension [36]. We discuss this in
Appendix A.4.

4.9 Possible Countermeasures

We list here some obvious ways of modifying Algorithm 1
and their impact:

• Increasing M (the size of the table of counters) – sur-
prisingly, this has very little effect on the basic tracking
technique, since no assumptions were made on M in the
ﬁrst place. It does affect the β reconstruction technique.

• Changing T into a cryptographically strong keyed-hash
function – while this change eliminates the original at-
tack, it is still possible to mount a weaker attack that
only tracks a device while its IPSRC does not change. In
fact, this applies to the entire abstract scheme proposed
in [18, Section 5.3]. See Appendix E.

• Changing the algorithm altogether (this is our recom-
mendation). A robust algorithm relies on industrial-
strength cryptography,
large enough key space, and
strong entropy source for the key, and uses them to gen-
erate IP IDs which (a) have guaranteed non-repetition
period; (b) are difﬁcult to predict; and (c) do not leak
useful data. The algorithm used in macOS/iOS [53] is a
good example. This eliminates the attack altogether.

5 Field Experiment – Attacking Windows

Machines in the Wild

We set up a fully operational system to test the IP ID behav-
ior in the wild, as well as to verify that the technique for ex-
tracting device IDs for Windows machine works as expected.

5.1 Setup

As explained in Appendices A.3.3 and C, in order to avoid
false positives (which almost always happen due to false
keys that differ from the true key in a few most signiﬁcant
bits), we need to trim the most signiﬁcant bits from the key
– i.e. use the key’s tail. For the full production setup (30
IP addresses), we calculated that a tail of 41 bits will suf-
ﬁce. Due to logistic and budgetary constraints, in our ex-
periment we used only 15 IP addresses (rather than 30) for
the key extraction (and 2 more IPs for veriﬁcation), with
J = 5, G = 5, Q = 1. Thus we lowered the tail length to 40,
and used the 40 bits K23, . . . , K62 as a device ID. That is, for
this experiment, we traded the device ID space size for a
smaller probability of false positives.

We then used WebSocket trafﬁc to the additional pair of
IP addresses (from a class B network that is different than
those in the initial set of 15 IPs) to verify the correctness of
the key bits extracted. In this experiment, since we do not
extract K17,...,22 we can only compute the least signiﬁcant 9
bits of the IPID, adapting eq. (6) into:

IPIDg,1 mod 29 = IPIDg,0 ± 1 + Sg,1 − Sg,0 mod 29

(We need to use ±1 since we cannot know the order of packet
generation. Thus given knowledge of IPIDg,0 we have two
candidates for IPIDg,1, out of a space of 29 = 512 values.)
A random choice of two values yields a success rate of 1/256.
We deem our algorithm to be valid if it consistently yields
the correct value (in one of the candidates) in all tests.

Both regular web trafﬁc (e.g. snippet download) and Web-
Socket trafﬁc were carried out in the clear, over HTTP ports
80 and 8080 respectively.

We asked “Friends and Family” to browse to the demo site

using Windows 8 or later, from various networks.

5.2 Results

Network distribution The experiment was conducted
from July 22nd, 2018 to October 20th, 2018. We collected
data on 75 different class B networks.16 The networks are
well dispersed across 18 countries and 4 continents with rep-
resentatives from Australia, Austria, Belgium, Canada, Den-
mark, Finland, France, Germany, Hong Kong, Israel, India,
Japan, The Netherlands, Poland, Sweden, Switzerland, UK
and USA. The networks are also usage-diverse (home net-
works, SMB networks, corporate networks, university net-
works, public hotspots and cellular networks). We asked the
users who connected to our demo site to use multiple reg-
ular browsers (indeed the snippet was accessed with all the
common Windows browsers) and networks, and connect at

16Except for 3 tests in the same class B network. In two of these tests,
the scenarios were of a user roaming from abroad having the same class
B as local cellular network access. In one case the subnet ownership was
different.

different times, and veriﬁed that the device ID remained the
same in all these connections.

Failures to extract a key – IP ID modiﬁcation In only
6 networks out of 75 (8%) we could not extract the key
and therefore concluded that the IP ID was not preserved
by the network. These six networks did not include any ma-
jor ISP and seem to be used by relatively few users: they
included an airport WiFi network, a government ofﬁce, and
a Windows machine connecting through one cellular hotspot
(hotspots that we tested in other cellular networks did not
change the IP ID). Of those six networks, in 3 networks we
had clear indication (via an HTTP request header - Via or
X-BlueCoat-Via) that a transparent proxy (in two cases -
Squid 3.1.23) or a web security gateway (in one case - Blue-
Coat ProxySG) was in path. In such cases, moving to Web-
Socket over HTTPS, or to UDP would probably have ad-
dressed the issue. Another case was a forward proxy (mov-
ing to UDP would have possibly addressed it). In the two
ﬁnal cases, the exact nature of interference was not identi-
ﬁed, however one case clearly exhibited Linux characteris-
tics at the IP and TCP level (hence, it is very likely to be
a Linux-based TCP gateway), and the other exhibited non-
Windows TCP artifacts (TCP timestamps), thus most likely
another TCP gateway. We can say then that optimistically,
only 2 networks out of 75 (2.7%) are incompatible with the
tracking technique, maybe even less (as it is still quite pos-
sible these two TCP gateways are actually transparent prox-
ies).

Positive results
In the remaining 69 networks, for 4 net-
works we did not keep trafﬁc for the additional two IPs, thus
we could not verify the key extraction. For the rest 65 net-
works, our algorithm extracted a single 40-bit key, and cor-
rectly predicted the least signiﬁcant 9 bits of the IPID of the
second IP in the last pair (i.e. the correct value was one of
the two candidates computed by the algorithm). This veriﬁes
the correctness of the algorithm and the key bits it extracts.

Lab veriﬁcation We tested a machine in the lab with
the above test setup to obtain 40 bits of K.
Then,
using WinDbg in local kernel mode, we obtained
tcpip!TcpToeplitzHashKey, extracted the 40 bits from
it and compared to the 40 bits calculated by the snippet – as
expected, they came out identical.

Actual run time Our demo system was implemented on
the least powerful (and cheapest) Azure VM (B1s class, 1
vCPU [40]). Based on the run time measured for Phase
1 with J = 5 (0.12 seconds), and since the attack in pro-
portional to J!, we can compute the CPU speed factor α,
α = 0.12
5! = 0.001 and using it we estimate the run time for
Phase 1 with J = 6 to be approx. 0.72 seconds. We esti-
mate the run time in Phase 2 to be 0.01 seconds or less, thus
the overall run time would be 0.73 seconds. Extrapolated to
10,000 Azure B1s, the run time would be 0.000073 seconds.

Packet loss and false negatives We analyzed 79 valid
tests17 (with Windows 8+ operating system, and no IP ID
modiﬁcation), and found only 3 cases wherein the analysis
logic failed to provide a device ID (additional test from the
In all such
same devices succeeded in extracting a key).
cases a manual analysis indicates that this is due to packet
loss. All three cases were from locations where Internet
connectivity is not ideal, and are also geographically remote
from our server (the tested networks were in Asia, whereas
our server is in the US). In two cases (both belong to the
same user, in a cellular network), there were 3 missing pack-
ets, and in one case – 4. Appendix A.3.4 describes additional
logic (not implemented in the experiment) that can be used
to reduce false negatives to a negligible level.

6 Linux and Android

The scope of our research is Linux kernel 3.0 and above.
Also, we only investigated the x64 (typical desktop Linux)
and ARM64 (Android) CPU architectures, although almost
all of the analysis is not architecture-speciﬁc.

6.1 Attack Outline

In order to track a Linux/Android device, the tracker needs
to control several hundred IP addresses. The tracking snip-
pet forces the browser to rapidly emit UDP packets to each
such IP (using WebRTC and speciﬁcally the STUN protocol,
which enables sending bursts of packets closely spaced in
time to controlled destination addresses). It also collects the
device’s source IP address (using WebRTC as well – [48] or
alternatively Appendix G.2.)

The tracker collects IP IDs from all IP addresses, and iden-
tiﬁes bucket collisions by looking for IP pairs whose IP IDs
are in close proximity. Recall that the choice of the bucket
is a function of the source and destination IP addresses, and
a device key. The tracker enumerates over the key space to
ﬁnd the (correct) key which generates collisions for the same
pairs for which collisions were observed. The key that is
found is the device ID.

6.2

IP ID Generation in Linux

The Linux kernel implementation of IP ID differs between
TCP and UDP [30]. The TCP implementation always used
a counter per TCP connection (initialized with a hash of the
connection endpoints and a secret key, combined with a high
resolution timer) and as such, is not interesting to us (col-
lisions are meaningless). The implementation of IP ID for
stateless over-IP protocols18 (e.g. UDP) has gone through an

17Some networks were tested multiple times
18This also covers the IP ID of TCP RST packets which do not belong to
an established TCP connection, e.g. RST for SYN received to a non-open
port, and RST for SYN+ACK received with no matching SYN previously

interesting evolution process. We focus on short datagrams,
i.e. datagrams shorter than MTU (maximum transmission
unit), that do not undergo fragmentation. We designate the
IP ID generation algorithms as A0, A1, A2 and A3, in their or-
der of evolution.

A0: In early Linux kernels, the IP ID for short datagrams

was simply set to 0.

A1 and A2: In Linux kernel 3.16.0 (released August 2014),
IP ID for short datagrams became dynamic (just like it has al-
ways been for long UDP datagrams).19 This was back-ported
to various active Linux 3.x branches (see Table 2). The gen-
eration algorithm20 in general has an array of M = 2048
buckets, each containing a value 0 ≤ β < 216 (the implemen-
tation uses 32 bit quantities, but only the least signiﬁcant 16
bits are used) and a time-stamp τ of the last time this bucket
was used (this time-stamp is taken in a resolution of f Hz,
where f depends on the version of the OS). The bucket array
is initialized at boot time with random data (using a PRNG).
The algorithm also uses the following parameters

• key – a 32-bit key (ip_idents_hashrnd) which is ini-
tialized upon ﬁrst IP transmission with random data.
• h – a hash function. The details of the hash function are
not important for understanding the attack. There are
two versions of the hash functions: the old one is used
in A1, and the new one is used in A2 and A3.21

• protocol – the IP “next level” protocol number (for
UDP, this value is 17). Nominally 8-bit ﬁeld, extended
to 32-bit by zero-ﬁlling the most signiﬁcant bits.

• RANDOM(x), x > 0 – a PRNG (a 96/128 bit Tausworthe
Generator) which receives x as a parameter and pro-
vides a random integer in the range [0, x). (We deﬁne
RANDOM(0) = 0). Note that RANDOM(1) = 0.

The IP ID generation algorithm is deﬁned in Algorithm 2.
The procedure picks an index to a counter as a function of the
source and destination IP address, the protocol and the key.
It picks a random value which is smaller than or equal to the

sent.

19See function __ip_select_ident in https://elixir.bootlin.

com/linux/v3.16/source/net/ipv4/route.c.

for

the

sets

20Except when

the UDP client

socket
IP_PMTUDISC_INTERFACE.

the PMTU discovery
mode
to IP_PMTUDISC_DO, IP_PMTUDISC_PROBE
or
via
can
In such
setsockopt(...,IPPROTO_IP,IP_MTU_DISCOVER,...).
case the IP ID algorithm used is fundamentally different, and the attack
described in this paper cannot be used with the socket’s datagrams. Note
that Chrome’s gQUIC implementation for Linux and Android sets the
PMTU discovery mode to IP_PMTUDISC_DO, and therefore the attack in
this paper does not apply to it.

done

This

be

21In A1 the hash function h is a modiﬁed Jenkins lookup3 hash function
[25], except that the initialization steps are taken from the Jenkins lookup2
hash function [24] but using a different constant (0xdeadbeef instead of
0x9e3779b9). This IP ID algorithm was back-ported to several earlier ker-
nel branches. In Linux 4.1 (released June 2015), the hash function h was
corrected to fully comply with the Jenkins lookup3 hash function. This
change was back-ported to Linux 3.18 (ver. 3.18.17) which is the active
development 3.x kernel branch, and to several earlier kernel branches. This
version is used in A2 and A3.

time that passed (measured in ticks, with tick frequency of f
per second) since the last usage of this counter, increments
the counter by this value, and outputs the result.

Algorithm 2 Linux IP ID Generation (A1/A2)

1: procedure GENERATE-IPID
2:
3:

i ← h(IPDST , IPSRC, protocol, key) mod M
hop ← 1 + RANDOM(tnow − τ[i])
β [i] ← (β [i] + hop) mod 216
τ[i] ← tnow
return β [i]

4:
5:
6:

A3: Starting with Linux 4.1, the net namespace of the
kernel context, net (a 64-bit pointer in kernel space) is in-
cluded in the hash calculation, conditional on a compilation
ﬂag CONFIG_NET_NS (which is on by default for Linux 4.1
and later, and for Android kernel 4.4 and later). The modiﬁ-
cation is for step 2, which now reads:

i ← h(IPDST , IPSRC, protocol ⊕ g(net), key) mod M

where g(x) is a right-shift (by ρ bits) and a truncation func-
tion that returns 32 bits from x. We designate this algorithm
as A3.

To summarize, there are four ﬂavors of IP ID generation

(for short stateless protocol datagrams) in Linux:

1. A0 - IP ID is always 0 (in ancient kernel versions)
2. A1 / A2 - Both versions use Algorithm 2, with the dif-

ferent implementations of h.

3. A3 - Algorithm 2, with h being a correctly implemented
Jenkins lookup3 hash function, with net namespace.

Of interest to us are algorithms A1 to A3. We focus mostly
on UDP, as this is a stateless protocol which can be emitted
by browsers.

The resolution f of the timer t in the algorithm is deter-
mined by the kernel compile-time constant CONFIG_HZ. A
common value for older Android Linux kernels is 100(Hz).
Newer Android Linux kernels (4.4 and above) use 300 or
100 (or rarely, 250). The default for Linux is f = 250.22 In
general, for tracking purposes, a lower value of f is better.

Note that key and net are generated during the operating
system initialization, which, unlike Windows, happens dur-
ing restart and during (shutdown+)start.

6.3 Setting the Stage

Our technique for tracking Android (and Linux) devices uses
HTML5’s WebRTC[1] both to discover the internal IP ad-
dress of the device [48], and to send multiple UDP pack-
ets. It works best when the WebRTC STUN [37] trafﬁc is
bursty. In order to analyze the effectiveness of the technique
we investigated the following features, focusing on Android
devices.

6.3.1 Android Versions and Linux Kernel Versions

The Android operating system is based on the Linux ker-
nel. However, Android versions do not map 1:1 to Linux
kernel versions. The same Android version may be built
with different Linux kernel versions by different vendors,
and sometimes by the same vendor. Moreover, when an An-
droid device updates its Android operating system, typically
its Linux kernel remains on the same branch (e.g. 3.18.x).
Android vendors also typically use somewhat old Linux ker-
nels. Therefore, many Android devices in the wild still have
Linux 3.x kernels, i.e. use algorithm A1 or A2.

6.3.2 Sending Short UDP Datagrams to Arbitrary Des-
tinations, or “Set Your Browsers to STUN”

The technique requires sending UDP datagrams from the
browser to multiple destinations. The content of the data-
grams is immaterial, as the tracker is interested only in the
IP ID ﬁeld. We use WebRTC (speciﬁcally – STUN) to send
short UDP datagrams (with no control over their content) to
arbitrary hosts. The RTCPeerConnection interface can be
used to instruct the browser’s WebRTC engine to use a list
of presumably STUN servers, and even allows setting the
UDP destination port per each host. The browser then sends
STUN “Binding Request” (UDP short datagram) to the des-
tination host and port.

to multiple

To send STUN requests
create

an array A of
invoke

Javascript),
form stun:host:port,
RTCPeerConnection({iceServers:
a regular WebRTC ﬂow e.g.
[19]).

(in
in the
constructor
in
[26] (applying the ﬁx from

strings
the

A}, ...)

servers

then

6.3.3 Browser Distribution in Android

We want to estimate the browser market share of “support-
ive” browsers (Chrome-like and Firefox) in the Android OS.
Based on April 2018 ﬁgures for operating systems,23 com-
bined with mobile browsers distribution in April 2018,24 we
conclude that the Chrome-like browsers (Google Chrome,
Opera Mini, Baidu, Opera) comprise 90% of the browser
usage in Android. Adding Firefox (even though its STUN
trafﬁc is less bursty, Firefox can still be tracked at least for
f = 100) gets this ﬁgure up to 92%.

6.3.4 Chrome’s STUN Trafﬁc Shape

Chrome sends the STUN requests to the list of supposedly
STUN servers, in bursts. A single burst may contain the full
list of the requested STUN servers (in ascending order of

23https://netmarketshare.com/operating-system-market-share.

22https://elixir.bootlin.com/linux/v4.19/source/kernel/

aspx

Kconfig.hz

24https://netmarketshare.com/browser-market-share.aspx

destination IP address), or a subset of the ordered list (typ-
ically with a missing range of destination hosts). We mea-
sured 1014 bursts (to L = 400 destination IP addresses) emit-
ted by a Google Pixel 2 mobile phone (Android 8.1.0, kernel
4.4.88), running Google Chrome 67 browser. The vast ma-
jority of bursts last between 0.1 seconds to 0.2 seconds, and
the maximal burst duration was 0.548 seconds. Thus we use
an upper bound of δL = 0.6 seconds for a single burst dura-
tion.

Chrome emits up to 9 bursts with increasing time delays,
at the following times (in seconds, where t = 0 is the ﬁrst
burst): 0, 0.25, 0.75, 1.75, 3.75, 7.75, 15.75, 23.75, 31.75.25
We label these bursts B0, . . . , B8 respectively, and we will be
interested in B4 and B5, as they’re sufﬁciently far from their
neighbors. Thus, we are only interested in the ﬁrst 8-9 sec-
onds of the STUN trafﬁc.

6.3.5 UDP Latency Distribution

While WebRTC trafﬁc is emitted by the browser in well de-
ﬁned, ordered bursts, one cannot assume the trafﬁc will re-
tain this “shape” when arriving to the destination servers. In-
deed, even order among packets within a burst is not guaran-
teed at the destination. Understanding the latency distribu-
tion in UDP short datagrams is therefore needed in order to
simulate the in-the-wild behavior, and consequently the ef-
ﬁcacy of various tracking techniques. The latency of UDP
datagrams is gamma-distributed according to [34] and [35].
However, for simplicity, we use normal distribution to ap-
proximate the in-the-wild latency distribution. On May 1st-
6th 2018, we measured the latency of connections to a server
in Microsoft Azure “East-US” location (in Virgina, USA)
from 8 different networks located in Israel, almost 10,000km
away. The maximum standard deviation was 0.081 seconds.
Hereinafter, we will use a standard deviation value σ = 0.1
seconds as a worst case scenario for UDP jitter.

6.3.6 Packet Loss

We identiﬁed two different packet loss scenarios:

• Packet loss during generation:

the WebRTC packet
stream (in Chrome-like browsers) is bursty in nature.
In some bursts, we noticed large chunks of missing
packets. These are quite rare (in the experiment we
describe in Section 6.3.4 we got 29 such cases out of
1014 – 2.9%, though they are more common in An-
droids whose kernel is 4.x and have f = 100) and eas-
ily identiﬁed. We can safely ignore them because the
tracker can detect a burst with a lot of missing pack-
ets, reject the sample and run the sampling logic again,
or use a more sophisticated logic incorporating infor-
mation from more than two bursts. Additionally, with

f = 100 there are far less false pairs, which helps the
analysis.

• Network packet loss: the UDP protocol does not guar-
antee delivery, and indeed packets get lost over the In-
ternet. The loss rate is not high, however, and we esti-
mate it to be ≤ 1%. This is also backed by research.26

6.4 The Tracking Technique

The technique that we use is different than prior art tech-
niques in focusing on bucket collisions. That is, in cases
wherein UDP datagrams for two different destination IP ad-
dresses end up with IPID generated using the same counter.
The tracker needs to control L Internet IPv4 addresses,
such that the IP-level trafﬁc to these addresses (and partic-
ularly, the IP ID ﬁeld) is available to the tracker. Ideally the
IPs are all in the same network, so that they are all subject
to the same jitter distribution. The tracker should be able to
monitor the trafﬁc to these IP addresses with time synchro-
nization resolution of about 10 milliseconds (or less) - e.g.
by having all the IPs bound to a single host.

With L different destination IP addresses and M buckets
(M = 2048 in Algorithm 2), there are (L
2)/M expected colli-
sions (unordered pairs of IP addresses which fall to the same
bucket), assuming no packet loss. In reality, the tracker can
only obtain an approximation of this set. The goal is to re-
duce those false negatives and false positives to levels which
allow assigning meaningful tracking IDs.

The basic property that enables the attacker to construct
the approximate list is that in an IP ID generation the counter
is updated by a random number which is smaller than 1 plus
the multiplication of the timer frequency f and the time that
passed since the last usage of that counter. Therefore for a
true pair (IPi, IP j) where the IP ID generation for IPi and
IP j used the same bucket (counter), the following inequality
almost always holds:

0 < (IPID j − IPIDi) mod 216 < f ∆t + 10

(We use f ∆t + 10 instead of f ∆t + 1 to support up to 10 IPs
colliding into the same bucket, as each collision may incre-
ment the counter by ≤ 1 + f ∆t where ∆t is from the previous
collision. So the counter can end up incrementing no more
than f ∆t + 10 where ∆t is the sum of the time difference
between collisions, i.e.
the time duration between the ﬁrst
collision and the last collision in the burst.)

Since we are looking at datagrams from the same burst we

have an upper bound δL such that ∆t < δL, and therefore:

0 < (IPID j − IPIDi) mod 216 < f δL + 10

For two IP addresses which are not mapped to the same
counter, the likelihood of this inequality to hold is only

25See https://chromium.googlesource.com/external/webrtc/

26See

http://www.verizonenterprise.com/about/network/

+/master/p2p/base/stunrequest.cc).

latency/, and [5].

216

( f δL+10)−1
216

which is (cid:28) 1 when f δL (cid:28) 216 (the worst case in
our setting is with f = 300 and δL = 0.6, where ( f δL+10)−1
<
0.003). The key extraction algorithm (Section 6.6) will ex-
amine IP ID values in two different communication bursts,
and this will further reduce the likelihood of a false positive.
Note that the probability of a false positive pair in a given
burst to survive into the next burst is roughly f δL+10
f ∆t ≈ δL
∆t
where ∆t is the time between the consecutive bursts, whereas
a true pair will occur in all bursts. Thus for the intersection
of 2 consecutive bursts ∆t = 4 seconds apart, the amount of
false positives (in both bursts) will be ≈ 0.15 of their amount
in a single burst.

Another requirement is that the set L of IP addresses is
large enough, so that the number of colliding pairs will be
sufﬁciently high in most of the tracking attempts, rather then
on the average (the expected number of colliding pairs is
(L
2)/M).

6.5 Attack Phase 1 – Collecting Collisions

The tracking snippet needs to be rendered for at least 8.5 sec-
onds, enough time for the browser to send the ﬁrst 6 STUN
bursts (B0, . . . , B5) – see Section 6.3.4. The tracking server
splits the STUN trafﬁc to bursts, based on the datagrams’
time of arrival, and on the expected burst time offsets (see
Section 6.3.4). For simplicity and ease of analysis, we hence-
forth only use trafﬁc from bursts B4 and B5, which can be
easily and unambiguously determined (since they are well
separated in time from other bursts). We note that in some
cases, requests in B4 or in B5 may be unsent, and in such
cases we may need to resort to using e.g. B3 and B5 or sim-
ilar combinations, but as long as these are “late” bursts (i.e.
separated from their neighboring bursts by a enough σ units,
where σ is the UDP jitter, see above), they can be separated
without errors (or almost without errors) and the following
If there are too many missing re-
analysis remains valid.
quests in a burst, the Tracking Server communicates with
the Tracking Snippet, instructing it to retest the device.

Assuming no (or few) missing requests in B4 and B5, the
Tracking Server starts analyzing the data per burst (in B4
and B5). For each burst the Tracking Server calculates a
set of pair candidates by collecting pairs of IP addresses
27 (IPi, IP j) for which IPi < IP j and 0 < (IPID j − IPIDi)
mod 216 < λL where λL = f δL + 10. It then identiﬁes pairs
which appear in the candidate sets of both bursts, and adds
them to a set U of full candidates. This set forms a single
measurement of a device. The tracker calculates the tracking
ID based on U in Phase 2.

27Chrome-like browsers send STUN requests ordered by IP address, thus

for a true pair a higher IP will have a higher IP ID.

Table 1: Approximated P distribution

f [Hz] E(P)
50.59
100
65.47
250
70.45
300

σ (P)
7.39
8.60
8.79

σ (P)/E(P)
0.146
0.131
0.125

6.6 Attack Phase 2 – Exhaustive Key Search

In the second phase the tracking server runs an exhaustive
search on the key space W where the key is 32 bits long for
algorithms A1 and A2, 41 bits long for algorithm A3 (Linux)
and 48 bits for A3 (Android). For each candidate key, the
algorithm counts how many IP pairs in U are predicted by
the candidate key. It is expected that only in one (the correct)
key, this number will exceed a threshold ν, and in such case,
this will be returned as the correct key (and the device ID).
See Algorithm 3 for details (the algorithm uses the notation
h(cid:48)(..., k) = h(..., protocol ⊕ g(net), key) where k is split into
g(net), key).

Algorithm 3 Exhaustive key search

1: procedure GENERATE-ID(U, IPsrc)

(cid:46) U is deﬁned in

Section 6.5

if |U| < ν then

return ERROR

X ← /0
for all 0 ≤ k < W do

Y ← {(IPi, IP j) ∈ U | h(cid:48)(IPi, IPSRC, k) =

h(cid:48)(IP j, IPSRC, k)}

if |Y | ≥ ν then

X ← X ∪ {k}

if |X| > 0 then
return X

else

(cid:46) Needs special treatment if |X| > 1

return ERROR

2:
3:

4:
5:
6:

7:
8:

9:
10:

11:
12:

We assume here knowledge of the version of the algorithm
(A) used – A1, A2 or A3. For A1 and A2, the key space size is
|W | = 232, and for A3, it is 241 for the x64 architecture and
248 for the ARM64 architecture (see Section 6.7.)

As explained in Section 6.11, false positives (|X| > 1) are
very rare – they can be handled but as this complicates the
analysis logic, it is left out of the paper.
Attack run time Where |U| = P pairs, the run time of Al-
gorithm 3 is proportional to |W |P. P’s distribution depends
on f ; Table 1 summarizes the expectancy and standard devi-
ation for common f values. These were approximated by a
computer simulation (100 million iterations.)
Time/memory optimization When the number of devices
to measure is much smaller than |W | it is possible to opti-
mize the technique for repeat visits. The optimization simply

amounts to keeping a list Λ of already encountered key val-
ues (or (g(net), key) values), and trying them ﬁrst. If a match
is found (i.e., this is a repeat visit), there is clearly no need to
continue searching the rest of the key space. Otherwise, the
algorithm needs to go through the remaining key space.

Targeted tracking Even if the key space W is too large to
make it economically efﬁcient to run large scale device track-
ing, it is still possible to use it for targeted tracking. The use
case is the following: The tracking snippet is invoked for a
speciﬁc target (device), e.g. when a suspect browses to a
honeypot website. At this point, the tracker (e.g.
law en-
forcement body) extracts the key, possibly using a very ex-
pensive array of processors, and not necessarily in real time.
Once the tracker has the target’s key, it is easy to test any
invocation of the tracking snippet against this particular key
and determine whether the connecting device is the targeted
device. Moreover, if the attacker targets a single device (or
very few devices), it is possible to reduce the number of IP
addresses used for re-identifying the device, by using only IP
addresses which are part of pairs that collide (into the same
counter bucket) under the known device key. Thus we can
use a single burst with as few as 5 IP pairs (10 addresses al-
together) per device to re-identify the device. The dwell time
in this case drops to near-zero.

6.7 The Effective Key Space in Attacking Al-

gorithm A3

In Algorithm A3, 32 bits of the net namespace are extracted
by a function we denote as g(), and are added to the calcu-
lation of the hash value. The attack depends on the effective
keyspace size |W | = |{key}| × |{g(net)}| = 232 · |{g(net)}|.
A detailed analysis for Linux kernel versions 4.8 and
above (on x64), and 4.6 and above (on ARM64, i.e. Android)
appears in Appendix F. The conclusion is that if KASLR is
turned off then the effective key space size is 32 bits in both
x64 and ARM64. If KASLR is turned on, then the effective
key space size is 41 bits in x64 and 48 bits in ARM64.

6.8 KASLR Bypass for Algorithm A3

By obtaining g(net) as part of Attack Phase 2 (Section 6.6),
the attacker gains 32 bits of the address of the net structure.
In single-container systems such as desktops and mobile de-
vices, this net structure resides in the .data segment of the
kernel image, and thus has a ﬁxed offset from the kernel im-
age load address. In default x64 and ARM64 conﬁgurations,
the 32 bits of g(net) completely reveal the random KASLR
displacement of net. This sufﬁces to reconstruct the kernel
image load address and thus fully bypass KASLR. See Ap-
pendix F for more details.

Figure 1: Prob(FP) + Prob(FN) for L and optimal ν

6.9 Optimal Selection of L

Since IP addresses are at premium, we choose a minimal
integer number L of IP addresses such that at the point
ν where Prob(FN) + Prob(FP) is minimal, Prob(FP) +
Prob(FN) ≤ 10−6. We assume f = 300 (worst case sce-
nario). For simplicity, at this stage we neglect packet loss,
and assume that δL = L
400 δ400 (we assume δL ∝ L, and we
measured δ400). For false negatives, we use the Poisson
approximation of birthday collisions [4] with λ = (cid:0)L
(cid:1)/M.
2
Therefore:

Prob(FN) ≈

ν−1
∑
i=0

λ ie−λ
i!

(cid:0)L
2

(cid:1) f δL+10

216 +

For false positives, we also assume that a burst contains
the average number of false pairs and true pairs A =
(L
2)
(cid:98) f δL+10
M (cid:99). We note that the probability for
f ∆t
a single false key to match exactly k pairs is (cid:0)A
M )k(1 −
k
1
M )A−k, thus the probability of a single false key not to be-
(cid:0)A
come a false positive is ∑ν−1
M )A−i. The prob-
i=0
i
ability of |W | − 1 false keys to generate at least one false
positive key is therefore:

M )i(1 − 1

(cid:1)( 1

(cid:1)( 1

Prob(FP) ≈ 1 −

(cid:16) ν−1
∑
i=0

(cid:19)
(

(cid:18)A
i

1
M

)i(1 −

1
M

)A−i(cid:17)|W |−1

Assuming |W | = 248 (worst case – Android), we enumerated
over all ν values for each L in {200, 250, . . . , 500} to ﬁnd the
optimal ν (per L). We plot the results in Fig. 1.

As can be seen, L = 400 (with ν = 11) is the minimal
“round” L satisfying Prob(FP) + Prob(FN) ≤ 10−6 at its
optimal ν.

6.10 A More Accurate Treatment for L = 400

Using a computer simulation, we approximated the distribu-
tions of all collisions pA(n) (using 108 simulation runs), and

Figure 2: Prob(FP) + Prob(FN) vs. ν for L = 400

of true collisions pT (n) (using 109 simulation runs). The
simulations took into account 1% packet loss. With these,
we can calculate more accurate approximations:

Prob(FN) ≈

ν−1
∑
i=0

pT (i)

(cid:19)
(

(cid:18)n
i

1
M

pA(n)

)i(1 −

Prob(FP) ≈ 1 −∑
n

(cid:16) ν−1
∑
i=0
(cid:1) = 0 where k > n.) We enumer-
(We use the convention (cid:0)n
k
ated over values 1 ≤ ν ≤ 20 for L = 400 and |W | = 248 (worst
case – Android.) and plotted the FP and FN probabilities in
Fig. 2 (eliminating values below 10−15).

)n−i(cid:17)|W |−1

1
M

As can be seen, the minimal Prob(FP) + Prob(FN) is at
ν = 11, where Prob(FP) = 6.2 × 10−10 and Prob(FN) =
4.2 × 10−8. We get the same optimal ν value for L = 400 as
we got in Section 6.9, which means that the approximation
steps we took there are reasonable.

6.11 Practical Considerations

Controlling packets from the browser As explained in
Section 6.3.2, it is possible to emit UDP trafﬁc to arbitrary
hosts and ports using WebRTC. The packet payload is not
controlled. The tracker can use the UDP destination port in
order to associate STUN trafﬁc to the same measurement.

Synchronization and packet transmission/arrival order
Unlike the Windows technique, in the Linux/Android track-
ing technique there is no need to know the exact transmission
order of the packets within a single burst.

False positives and false negatives Using a computer sim-
ulation with L = 400 destination IP addresses, a burst length
of δL = 0.6 seconds, and packet loss rate of 0.01, we cal-
culated an approximation of for the false negative rate of
4.2 × 10−8 for ν = 11, and an approximation for the false
positive rate of 6.2 × 10−10. These approximations were
computed assuming |W | = 248 (worst case – Android). See
Section 6.10 for more details.

Device ID collisions The expected number of pairs of de-
vices with colliding IDs, due to the birthday paradox, and
given R devices and a key space of size |W |, is (R
2)/|W |. For
Algorithms A1 and A2 the key space size is |W | = 232, and
will cause device ID collisions once there are several tens of
thousands of devices. For R = 106 this will affect 0.00023 of
the population (2 out of every 10,000 devices). For Alg. A3,
the key space size (with KASLR) is ≥ 241, so collisions start
showing up with R in the millions. Even for R = 128 · 106,
collisions affect only 0.00006 of the population.
In order to record B5, the snippet page needs to
Dwell time
be loaded in the browser for 8-9 seconds. Navigating away
from the page will immediately terminate the STUN trafﬁc.
Environment factors All the UDP-related topics in Sec-
tion 4.8 are applicable as environment factors on the
Linux/Android tracking technique.
Longevity The device ID remains valid as long as the de-
vice is not shutdown or restarted. Mobile devices are rarely
shut down, and are typically restarted only on updates, which
happen once every several months, or even less frequently.
Scalability The attack is scalable. Device ID collisions
are rare even with many millions of devices (see above).
False positives and false negatives are also rare (less than
4.3 × 10−8 combined). From a resource perspective, the at-
tack uses a ﬁxed number of IPs and servers, and a ﬁxed-size
RAM/disk. The required CPU power is proportional to the
number of devices measured per time unit. Network con-
sumption per test is negligible – approx. 13.5KB/s (at the IP
level) during measurement.

6.12 Possible Countermeasures

Increasing M Changing the algorithm to use a larger num-
ber M of counters, will reduce the likelihood of pairs of IP
addresses using the same counter.
In response to such a
change the tracker can increase the number L of IP addresses
that is uses. The expected number of collisions is (L
2)/M, and
therefore increasing M by a factor of c requires the attacker
to increase L by only a factor of

√

c.

On the other hand, δL also grows (probably linearly in L),
and when f δL ≥ 216 no information is practically revealed to
the tracker. It is probably safe to assume that the tracker can
handle an increase of L by a factor of ×10, which means that
in order to stop the attacker the IP ID generation algorithm
must increase M by more than ×100, making it too mem-
ory expensive to be practical. (Decreasing M only makes it
easier for the tracker, except for M = 1 in which case the sys-
tem becomes a global counter (with random hops depending
on the time since last transmission), which renders the at-
tack ineffective, yet has several other security issues, such as
described for example in [51].)
Increasing the key size (W) This can be an effective
counter-measure for the exhaustive search phase, though the

pair collection phase is unaffected by it. Yet some choices of
the hash function h might still allow fast cryptanalysis.
Strengthening h Our analysis does not rely on any prop-
erty of the hash function h, except that it is more-or-less uni-
form. Thus, changing h (while keeping the same key space
W ) will not affect our results.
Replacing the algorithm See the last item in Section 4.9.

7 Experiment – Attacking Linux and Android

Devices in the Lab

In order to verify that we can extract the key used by Linux
and Android devices, we need to control hundreds of IP ad-
dresses. Controlling such a magnitude of Internet-routable
IP addresses was logistically out of scope for this research.
Therefore we had to settle for an in-the-lab setup, which nat-
urally limited the number of devices we could test.

7.1 Setup

We connected the tested devices to our own WiFi ac-
cess point, which advertised our laptop as a network gate-
way. Then we launched a Chrome-like browser inside the
Linux/Android device, and navigated to a page containing
a tracking snippet. The tracking snippet used WebRTC to
force UDP trafﬁc to a list of L = 400 hosts, and this trafﬁc
passed through our laptop (as a gateway) and was recorded.
We then ran the collision collection logic (Phase 1), and
fed its output (IP pairs whose IP IDs collide) to the exhaus-
tive key search logic (Phase 2). For KASLR-enabled de-
vices, we also provided the algorithm with the offset (relative
to the kernel image) of init_net, which we extracted from
the kernel image ﬁle given the build ID (can be inferred e.g.
from the User-Agent HTTP request header). We expected
that the algorithm will output a single key, which will match
a large part of the collisions.

7.2 Results

We tested 2 Linux laptops and 6 Android devices, together
covering the vast majority of operating system and hardware
parameters that regulate the IP ID generation. The results
from all tests were positive - our technique extracted a sin-
gle key and a kernel address of init_net where applicable
(which was identical to the address in /proc/kallsyms).
Note that due to hardware availability constraints, for the
Pixel 2XL case (|W | = 248), we provided the algorithm with
the correct 16 bit kernel displacement to reduce the key
search to 232. Table 2 provides information about the com-
mon kernel versions, their parameter combinations and the
tested devices.

The Attack time column is the extrapolated attack time in
seconds with 10,000 Azure B1s machines, based on E(Pf )
the average attack time is r · |W | · E(Pf )
from Table 1, i.e.

where r is the time it takes a single B1s machine to test a sin-
gle key with a single pair, divided by 10,000. The standard
deviation of the attack time for a given f is r · |W | · σ (Pf ),
which is σ (Pf )/E(Pf ) in Table 1 times the average attack run
time in Table 2. From a calibration run (single B1s machine,
10 pairs, 232 keys, 294.83 seconds run time) we calculated
r = 6.8645 × 10−13, and populated the Attack Time column
in Table 1 with r · |W | · E(Pf ).

Applicability in-the-wild While our tests were carried out
in the lab, we argue that the results are representative of an
in-the-wild experiment with the same devices. We list the
following potential differences between in-the-lab and in-
the-wild experiment, and for each difference, we note why
our experiment can be projected to an in-the-wild scenario.
• Packet loss: our technique is not sensitive to packet
loss. We ran false positive/negative computer simula-
tions (assuming 1% packet loss) supporting this fact.
• Network latency: our technique is not sensitive to net-
work latency (which is just a constant time-shift, from
our perspective).

• UDP jitter: this only affects correctly splitting the trafﬁc
into bursts. Our technique uses the “late” bursts, thus
assuring that the bursts are well separated time-wise and
that a jitter of σ = 0.1s does not affect tracking.

• Network interference (IPID modiﬁcation):

this issue
was already evaluated in-the-wild in the Windows ex-
periment, and the Windows results can be applied to
the Linux/Android use case.

• Packet reordering (within a burst): Our technique does

not rely on packet order within a burst.

Thus we conclude that our results (and henceforth, the prac-
ticality of our technique) are applicable in-the-wild.

8 Conclusions

Our work demonstrates that using non-cryptographic ran-
dom number generation of attacker-observable values (even
if the values themselves are not security sensitive), may be
a security vulnerability in itself, due to an attacker’s ability
to extract the key/seed used by the algorithm, and use it as a
ﬁngerprint of the system.

Speciﬁcally, we ﬁnd that the IP ID generation scheme pro-
posed in RFC 7739 [18, Section 5.3], and implemented in
Windows 8 and later is vulnerable to an attack of this type,
and that the Linux/Android IP ID generation algorithm is
also vulnerable to such an attack. We demonstrate these at-
tacks and are able to extract device IDs for systems running
Windows, Linux and Android.

We stress that any replacement cryptographic algorithm
must not be hampered by using a key that is too short, in
order to avoid a key enumeration attack. Also, as a security
measure, we strongly recommend generating unique keys for

O/S

Kernel
Version

Linux (x64)

4.19+

Linux (x64)

4.8-4.18.x

Android
(ARM64)
Android
(ARM64)

Android
(ARM64)

4.4.56+,
4.9, 4.14
3.18.17+
3.4.109+
3.18.0-3.18.6
3.10.53+
3.4.103-3.4.108

Table 2: Common Linux/Android Kernels and Their Parameter Combinations

Alg.

f [Hz] KASLR NET_NS

ρ

log2 |W | Tested System

A3

A3

A3

A2

A1

250

250

300/
100

100

Yes

Yes

Yes

No

100

No

Yes

Yes

Yes

No

No

12

6

6/7

Don’t
care

Don’t
care

41

41

48

32

32

Dell Latitude
E7450 laptop
Dell Latitude
E7450 laptop

Pixel 2XL (ρ = 6)

Redmi Note 4
Xiaomi Mi4
Samsung J7 prime
Samsung S7
Meizu M2 Note

Attack
Time [s]

99

99

13,612/
9,775

0.15

0.15

such cryptographic usage, without resorting to using secret
data that is used for other purposes (which – in case of a
cryptographic weakness in the algorithm – can leak out).

9 Acknowledgements

This work was supported by the BIU Center for Research
in Applied Cryptography and Cyber Security in conjunction
with the Israel National Cyber Directorate in the Prime Min-
ister’s Ofﬁce.

We would like to thank the anonymous USENIX 2019 re-
viewers for their feedback, Assi Barak for his help to the
project, as well as Avi Rosen, Sharon Oz, Oshri Asher and
the Kaymera Team for their help with obtaining a rooted An-
droid device.

References

[5] D. Baltrunas, A. Elmokashﬁ, A. Kvalbein, and Ö. Alay.
Investigating packet loss in mobile broadband networks
under mobility. In 2016 IFIP Networking Conference
and Workshops, pages 225–233, 2016.

[6] S. M. Bellovin. A technique for counting Natted hosts.
In 2nd SIGCOMM Workshop on Internet Measurement,
pages 267–272, 2002.

[7] N. Blum. Webrtc m72 release notes.

https:

//groups.google.com/forum/#!topic/
discuss-webrtc/3h4y0fimHwg, December 2018.

[8] H. Bojinov, Y. Michalevsky, G. Nakibly, and D. Boneh.
Mobile device identiﬁcation via sensor ﬁngerprinting.
CoRR, abs/1408.1416, 2014.

[9] T. Bujlow, V. Carela-Español, J. Solé-Pareta, and
P. Barlet-Ros. Web tracking: Mechanisms, implica-
tions, and defenses. CoRR, abs/1507.07872, 2015.

[1] B. Aboba, D. Burnett, T. Brandstetter, C. Jennings,
A. Narayanan,
J.-I. Bruaroey, and A. Bergkvist.
WebRTC 1.0: Real-time communication between
browsers. Candidate recommendation, W3C, June
2018.
https://www.w3.org/TR/2018/CR-webrtc-
20180621/.

[2] G. Acar, M. Juarez, N. Nikiforakis, C. Diaz, S. Gürses,
F. Piessens, and B. Preneel. FPDetective: dusting the
web for ﬁngerprinters. In ACM CCS ’13, pages 1129–
1140, 2013.

[3] F. Alaca and P. C. van Oorschot. Device ﬁngerprinting
for augmenting web authentication: Classiﬁcation and
In ACSAC ’16, pages 289–301,
analysis of methods.
2016.

[10] Y. Cao, S. Li, and E. Wijmans. (cross-)browser ﬁnger-
printing via OS and hardware level features. In NDSS
2017, San Diego, California, USA, 2017.

[11] G. Chappell. RTL_PROCESS_MODULE_INFORMATION.

https://www.geoffchappell.com/studies/
windows/km/ntoskrnl/api/rtl/ldrreloc/
process_module_information.htm.

[12] G. Chappell.

RTL_PROCESS_MODULES.

https://www.geoffchappell.com/studies/
windows/km/ntoskrnl/api/rtl/ldrreloc/
process_modules.htm.

[13] Chromium. Maintain separate tls session caches
https://bugs.chromium.org/p/

per-proﬁle.
chromium/issues/detail?id=30877.

[4] R. Arratia, L. Goldstein, and L. Gordon. Two mo-
ments sufﬁce for poisson approximations: The chen-
stein method. Ann. Probab., 17(1):9–25, 01 1989.

[14] A. Das, N. Borisov, and M. Caesar. Tracking mobile
web users through motion sensors: Attacks and de-
fenses. In NDSS 2016, 2016.

[15] Y. Fablet, J. Borst, J. Uberti, and Q. Wang. Us-
ing multicast dns to protect privacy when exposing
Internet-Draft draft-ietf-rtcweb-
ice candidates.
mdns-ice-candidates-02,
IETF Secretariat, October
2018. http://www.ietf.org/internet-drafts/
draft-ietf-rtcweb-mdns-ice-candidates-02.
txt.

[16] E. W. Felten and M. A. Schneider. Timing attacks on
web privacy. In ACM CCS ’00, pages 25–32, 2000.

[17] Y. Gilad and A. Herzberg. Fragmentation considered
vulnerable. ACM Trans. Inf. Syst. Secur., 15(4):16:1–
16:31, Apr. 2013.

[18] F. Gont. Security Implications of Predictable Fragment

Identiﬁcation Values. RFC 7739, Feb. 2016.

[19] Google.

Issue 928273: uniﬁed plan breaks rtp dat-

achannels with empty datachannel label, Feb. 2019.

[20] A. Herzberg and H. Shulman. Fragmentation consid-

ered poisonous. CoRR, abs/1205.4011, 2012.

[21] T. Hudek and D. MacMichael. RSS hashing functions.

[22] Information Sciences Institute (University of Southern

California). Internet Protocol. RFC 791, Sept. 1981.

[23] A. Janc and M. Zalewski.

of client
identiﬁcation mechanisms.
www.chromium.org/Home/chromium-security/
client-identification-mechanisms.

Technical analysis
https://

[24] B. Jenkins. lookup2.c. http://burtleburtle.net/

bob/c/lookup2.c, December 1996.

[25] B. Jenkins. lookup3.c. http://burtleburtle.net/

bob/c/lookup3.c, May 2006.

[26] M. Khan.

RTCDataChannel

for

beginners.

https://www.webrtc-experiment.com/docs/
rtc-datachannel-for-beginners.html, 2013.

[27] A. Klein.

Predictable javascript math.random
http:

and http multipart boundary string.
//www.securitygalore.com/site3/math_
random_and_multipart_boundary.

[30] J. Knockel and J. R. Crandall. Counting packets sent
between arbitrary internet hosts. In 4th USENIX Work-
shop on Free and Open Communications on the Inter-
net (FOCI 14), 2014.

[31] T. Kohno, A. Broido, and k. Claffy. Remote physical
device ﬁngerprinting. IEEE Transactions on Depend-
able and Secure Computing, 2(2):93–108, May 2005.

[32] A. Kumar, V. Paxson, and N. Weaver. Exploiting
underlying structure for detailed reconstruction of an
internet-scale event. In 5th ACM SIGCOMM Conf. on
Internet Measurement, IMC ’05, pages 33–33, 2005.

[33] G. Landsberg. Ueber eine Anzahlbestimmung und
eine damit zusammenhängende Reihe. J. Reine Angew.
Math., 111:87–88, 1893.

[34] H. Li and L. Mason. Estimation and simulation of net-
work delay traces for voip in service overlay network.
2007 International Symposium on Signals, Systems and
Electronics, pages 423–425, 2007.

[35] S. Maheshwari, K. Vasu, S. Mahapatra, and C. S. Ku-
mar. Measurement and analysis of UDP trafﬁc over
wi-ﬁ and GPRS. CoRR, abs/1707.08539, 2017.

[36] G. Maone. NoScript. https://noscript.net/.

[37] P. Matthews, J. Rosenberg, D. Wing, and R. Mahy. Ses-
sion Traversal Utilities for NAT (STUN). RFC 5389,
Oct. 2008.

[38] A. Melnikov and I. Fette. The WebSocket Protocol.

RFC 6455, Dec. 2011.

[39] R. Menscher. Exploiting Windows’ IP ID random-
ization bug to leak kernel data and more (CVE-
2018-8493).
https://menschers.com/2018/10/
30/what-is-cve-2018-8493/, November 2018.

[40] Microsoft.
chine
en-us/azure/virtual-machines/windows/
b-series-burstable.

virtual ma-
B-series
https://docs.microsoft.com/

burstable

sizes.

[41] Microsoft.
TCP/IP
https://portal.msrc.microsoft.com/en-US/
security-guidance/advisory/CVE-2018-8493.

CVE-2018-8493
disclosure

windows
|
vulnerability.

information

[28] A. Klein. Detecting operation of a virtual machine (US

patent 9384034), July 2016.

[29] A. Klein and B. Pinkas. DNS cache-based user track-
ing. In 26th Annual Network and Distributed System
Security Symposium, NDSS 2019, San Diego, Califor-
nia, USA, February 24-27, 2019. The Internet Society,
2019.

[42] Mozilla. Bug 1101528 - Firefox uses the same TLS
session ticket and/or ID between normal and pri-
vate browsing. https://bugzilla.mozilla.org/
show_bug.cgi?id=1101528.

[43] L. Orevi, A. Herzberg, and H. Zlatokrilov. DNS-DNS:
DNS-based de-nat scheme. In Cryptology and Network
Security CANS, pages 69–88, 2018.

[44] PCI Security Standards Council.

Payment Card
Industry (PCI) Data Security Standard v3.2.1.
https://www.pcisecuritystandards.org/
documents/PCI_DSS_v3-2-1.pdf, May 2019.

[45] A. Popov, M. Nystrom, D. Balfanz, A. Langley, and
J. Hodges. The Token Binding Protocol Version 1.0.
Internet-Draft draft-ietf-tokbind-protocol-16, Internet
Engineering Task Force, Oct. 2017. Work in Progress.

[46] D. Reed, P. S. Traina, and P. Ziemba. Security Con-
siderations for IP Fragment Filtering. RFC 1858, Oct.
1995.

[47] R. Roemer, E. Buchanan, H. Shacham, and S. Sav-
age. Return-oriented programming: Systems,
lan-
guages, and applications. ACM Trans. Inf. Syst. Secur.,
15(1):2:1–2:34, Mar. 2012.

[48] D. Roesler. Demo. https://diafygi.github.io/

webrtc-ips/, 2015.

[49] F. Salutari, D. Cicalese, and D. Rossi. A closer look at
ip-id behavior in the wild. In International Conference
on Passive and Active Network Measurement (PAM),
Berlin, Germany, Mar. 2018.

[50] I. Sanchez Rola, I. Santos, and D. Balzarotti. Clock
around the Clock: Time-based device ﬁngerprinting.
In CCS 2018, 25th ACM Conference on Computer
and Communications Security, October 15-19, 2018,
Toronto, Canada, Toronto, CANADA, 10 2018.

[51] S. Sanﬁlippo.

new tcp scan method.

http://
seclists.org/bugtraq/1998/Dec/79, December
1998.

[52] H. Shulman. Pretty bad privacy: Pitfalls of DNS en-
In 13th Workshop on Privacy in the Elec-

cryption.
tronic Society, WPES ’14, pages 191–200, 2014.

[53] M. J. Silbersack.

darwin-xnu/bsd/netinet/ip_id.c.

https://opensource.apple.com/source/xnu/
xnu-4570.41.2/bsd/netinet/ip_id.c.

[54] M. Stockley. Anatomy of a browser dilemma – how
HSTS ‘supercookies’ make you choose between pri-
vacy or security. https://nakedsecurity.sophos.
com.

[55] E. Sy, C. Burkert, H. Federrath, and M. Fischer. Track-
ing users across the web via tls session resumption. In
2018 Annual Computer Security Applications Confer-
ence (ACSAC ’18), December 3–7, 2018, Dec. 2018.

[56] P. Team. address space layout randomization. https:
//pax.grsecurity.net/docs/aslr.txt, 2001.

[57] S. Tolvanen. Hardening the kernel in android Oreo,

Aug. 2017.

[58] A. Vastel, P. Laperdrix, W. Rudametkin, and R. Rou-
voy.
FP-STALKER: Tracking Browser Fingerprint
Evolutions. In IEEE Symposium on Security and Pri-
vacy, pages 728–741. IEEE, May 2018.

[59] H. Wramner. Tracking users on the world wide web.
http://www.nada.kth.se/utbildning/grukth/
exjobb/rapportlistor/2011/rapporter11/
wramner_henrik_11041.pdf, 2011.

[60] J. Xu and T. Nguyen.

Private browsing in ﬂash
player 10.1.
https://www.adobe.com/devnet/
flashplayer/articles/privacy_mode_fp10_1.
html.

[61] M. Zalewski. Silence on the Wire. No Starch Press,

2005.

[62] Y. Zhu.

Weird new tricks

for browser ﬁn-
https://zyan.scripts.mit.edu/

gerprinting.
presentations/toorcon2015.pdf.

A Details of the Attack on Windows

A.1 Speeding up Phase 1 of the Windows At-

tack Using Preprocessing

Denote by C ∈ GF(2)15(J−1)×30 the matrix of equation coef-
ﬁcients derived from IP j ⊕IP0, which is known at setup time.
Entry C15( j−1)+(i−17),(i−17)+(m−16) in this matrix is equal to
(IP j ⊕ IP0)m for j ∈ [1, J − 1], i ∈ [17, 31] and m ∈ [16, 31],
and to 0 elsewhere.

During

Z ∈
an
GF(2)15(J−1)×15(J−1) for C is calculated using a Gaus-

“inverse” matrix,

setup

time,

sian elimination process

starting with

GF(2)15(J−1)×15(J−1) and C, so that

(cid:18)Id30
0

(cid:19)
0
0

∈

Z ·C =

(cid:19)

(cid:18)Id30
0

∈ GF(2)15(J−1)×30

For j = 1, . . . , J − 1, deﬁne D j = (Vec(IPID j − (β0 + j)
mod 215) ⊕ Vec(IPID0 − (β0) mod 215))17,...,31, then eq. (4)
becomes (for i = 17, . . . , 31):

31
(cid:77)

(IP j ⊕ IP0)m · Ki+m = D j
i

m=16

(7)

Note that the most signiﬁcant bit of β0 mod 215 cancels
itself and does not affect D j, hence it is not needed in order
to calculate D j (i.e. the enumeration can take place over β0
mod 214). With Z it is now easy to ﬁnd the 30 bits of K: the

tracker simply calculates Z · (D0|| · · · ||DJ − 1) to get a vector
with the 30 K bits, and 15(J − 1) − 30 trailing zeros (if the
guess of β0 is correct). Note that if 15(J − 1) is larger than
the word size of the attacker CPU (e.g. 64), it is faster to use
only as many equations as the word size for the matrix and
vector operations, and then (with the known 30 bits of K and
eq. (7)), proceed to use the remaining equations to eliminate
keys.

A.2 Details of Phase 2 of the Attack

Note that the leftmost bit of β0 mod 215 cancels itself in
eq. (6) (since (x ⊕ 2k−1) mod 2k = (x + 2k−1) mod 2k),
therefore it is not needed in the calculation. Likewise, K17
cancels itself in eq. (6) (it only appears as an addendum
0 ⊕ IPg, j
0 )K17 in T (K, IP0 ⊕ IPg, j)17, when expanded ac-
(IP0
0 ⊕ IPg, j
cording to eq.
0 does not
change between j = 0 and j = 1 because IPg,0
as
they are in the same class B network). Therefore this bit is
not needed as well.

(1)), and its coefﬁcient IP0

0 = IPg,1

0

Finding the remaining key bits: Thus, knowing β0
mod 214 and K18, . . . , K62 sufﬁces to calculate the right hand
side of eq. (6). The values of β0 mod 214 and K33, . . . , K62
are known from phase 1, and since the left hand side is also
known, the equation can be used to eliminate false guesses of
K18, . . . , K32 (and also other false keys, such as ones caused
by incorrect β0 mod 214).

1 ⊕ IPg, j

The bit K18 deserves special attention. It appears only in
T (K, IP0 ⊕ IPg, j)17,...,31 as (IP0
1 )K18 in the leftmost
0 ⊕ IPg, j
bit, and (IP0
0 )K18 in the second-from-left bit. If in
0 = IPg, j
all pairs it holds that IP0
0 , then K18 only appears (as
an addendum) in the leftmost bit, which cancels itself in the
subtraction. Thus, in order to extract K18, the IP set needs
to satisfy ∃0<g≤GIPg,0
0}|,
0
then this requirement is equivalent to Q < G. An optimal
value of Q is calculated in Appendix C.

0. Deﬁne Q = |{g|IPg,0

0 = IP0

(cid:54)= IP0

A.3 Practical Considerations

A.3.1 Controlling Packets from the Browser

UDP: As explained in Section 6.3.2, it is possible to emit
UDP trafﬁc to arbitrary hosts and ports using WebRTC. The
packet payload is not controlled. The tracker can use the
UDP destination port in order to associate STUN trafﬁc to
the same measurement.
TCP: WebSocket [38] emits TCP trafﬁc in a controlled fash-
ion once a circuit is established, thus can be used by the snip-
pet to fully control packet transmission. The downside of
using TCP-based protocols is the TCP-level retransmission,
which can introduce loss of synchronization between the de-
vice and the server side, regarding how many packets were
sent. The tracker can use the packet payload to mark packets
that belong to the same measurement.

Table 3: Common tail length probability - measured with
1000 randomly chosen sets of 30 IPs (J = 6, G = 12, Q = 3),
10,000 tests each (107 tests altogether).

Common
tail [bits]
45
44
43
42
41
≤ 40

Prob.

0.9937579
0.0058328
0.0003783
2.6 × 10−5
2.9 × 10−6
2.1 × 10−6

A.3.2 Packet Transmission Order

We encountered cases in the wild where the packet payload
generation order is not identical to packet transmission or-
der. Speciﬁcally, Microsoft IE and Edge are prone to this
behavior. This is only relevant in the same class B network
(since there the original extraction algorithm makes an as-
sumption on the order of the packets). Therefore, the tracker
should try all possible permutations of packet order (per class
B network IPs). In Phase 1, this means enumerating over all
π ∈ SJ (J! permutations). For each permutation, use the fol-
lowing deﬁnition of D j (instead of the original one):

D j = (Vec(IPID j − (β0 + π( j)) mod 215)⊕

Vec(IPID0 − (β0 + π(0)) mod 215))17,...,31
Observe that the IPID values used in D j are in the same order
of the IP addresses used to calculate Z, therefore there is no
need to re-calculate Z with each iteration.
It follows that
enumerating over all possible orders will increase the run
time of Phase 1 by a factor of J!. In Phase 2, for each pair
of IP addresses, there are only 2! permutations, and since the
elimination is so powerful, this will only affect the run time
due to the ﬁrst pair, i.e. will double the run time.

A.3.3 Handling False Positives

The issue of false positive keys is covered in Appendix C. As
mentioned there, the vast majority of false positive keys only
differ from the correct key by a few leftmost bits. Table 3
demonstrates that with an optimal choice of 30 IP addresses,
if the tracker keeps only 41 bits of the key tail, he/she will
get multiple keys with probability 2.1 × 10−6, which is suf-
ﬁciently small even for a large scale deployment.

In the case where multiple keys are emitted by the al-
gorithm (even after truncation, e.g.
to 41 bits), two strate-
gies can be applied: either (a) determining that this partic-
ular device cannot be assigned an ID (at the price of losing
2.1 × 10−6 of the devices); or (b) assigning multiple IDs to
the device (which makes tracking the device more compli-
cated and more prone to ID collisions).

A.3.4 Handling False Negatives and Interference

It is important to note that while there may be false positives,
there are no algorithmic false negatives, i.e.
the algorithm
always emits the correct key (possibly along with incorrect
keys), given the correct data. However, it is possible for the
algorithm to receive incorrect data, in the sense that IP IDs
are provided which are not (even after re-ordering) derived
from an incrementing counter – i.e. there are “gaps” in the
counter values associated with the IP IDs. This can happen
either due to packet loss or due to interference.
Packet loss: In TCP, when a packet from the client to the
server is lost, the client will note a missing ACK and will
eventually retransmit the original data (with incremented IP
ID). This will cause a gap in the counter values, which can
be enumerated by the analysis logic (our analysis logic does
not currently implement this). Another packet loss scenario
is wherein the ACK packet from the server to the client is
lost, and the client retransmits the original data. The server
however receives two such packets, and can simply discard
the one with incremented IP ID. Thus the “problematic” sce-
nario is the one wherein the original data packet is lost.
Interference: Theoretically, an unrelated packet sent by the
Windows device in between measurement packets may inter-
fere with the measurement. However, this is very unlikely.
First, the interfering packet must fall into the same counter
bucket as that of the measurement packets – this happens
with probability of 1/8192 for a given bucket. Second, the
timing is delicate – the interfering packet should be sent be-
tween the ﬁrst and the last measurement packet. This time
window is below 1 second, so overall the likelihood for in-
terference is very low. When such an interference happens,
it creates a gap in the IP ID values, which can be addressed
as explained below.
Addressing “gaps”: The analysis logic can compensate for
up to l lost packets in the ﬁrst class B network (g = 0) by
(cid:1) gap conﬁgura-
enumerating over all possible ∑l
tions (each addendum counts all weak compositions of d
into J − 1 parts). In our experiment, we measured l = 4 for
some “difﬁcult” networks, so for J = 6 there are 126 gap
conﬁgurations, thus a ×126 factor in the runtime. Note that
a gap in the transmissions for g > 0 is much easier to han-
dle, as (IPIDg,1 − IPIDg,0) in eq (6) may now take values
in {1, . . . , l + 1}, so there is no runtime factor for this case.
When the total gap space is larger than l, the algorithm will
yield no key. In such a case, the server can instruct the snip-
pet to run another test. Therefore the actual false negative
probability can be reduced to as small as necessary.

(cid:0)J−2+d
J−2

d=0

A.4 Deploying the Attack when Javascript is

Disabled

When Javascript (or any client side scripting) is not available,
e.g. with NoScript browser extension [36], it is still possible

to send TCP packets to arbitrary hosts. Instead of orches-
trating the packet transmission with Javascript, the snippet
simply instructs the browser to load images (via IMG HTML
tag) from the destination IP addresses. This generates TCP
trafﬁc to the IP addresses, so it should be still possible for
the tracking host to reconstruct a device ID from the key
K. It is of course a bit more complicated since (unlike the
Javascript-based implementation), the increments in β [i] be-
tween packets sent to different IPs are no longer 1 - they rely
on the exact order of transmission, and also need to take into
account SYN packets, ACK packets, and FIN packets.

A.5 Speeding the Attack Using Incremental

Enumeration

In the ﬁrst phase of the attack, instead of enumerating over
214 values of β0 en-masse, it is possible to enumerate over
the least signiﬁcant 3 bits, solve the linear equations to yield
16+3 bits of K (with 4(J − 1) elimination bits), and for the
surviving guesses, proceed to guess the next K bit and the
next β0 bit, eliminate using additional J − 1 bits, and so
on. The second phase of the attack proceeds along similar
lines, with the remaining bits of K guessed one by one and
eliminated. We did not implement this improvement as the
straightforward implementation described above sufﬁced to
ensure real-time tracking.

B Assuring that the Matrix C in the Windows

Attack is Invertible

We discuss here necessary conditions for the condition that
rank(ker(C)) = 0 to hold. (This condition is required in order
for the matrix C to be invertible and allow learning sufﬁcient
linear equations for extracting the key in the ﬁrst phase of the
attack.)

If C was chosen at random from GF(2)15(J−1)×30, then per
215(J−1)−a ), and for J = 6
a=0(1 −

[33], Pr(rank(C) = 30) = ∏29
this yields Pr(rank(ker(C)) > 0) ≈ 2−45.

1

However,

in our case C has a special structure, very
unlike a random matrix, which affects the distribution of
rank(ker(C)). It is therefore needed to check the probabil-
ity of this event based on this distribution.

We ran an experiment where we simulated 10,000,000 sets
of destination IP addresses. The following are the lead fac-
tors with regards to the invertability of C, according to our
experiments:

• Denote by n1 the ﬁxed ﬁrst common bits inside the class
B subnet of all IP j (i.e.
the ﬁrst 16 + n1 bits of the
IP address are ﬁxed). Since (trivially) rank(ker(C)) ≥
n1, it follows that n1 = 0 is a necessary condition for
rank(ker(C)) = 0.

• Likewise, denote by n2 the ﬁxed last common bits in-
side the class B subnet of all IP j. Since rank(ker(C)) ≥

n2, it follows that n2 = 0 is a necessary condition for
rank(ker(C)) = 0.

(cid:76)31

• Due to the speciﬁc structure of the equations, there are
some (cyclic) nonzero vectors in ker(C) given some
simple (but rare) conditions on IP j. The most common
m=16(IP j ⊕ IP0)m = 0 which,
condition is ∀0< j≤J−1
if met (probability for random IP j values is 2−(J−1)),
yields C · (1, 1, . . . , 1) = 0 (i.e.
this vector of cycle
length 1 is in ker(C)). Thus, a necessary condition for
m=16(IP j ⊕ IP0)m = 1.
rank(ker(C)) = 0 is ∃0< j≤J−1
Other such vectors exist for longer cycles, but their con-
ditions are much more rare.

(cid:76)31

IP sets of size J = 6 that fulﬁll the above three requirements
have a probability of roughly 1:1000 to yield rank(ker(C)) >
0 (We estimated this probability empirically, by simu-
lating 10,000,000 random sets, of which 10,257 yielded
rank(ker(C)) > 0). This demonstrates that by fulﬁlling these
three simple requirements (which are indeed very easy to
meet), C becomes “invertible” with very high probability
(99.9% for J = 6). Of course, to determine whether a par-
ticular C is “invertible” requires applying the Gaussian elim-
ination process (and calculating Z).

Conclusion: There should not be any problem choosing
an IP set that makes C “invertible” (in setup time, before
starting to deploy the tracking system). The requirements are
very realistic and can likely be met with any major ISP/cloud
service.

C False Positives in the Windows Attack

Naïvely, with an elimination power of 15 · G bits, G = 2
should sufﬁce to eliminate almost all false guesses in Phase
2. However, this does not take into account the problem of
false positives which only differ from the correct key by their
few leftmost bits. Below is a detailed analysis of this sce-
nario, speciﬁcally for keys differing only in their leftmost bit
(K18).

C.1 Correct Counter Value (β )

Consider a false key that yields correct data at the end of
it has the same (K33, . . . , K62) and same β0
Phase 1 (i.e.
mod 214 as the correct key), but has a different K18.
In Section 4.4 we saw that for g where IPg,0

0, K18
does not affect the expression on the right hand side of
eq. (6). Therefore we can focus on g where IPg,0
(cid:54)= IP0
0
0
(i.e. IPg, j
0 = 1). It is still possible in such cases, that
the right hand side of eq. (6) will be identical for the two
keys, depending on the second from left bit of T (K, IP0 ⊕
IPg, j)17,...,31 ⊕ Vec(IPID0 − β0 mod 215)17,...,31.

0 = IP0

0 ⊕ IP0

This bit can be written as (IP0

1 , where
depends on K19, . . . , K62, IPIDg, j, and β0 mod 215.

0 )K18 ⊕ Ψg,1

0 ⊕ IPg, j

Ψg, j
1

Denote the remaining bits of T (K, IP0 ⊕ IPg, j)17,...,31 ⊕
Vec(IPID0 − β0 mod 215)17,...,31 with the corresponding
Ψg, j
i−17 notation, and note that they do not depend on K18 (ex-
cept for Ψg, j
0 , in which K18 cancels itself in the subtraction),
and hence are identical across the two keys. Therefore the
right hand side of eq. (6) can be written as follows (with K18
being in effect only where it is explicitly written):

1 + Num(Ψg,1
− Num(Ψg,0

0 , Ψg,1

1 ⊕ K18, Ψg,1

1 , . . . , Ψg,1
14 )

(i.e. Ψg,1

0 , Ψg,0

1 ⊕ Ψg,0

1 , . . . , Ψg,0

1 ⊕ K18, Ψg,0
14 ) mod 215
Now it is easy to see that K18 only affects the result if Ψg,1
1
Ψg,0
1
into the leftmost bit is different. Assuming Ψg,1
random, then a pair of IPs in class bg with IPg,0
0
a probability 1
there is a lower bound of
2−|{g|IPg,0

(cid:54)=
1 = 1) since only in this case the borrow
1 ⊕ Ψg,0
is
1
(cid:54)= IP0
0 has
2 to distinguish the two keys. In other words,

0}| = 2−(G−Q)

0 (cid:54)=IP0

on the false positive probability (which due to incorrect keys
which differ in K18 from the correct key, and whose β0
mod 214 is correct).

C.2

Incorrect Counter Value (β )

Another source of false positives is the case where Phase 1
emits multiple values for β0 mod 214 (a correct one, and one
or more incorrect ones). Speciﬁcally, consider β0 mod 214
which differs from the correct value only in its most signiﬁ-
cant bit.

If D j are unchanged, then the correct K33, . . . , K62 will
solve equations eq. (7), and thus Phase 1 will emit correct
key bits, but incorrect β0 mod 214 to Phase 2. In order for
D j not to change, the borrow in IPID j − β0 mod 215 (ig-
noring the j addendum since j is small and we are inter-
ested in the leftmost bits) must be identical to the borrow in
IPID0 − β0 mod 215 induced by the change in β0 mod 214.
This event only happens when the second-from-left bits in
IPID j and in IPID0 are identical. In such a case, Phase 2 will
get correct K33, . . . , K62, but incorrect β0 mod 214 (ﬂipped
leftmost bit). This happens with probability 2−(J−1).

In Phase 2 (eq. (6)), Vec(IPID0 − β0 mod 215)17,...,31 will
have its second-from-left bit ﬂipped. Consider now an in-
correct key which is identical to the correct key in all bits but
K18 (which is ﬂipped). The coefﬁcient of K18 as linear adden-
dum in the second-from-left bit of T (K, IP0 ⊕ IPg, j)17,...,31 is
(IP0 ⊕ IPg, j)0, so if (IP0 ⊕ IPg, j)0 = 1 then the ﬂipping of
the second-from-left bit of Vec(IPID0 − β0 mod 215)17,...,31
is cancelled by the ﬂipping in the second-from-left bit of
T (K, IP0 ⊕ IPg, j)17,...,31 induced by the ﬂipped K18, and
therefore eq. (6) holds.

If (IP0 ⊕ IPg, j)0 = 0 then the ﬂipping in Vec(IPID0 − β0
mod 215)17,...,31 may still cancel itself in the subtraction, if

T (K, IP0 ⊕ IPg,0)18 = T (K, IP0 ⊕ IPg,1)18, which has 1
ability.

2 prob-

In conclusion, Phase 2 emits the false key with a probabil-
ity of approximately (due to neglecting of the j addendum)

2−(J−1)−|{g|IPg,0

0 =IP0

0}| = 2−(J−1)−Q.

C.3

Incorrect Data (IP IDs)

The above discussion assumes that the data fed into Phase 1
(the IPIDg, j values) is correct, i.e.
that these are the exact
same IP IDs generated by the device. This assumption may
break if one or more of the following conditions hold:

• TCP retransmissions combined with lost packets (e.g. a
TCP packet is lost, then retransmitted, or a TCP packet
is received, but considered lost by the sender, retrans-
mitted, but then the retransmitted packet is lost). In both
cases, the receiver has no idea that a packet was lost on
the way, so the IP ID counter “synchornization” is lost.

• The sender (device) sends one or more packets whose
IP ID is generated through the same bucket β [i], be-
tween sending the intended packets to IP0 and IPJ−1 or
to IPg,0 and IPg,1. In such case, again there will be a
“synchronization” loss due to the unaccounted-for in-
crement in β [i].

• The IP ID is not generated by Windows 8 or later.

We claim that in such cases, with extremely high probabil-
ity, the algorithm will yield no key at all, which can then
be handled by an upper-level logic (e.g. re-test the device
to eliminate temporary adverse conditions). Speciﬁcally, a
case in which the IP ID is not generated by Windows 8 or
later is extremely unlikely to yield any key (if the IP ID
are randomly or pseudo-randomly generated), so this one
is trivially dismissed. One exception is a counter-based IP
ID (either global counter, or per-IP counter), which can con-
form to a key wherein K18 = · · · = K62 = 0 (this key yields
T (K, I)17,··· ,31 = (0, 0, . . . , 0) for |I| = 32), but this case can
be easily detected since IPIDg, j+1 − IPIDg, j mod 215 = 1
which is extremely improbable for IP ID’s generated by Win-
dows 8 or later.

The remaining cases all involve a situation wherein β [i]
gets incremented out of sync. Both cases are rare (the
ﬁrst one only happens in adverse network conditions, and
in the second one, the probability of a packet destined to
a random IP address to hit a speciﬁc bucket is 2−13, and
the timing is extremely delicate). Nevertheless, we simu-
lated this condition with 100 randomly chosen sets of 30 IPs
(J = 6, G = 12, Q = 3), 10,000 tests each, where in each indi-
vidual test, we chose a random class (g) and a random posi-
tion ( j) within the class, and incremented β [i] once (between
calculating IPIDg, j and IPIDg, j+1). In each of the 1,000,000
tests, no keys were emitted by the algorithm.

C.4 Optimizing the IP Set for Minimum False

Positives

2

Since (from Table 3) keys with ﬂipped K18 are the source of
most false positives, the tracker should choose a set of IP ad-
dresses that minimizes (over Q) this false positive probabil-
ity, 2−(J−1)−Q + 2−(G−Q) (see Appendix C.) The said min-
imum is at Q = G−(J−1)/2, and yields false positive lead-
ing term of 2 · 2− G+J−1
. For G = 12, J = 6, the optimum
there are 3 (or 4) bg values
is at Q = 3 or Q = 4, i.e.
whose leftmost bit is identical to the one of b0.
In such
case, the combined probability of a false key which differs
in K18 is 2−8 + 2−9 = 0.005859375. Note that in Table 3,
the probability of a common tail length of 44 bits is ex-
actly the probability of a false key differing in K18 only, and
the value measured, 0.0058328, is in line with the theory
(E = 0.005859375, for 10,000,000 tests, σ = 2.41 × 10−5,
so 0.0058328 = E − 1.1σ ).

D Windows: Exposing Kernel Data

Prior to Microsoft’s October 2018 Security Update, The
β array (IpFragmentIdIncrementTable in the Win-
dows tcpip.sys module) was not
initialized (except
two cells), so it contained data left over
for the ﬁrst
in memory from the previous kernel modules.
This
data happens to be an extension of the data structure
RTL_PROCESS_MODULES [12] which is essentially a list of
RTL_PROCESS_MODULE_INFORMATION structures [11], each
describing a loaded kernel module. Knowing K, the at-
tacker forces the device to send a packet to 8192 IP ad-
dresses, chosen so that T (K, IPg
0,...,15)19,...,31 takes all pos-
sible M = 8192 values (note this requires a stronger ad-
versary model a-la MitM, and that the attacker can only
choose the IP set after K is reconstructed). This in turn
ensures that ig goes through all possible M = 8192 values.
Per Section 4.4, the attacker extracts β [ig] mod 214 for each
packet. However, the attacker still does not know the order,
i.e. which index i belongs to which value extracted. The at-
tacker now enumerates over (K2 ⊕ T (K, IPSRC))19,...,31 (13
bits), and together with the (known) T (K, IPg
0,...,15)19,...,31,
calculates i for each IPg and IPIDg. Given the data structure
of RTL_PROCESS_MODULES, and that the ﬁrst module listed
is always \SystemRoot\system32\ntoskrnl.exe, the at-
tacker can eliminate false guesses and obtain the kernel data
in the correct order (15 least signiﬁcant bits from each 32-bit
DWORD). Note that RTL_PROCESS_MODULE_INFORMATION
contains kernel address data, so this method partially by-
passes KASLR.

E Attacking RFC 7739’s Hash-Based Frag-
ment Identiﬁcation Selection Algorithm

The Windows algorithm is an implementation of the follow-
ing abstract scheme (as proposed in RFC 7739 [18, Section
5.3]):

IPID = F(IPSRC, IPDST , Key1)+

counter[G(IPSRC,ClassB(IPDST ), Key2)] mod 215

This scheme lends itself easily to tracking as long as IPSRC
does not change (i.e.
the device remains in the same net-
work). Observe that packets sent to IPs in the same class B
network have their IP IDs generated using the same counter.
The tracker needs to control several (J) IPs in the same class
B network - denote these by IP j (where 0 ≤ j < J), and force
the device to send packets to these addresses in rapid suc-
cession, observing their corresponding IP ID values IPID j.
Observe that

IPID j − IPID0 mod 215 =
j + F(IPSRC, IP j, key1) − F(IPSRC, IP0, key1) mod 215

And the right hand side is ﬁxed (for ﬁxed IPSRC). The de-
vice ID then is simply a vector of IPID j − IPID0 mod 215
(J − 1 values). Since each element in the vector is 15 bit,
3-4 elements sufﬁce to ﬁngerprint devices in a large scale
deployment, hence J = 4 or J = 5 IP addresses (in the same
class B network) are needed.

F Analysis of the Effective Key Space in At-

tacking Algorithm A3

The function g(net) is a shift right of net by ρ (architec-
ture dependent) bits.28 net is the address of the network
namespace object associated with the current container (OS
isolation compartment). All such objects are maintained by
Linux in a linked list. The head of the list is a global vari-
able (init_net),29 which means that the ﬁrst container will

28ρ = L1_CACHE_SHIFT

(https://git.kernel.org/pub/

scm/linux/kernel/git/stable/linux-stable.git/plain/
include/net/netns/hash.h)
to
ρ = (cid:98)log2 sizeof(struct net)(cid:99) in versions 4.19 and later.

versions

kernel

up

in

4.18,

L1_CACHE_SHIFT is log2 of the L1 cache line size, and is architec-
ture/chipset dependent.
In x64 architecture (modern Linux) and in older
ARM64 chipsets (e.g. Snapdragon 835) it is 6, and in newer ARM64
chipsets (e.g. Snapdragon 845) it is 7. ρ can be extracted statically from
the kernel image ﬁle.

sizeof(struct net) is determined by many conﬁguration options,
and therefore can considerably vary among builds and architectures. In one
Azure Ubuntu 16.04.1 (Linux kernel 4.15.0) machine with x64 architecture,
we observed a value of 6080 bytes, so we assume most values will be in the
range 4096-8191, i.e. (cid:98)log2 sizeof(struct net)(cid:99) = 12.

29https://elixir.bootlin.com/linux/v4.0/source/net/

have its net address in the .data segment of the kernel im-
age, i.e. will have a ﬁxed offset from the start of the kernel
image in memory. This is relevant for all single-container
Linux installations: desktops/laptops, most servers, and An-
droid devices. This offset from the start of the kernel image
is determined in compile time, and is build-speciﬁc. Given
the build, it is possible to determine the offset ofﬂine, since it
depends only on the Linux build, rather than on the hardware
or any temporal conditions, and can be extracted from the
kernel image ﬁle (indeed, we wrote a Perl script that extracts
it from some Linux and Android kernel image ﬁles). Also,
from the kernel image ﬁle it is also possible to extract the
value of (cid:98)log2 sizeof(struct net)(cid:99) if needed (e.g. from
the implementation of net_hash_mix.)30

The build identity can be either inferred or obtained in
many ways.
In many Android devices for example, the
Chrome browser reports the exact build identiﬁer as part of
the User-Agent HTTP request header. And in Linux, when
the distribution version is known, there are only a few differ-
ent builds that are associated with it. Once the build identity
is known, it is possible (in Linux) to obtain the kernel image
ﬁle directly via a download site, or (in Android) to extract the
kernel image from a stock ROM ﬁle from a download site.
Henceforth we assume that the offset of init_net (from the
kernel image base address) is known.

As for the Android/ARM64: the “ofﬁcial” KASLR sup-
port for ARM64 architecture was introduced in Linux kernel
4.6. Google back-ported it to kernel 4.4.56 used in Android
8.x [57], Android builds based on kernel 4.4.56+ include
KASLR, and Androids based on earlier builds do not.

F.1 Linux (x86_64 Architecture), KASLR Dis-

abled

In some Linux distributions, KASLR is disabled by default
(e.g., in older Ubuntu distributions.)31 Without KASLR, the
kernel image is always loaded at virtual address
__START_KERNEL=__START_KERNEL_map +
__PHYSICAL_START=0xffffffff80000000+
CONFIG_PHYSICAL_START,32
default,
by
CONFIG_PHYSICAL_START=0x1000000,33
net
will be 0xffffffff81000000 plus the init_net offset.
In this case, |{g(net)}| = 1, thus |W | = 232.
In our mea-
surements, given an average (based on simulations) of 70.45
pairs (of which 37.48 pairs on average are correct), Azure’s
second weakest and cheapest VM (B1ms class, 1 vCPU
[40]) can go over all 232 keys in 2077 seconds (less than

thus

and

30https://git.kernel.org/pub/scm/linux/kernel/git/
stable/linux-stable.git/plain/include/net/netns/hash.h

31https://wiki.ubuntu.com/Security/Features
32

https://elixir.bootlin.com/linux/v4.0/source/arch/
x86/include/asm/page_types.h, https://elixir.bootlin.com/
linux/v4.8/source/arch/x86/include/asm/page_64_types.h
33https://elixir.bootlin.com/linux/v4.0/source/arch/

core/net_namespace.c

x86/Kconfig

35 minutes). A machine/cluster of 128 CPUs can provide
real-time performance in this case.

Practically, we are not aware of Android kernels wherein
CONFIG_NET_NS is enabled, and KASLR is not enabled.

F.2 Linux (x86_64 Architecture), KASLR En-

F.4 Android (ARM 64-Bit Architecture),

abled

KASLR Enabled

enabled,

random quantity is
When KASLR is
a
added to the original kernel
address
image base
(0xffffffff81000000), and the new value is used as
the effective image base address. This quantity is computed
in find_random_virt_addr34 as a subset of all possible
increments of CONFIG_PHYSICAL_ALIGN=2MB35 from 0
to KERNEL_IMAGE_SIZE=1GB,36 thus there are up to 512
possible values. Note that all the random bits are part of the
least signiﬁcant 30 bits of the address, and therefore all of
them are part of g(net), regardless of the value of ρ. Hence
|{g(net)}| = 29 and |W | = 241.

This is still a realistic scenario for an attack, possibly even
in real time given a powerful enough CPU (or CPUs - the ex-
haustive search can be extremely parallelized). For example,
we estimate that 10,000 B1s virtual machines in Microsoft
Azure (each $3.20/month) would be able to enumerate this
key space (for an average 70.45 pairs of IP addresses) in
around 99 seconds. Using stronger machines can bring this
down to real-time performance. Given g(net) it is possible
to reconstruct init_net, and subtracting its offset, to get to
__START_KERNEL, from which it is easy to ﬁnd all addresses
of code and global/static variables in the kernel. Therefore
the technique provides a full kernel KASLR bypass.

F.3 Android (ARM 64-Bit Architecture),

Just like in the x86_64 architecture, a random quantity is
added to the original kernel image base address. The quantity
is computed in kaslr_early_init as ARM64_VA_BITS-23
random bits followed by 21 zero bits.39 Thus the num-
ber of random bits is 16. Since g(net) is truncated to
32 bits (after a right shift of init_net by ρ, where ρ =
L1_CACHE_SHIFT = 6 or ρ = 7 for kernel version 4.18.x
and earlier, and ρ = (cid:98)log2 sizeof(net)(cid:99) ≈ 12 for kernel
version 4.19 and later), all 16 random bits will be part of
g(net).Therefore |{g(net)}| = 216 and |W | = 248. While not
economically efﬁcient, it is still possible to amass enough
computing power to extract this data in speciﬁc cases. Given
g(net) it is possible to reconstruct init_net, and subtract-
ing its offset, to get to KIMAGE_VADDR, from which it is easy
to ﬁnd all addresses of code and global/static variables in the
kernel. Therefore the technique provides a full KASLR by-
pass.
NOTE: Samsung devices implement a different KASLR
mechanism (part of Samsung Knox). The implementation
details are not public, but assuming KASLR is implemented
as an offset of up to 16 entropy bits, our analysis of Android
applies for Samsung devices as well.

G Other Linux/Android Attack Scenarios

KASLR Disabled

G.1 KASLR Attacks

The original (non-randomized) kernel image base address is
KIMAGE_VADDR = 264 − 2CONFIG_ARM64_VA_BITS + 227, with the
.text segment TEXT_OFFSET=0x80000 above that.37 and
CONFIG_ARM64_VA_BITS=39 by default.38 All the Android
kernel images we reviewed use these default values. The
kernel image .text segment start address is therefore al-
ways 0xffffff8008080000, and init_net takes its offset
from this address. Since there is no KASLR, the offset of
init_net is constant, hence |{g(net)}| = 1 and |W | = 232.

34https://elixir.bootlin.com/linux/v4.8/source/arch/

x86/boot/compressed/kaslr.c

35https://elixir.bootlin.com/linux/v4.0/source/arch/

x86/Kconfig

36https://elixir.bootlin.com/linux/v4.8/source/arch/

x86/include/asm/page_64_types.h

37https://elixir.bootlin.com/linux/v4.6/source/

arch/arm64/include/asm/memory.h,
bootlin.com/linux/v4.6/source/arch/arm64/Makefile,
https://elixir.bootlin.com/linux/v4.6/source/drivers/
firmware/efi/libstub/arm64-stub.c

https://elixir.

38https://elixir.bootlin.com/linux/v4.6/source/arch/

arm64/Kconfig

In previous sections, we focused on an attack scenario
wherein a client device accesses a web page via a browser.
This scenario is relevant for both tracking and KASLR at-
tacks. There are, however, additional attack scenarios which
are relevant to (only) the KASLR attack.

It should be noted that the attack technique can be used
with various protocols over UDP (not just WebRTC/STUN)
- particularly with DNS. Also, non-UDP stateless protocols
can be used, e.g. ICMP. In all such cases, the attacker needs
to know the internal IP address of the target device (in We-
bRTC this can be obtained as part of the protocol) – ei-
ther via prior knowledge or via additional enumeration (Ap-
pendix G.2).

Based on this, the KASLR attack can be applied also to

servers, and to client devices in additional scenarios:

• Attacking UDP-based servers:

the attacker can send
queries from multiple IP addresses to the target server,

39https://elixir.bootlin.com/linux/v4.6/source/arch/

arm64/kernel/kaslr.c

and collect answers (which are sent over UDP) and ana-
lyze their IP IDs. This applies to any UDP-based proto-
col, e.g. DNS. The attacker can also force a UDP-based
server to send outgoing packets to attacker IPs (without
sending packets to the server from these IPs), e.g. in a
DNS resolver scenario, the attacker can provide the re-
solver with an authoritative answer containing multiple
NS records pointing at the attacker’s hosts.

• ICMP Echo Request+Reply packets (ping): the attacker
can send ICMP Echo Request packets from multiple IP
addresses to the target device (client or server), and as-
suming the ICMP packets are not dropped/rejected (as
often happens), the device will return ICMP Echo Reply
packets, which (ICMP being a stateless protocol over IP,
hence the analysis applies to its IP ID) can be used to
attack KASLR.

G.2

Internal IP Disclosure

In order to extract key,
the attacker needs to know the
(internal) IP address used as a source address for hash-
ing. When the attack is browser-based, WebRTC can be
used to extract the internal IP address [48]. This issue
is well known, and a standartization effort around reme-
diation is in the works (currently an RFC draft [15]).
In
accordance with this draft RFC, Google introduced a ﬂag
enable-webrtc-hide-local-ips-with-mdns to Google
Chrome v72 to prevent this leakage [7]. This ﬂag is turned
off by default, and is not available for Chrome in Android
(it is available for Chrome in Linux). As such, at present, it
does not have any signiﬁcant impact on our attack.

When WebRTC is not available (e.g.

the attack is
not browser-based, as in Appendix G.1), or when We-
bRTC cannot be used to disclose the internal IP ad-
dress (e.g. Linux Chrome users who explicitly turn on
enable-webrtc-hide-local-ips-with-mdns),
the at-
tacker can combine the enumeration over key with enumer-
artion over the internal IP address space, assuming prior
knowledge of that space. For example, if it is known that
the internal IP is in the 192.168.0.0/16 address space, then
this adds 16 bits to the enumeration of key, which is still
feasible for a 32-bit key. This yields both key and the inter-
nal IP address. Another example is Microsoft Azure, which
assigns internal IP addresses to servers in a customer farm
sequentially, starting from 10.0.1.1. Therefore, enumerat-
ing according to this order will require log2 F additional bits,
where F is the farm size.

Disclosing the internal IP address of a server is consid-
ered a vulnerability in itself. Speciﬁcally, it is a violation
of the PCI DSS version 3.2.1 article 1.3.7 (“Do not disclose
private IP addresses and routing information to unauthorized
parties”) [44].


