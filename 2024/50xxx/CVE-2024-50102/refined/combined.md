=== Content from git.kernel.org_af04c772_20250114_192550.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=291313693677a345d4f50aae3c68e28b469f601e)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=291313693677a345d4f50aae3c68e28b469f601e)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=291313693677a345d4f50aae3c68e28b469f601e)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=291313693677a345d4f50aae3c68e28b469f601e)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Linus Torvalds <torvalds@linux-foundation.org> | 2024-10-23 18:17:46 -0700 |
| --- | --- | --- |
| committer | Greg Kroah-Hartman <gregkh@linuxfoundation.org> | 2024-11-01 02:02:44 +0100 |
| commit | [291313693677a345d4f50aae3c68e28b469f601e](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=291313693677a345d4f50aae3c68e28b469f601e) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=291313693677a345d4f50aae3c68e28b469f601e)) | |
| tree | [e23ea23bbb5173639e2bfeabe33fc0caa51bbac0](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=291313693677a345d4f50aae3c68e28b469f601e) | |
| parent | [ee6f1a67693399e346dc4ce8ea9b2968036856db](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=ee6f1a67693399e346dc4ce8ea9b2968036856db) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=291313693677a345d4f50aae3c68e28b469f601e&id2=ee6f1a67693399e346dc4ce8ea9b2968036856db)) | |
| download | [linux-291313693677a345d4f50aae3c68e28b469f601e.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-291313693677a345d4f50aae3c68e28b469f601e.tar.gz) | |

x86: fix user address masking non-canonical speculation issuecommit 86e6b1547b3d013bc392adf775b89318441403c2 upstream.
It turns out that AMD has a "Meltdown Lite(tm)" issue with non-canonical
accesses in kernel space. And so using just the high bit to decide
whether an access is in user space or kernel space ends up with the good
old "leak speculative data" if you have the right gadget using the
result:
CVE-2020-12965 “Transient Execution of Non-Canonical Accesses“
Now, the kernel surrounds the access with a STAC/CLAC pair, and those
instructions end up serializing execution on older Zen architectures,
which closes the speculation window.
But that was true only up until Zen 5, which renames the AC bit [1].
That improves performance of STAC/CLAC a lot, but also means that the
speculation window is now open.
Note that this affects not just the new address masking, but also the
regular valid\_user\_address() check used by access\_ok(), and the asm
version of the sign bit check in the get\_user() helpers.
It does not affect put\_user() or clear\_user() variants, since there's no
speculative result to be used in a gadget for those operations.
Reported-by: Andrew Cooper <andrew.cooper3@citrix.com>
Link: [https://lore.kernel.org/all/80d94591-1297-4afb-b510-c665efd37f10@citrix.com/](https://lore.kernel.org/all/80d94591-1297-4afb-b510-c665efd37f10%40citrix.com/)
Link: [https://lore.kernel.org/all/20241023094448.GAZxjFkEOOF\_DM83TQ@fat\_crate.local/](https://lore.kernel.org/all/20241023094448.GAZxjFkEOOF_DM83TQ%40fat_crate.local/) [1]
Link: <https://www.amd.com/en/resources/product-security/bulletin/amd-sb-1010.html>
Link: <https://arxiv.org/pdf/2108.10771>
Cc: Josh Poimboeuf <jpoimboe@kernel.org>
Cc: Borislav Petkov <bp@alien8.de>
Tested-by: Maciej Wieczor-Retman <maciej.wieczor-retman@intel.com> # LAM case
Fixes: 2865baf54077 ("x86: support user address masking instead of non-speculative conditional")
Fixes: 6014bc27561f ("x86-64: make access\_ok() independent of LAM")
Fixes: b19b74bc99b1 ("x86/mm: Rework address range check in get\_user() and put\_user()")
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=291313693677a345d4f50aae3c68e28b469f601e)

| -rw-r--r-- | [arch/x86/include/asm/uaccess\_64.h](/pub/scm/linux/kernel/git/stable/linux.git/diff/arch/x86/include/asm/uaccess_64.h?id=291313693677a345d4f50aae3c68e28b469f601e) | 43 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |
| -rw-r--r-- | [arch/x86/kernel/cpu/common.c](/pub/scm/linux/kernel/git/stable/linux.git/diff/arch/x86/kernel/cpu/common.c?id=291313693677a345d4f50aae3c68e28b469f601e) | 10 | |  |  |  | | --- | --- | --- | |
| -rw-r--r-- | [arch/x86/kernel/vmlinux.lds.S](/pub/scm/linux/kernel/git/stable/linux.git/diff/arch/x86/kernel/vmlinux.lds.S?id=291313693677a345d4f50aae3c68e28b469f601e) | 1 | |  |  |  | | --- | --- | --- | |
| -rw-r--r-- | [arch/x86/lib/getuser.S](/pub/scm/linux/kernel/git/stable/linux.git/diff/arch/x86/lib/getuser.S?id=291313693677a345d4f50aae3c68e28b469f601e) | 9 | |  |  |  | | --- | --- | --- | |

4 files changed, 42 insertions, 21 deletions

| diff --git a/arch/x86/include/asm/uaccess\_64.h b/arch/x86/include/asm/uaccess\_64.hindex a10149a96d9e99..250e28cba0a0f6 100644--- a/[arch/x86/include/asm/uaccess\_64.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/include/asm/uaccess_64.h?id=ee6f1a67693399e346dc4ce8ea9b2968036856db)+++ b/[arch/x86/include/asm/uaccess\_64.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/include/asm/uaccess_64.h?id=291313693677a345d4f50aae3c68e28b469f601e)@@ -12,6 +12,13 @@ #include <asm/cpufeatures.h> #include <asm/page.h> #include <asm/percpu.h>+#include <asm/runtime-const.h>++/\*+ \* Virtual variable: there's no actual backing store for this,+ \* it can purely be used as 'runtime\_const\_ptr(USER\_PTR\_MAX)'+ \*/+extern unsigned long USER\_PTR\_MAX;  #ifdef CONFIG\_ADDRESS\_MASKING /\*@@ -46,19 +53,24 @@ static inline unsigned long \_\_untagged\_addr\_remote(struct mm\_struct \*mm,  #endif -/\*- \* The virtual address space space is logically divided into a kernel- \* half and a user half. When cast to a signed type, user pointers- \* are positive and kernel pointers are negative.- \*/-#define valid\_user\_address(x) ((\_\_force long)(x) >= 0)+#define valid\_user\_address(x) \+ ((\_\_force unsigned long)(x) <= runtime\_const\_ptr(USER\_PTR\_MAX))  /\* \* Masking the user address is an alternative to a conditional \* user\_access\_begin that can avoid the fencing. This only works \* for dense accesses starting at the address. \*/-#define mask\_user\_address(x) ((typeof(x))((long)(x)|((long)(x)>>63)))+static inline void \_\_user \*mask\_user\_address(const void \_\_user \*ptr)+{+ unsigned long mask;+ asm("cmp %1,%0\n\t"+ "sbb %0,%0"+ :"=r" (mask)+ :"r" (ptr),+ "0" (runtime\_const\_ptr(USER\_PTR\_MAX)));+ return (\_\_force void \_\_user \*)(mask | (\_\_force unsigned long)ptr);+} #define masked\_user\_access\_begin(x) ({ \_\_uaccess\_begin(); mask\_user\_address(x); })  /\*@@ -66,23 +78,16 @@ static inline unsigned long \_\_untagged\_addr\_remote(struct mm\_struct \*mm, \* arbitrary values in those bits rather then masking them off. \* \* Enforce two rules:- \* 1. 'ptr' must be in the user half of the address space+ \* 1. 'ptr' must be in the user part of the address space \* 2. 'ptr+size' must not overflow into kernel addresses \*- \* Note that addresses around the sign change are not valid addresses,- \* and will GP-fault even with LAM enabled if the sign bit is set (see- \* "CR3.LAM\_SUP" that can narrow the canonicality check if we ever- \* enable it, but not remove it entirely).- \*- \* So the "overflow into kernel addresses" does not imply some sudden- \* exact boundary at the sign bit, and we can allow a lot of slop on the- \* size check.+ \* Note that we always have at least one guard page between the+ \* max user address and the non-canonical gap, allowing us to+ \* ignore small sizes entirely. \* \* In fact, we could probably remove the size check entirely, since \* any kernel accesses will be in increasing address order starting- \* at 'ptr', and even if the end might be in kernel space, we'll- \* hit the GP faults for non-canonical accesses before we ever get- \* there.+ \* at 'ptr'. \* \* That's a separate optimization, for now just handle the small \* constant case.diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.cindex ab0e2da7c9ef50..b7d97f97cd9822 100644--- a/[arch/x86/kernel/cpu/common.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/kernel/cpu/common.c?id=ee6f1a67693399e346dc4ce8ea9b2968036856db)+++ b/[arch/x86/kernel/cpu/common.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/kernel/cpu/common.c?id=291313693677a345d4f50aae3c68e28b469f601e)@@ -69,6 +69,7 @@ #include <asm/sev.h> #include <asm/tdx.h> #include <asm/posted\_intr.h>+#include <asm/runtime-const.h>  #include "cpu.h" @@ -2371,6 +2372,15 @@ void \_\_init arch\_cpu\_finalize\_init(void) alternative\_instructions();  if (IS\_ENABLED(CONFIG\_X86\_64)) {+ unsigned long USER\_PTR\_MAX = TASK\_SIZE\_MAX-1;++ /\*+ \* Enable this when LAM is gated on LASS support+ if (cpu\_feature\_enabled(X86\_FEATURE\_LAM))+ USER\_PTR\_MAX = (1ul << 63) - PAGE\_SIZE - 1;+ \*/+ runtime\_const\_init(ptr, USER\_PTR\_MAX);+ /\* \* Make sure the first 2MB area is not mapped by huge pages \* There are typically fixed size MTRRs in there and overlappingdiff --git a/arch/x86/kernel/vmlinux.lds.S b/arch/x86/kernel/vmlinux.lds.Sindex 6e73403e874fc6..6fb8d7ba9b50aa 100644--- a/[arch/x86/kernel/vmlinux.lds.S](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/kernel/vmlinux.lds.S?id=ee6f1a67693399e346dc4ce8ea9b2968036856db)+++ b/[arch/x86/kernel/vmlinux.lds.S](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/kernel/vmlinux.lds.S?id=291313693677a345d4f50aae3c68e28b469f601e)@@ -359,6 +359,7 @@ SECTIONS  RUNTIME\_CONST(shift, d\_hash\_shift) RUNTIME\_CONST(ptr, dentry\_hashtable)+ RUNTIME\_CONST(ptr, USER\_PTR\_MAX)  . = ALIGN(PAGE\_SIZE); diff --git a/arch/x86/lib/getuser.S b/arch/x86/lib/getuser.Sindex d066aecf8aeb22..4357ec2a0bfc2c 100644--- a/[arch/x86/lib/getuser.S](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/lib/getuser.S?id=ee6f1a67693399e346dc4ce8ea9b2968036856db)+++ b/[arch/x86/lib/getuser.S](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/lib/getuser.S?id=291313693677a345d4f50aae3c68e28b469f601e)@@ -39,8 +39,13 @@  .macro check\_range size:req .if IS\_ENABLED(CONFIG\_X86\_64)- mov %rax, %rdx- sar $63, %rdx+ movq $0x0123456789abcdef,%rdx+ 1:+ .pushsection runtime\_ptr\_USER\_PTR\_MAX,"a"+ .long 1b - 8 - .+ .popsection+ cmp %rax, %rdx+ sbb %rdx, %rdx or %rdx, %rax .else cmp $TASK\_SIZE\_MAX-\size+1, %eax |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-14 19:24:27 +0000



=== Content from git.kernel.org_66ae9860_20250114_192550.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=86e6b1547b3d013bc392adf775b89318441403c2)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=86e6b1547b3d013bc392adf775b89318441403c2)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=86e6b1547b3d013bc392adf775b89318441403c2)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=86e6b1547b3d013bc392adf775b89318441403c2)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Linus Torvalds <torvalds@linux-foundation.org> | 2024-10-23 18:17:46 -0700 |
| --- | --- | --- |
| committer | Linus Torvalds <torvalds@linux-foundation.org> | 2024-10-25 09:53:03 -0700 |
| commit | [86e6b1547b3d013bc392adf775b89318441403c2](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=86e6b1547b3d013bc392adf775b89318441403c2) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=86e6b1547b3d013bc392adf775b89318441403c2)) | |
| tree | [aaf70f929fe68d0940ae53dd1ff489967356006d](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=86e6b1547b3d013bc392adf775b89318441403c2) | |
| parent | [ae90f6a6170d7a7a1aa4fddf664fbd093e3023bc](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=ae90f6a6170d7a7a1aa4fddf664fbd093e3023bc) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=86e6b1547b3d013bc392adf775b89318441403c2&id2=ae90f6a6170d7a7a1aa4fddf664fbd093e3023bc)) | |
| download | [linux-86e6b1547b3d013bc392adf775b89318441403c2.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-86e6b1547b3d013bc392adf775b89318441403c2.tar.gz) | |

x86: fix user address masking non-canonical speculation issueIt turns out that AMD has a "Meltdown Lite(tm)" issue with non-canonical
accesses in kernel space. And so using just the high bit to decide
whether an access is in user space or kernel space ends up with the good
old "leak speculative data" if you have the right gadget using the
result:
CVE-2020-12965 “Transient Execution of Non-Canonical Accesses“
Now, the kernel surrounds the access with a STAC/CLAC pair, and those
instructions end up serializing execution on older Zen architectures,
which closes the speculation window.
But that was true only up until Zen 5, which renames the AC bit [1].
That improves performance of STAC/CLAC a lot, but also means that the
speculation window is now open.
Note that this affects not just the new address masking, but also the
regular valid\_user\_address() check used by access\_ok(), and the asm
version of the sign bit check in the get\_user() helpers.
It does not affect put\_user() or clear\_user() variants, since there's no
speculative result to be used in a gadget for those operations.
Reported-by: Andrew Cooper <andrew.cooper3@citrix.com>
Link: [https://lore.kernel.org/all/80d94591-1297-4afb-b510-c665efd37f10@citrix.com/](https://lore.kernel.org/all/80d94591-1297-4afb-b510-c665efd37f10%40citrix.com/)
Link: [https://lore.kernel.org/all/20241023094448.GAZxjFkEOOF\_DM83TQ@fat\_crate.local/](https://lore.kernel.org/all/20241023094448.GAZxjFkEOOF_DM83TQ%40fat_crate.local/) [1]
Link: <https://www.amd.com/en/resources/product-security/bulletin/amd-sb-1010.html>
Link: <https://arxiv.org/pdf/2108.10771>
Cc: Josh Poimboeuf <jpoimboe@kernel.org>
Cc: Borislav Petkov <bp@alien8.de>
Tested-by: Maciej Wieczor-Retman <maciej.wieczor-retman@intel.com> # LAM case
Fixes: 2865baf54077 ("x86: support user address masking instead of non-speculative conditional")
Fixes: 6014bc27561f ("x86-64: make access\_ok() independent of LAM")
Fixes: b19b74bc99b1 ("x86/mm: Rework address range check in get\_user() and put\_user()")
Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=86e6b1547b3d013bc392adf775b89318441403c2)

| -rw-r--r-- | [arch/x86/include/asm/uaccess\_64.h](/pub/scm/linux/kernel/git/stable/linux.git/diff/arch/x86/include/asm/uaccess_64.h?id=86e6b1547b3d013bc392adf775b89318441403c2) | 43 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |
| -rw-r--r-- | [arch/x86/kernel/cpu/common.c](/pub/scm/linux/kernel/git/stable/linux.git/diff/arch/x86/kernel/cpu/common.c?id=86e6b1547b3d013bc392adf775b89318441403c2) | 10 | |  |  |  | | --- | --- | --- | |
| -rw-r--r-- | [arch/x86/kernel/vmlinux.lds.S](/pub/scm/linux/kernel/git/stable/linux.git/diff/arch/x86/kernel/vmlinux.lds.S?id=86e6b1547b3d013bc392adf775b89318441403c2) | 1 | |  |  |  | | --- | --- | --- | |
| -rw-r--r-- | [arch/x86/lib/getuser.S](/pub/scm/linux/kernel/git/stable/linux.git/diff/arch/x86/lib/getuser.S?id=86e6b1547b3d013bc392adf775b89318441403c2) | 9 | |  |  |  | | --- | --- | --- | |

4 files changed, 42 insertions, 21 deletions

| diff --git a/arch/x86/include/asm/uaccess\_64.h b/arch/x86/include/asm/uaccess\_64.hindex afce8ee5d7b794..b0a887209400de 100644--- a/[arch/x86/include/asm/uaccess\_64.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/include/asm/uaccess_64.h?id=ae90f6a6170d7a7a1aa4fddf664fbd093e3023bc)+++ b/[arch/x86/include/asm/uaccess\_64.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/include/asm/uaccess_64.h?id=86e6b1547b3d013bc392adf775b89318441403c2)@@ -12,6 +12,13 @@ #include <asm/cpufeatures.h> #include <asm/page.h> #include <asm/percpu.h>+#include <asm/runtime-const.h>++/\*+ \* Virtual variable: there's no actual backing store for this,+ \* it can purely be used as 'runtime\_const\_ptr(USER\_PTR\_MAX)'+ \*/+extern unsigned long USER\_PTR\_MAX;  #ifdef CONFIG\_ADDRESS\_MASKING /\*@@ -46,19 +53,24 @@ static inline unsigned long \_\_untagged\_addr\_remote(struct mm\_struct \*mm,  #endif -/\*- \* The virtual address space space is logically divided into a kernel- \* half and a user half. When cast to a signed type, user pointers- \* are positive and kernel pointers are negative.- \*/-#define valid\_user\_address(x) ((\_\_force long)(x) >= 0)+#define valid\_user\_address(x) \+ ((\_\_force unsigned long)(x) <= runtime\_const\_ptr(USER\_PTR\_MAX))  /\* \* Masking the user address is an alternative to a conditional \* user\_access\_begin that can avoid the fencing. This only works \* for dense accesses starting at the address. \*/-#define mask\_user\_address(x) ((typeof(x))((long)(x)|((long)(x)>>63)))+static inline void \_\_user \*mask\_user\_address(const void \_\_user \*ptr)+{+ unsigned long mask;+ asm("cmp %1,%0\n\t"+ "sbb %0,%0"+ :"=r" (mask)+ :"r" (ptr),+ "0" (runtime\_const\_ptr(USER\_PTR\_MAX)));+ return (\_\_force void \_\_user \*)(mask | (\_\_force unsigned long)ptr);+} #define masked\_user\_access\_begin(x) ({ \ \_\_auto\_type \_\_masked\_ptr = (x); \ \_\_masked\_ptr = mask\_user\_address(\_\_masked\_ptr); \@@ -69,23 +81,16 @@ static inline unsigned long \_\_untagged\_addr\_remote(struct mm\_struct \*mm, \* arbitrary values in those bits rather then masking them off. \* \* Enforce two rules:- \* 1. 'ptr' must be in the user half of the address space+ \* 1. 'ptr' must be in the user part of the address space \* 2. 'ptr+size' must not overflow into kernel addresses \*- \* Note that addresses around the sign change are not valid addresses,- \* and will GP-fault even with LAM enabled if the sign bit is set (see- \* "CR3.LAM\_SUP" that can narrow the canonicality check if we ever- \* enable it, but not remove it entirely).- \*- \* So the "overflow into kernel addresses" does not imply some sudden- \* exact boundary at the sign bit, and we can allow a lot of slop on the- \* size check.+ \* Note that we always have at least one guard page between the+ \* max user address and the non-canonical gap, allowing us to+ \* ignore small sizes entirely. \* \* In fact, we could probably remove the size check entirely, since \* any kernel accesses will be in increasing address order starting- \* at 'ptr', and even if the end might be in kernel space, we'll- \* hit the GP faults for non-canonical accesses before we ever get- \* there.+ \* at 'ptr'. \* \* That's a separate optimization, for now just handle the small \* constant case.diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.cindex f1040cb648414b..a5f221ea568885 100644--- a/[arch/x86/kernel/cpu/common.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/kernel/cpu/common.c?id=ae90f6a6170d7a7a1aa4fddf664fbd093e3023bc)+++ b/[arch/x86/kernel/cpu/common.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/kernel/cpu/common.c?id=86e6b1547b3d013bc392adf775b89318441403c2)@@ -69,6 +69,7 @@ #include <asm/sev.h> #include <asm/tdx.h> #include <asm/posted\_intr.h>+#include <asm/runtime-const.h>  #include "cpu.h" @@ -2389,6 +2390,15 @@ void \_\_init arch\_cpu\_finalize\_init(void) alternative\_instructions();  if (IS\_ENABLED(CONFIG\_X86\_64)) {+ unsigned long USER\_PTR\_MAX = TASK\_SIZE\_MAX-1;++ /\*+ \* Enable this when LAM is gated on LASS support+ if (cpu\_feature\_enabled(X86\_FEATURE\_LAM))+ USER\_PTR\_MAX = (1ul << 63) - PAGE\_SIZE - 1;+ \*/+ runtime\_const\_init(ptr, USER\_PTR\_MAX);+ /\* \* Make sure the first 2MB area is not mapped by huge pages \* There are typically fixed size MTRRs in there and overlappingdiff --git a/arch/x86/kernel/vmlinux.lds.S b/arch/x86/kernel/vmlinux.lds.Sindex 6726be89b7a663..b8c5741d2fb480 100644--- a/[arch/x86/kernel/vmlinux.lds.S](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/kernel/vmlinux.lds.S?id=ae90f6a6170d7a7a1aa4fddf664fbd093e3023bc)+++ b/[arch/x86/kernel/vmlinux.lds.S](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/kernel/vmlinux.lds.S?id=86e6b1547b3d013bc392adf775b89318441403c2)@@ -358,6 +358,7 @@ SECTIONS #endif  RUNTIME\_CONST\_VARIABLES+ RUNTIME\_CONST(ptr, USER\_PTR\_MAX)  . = ALIGN(PAGE\_SIZE); diff --git a/arch/x86/lib/getuser.S b/arch/x86/lib/getuser.Sindex d066aecf8aeb22..4357ec2a0bfc2c 100644--- a/[arch/x86/lib/getuser.S](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/lib/getuser.S?id=ae90f6a6170d7a7a1aa4fddf664fbd093e3023bc)+++ b/[arch/x86/lib/getuser.S](/pub/scm/linux/kernel/git/stable/linux.git/tree/arch/x86/lib/getuser.S?id=86e6b1547b3d013bc392adf775b89318441403c2)@@ -39,8 +39,13 @@  .macro check\_range size:req .if IS\_ENABLED(CONFIG\_X86\_64)- mov %rax, %rdx- sar $63, %rdx+ movq $0x0123456789abcdef,%rdx+ 1:+ .pushsection runtime\_ptr\_USER\_PTR\_MAX,"a"+ .long 1b - 8 - .+ .popsection+ cmp %rax, %rdx+ sbb %rdx, %rdx or %rdx, %rax .else cmp $TASK\_SIZE\_MAX-\size+1, %eax |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-14 19:24:27 +0000


