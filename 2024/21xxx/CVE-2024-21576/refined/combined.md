=== Content from github.com_03cba1a1_20250114_223254.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fbmad4ever%2Fcomfyui_bmad_nodes%2Fblob%2F392af9490cbadf32a1fe92ff820ebabe88c51ee8%2Fcv_nodes.py)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fbmad4ever%2Fcomfyui_bmad_nodes%2Fblob%2F392af9490cbadf32a1fe92ff820ebabe88c51ee8%2Fcv_nodes.py)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=bmad4ever%2Fcomfyui_bmad_nodes)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[bmad4ever](/bmad4ever)
/
**[comfyui\_bmad\_nodes](/bmad4ever/comfyui_bmad_nodes)**
Public

* [Notifications](/login?return_to=%2Fbmad4ever%2Fcomfyui_bmad_nodes) You must be signed in to change notification settings
* [Fork
  11](/login?return_to=%2Fbmad4ever%2Fcomfyui_bmad_nodes)
* [Star
   62](/login?return_to=%2Fbmad4ever%2Fcomfyui_bmad_nodes)

* [Code](/bmad4ever/comfyui_bmad_nodes)
* [Issues
  4](/bmad4ever/comfyui_bmad_nodes/issues)
* [Pull requests
  0](/bmad4ever/comfyui_bmad_nodes/pulls)
* [Actions](/bmad4ever/comfyui_bmad_nodes/actions)
* [Projects
  0](/bmad4ever/comfyui_bmad_nodes/projects)
* [Security](/bmad4ever/comfyui_bmad_nodes/security)
* [Insights](/bmad4ever/comfyui_bmad_nodes/pulse)

Additional navigation options

* [Code](/bmad4ever/comfyui_bmad_nodes)
* [Issues](/bmad4ever/comfyui_bmad_nodes/issues)
* [Pull requests](/bmad4ever/comfyui_bmad_nodes/pulls)
* [Actions](/bmad4ever/comfyui_bmad_nodes/actions)
* [Projects](/bmad4ever/comfyui_bmad_nodes/projects)
* [Security](/bmad4ever/comfyui_bmad_nodes/security)
* [Insights](/bmad4ever/comfyui_bmad_nodes/pulse)

## Files

 392af94
## Breadcrumbs

1. [comfyui\_bmad\_nodes](/bmad4ever/comfyui_bmad_nodes/tree/392af9490cbadf32a1fe92ff820ebabe88c51ee8)
/
# cv\_nodes.py

Copy path Blame  Blame
## Latest commit

## History

[History](/bmad4ever/comfyui_bmad_nodes/commits/392af9490cbadf32a1fe92ff820ebabe88c51ee8/cv_nodes.py)2341 lines (1922 loc) · 83.4 KB 392af94
## Breadcrumbs

1. [comfyui\_bmad\_nodes](/bmad4ever/comfyui_bmad_nodes/tree/392af9490cbadf32a1fe92ff820ebabe88c51ee8)
/
# cv\_nodes.py

Top
## File metadata and controls

* Code
* Blame

2341 lines (1922 loc) · 83.4 KB[Raw](https://github.com/bmad4ever/comfyui_bmad_nodes/raw/392af9490cbadf32a1fe92ff820ebabe88c51ee8/cv_nodes.py)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000from abc import ABCimport numpy as npimport cv2 as cvimport mathfrom .utils.dry import (tensor2opencv, opencv2tensor, image\_output\_formats\_options, rect\_modes, rect\_modes\_map, maybe\_convert\_img, image\_output\_formats\_options\_map, prepare\_text\_for\_eval, cache\_with\_ids, filter\_expression\_names, base\_category\_path, images\_category\_path, print\_yellow)from .utils.color import (ImageColor, setup\_color\_to\_correct\_type, find\_complementary\_color, HSV\_Samples, Interval)from .utils.templates import ComboWrapperNode
# TODO these nodes return the mask, not the image with the background removed!# this is somewhat misleading. Consider changing the methods names.# ( but to what? GrabCutMask? FramedMaskGrabCutMask? ...)
# region types and constants
thresh\_types\_map = { 'BINARY': cv.THRESH\_BINARY, 'BINARY\_INV': cv.THRESH\_BINARY\_INV, 'TRUNC': cv.THRESH\_TRUNC, 'TOZERO': cv.THRESH\_TOZERO, 'TOZERO\_INV': cv.THRESH\_TOZERO\_INV,}thresh\_types = list(thresh\_types\_map.keys())
border\_types\_map = { 'BORDER\_CONSTANT': cv.BORDER\_CONSTANT, 'BORDER\_REPLICATE': cv.BORDER\_REPLICATE, 'BORDER\_REFLECT': cv.BORDER\_REFLECT, 'BORDER\_REFLECT101': cv.BORDER\_REFLECT101, 'BORDER\_WRAP': cv.BORDER\_WRAP, 'BORDER\_TRANSPARENT': cv.BORDER\_TRANSPARENT, 'BORDER\_DEFAULT': cv.BORDER\_DEFAULT, 'BORDER\_ISOLATED': cv.BORDER\_ISOLATED}
border\_types = list(border\_types\_map.keys())
border\_types\_excluding\_transparent = border\_types\_map.copy()border\_types\_excluding\_transparent.pop("BORDER\_TRANSPARENT")border\_types\_excluding\_transparent = list(border\_types\_excluding\_transparent.keys())
interpolation\_types\_map = { "INTER\_NEAREST": cv.INTER\_NEAREST, "INTER\_LINEAR": cv.INTER\_LINEAR, "INTER\_AREA": cv.INTER\_AREA, "INTER\_LANCZOS4": cv.INTER\_LANCZOS4, "INTER\_CUBIC": cv.INTER\_CUBIC, # "INTER\_LINEAR\_EXACT": cv.INTER\_LINEAR\_EXACT, # "INTER\_NEAREST\_EXACT": cv.INTER\_NEAREST\_EXACT,}interpolation\_types = list(interpolation\_types\_map.keys())
cv\_category\_path = f"{base\_category\_path}/CV"
# endregion
# region misc
class CopyMakeBorderSimple: @classmethod def INPUT\_TYPES(cls): return { "required": { "image": ("IMAGE",), "border\_size": ("INT", {"default": 64}), "border\_type": (border\_types\_excluding\_transparent, {"default": border\_types[0]}) }}
 RETURN\_TYPES = ("IMAGE",) FUNCTION = "make\_border" CATEGORY = f"{cv\_category\_path}/Misc"
 def make\_border(self, image, border\_size, border\_type): image = tensor2opencv(image, 0) image = cv.copyMakeBorder(image, border\_size, border\_size, border\_size, border\_size, border\_types\_map[border\_type]) image = opencv2tensor(image) return (image,)
class ConvertImg: """ An explicit conversion, instead of using workarounds when using certain custom nodes. """ options\_map = { "RGBA": 4, "RGB": 3, "GRAY": 1, } options = list(options\_map.keys())
 @classmethod def INPUT\_TYPES(cls): return {"required": { "image": ("IMAGE",), "to": (cls.options, {"default": cls.options[1]}) }}
 RETURN\_TYPES = ("IMAGE",) FUNCTION = "convert" CATEGORY = f"{cv\_category\_path}"
 def convert(self, image, to): image = tensor2opencv(image, self.options\_map[to]) return (opencv2tensor(image),)
class AddAlpha: method = ["default", "invert"]
 @classmethod def INPUT\_TYPES(cls): return { "required": { "rgb\_image": ("IMAGE",), }, "optional": { "alpha": ("IMAGE",), "method": (cls.method, {"default": cls.method[0]}), } }
 RETURN\_TYPES = ("IMAGE",) FUNCTION = "add\_alpha" CATEGORY = images\_category\_path
 def add\_alpha(self, rgb\_image, alpha=None, method=None): rgb\_image = tensor2opencv(rgb\_image, 3) rgba = cv.cvtColor(rgb\_image, cv.COLOR\_RGB2RGBA) if alpha is not None: alpha = tensor2opencv(alpha, 1) rgba[:, :, 3] = alpha if method == self.method[0] else 255 - alpha rgba = opencv2tensor(rgba) return (rgba,)
class FadeMaskEdges: """ The original intent is to premultiply and alpha blend a subject's edges to avoid outer pixels creeping in.
 A very slight blur near the edges afterwards when using paste\_original\_blacks and low tightness may be required, but this should be done after premultiplying and setting the alpha.
 Stylized subject's, such as drawings with black outlines, may benefit from using different 2 edge fades: 1. a fade with higher edge size for the premultiplication, fading the subject into blackness 2. a tighter fade for the alpha """
 @classmethod def INPUT\_TYPES(cls): return { "required": { "binary\_image": ("IMAGE",), "edge\_size": ("FLOAT", {"default": 5.0, "min": 1.0, "step": 1.0}), # how quick does it fade to black "edge\_tightness": ("FLOAT", {"default": 1.1, "min": 1.0, "max": 10.0, "step": 0.05}), # how does it fade, may be used to weaken small lines; 1 = linear transition "edge\_exponent": ("FLOAT", {"default": 1, "min": 0.1, "max": 10.0, "step": 0.1}), "smoothing\_diameter": ("INT", {"default": 10, "min": 2, "max": 256, "step": 1}), "paste\_original\_blacks": ("BOOLEAN", {"default": True}) } }
 RETURN\_TYPES = ("IMAGE",) FUNCTION = "apply" CATEGORY = f"{cv\_category\_path}/Misc"
 def apply(self, binary\_image, edge\_size, edge\_tightness, edge\_exponent, smoothing\_diameter, paste\_original\_blacks): binary\_image = tensor2opencv(binary\_image, 1) # \_, binary\_image = cv.threshold(gray\_image, 128, 255, cv.THRESH\_BINARY) # suppose it's already binary
 # compute L2 (euclidean) distance -> normalize with respect to edge size -> smooth distance\_transform = cv.distanceTransform(binary\_image, cv.DIST\_L2, cv.DIST\_MASK\_3) normalized\_distance = distance\_transform / edge\_size smoothed\_distance = cv.bilateralFilter(normalized\_distance, smoothing\_diameter, 75, 75)
 # darken the white pixels based on smoothed distance and "edge tightness" diff = 1 - smoothed\_distance darkened\_image = (abs(diff \* edge\_tightness) \*\* (1 / edge\_exponent)) \* np.sign(diff) darkened\_image = np.clip(darkened\_image, 0, 1) darkened\_image = (darkened\_image \* 255).astype(np.uint8)
 if paste\_original\_blacks: # mask original black pixels black\_mask = binary\_image < 1 darkened\_image[black\_mask] = 0
 output\_image = binary\_image - darkened\_image # darken original image output\_image = opencv2tensor(output\_image) return (output\_image,)
# endregion
# region grabcut nodes
class FramedMaskGrabCut: frame\_options\_values = { 'FULL\_FRAME': 0, 'IGNORE\_BOTTOM': 1, 'IGNORE\_TOP': 2, 'IGNORE\_RIGHT': 4, 'IGNORE\_LEFT': 8, 'IGNORE\_HORIZONTAL': 12, 'IGNORE\_VERTICAL': 3, } frame\_options = list(frame\_options\_values.keys())
 @classmethod def INPUT\_TYPES(cls): return { "required": { "image": ("IMAGE",), "thresh": ("IMAGE",), "iterations": ("INT", { "default": 25, "min": 0, "max": 200, "step": 1 }), "margin": ("INT", { "default": 2, "min": 1, "max": 100, "step": 1 }), "frame\_option": (cls.frame\_options, { "default": cls.frame\_options[0] }),
 # to only use PR FGD set threshold\_FGD to 0 # to only use only FGD set threshold\_FGD to a lower value than threshold\_PR\_FGD # using one of these also works as a safeguard in case thresh has other values besides 0s and 1s "threshold\_FGD": ("INT", { "default": 250, "min": 0, "max": 255, "step": 1 }), "threshold\_PR\_FGD": ("INT", { "default": 128, "min": 1, "max": 255, "step": 1 }), "output\_format": (image\_output\_formats\_options, { "default": image\_output\_formats\_options[0] }) }, }
 RETURN\_TYPES = ("IMAGE",) FUNCTION = "grab\_cut" CATEGORY = f"{cv\_category\_path}/GrabCut"
 def grab\_cut(self, image, thresh, iterations, margin, frame\_option, threshold\_FGD, threshold\_PR\_FGD, output\_format): image = tensor2opencv(image) thresh = tensor2opencv(thresh, 1)
 assert image.shape[:2] == thresh.shape
 fg\_model = np.zeros((1, 65), dtype="float") bg\_model = np.zeros((1, 65), dtype="float") mask = np.full(image.shape[:2], cv.GC\_PR\_BGD, dtype=np.uint8) # probable background # foreground and probable foreground if threshold\_FGD > threshold\_PR\_FGD: mask[thresh >= threshold\_PR\_FGD] = cv.GC\_PR\_FGD if threshold\_FGD > 0: mask[thresh >= threshold\_FGD] = cv.GC\_FGD
 # check what borders should be painted frame\_option = self.frame\_options\_values[frame\_option] include\_bottom = not (frame\_option & self.frame\_options\_values['IGNORE\_BOTTOM']) include\_top = not (frame\_option & self.frame\_options\_values['IGNORE\_TOP']) include\_right = not (frame\_option & self.frame\_options\_values['IGNORE\_RIGHT']) include\_left = not (frame\_option & self.frame\_options\_values['IGNORE\_LEFT'])
 # paint the borders as being background if include\_bottom: mask[-margin:, :] = cv.GC\_BGD if include\_top: mask[0:margin, :] = cv.GC\_BGD if include\_right: mask[:, -margin:] = cv.GC\_BGD if include\_left: mask[:, 0:margin] = cv.GC\_BGD
 mask, bg\_model, fg\_model = cv.grabCut(image, mask, None, bg\_model, fg\_model, iterCount=iterations, mode=cv.GC\_INIT\_WITH\_MASK)
 # generate mask with "pixels" classified as background/foreground output\_mask = np.where((mask == cv.GC\_BGD) | (mask == cv.GC\_PR\_BGD), 0, 1)
 output\_mask = (output\_mask \* 255).astype("uint8")
 output\_mask = maybe\_convert\_img(output\_mask, 1, image\_output\_formats\_options\_map[output\_format]) image = opencv2tensor(output\_mask)
 return (image,)
class RectGrabCut: # TODO add option to crop or just leave as 0 the section outside the rect # TODO maybe add option to exclude PR\_BGD or include PR\_FGD in outputMask
 @classmethod def INPUT\_TYPES(cls): return { "required": { "image": ("IMAGE",), "x1": ("INT", { "default": 5, "min": 0, "max": 2000, "step": 1 }), "y1": ("INT", { "default": 5, "min": 0, "max": 2000, "step": 1 }), "x2": ("INT", { "default": 5, "min": 0, "max": 2000, "step": 1 }), "y2": ("INT", { "default": 5, "min": 0, "max": 2000, "step": 1 }), "iterations": ("INT", { "default": 25, "min": 0, "max": 200, "step": 1 }), "output\_format": (image\_output\_formats\_options, { "default": image\_output\_formats\_options[0] }) }, }
 RETURN\_TYPES = ("IMAGE",) FUNCTION = "grab\_cut"
 CATEGORY = f"{cv\_category\_path}/GrabCut"
 def grab\_cut(self, image, iterations, x1, y1, x2, y2, output\_format): image = tensor2opencv(image)
 fg\_model = np.zeros((1, 65), dtype="float") bg\_model = np.zeros((1, 65), dtype="float") mask = np.zeros(image.shape[:2], dtype="uint8") rect = (x1, y1, x2, y2)
 mask, bg\_model, fg\_model = cv.grabCut(image, mask, rect, bg\_model, fg\_model, iterCount=iterations, mode=cv.GC\_INIT\_WITH\_RECT)
 # generate mask with "pixels" classified as background/foreground output\_mask = np.where((mask == cv.GC\_BGD) | (mask == cv.GC\_PR\_BGD), 0, 1) output\_mask = (output\_mask \* 255).astype("uint8")
 output\_mask = maybe\_convert\_img(output\_mask, 1, image\_output\_formats\_options\_map[output\_format]) image = opencv2tensor(output\_mask) # image = image[y1:y2, x1:x2] #TODO maybe add option whether to crop or not
 return (image,)
class FramedMaskGrabCut2: # TODO option to ignore probable background in sure\_thresh
 frame\_options = ['FULL\_FRAME', 'IGNORE\_BOTTOM', 'IGNORE\_TOP', 'IGNORE\_RIGHT', 'IGNORE\_LEFT', 'IGNORE\_HORIZONTAL' , 'IGNORE\_VERTICAL'] frame\_options\_values = { 'FULL\_FRAME': 0, 'IGNORE\_BOTTOM': 1, 'IGNORE\_TOP': 2, 'IGNORE\_RIGHT': 4, 'IGNORE\_LEFT': 8, 'IGNORE\_HORIZONTAL': 12, 'IGNORE\_VERTICAL': 3, }
 @classmethod def INPUT\_TYPES(cls): return { "required": { "image": ("IMAGE",), "thresh\_maybe": ("IMAGE",), "thresh\_sure": ("IMAGE",), "iterations": ("INT", { "default": 25, "min": 0, "max": 200, "step": 1 }), "margin": ("INT", { "default": 2, "min": 1, "max": 100, "step": 1 }), "frame\_option": (cls.frame\_options, { "default": 'FULL\_FRAME' }), # source thresh may not be only 0s and 1s, use this as a safeguard "binary\_threshold": ("INT", { "default": 128, "min": 1, "max": 255, "step": 1 }), "maybe\_black\_is\_sure\_background": ("BOOLEAN", {"default": False}), "output\_format": (image\_output\_formats\_options, { "default": image\_output\_formats\_options[0] }) }, }
 RETURN\_TYPES = ("IMAGE",) FUNCTION = "grab\_cut"
 CATEGORY = f"{cv\_category\_path}/GrabCut"
 def grab\_cut(self, image, thresh\_maybe, thresh\_sure, iterations, margin, frame\_option, binary\_threshold, maybe\_black\_is\_sure\_background, output\_format): image = tensor2opencv(image)
 thresh\_maybe = tensor2opencv(thresh\_maybe, 1) thresh\_sure = tensor2opencv(thresh\_sure, 1)
 fg\_model = np.zeros((1, 65), dtype="float") bg\_model = np.zeros((1, 65), dtype="float") mask = np.full(image.shape[:2], cv.GC\_PR\_BGD, dtype=np.uint8) # probable background mask[thresh\_maybe >= binary\_threshold] = cv.GC\_PR\_FGD # probable foreground mask[thresh\_sure >= binary\_threshold] = cv.GC\_FGD # foreground
 frame\_option = self.frame\_options\_values[frame\_option] include\_bottom = not (frame\_option & self.frame\_options\_values['IGNORE\_BOTTOM']) include\_top = not (frame\_option & self.frame\_options\_values['IGNORE\_TOP']) include\_right = not (frame\_option & self.frame\_options\_values['IGNORE\_RIGHT']) include\_left = not (frame\_option & self.frame\_options\_values['IGNORE\_LEFT'])
 if include\_bottom: mask[-margin:, :] = cv.GC\_BGD if include\_top: mask[0:margin, :] = cv.GC\_BGD if include\_right: mask[:, -margin:] = cv.GC\_BGD if include\_left: mask[:, 0:margin] = cv.GC\_BGD
 if maybe\_black\_is\_sure\_background: mask[thresh\_maybe < binary\_threshold] = cv.GC\_BGD # background
 mask, bg\_model, fg\_model = cv.grabCut(image, mask, None, bg\_model, fg\_model, iterCount=iterations, mode=cv.GC\_INIT\_WITH\_MASK)
 # generate mask with "pixels" classified as background/foreground output\_mask = np.where((mask == cv.GC\_BGD) | (mask == cv.GC\_PR\_BGD), 0, 1) output\_mask = (output\_mask \* 255).astype("uint8")
 output\_mask = maybe\_convert\_img(output\_mask, 1, image\_output\_formats\_options\_map[output\_format]) image = opencv2tensor(output\_mask)
 return (image,)
# endregion grabcut nodes
# region contour nodes
class Contours: """ Note: The image is converted to grey, but no threshold is applied. Apply the thresholding before using and feed a black and white image. """
 approximation\_modes\_map = { 'CHAIN\_APPROX\_NONE': cv.CHAIN\_APPROX\_NONE, 'CHAIN\_APPROX\_SIMPLE': cv.CHAIN\_APPROX\_SIMPLE, 'CHAIN\_APPROX\_TC89\_L1': cv.CHAIN\_APPROX\_TC89\_L1, 'CHAIN\_APPROX\_TC89\_KCOS': cv.CHAIN\_APPROX\_TC89\_KCOS } approximation\_modes = list(approximation\_modes\_map.keys())
 retrieval\_modes\_map = { 'RETR\_EXTERNAL': cv.RETR\_EXTERNAL, 'RETR\_LIST': cv.RETR\_LIST, 'RETR\_CCOMP': cv.RETR\_CCOMP, 'RETR\_TREE': cv.RETR\_TREE, 'RETR\_FLOODFILL': cv.RETR\_FLOODFILL } retrieval\_modes = list(retrieval\_modes\_map.keys())
 @classmethod def INPUT\_TYPES(cls): return { "required": { "image": ("IMAGE",), "retrieval\_mode": (cls.retrieval\_modes, {"default": "RETR\_LIST"}), "approximation\_mode": (cls.approximation\_modes, {"default": "CHAIN\_APPROX\_SIMPLE"}), }, }
 RETURN\_TYPES = ("CV\_CONTOURS", "CV\_CONTOUR", "CV\_CONTOURS\_HIERARCHY") FUNCTION = "find\_contours" CATEGORY = f"{cv\_category\_path}/Contour" OUTPUT\_IS\_LIST = (False, True, False)
 def find\_contours(self, image, retrieval\_mode, approximation\_mode): image = tensor2opencv(image) thresh = cv.cvtColor(image, cv.COLOR\_RGB2GRAY)
 # no thresh applied here, non zeroes are treated as 1 according to documentation; # thresh should have been already applied to the image, before passing it to this node.
 contours, hierarchy = cv.findContours( thresh, self.retrieval\_modes\_map[retrieval\_mode], self.approximation\_modes\_map[approximation\_mode])
 return (contours, contours, hierarchy,)
class DrawContours: @classmethod def INPUT\_TYPES(cls): return { "required": { "image": ("IMAGE",), "contours": ("CV\_CONTOURS",), "index\_to\_draw": ("INT", { "default": -1, "min": -1, "max": 1000, "step": 1 }), "thickness": ("INT", { "default": 5, "min": -1, "max": 32, "step": 1 }), "color": ("COLOR",), } }
 RETURN\_TYPES = ("IMAGE",) FUNCTION = "draw"
 CATEGORY = f"{cv\_category\_path}/Contour"
 def draw(self, image, contours, index\_to\_draw, color, thickness): background = tensor2opencv(image)
 um\_image = cv.UMat(background) cv.drawContours(um\_image, contours, index\_to\_draw, ImageColor.getcolor(color, "RGB"), thickness) contour\_image = um\_image.get()
 image = opencv2tensor(contour\_image)
 return (image,)
class GetContourFromList: @classmethod def INPUT\_TYPES(cls): return { "required": { "contours": ("CV\_CONTOURS",), "index": ("INT", {"default": 0, "min": 0, "step": 1}) } }
 RETURN\_TYPES = ("CV\_CONTOUR",) FUNCTION = "get\_contour" CATEGORY = f"{cv\_category\_path}/Contour"
 def get\_contour(self, contours, index): if index >= len(contours): return (None,) return (contours[index],)
class ContourGetBoundingRect: @classmethod def INPUT\_TYPES(cls): return { "required": { "contour": ("CV\_CONTOUR",), "return\_mode": (rect\_modes, {"default": rect\_modes[1]}) }, }
 RETURN\_TYPES = tuple(["INT" for \_ in range(4)]) FUNCTION = "compute" CATEGORY = f"{cv\_category\_path}/Contour"
 def compute(self, contour, return\_mode): if contour is None: print("Contour = None !") return (0, 0, 0, 0,)
 # convert opencv boundingRect format to bounds bounds = rect\_modes\_map[rect\_modes[0]]["toBounds"](\*cv.boundingRect(contour))
 # convert from bounds to desired output format on return return rect\_modes\_map[return\_mode]["fromBounds"](\*bounds)
class FilterContour: @staticmethod def MODE(cnts, fit): sorted\_list = sorted(cnts, key=fit) return [sorted\_list[len(sorted\_list) // 2]]
 return\_modes\_map = { "MAX": lambda cnts, fit: [sorted(cnts, key=fit)[-1]], "MIN": lambda cnts, fit: [sorted(cnts, key=fit)[0]], "MODE": MODE, "FILTER": lambda cnts, fit: list(filter(fit, cnts)), } return\_modes = list(return\_modes\_map.keys())
 @classmethod def INPUT\_TYPES(cls): return { "required": { "contours": ("CV\_CONTOURS",), "fitness": ("STRING", {"multiline": True, "default": "# Contour Fitness Function\n"}), "select": (cls.return\_modes, {"default": cls.return\_modes[0]}) }, "optional": { "image": ("IMAGE",), "aux\_contour": ("CV\_CONTOUR",) } }
 RETURN\_TYPES = ("CV\_CONTOUR", "CV\_CONTOURS") FUNCTION = "filter" CATEGORY = f"{cv\_category\_path}/Contour"
 def filter(self, contours, fitness, select, image=None, aux\_contour=None): import math import cv2 import numpy
 if len(contours) == 0: print("Contour list is empty") return ([[]], contours)
 # region prepare inputs if image is not None: image = tensor2opencv(image)
 fitness = prepare\_text\_for\_eval(fitness)
 # endregion
 # region available functions # cv methods, but cache them @cache\_with\_ids(single=False) def boundingRect(cnt): return cv.boundingRect(cnt)
 @cache\_with\_ids(single=False) def contourArea(cnt): return cv.contourArea(cnt)
 @cache\_with\_ids(single=False) def arcLength(cnt): return cv.arcLength(cnt, True)
 @cache\_with\_ids(single=True) def minAreaRect(cnt): return cv.minAreaRect(cnt)
 @cache\_with\_ids(single=True) def minEnclosingCircle(cnt): return cv.minEnclosingCircle(cnt)
 @cache\_with\_ids(single=True) def fitEllipse(cnt): return cv.fitEllipse(cnt)
 @cache\_with\_ids(single=True) def convexHull(cnt): return cv.convexHull(cnt)
 # useful properties; adapted from multiple sources, including cv documentation @cache\_with\_ids(single=True) def aspect\_ratio(cnt): \_, \_, w, h = boundingRect(cnt) return float(w) / h
 @cache\_with\_ids(single=True) def extent(cnt): area = contourArea(cnt) \_, \_, w, h = boundingRect(cnt) rect\_area = w \* h return float(area) / rect\_area
 @cache\_with\_ids(single=True) def solidity(cnt): area = contourArea(cnt) hull = convexHull(cnt) hull\_area = contourArea(hull) return float(area) / hull\_area
 @cache\_with\_ids(single=True) def equi\_diameter(cnt): area = contourArea(cnt) return math.sqrt(4 \* area / math.pi)
 @cache\_with\_ids(single=True) def center(cnt): m = cv.moments(cnt) c\_x = int(m["m10"] / m["m00"]) c\_y = int(m["m01"] / m["m00"]) return c\_x, c\_y
 @cache\_with\_ids(single=False) def contour\_mask(cnt, img): if len(img.shape) > 2: height, width, \_ = img.shape else: height, width = img.shape
 mask = numpy.zeros((height, width, 1), numpy.uint8) cv.drawContours(mask, [cnt], 0, 255, -1) return mask
 @cache\_with\_ids(single=True) def mean\_color(cnt, img): return cv.mean(img, mask=contour\_mask(cnt, img))
 @cache\_with\_ids(single=True) def mean\_intensity(cnt, img): gray = cv.cvtColor(img, cv.COLOR\_RGB2GRAY) return mean\_color(cnt, gray)[0]
 @cache\_with\_ids(single=True) def extreme\_points(cnt): l = tuple(cnt[cnt[:, :, 0].argmin()][0]) r = tuple(cnt[cnt[:, :, 0].argmax()][0]) t = tuple(cnt[cnt[:, :, 1].argmin()][0]) b = tuple(cnt[cnt[:, :, 1].argmax()][0]) return {"top": t, "right": r, "bottom": b, "left": l}
 def intercepts\_mask(cnt, img): # where img should be a binary mask gray = cv.cvtColor(img, cv.COLOR\_RGB2GRAY) intersection = cv2.bitwise\_and( gray, cv2.drawContours(np.zeros\_like(gray), [cnt], 0, 255, thickness=cv2.FILLED)) return cv2.countNonZero(intersection) > 0
 # endregion
 available\_funcs = {} for key, value in locals().items(): if callable(value): available\_funcs[key] = value
 fitness = eval(f"lambda c, i, a: {fitness}", { "\_\_builtins\_\_": {}, "tuple": tuple, "list": list, 'm': math, 'cv': cv2, 'np': numpy, \*\*available\_funcs }, {})
 ret = self.return\_modes\_map[select](contours, lambda c: fitness(c, image, aux\_contour)) return (ret[0], ret,)
class ContourToMask: @classmethod def INPUT\_TYPES(cls): return { "required": { "image": ("IMAGE",), "contour": ("CV\_CONTOUR",), "output\_format": (image\_output\_formats\_options, { "default": image\_output\_formats\_options[0] }) } }
 RETURN\_TYPES = ("IMAGE",) FUNCTION = "draw" CATEGORY = f"{cv\_category\_path}/Contour"
 def draw(self, image, contour, output\_format): image = tensor2opencv(image, 1) image = np.zeros(image.shape, dtype=np.uint8) cv.drawContours(image, [contour], 0, (255), -1) image = maybe\_convert\_img(image, 1, image\_output\_formats\_options\_map[output\_format]) image = opencv2tensor(image) return (image,)
# endregion contour nodes
# region Computational Photography
class SeamlessClone: clone\_modes\_map = { "NORMAL": cv.NORMAL\_CLONE, "MIXED": cv.MIXED\_CLONE, "MONO": cv.MONOCHROME\_TRANSFER } clone\_modes = list(clone\_modes\_map.keys())
 @classmethod def INPUT\_TYPES(cls): return { "required": { "dst": ("IMAGE",), "src": ("IMAGE",), "src\_mask": ("IMAGE",), "flag": (cls.clone\_modes, {"default": cls.clone\_modes[0]}), "cx": ("INT", {"default": 0, "min": -999999, "step": 1}), "cy": ("INT", {"default": 0, "min": -999999, "step": 1}), }, }
 RETURN\_TYPES = ("IMAGE",) FUNCTION = "paste" CATEGORY = f"{cv\_category\_path}/C.Photography"
 def paste(self, src, dst, src\_mask, flag, cx, cy): src = tensor2opencv(src) dst = tensor2opencv(dst) src\_mask = tensor2opencv(src\_mask, 1)
 result = cv.seamlessClone(src, dst, src\_mask, (cx, cy), self.clone\_modes\_map[flag]) result = opencv2tensor(result)
 return (result,)
class SeamlessCloneSimpler: @classmethod def INPUT\_TYPES(cls): return { "required": { "dst": ("IMAGE",), "src": ("IMAGE",), "src\_mask": ("IMAGE",), "flag": (SeamlessClone.clone\_modes, {"default": SeamlessClone.clone\_modes[0]}), }, }
 RETURN\_TYPES = ("IMAGE",) FUNCTION = "paste" CATEGORY = f"{cv\_category\_path}/C.Photography"
 @staticmethod def get\_center(cv\_mask): br = cv.boundingRect(cv\_mask) return br[0] + br[2] // 2, br[1] + br[3] // 2
 def paste(self, src, dst, src\_mask, flag): src\_mask\_cv = tensor2opencv(src\_mask, 1) cx, cy = SeamlessCloneSimpler.get\_center(src\_mask\_cv) sc = SeamlessClone() return sc.paste(src, dst, src\_mask, flag, cx, cy)
class Inpaint: inpaint\_method\_map = { "TELEA": cv.INPAINT\_TELEA, "NS": cv.INPAINT\_NS, } inpaint\_methods = list(inpaint\_method\_map.keys())
 @classmethod def INPUT\_TYPES(cls): return { "required": { "img": ("IMAGE",), "mask": ("IMAGE",), "radius": ("INT", {"default": 3, "min": 0, "step": 1}), "flag": (cls.inpaint\_methods, {"default": cls.inpaint\_methods[0]}), }, }
 RETURN\_TYPES = ("IMAGE",) FUNCTION = "paint" CATEGORY = f"{cv\_category\_path}/C.Photography"
 def paint(self, img, mask, radius, flag): img = tensor2opencv(img) mask = tensor2opencv(mask, 1) dst = cv.inpaint(img, mask, radius, self.inpaint\_method\_map[flag]) result = opencv2tensor(dst) return (result,)
class ChameleonMask: # wtf would I name this node as? mode\_func\_map = { "GRAY": lambda i: cv.cvtColor(i, cv.COLOR\_BGR2GRAY), "VALUE": lambda i: cv.cvtColor(i, cv.COLOR\_RGB2HSV)[:, :, 2], "LIGHTNESS": lambda i: cv.cvtColor(i, cv.COLOR\_RGB2HLS)[:, :, 1],
 # not sure if these would be useful, but costs nothing to leave them here "HUE": lambda i: cv.cvtColor(i, cv.COLOR\_RGB2HSV)[:, :, 0], "SATURATION (HSV)": lambda i: cv.cvtColor(i, cv.COLOR\_RGB2HSV)[:, :, 1], "SATURATION (HSL)": lambda i: cv.cvtColor(i, cv.COLOR\_RGB2HLS)[:, :, 2], } modes = list(mode\_func\_map.keys())
 @classmethod def INPUT\_TYPES(cls): return { "required": { "dst": ("IMAGE",), "src": ("IMAGE",), "thresh\_blur": ("INT", {"default": 30, "min": 2, "step": 2}), "close\_dist": ("INT", {"default": 32, "min": 0, "step": 1}), "open\_dist": ("INT", {"default": 32, "min": 0, "step": 1}), "size\_dist": ("INT", {"default": 8, "min": -99999, "step": 1}), "mask\_blur": ("INT", {"default": 64, "min": 0, "step": 2}), "contrast\_adjust": ("FLOAT", {"default": 2.4, "min": 0, "max": 20, "step": .5}), "mode": (cls.modes, {"default": cls.modes[0]}), "output\_format": (image\_output\_formats\_options, { "default": image\_output\_formats\_options[0] }),
 }, "optional": { "optional\_roi\_mask": ("IMAGE",) } }
 RETURN\_TYPES = ("IMAGE", "IMAGE",) FUNCTION = "create\_mask" CATEGORY = f"{cv\_category\_path}/C.Photography"
 def create\_mask(self, src, dst, thresh\_blur, close\_dist, open\_dist, size\_dist, mask\_blur, contrast\_adjust, mode: str, output\_format, optional\_roi\_mask=None): src = tensor2opencv(src) dst = tensor2opencv(dst)
 thresh\_blur += 1 if mask\_blur > 0: mask\_blur += 1
 # compute the difference between images based on mode src = self.mode\_func\_map[mode](src) # type:ignore dst = self.mode\_func\_map[mode](dst) # type:ignore diff = cv.absdiff(src, dst)
 if mode == "HUE": diff = np.minimum(diff, 180 - diff)
 # binary thresholding # \_, mask = cv.threshold(diff, threshold, 255, cv.THRESH\_BINARY) diff = cv.GaussianBlur(diff, (thresh\_blur, thresh\_blur), 0) \_, mask = cv.threshold(diff, 0, 255, cv.THRESH\_BINARY + cv.THRESH\_OTSU) if optional\_roi\_mask is not None: optional\_roi\_mask = tensor2opencv(optional\_roi\_mask, 1) mask[optional\_roi\_mask < 127] = 0
 # morphological closing > closing > dilate/erode if close\_dist > 0: close\_kernel = cv.getStructuringElement(cv.MORPH\_ELLIPSE, (close\_dist, close\_dist)) mask = cv.morphologyEx(mask, cv.MORPH\_CLOSE, close\_kernel) if open\_dist > 0: open\_kernel = cv.getStructuringElement(cv.MORPH\_ELLIPSE, (open\_dist, open\_dist)) mask = cv.morphologyEx(mask, cv.MORPH\_OPEN, open\_kernel)
 if size\_dist > 0: size\_op = cv.MORPH\_DILATE size = size\_dist else: size\_op = cv.MORPH\_ERODE size = abs(size\_dist) if size\_dist != 0: size\_kernel = cv.getStructuringElement(cv.MORPH\_ELLIPSE, (size, size)) mask = cv.morphologyEx(mask, size\_op, size\_kernel)
 # gaussian blur + contrast adjust if mask\_blur > 0: mask = cv.GaussianBlur(mask, (mask\_blur, mask\_blur), 0) mask = cv.convertScaleAbs(mask, alpha=1 + contrast\_adjust, beta=0) # / 100, beta=0)
 # convert to target format and output as tensor # note: diff is only meant to be used for debug purposes mask = maybe\_convert\_img(mask, 1, image\_output\_formats\_options\_map[output\_format])[View remainder of file in raw view](https://github.com/bmad4ever/comfyui_bmad_nodes/raw/392af9490cbadf32a1fe92ff820ebabe88c51ee8/cv_nodes.py)

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.


