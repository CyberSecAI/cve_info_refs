=== Content from github.com_b6b6f530_20250114_212908.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fhay86%2FComfyUI_AceNodes%2Fblob%2F5ba01db8a3b7afb8e4aecfaa48823ddeb132bbbb%2Fnodes.py)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fhay86%2FComfyUI_AceNodes%2Fblob%2F5ba01db8a3b7afb8e4aecfaa48823ddeb132bbbb%2Fnodes.py)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=hay86%2FComfyUI_AceNodes)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[hay86](/hay86)
/
**[ComfyUI\_AceNodes](/hay86/ComfyUI_AceNodes)**
Public

* [Notifications](/login?return_to=%2Fhay86%2FComfyUI_AceNodes) You must be signed in to change notification settings
* [Fork
  2](/login?return_to=%2Fhay86%2FComfyUI_AceNodes)
* [Star
   47](/login?return_to=%2Fhay86%2FComfyUI_AceNodes)

* [Code](/hay86/ComfyUI_AceNodes)
* [Issues
  4](/hay86/ComfyUI_AceNodes/issues)
* [Pull requests
  0](/hay86/ComfyUI_AceNodes/pulls)
* [Actions](/hay86/ComfyUI_AceNodes/actions)
* [Projects
  0](/hay86/ComfyUI_AceNodes/projects)
* [Security](/hay86/ComfyUI_AceNodes/security)
* [Insights](/hay86/ComfyUI_AceNodes/pulse)

Additional navigation options

* [Code](/hay86/ComfyUI_AceNodes)
* [Issues](/hay86/ComfyUI_AceNodes/issues)
* [Pull requests](/hay86/ComfyUI_AceNodes/pulls)
* [Actions](/hay86/ComfyUI_AceNodes/actions)
* [Projects](/hay86/ComfyUI_AceNodes/projects)
* [Security](/hay86/ComfyUI_AceNodes/security)
* [Insights](/hay86/ComfyUI_AceNodes/pulse)

## Files

 5ba01db
## Breadcrumbs

1. [ComfyUI\_AceNodes](/hay86/ComfyUI_AceNodes/tree/5ba01db8a3b7afb8e4aecfaa48823ddeb132bbbb)
/
# nodes.py

Copy path Blame  Blame
## Latest commit

## History

[History](/hay86/ComfyUI_AceNodes/commits/5ba01db8a3b7afb8e4aecfaa48823ddeb132bbbb/nodes.py)1317 lines (1109 loc) · 45.1 KB 5ba01db
## Breadcrumbs

1. [ComfyUI\_AceNodes](/hay86/ComfyUI_AceNodes/tree/5ba01db8a3b7afb8e4aecfaa48823ddeb132bbbb)
/
# nodes.py

Top
## File metadata and controls

* Code
* Blame

1317 lines (1109 loc) · 45.1 KB[Raw](https://github.com/hay86/ComfyUI_AceNodes/raw/5ba01db8a3b7afb8e4aecfaa48823ddeb132bbbb/nodes.py)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000import osimport reimport torchimport hashlibimport folder\_pathsimport numpy as np
from PIL import Imagefrom datetime import datetimefrom torchvision.transforms.v2 import ToTensor, ToPILImage
################################### Global Variables and Functions ###################################
class AnyType(str): def \_\_eq\_\_(self, \_) -> bool: return True
 def \_\_ne\_\_(self, \_\_value: object) -> bool: return False
any = AnyType("\*")
to\_tensor = ToTensor()to\_image = ToPILImage()
 ############################ ACE Nodes of Primitives ############################
class ACE\_Integer: @classmethod def INPUT\_TYPES(cls): return { "required": { "int": ("INT", {"default": 0, "min": -0xffffffffffffffff, "max": 0xffffffffffffffff, "step": 1}), } }
 RETURN\_TYPES = ("INT",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, int): return (int,) class ACE\_Float: @classmethod def INPUT\_TYPES(cls): return { "required": { "float": ("FLOAT", {"default": 0.0, "min": -0xffffffffffffffff, "max": 0xffffffffffffffff, "step": 0.001}), } }
 RETURN\_TYPES = ("FLOAT",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, float): return (float,)
class ACE\_Text: @classmethod def INPUT\_TYPES(cls): return { "required": { "text": ("STRING", {"default": '', "multiline": True}), } }
 RETURN\_TYPES = ("STRING",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, text): return (text,) class ACE\_Seed: @classmethod def INPUT\_TYPES(cls): return { "required": { "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}), } }
 RETURN\_TYPES = ("INT",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, seed): return (seed,)
###################### ACE Nodes of Text ###################### class ACE\_TextConcatenate: @ classmethod def INPUT\_TYPES(cls): return { "required": { "text1": ("STRING", {"multiline": True, "forceInput": True}),  "text2": ("STRING", {"multiline": True, "forceInput": True}),  "separator": ("STRING", {"default": ", ", "multiline": False}),  } }
 RETURN\_TYPES = ("STRING",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, text1, text2, separator): return (text1 + separator + text2,) class ACE\_TextInputSwitch2Way: @classmethod def INPUT\_TYPES(cls): return { "required": { "input": ("INT", {"default": 1, "min": 1, "max": 2}), }, "optional": { "text1": ("STRING", {"default": '', "multiline": True, "forceInput": True}), "text2": ("STRING", {"default": '', "multiline": True, "forceInput": True}), } }
 RETURN\_TYPES = ("STRING",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, input, text1='', text2=''): if input <= 1: return (text1,) else: return (text2,)
class ACE\_TextInputSwitch4Way: @classmethod def INPUT\_TYPES(cls): return { "required": { "input": ("INT", {"default": 1, "min": 1, "max": 4}), }, "optional": { "text1": ("STRING", {"default": '', "multiline": True, "forceInput": True}), "text2": ("STRING", {"default": '', "multiline": True, "forceInput": True}), "text3": ("STRING", {"default": '', "multiline": True, "forceInput": True}), "text4": ("STRING", {"default": '', "multiline": True, "forceInput": True}),  } }
 RETURN\_TYPES = ("STRING",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, input, text1='', text2='', text3='', text4=''): if input <= 1: return (text1,) elif input == 2: return (text2,) elif input == 3: return (text3,) else: return (text4,)
class ACE\_TextInputSwitch8Way: @classmethod def INPUT\_TYPES(cls): return { "required": { "input": ("INT", {"default": 1, "min": 1, "max": 8}), }, "optional": { "text1": ("STRING", {"default": '', "multiline": True, "forceInput": True}), "text2": ("STRING", {"default": '', "multiline": True, "forceInput": True}), "text3": ("STRING", {"default": '', "multiline": True, "forceInput": True}), "text4": ("STRING", {"default": '', "multiline": True, "forceInput": True}),  "text5": ("STRING", {"default": '', "multiline": True, "forceInput": True}), "text6": ("STRING", {"default": '', "multiline": True, "forceInput": True}), "text7": ("STRING", {"default": '', "multiline": True, "forceInput": True}), "text8": ("STRING", {"default": '', "multiline": True, "forceInput": True}),  } }
 RETURN\_TYPES = ("STRING",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, input, text1='', text2='', text3='', text4='', text5='', text6='', text7='', text8=''): if input <= 1: return (text1,) elif input == 2: return (text2,) elif input == 3: return (text3,) elif input == 4: return (text4,) elif input == 5: return (text5,) elif input == 6: return (text6,) elif input == 7: return (text7,) else: return (text8,)  class ACE\_TextList: @classmethod def INPUT\_TYPES(cls): return { "required":{ "list\_text": ("STRING", {"default": '', "multiline": True}),  } }
 RETURN\_TYPES = ("STRING",) OUTPUT\_IS\_LIST = (True,) FUNCTION = "execute" CATEGORY = "Ace Nodes"  def execute(self, list\_text): lines = list\_text.split('\n') list\_out = [x.strip() for x in lines if x.strip()] return (list\_out,) class ACE\_TextPreview: @classmethod def INPUT\_TYPES(cls): return { "required": { "text": ("STRING", {"forceInput": True}), } }
 INPUT\_IS\_LIST = True RETURN\_TYPES = ("STRING",) OUTPUT\_NODE = True OUTPUT\_IS\_LIST = (True,) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, text): return {"ui": {"text": text}, "result": (text,)} class ACE\_TextSelector: @classmethod def INPUT\_TYPES(cls): return { "required":{ "list\_text": ("STRING", {"default": '', "multiline": True}),  "select": ("INT", {"default": 0, "min": 0}),  } }
 RETURN\_TYPES = ("STRING",) FUNCTION = "execute" CATEGORY = "Ace Nodes"  def execute(self, list\_text, select): lines = list\_text.split('\n') list\_out = [x.strip() for x in lines if x.strip()] select = max(min(select, len(list\_out)-1), 0) return (list\_out[select],) class ACE\_TextToResolution: @classmethod def INPUT\_TYPES(cls): return { "required":{ "text": ("STRING", {"default": '512x512', "forceInput": True}), } }
 RETURN\_TYPES = ("INT","INT",) RETURN\_NAMES = ("WIDTH","HEIGHT",) FUNCTION = "execute" CATEGORY = "Ace Nodes"  def execute(self, text): width, height = text.strip().split(" ")[0].split("x") width, height = int(width), int(height) return (width,height,) class ACE\_TextTranslate: def \_\_init\_\_(self): self.model\_checkpoint = None self.tokenizer = None self.model = None self.device = ( torch.device("mps")  if torch.backends.mps.is\_available() else torch.device("cuda")  if torch.cuda.is\_available() else torch.device("cpu") )
 @classmethod def INPUT\_TYPES(cls): supported\_lang = [ 'en', # 英语 'zh', # 中文 'es', # 西班牙语 'hi', # 印度语 'ar', # 阿拉伯语 'pt', # 葡萄牙语 'ru', # 俄语 'ja', # 日语 'de', # 德语 'fr', # 法语 'ko', # 韩语 'it', # 意大利语 'nl', # 荷兰语 'tr', # 土耳其语 'sv', # 瑞典语 'pl', # 波兰语 'th', # 泰语 'vi', # 越南语 'id', # 印尼语 'el', # 希腊语 'cs', # 捷克语 'da', # 丹麦语 'fi', # 芬兰语 'hu', # 匈牙利语 'no', # 挪威语 'ro', # 罗马尼亚语 'sk', # 斯洛伐克语 'uk', # 乌克兰语 ] return { "required":{ "text": ("STRING", {"default": '', "multiline": True}), "from\_lang": (supported\_lang, {"default": 'en'}), "to\_lang": (supported\_lang, {"default": 'en'}), } }
 RETURN\_TYPES = ("STRING",) FUNCTION = "execute" CATEGORY = "Ace Nodes"  def execute(self, text, from\_lang, to\_lang): if from\_lang == to\_lang: return (text,)  model\_id = f'Helsinki-NLP/opus-mt-{from\_lang}-{to\_lang}' model\_checkpoint = os.path.join(folder\_paths.models\_dir, 'prompt\_generator', os.path.basename(model\_id))
 if not os.path.exists(model\_checkpoint): from huggingface\_hub import snapshot\_download snapshot\_download(repo\_id=model\_id, local\_dir=model\_checkpoint, local\_dir\_use\_symlinks=False)
 if self.model\_checkpoint != model\_checkpoint: self.model\_checkpoint = model\_checkpoint from transformers import AutoTokenizer, AutoModelForSeq2SeqLM self.tokenizer = AutoTokenizer.from\_pretrained(model\_checkpoint) self.model = AutoModelForSeq2SeqLM.from\_pretrained(model\_checkpoint).to(self.device).eval()
 with torch.no\_grad(): texts = [x.strip() for x in text.split("\n") if x.strip()] encoded = self.tokenizer(texts, padding=True, truncation=True, return\_tensors="pt").to(self.device) sequences = self.model.generate(\*\*encoded) translation = self.tokenizer.batch\_decode(sequences, skip\_special\_tokens=True) translation\_text = "\n".join([x.rstrip('.') for x in translation]) return (translation\_text,) class ACE\_TextGoogleTranslate: @classmethod def INPUT\_TYPES(cls): supported\_lang = [ 'en', # 英语 'zh', # 中文 'es', # 西班牙语 'hi', # 印度语 'ar', # 阿拉伯语 'pt', # 葡萄牙语 'ru', # 俄语 'ja', # 日语 'de', # 德语 'fr', # 法语 'ko', # 韩语 'it', # 意大利语 'nl', # 荷兰语 'tr', # 土耳其语 'sv', # 瑞典语 'pl', # 波兰语 'th', # 泰语 'vi', # 越南语 'id', # 印尼语 'el', # 希腊语 'cs', # 捷克语 'da', # 丹麦语 'fi', # 芬兰语 'hu', # 匈牙利语 'no', # 挪威语 'ro', # 罗马尼亚语 'sk', # 斯洛伐克语 'uk', # 乌克兰语 ] return { "required":{ "text": ("STRING", {"default": '', "multiline": True}), "from\_lang": (supported\_lang, {"default": 'en'}), "to\_lang": (supported\_lang, {"default": 'en'}), } }
 RETURN\_TYPES = ("STRING",) FUNCTION = "execute" CATEGORY = "Ace Nodes"  def execute(self, text, from\_lang, to\_lang): if from\_lang == to\_lang: return (text,)  import requests response = requests.get(f'https://translate.google.com/m?sl={from\_lang}&tl={to\_lang}&q={text}')
 if response.status\_code == 200: from bs4 import BeautifulSoup soup = BeautifulSoup(response.text, "html.parser") element = soup.find('div', {"class": "result-container"})
 if element: translation\_text = element.get\_text(strip=True) return (translation\_text,)
 return (text,)
####################### ACE Nodes of Image #######################
class ACE\_ImageConstrain: @classmethod def INPUT\_TYPES(cls): return { "required": { "images": ("IMAGE",), "max\_width": ("INT", {"default": 1024, "min": 0}), "max\_height": ("INT", {"default": 1024, "min": 0}), "min\_width": ("INT", {"default": 0, "min": 0}), "min\_height": ("INT", {"default": 0, "min": 0}), "crop\_if\_required": ("BOOLEAN", {"default": False, "label\_on": "yes", "label\_off": "no"}), }, "optional": { "crop\_position": (["center", "top", "bottom", "left", "right"], {"default": "center"}), }, }
 RETURN\_TYPES = ("IMAGE",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, images, max\_width, max\_height, min\_width, min\_height, crop\_if\_required, crop\_position="center"): images = images.permute([0,3,1,2]) output = []
 for image in images: image = to\_image(image)
 current\_width, current\_height = image.size aspect\_ratio = current\_width / current\_height
 target\_width = min(max(current\_width, min\_width), max\_width) target\_height = min(max(current\_height, min\_height), max\_height)
 if crop\_if\_required: if target\_width / target\_height < aspect\_ratio: resize\_width, resize\_height = int(target\_height \* aspect\_ratio), int(target\_height) else: resize\_width, resize\_height = int(target\_width), int(target\_width / aspect\_ratio) image = image.resize((resize\_width, resize\_height), resample=Image.Resampling.LANCZOS) x0, y0 = max((resize\_width-target\_width)/2, 0), max((resize\_height-target\_height)/2, 0) if crop\_position == "top": y0 = 0 elif crop\_position == "bottom": y0 = resize\_height - target\_height elif crop\_position == "left": x0 = 0 elif crop\_position == "right": x0 = resize\_width - target\_width image = image.crop((x0, y0, x0+target\_width, y0+target\_height)) else: if target\_width / target\_height > aspect\_ratio: target\_width, target\_height = int(target\_height \* aspect\_ratio), int(target\_height) else: target\_width, target\_height = int(target\_width), int(target\_width / aspect\_ratio) resize\_width, resize\_height = max(target\_width, min\_width), max(target\_height, min\_height) image = image.resize((resize\_width, resize\_height), resample=Image.Resampling.LANCZOS)
 output.append(to\_tensor(image))
 output = torch.stack(output, dim=0) output = output.permute([0,2,3,1])  return (output[:, :, :, :3],) class ACE\_ImageRemoveBackground: def \_\_init\_\_(self): self.model\_dir = os.path.join(folder\_paths.models\_dir, "rembg") os.environ["U2NET\_HOME"] = self.model\_dir  self.model\_checkpoint = None self.model = None self.device = ( torch.device("mps")  if torch.backends.mps.is\_available() else torch.device("cuda")  if torch.cuda.is\_available() else torch.device("cpu") )
 @classmethod def INPUT\_TYPES(cls): return { "required": { "images": ("IMAGE",), "model": (["briarmbg", "u2net", "u2netp", "u2net\_human\_seg", "u2net\_cloth\_seg", "silueta", "isnet-general-use", "isnet-anime", "sam"],), }, }
 RETURN\_TYPES = ("IMAGE","MASK",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, images, model): if model == "briarmbg": model\_checkpoint = os.path.join(self.model\_dir, 'briarmbg.pth')
 from .core.image.briarmbg import BriaRMBG if self.model\_checkpoint != model\_checkpoint: if not os.path.exists(model\_checkpoint): from huggingface\_hub import hf\_hub\_download hf\_hub\_download(repo\_id='briaai/RMBG-1.4', filename='model.pth', local\_dir=self.model\_dir) os.rename(os.path.join(self.model\_dir, 'model.pth'), model\_checkpoint)  self.model\_checkpoint = model\_checkpoint self.model = BriaRMBG() self.model.load\_state\_dict(torch.load(self.model\_checkpoint, map\_location=self.device)) self.model.to(self.device) self.model.eval()
 images = images.permute([0,3,1,2]) processed\_images = [] processed\_masks = []
 import torch.nn.functional as F from torchvision.transforms.v2.functional import normalize for image in images: orig\_image = to\_image(image) w,h = orig\_image.size image = orig\_image.convert('RGB') image = image.resize((1024, 1024), Image.Resampling.LANCZOS) im\_np = np.array(image) im\_tensor = torch.tensor(im\_np, dtype=torch.float32).permute(2,0,1) im\_tensor = torch.unsqueeze(im\_tensor,0) im\_tensor = torch.divide(im\_tensor,255.0) im\_tensor = normalize(im\_tensor,[0.5,0.5,0.5],[1.0,1.0,1.0]) im\_tensor = im\_tensor.to(self.device)
 result = self.model(im\_tensor) result = torch.squeeze(F.interpolate(result[0][0], size=(h,w), mode='bilinear') ,0) ma = torch.max(result) mi = torch.min(result) result = (result-mi)/(ma-mi)  im\_array = (result\*255).cpu().data.numpy().astype(np.uint8) pil\_im = Image.fromarray(np.squeeze(im\_array)) new\_im = Image.new("RGB", pil\_im.size, (0,0,0)) new\_im.paste(orig\_image, mask=pil\_im)
 processed\_images.append(to\_tensor(new\_im)) processed\_masks.append(to\_tensor(pil\_im))
 new\_ims = torch.stack(processed\_images, dim=0) new\_masks = torch.stack(processed\_masks, dim=0) new\_ims = new\_ims.permute([0,2,3,1])
 return (new\_ims, new\_masks,)
 else: from rembg import new\_session, remove if self.model\_checkpoint != model: self.model\_checkpoint = model self.model = new\_session(self.model\_checkpoint, providers=['CPUExecutionProvider'])
 images = images.permute([0,3,1,2]) output = []  for image in images: image = to\_image(image) image = remove(image, session=self.model) output.append(to\_tensor(image))
 output = torch.stack(output, dim=0) output = output.permute([0,2,3,1]) mask = output[:, :, :, 3] if output.shape[3] == 4 else torch.ones\_like(output[:, :, :, 0])
 return (output[:, :, :, :3], mask,) class ACE\_ImageColorFix: @classmethod def INPUT\_TYPES(s): return { "required": { "images": ("IMAGE",), "color\_map\_images": ("IMAGE",), "color\_fix": ( [ "Wavelet", "AdaIN", ], ), }, }
 RETURN\_TYPES = ("IMAGE",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, images, color\_map\_images, color\_fix): from .core.image.colorfix import adain\_color\_fix, wavelet\_color\_fix color\_fix\_func = ( wavelet\_color\_fix if color\_fix == "Wavelet" else adain\_color\_fix )
 images = images.permute([0,3,1,2]) color\_map\_images = color\_map\_images.permute([0,3,1,2]) output = []
 last\_element = images[-1] if len(images) < len(color\_map\_images) else color\_map\_images[-1]  from itertools import zip\_longest for image, color\_map\_image in zip\_longest(images, color\_map\_images, fillvalue=last\_element): result\_image = color\_fix\_func(to\_image(image), to\_image(color\_map\_image)) output.append(to\_tensor(result\_image))
 output = torch.stack(output, dim=0) output = output.permute([0,2,3,1])  return (output[:, :, :, :3],)
class ACE\_ImageQA: def \_\_init\_\_(self): self.model\_checkpoint = None self.tokenizer = None self.model = None self.device = ( torch.device("mps")  if torch.backends.mps.is\_available() else torch.device("cuda")  if torch.cuda.is\_available() else torch.device("cpu") ) self.bf16\_support = ( torch.backends.mps.is\_available() or  (torch.cuda.is\_available() and torch.cuda.get\_device\_capability(self.device)[0] >= 8) )
 @classmethod def INPUT\_TYPES(s): return { "required": { "image": ("IMAGE",), "text": ("STRING", {"default": '', "multiline": True}), "model": (["moondream2", "MiniCPM-V-2"],), }, }
 RETURN\_TYPES = ("STRING",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, image, text, model): if model == "moondream2": model\_id = "vikhyatk/moondream2" elif model == "MiniCPM-V-2": model\_id = "openbmb/MiniCPM-V-2" else: raise Exception(f'Model "{model}" is not supported')  model\_checkpoint = os.path.join(folder\_paths.models\_dir, 'prompt\_generator', os.path.basename(model\_id))
 if not os.path.exists(model\_checkpoint): from huggingface\_hub import snapshot\_download snapshot\_download(repo\_id=model\_id, local\_dir=model\_checkpoint, local\_dir\_use\_symlinks=False)
 if self.model\_checkpoint != model\_checkpoint: self.model\_checkpoint = model\_checkpoint if model == "moondream2": from transformers import AutoTokenizer, AutoModelForCausalLM self.tokenizer = AutoTokenizer.from\_pretrained(model\_checkpoint, trust\_remote\_code=True) self.model = AutoModelForCausalLM.from\_pretrained(model\_checkpoint, trust\_remote\_code=True) self.model = self.model.to(self.device).eval() elif model == "MiniCPM-V-2": from transformers import AutoTokenizer, AutoModel self.tokenizer = AutoTokenizer.from\_pretrained(model\_checkpoint, trust\_remote\_code=True) self.model = AutoModel.from\_pretrained(model\_checkpoint, trust\_remote\_code=True, torch\_dtype=torch.bfloat16) self.model = self.model.to(self.device, dtype=torch.bfloat16 if self.bf16\_support else torch.float16).eval()
 with torch.no\_grad(): image = to\_image(image.permute([0,3,1,2])[0]).convert("RGB")
 if model == "moondream2": encoded\_image = self.model.encode\_image(image) result = self.model.answer\_question(encoded\_image, text, self.tokenizer) elif model == "MiniCPM-V-2": result, context, \_ = self.model.chat( image=image, msgs=[{'role': 'user', 'content': text}], context=None, tokenizer=self.tokenizer, sampling=True ) return (result,) class ACE\_ImageLoadFromCloud: @classmethod def INPUT\_TYPES(s): return { "required": { "filepath": ("STRING", {"default": ''}), "bucket": ("STRING", {"default": ''}), "region": ("STRING", {"default": ''}), "cloud": (["aws-s3","aliyun-oss"],), "access\_key\_id": ("STRING", {"default": ''}), "access\_key\_secret": ("STRING", {"default": ''}), }, }  RETURN\_TYPES = ("IMAGE", "MASK",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, filepath, bucket, region, cloud, access\_key\_id, access\_key\_secret): save\_path = os.path.join(folder\_paths.temp\_directory, bucket, filepath) os.makedirs(os.path.dirname(save\_path), exist\_ok=True)
 if cloud == "aws-s3": import boto3 s3 = boto3.client('s3',  aws\_access\_key\_id=access\_key\_id,  aws\_secret\_access\_key=access\_key\_secret,  region\_name=region) s3.download\_file(bucket, filepath, save\_path) elif cloud == "aliyun-oss": import oss2 oss\_auth = oss2.Auth(access\_key\_id, access\_key\_secret) oss\_bucket = oss2.Bucket(oss\_auth, region, bucket) oss\_bucket.get\_object\_to\_file(filepath, save\_path) else: raise Exception(f'Cloud "{cloud}" is not supported')  image = f"{bucket}/{filepath} [temp]"  image\_path = folder\_paths.get\_annotated\_filepath(image) from PIL import ImageSequence, ImageOps img = Image.open(image\_path) output\_images = [] output\_masks = [] for i in ImageSequence.Iterator(img): i = ImageOps.exif\_transpose(i) if i.mode == 'I': i = i.point(lambda i: i \* (1 / 255)) image = i.convert("RGB") image = np.array(image).astype(np.float32) / 255.0 image = torch.from\_numpy(image)[None,] if 'A' in i.getbands(): mask = np.array(i.getchannel('A')).astype(np.float32) / 255.0 mask = 1. - torch.from\_numpy(mask) else: mask = torch.zeros((64,64), dtype=torch.float32, device="cpu") output\_images.append(image) output\_masks.append(mask.unsqueeze(0))
 if len(output\_images) > 1: output\_image = torch.cat(output\_images, dim=0) output\_mask = torch.cat(output\_masks, dim=0) else: output\_image = output\_images[0] output\_mask = output\_masks[0]
 return (output\_image, output\_mask)
class ACE\_ImageSaveToCloud: @classmethod def INPUT\_TYPES(s): return { "required": { "images": ("IMAGE",), "filepath": ("STRING", {"default": 'ComfyUI\_{0:05d}\_{1:%Y-%m-%d\_%H:%M:%S}.png'}), "bucket": ("STRING", {"default": ''}), "region": ("STRING", {"default": ''}), "cloud": (["aws-s3","aliyun-oss"],), "access\_key\_id": ("STRING", {"default": ''}), "access\_key\_secret": ("STRING", {"default": ''}), }, }  RETURN\_TYPES = () OUTPUT\_NODE = True FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, images, filepath, bucket, region, cloud, access\_key\_id, access\_key\_secret): now = datetime.now() results = [] files\_to\_upload = [] for (batch\_number, image) in enumerate(images): i = 255. \* image.cpu().numpy() img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))
 filepath\_formated = filepath.format(batch\_number, now) save\_path = os.path.join(folder\_paths.temp\_directory, bucket, filepath\_formated) os.makedirs(os.path.dirname(save\_path), exist\_ok=True) img.save(save\_path, compress\_level=1)
 file, subfolder = os.path.basename(filepath\_formated), os.path.join(bucket, os.path.dirname(filepath\_formated)) results.append({ "filename": file, "subfolder": subfolder, "type": "temp" }) files\_to\_upload.append((save\_path, filepath\_formated))
 if cloud == "aws-s3": import boto3 s3 = boto3.client('s3',  aws\_access\_key\_id=access\_key\_id,  aws\_secret\_access\_key=access\_key\_secret,  region\_name=region) for filename, objectname in files\_to\_upload: try: s3.upload\_file(filename, bucket, objectname) except Exception as e: print(f'An error occurred: {e}') elif cloud == "aliyun-oss": import oss2 oss\_auth = oss2.Auth(access\_key\_id, access\_key\_secret) oss\_bucket = oss2.Bucket(oss\_auth, region, bucket) for filename, objectname in files\_to\_upload: try: oss\_bucket.put\_object\_from\_file(objectname, filename) except Exception as e: print(f'An error occurred: {e}') else: raise Exception(f'Cloud "{cloud}" is not supported')
 return { "ui": { "images": results } } class ACE\_ImageGetSize: @classmethod def INPUT\_TYPES(s): return { "required": { "image": ("IMAGE",), } }
 RETURN\_TYPES = ("INT", "INT",) RETURN\_NAMES = ("WIDTH","HEIGHT",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, image): return (image.shape[2], image.shape[1],) class ACE\_ImageFaceCrop: def \_\_init\_\_(self): self.model\_name = None self.model = None
 @classmethod def INPUT\_TYPES(s): return { "required": { "image": ("IMAGE",), "model": (["retinaface", "insightface"],), "crop\_width": ("INT", {"default": 512, "min": 1, "max": 16384, "step": 1}), "crop\_height": ("INT", {"default": 512, "min": 1, "max": 16384, "step": 1}), } }
 RETURN\_TYPES = ("IMAGE","MASK","BOOLEAN",) RETURN\_NAMES = ("IMAGE","MASK","FACE\_DETECTED",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, image, model, crop\_width, crop\_height): image = to\_image(image.permute([0,3,1,2])[0]).convert("RGB") im\_np = np.array(image)
 face\_bboxes = [] face\_images = [] face\_masks = []
 if model == 'retinaface': from retinaface import RetinaFace if self.model\_name != model: self.model\_name = model self.model = RetinaFace.build\_model()
 faces = RetinaFace.detect\_faces(im\_np, model=self.model) if faces: for face in faces.values(): face\_bboxes.append(face['facial\_area']) elif model == 'insightface': from insightface.app import FaceAnalysis if self.model\_name != model: self.model\_name = model self.model = FaceAnalysis(providers=['CUDAExecutionProvider', 'CPUExecutionProvider'], root=os.path.join(folder\_paths.models\_dir, 'insightface')) self.model.prepare(ctx\_id=0)
 faces = self.model.get(im\_np) if faces: for face in faces: face\_bboxes.append(face.bbox.astype(int)) else: raise Exception(f'Model "{model}" is not supported')  if face\_bboxes: face\_bboxes = sorted(face\_bboxes, key=lambda x: -(x[2]-x[0])\*(x[3]-x[1])) # sort by area for bbox in face\_bboxes: x1, y1, x2, y2 = bbox width, height = x2-x1, y2-y1 if width / height > crop\_width / crop\_height: new\_height = int(width \* crop\_height / crop\_width) y\_offset = int((new\_height - height) / 2) y1, y2 = y1-y\_offset, y2+y\_offset else: new\_width = int(height \* crop\_width / crop\_height) x\_offset = int((new\_width - width) / 2) x1, x2 = x1-x\_offset, x2+x\_offset  face\_image = image.crop((x1, y1, x2, y2)).resize((crop\_width, crop\_height), Image.Resampling.LANCZOS) face\_images.append(to\_tensor(face\_image))
 face\_mask = torch.zeros(image.size) face\_mask[max(x1,0):min(x2,image.size[0]-1), max(y1,0):min(y2,image.size[0]-1)] = 1 face\_masks.append(face\_mask) else: face\_image = torch.zeros((3, crop\_width, crop\_height)) face\_images.append(to\_tensor(face\_image))  face\_mask = torch.zeros(image.size) face\_masks.append(face\_mask)
 output\_images = torch.stack(face\_images, dim=0) output\_images = output\_images.permute([0,2,3,1]) output\_masks = torch.stack(face\_masks, dim=0) output\_masks = output\_masks.permute([0,2,1])  return (output\_images, output\_masks, len(face\_bboxes)>0)
class ACE\_ImagePixelate: @classmethod def INPUT\_TYPES(s): return { "required": { "images": ("IMAGE",), "pixel\_size": ("INT", {"default": 8, "min": 1, "max": 64, "step": 1}), "palette\_colors": ("STRING", {"default": '121212\n31342F\n555F50\n7E8C77\n9DA09B', "multiline": True}), } }
 RETURN\_TYPES = ("IMAGE",) FUNCTION = "execute" CATEGORY = "Ace Nodes"
 def execute(self, images, pixel\_size, palette\_colors): images = images.permute([0,3,1,2]) palette = palette\_colors.split('\n') output = []  from PIL import ImageDraw
 def hex\_to\_rgb(hex\_color): hex\_color = hex\_color.lstrip('0x').strip() return tuple(int(hex\_color[i:i+2], 16) for i in (0, 2, 4))  def get\_color\_for\_depth(depth, palette): step = 256//len(palette) threshold = list(range(0, 255, step)) for i in range(1, len(threshold)): if depth < threshold[i]: return hex\_to\_rgb(palette[i-1]) return hex\_to\_rgb(palette[-1])
 for image in images: image = to\_image(image).convert('L') width, height = image.size small\_image = image.resize((width // pixel\_size, height // pixel\_size), Image.LANCZOS) pixelated\_image = small\_image.resize((width, height), Image.LANCZOS)[View remainder of file in raw view](https://github.com/hay86/ComfyUI_AceNodes/raw/5ba01db8a3b7afb8e4aecfaa48823ddeb132bbbb/nodes.py)

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.


