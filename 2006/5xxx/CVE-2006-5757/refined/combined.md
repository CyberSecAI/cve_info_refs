=== Content from www.redhat.com_e0762cd4_20250126_104121.html ===


[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

**We're sorry but cve-details doesn't work properly without JavaScript enabled. Please enable it to continue.**

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2025 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from www.vupen.com_9497334f_20250125_174337.html ===

[![](/__ovh/common/img/logo-white.png)](https://www.ovhcloud.com/)

![](/__ovh/common/img/icon-traffic-cone.png)

# Site en construction

![](/__ovh/common/img/shadow.png)

Besoin d'assistance ou d'informations ?

[![](/__ovh/common/img/icon-book.png)
Guides](https://docs.ovh.com/fr/hosting/ "Guides")
[![](/__ovh/common/img/icon-speech-bubble.png)
Forum](https://community.ovh.com/ "Forum")
[![](/__ovh/common/img/icon-user-support.png)
Contact](https://help.ovhcloud.com/fr/ "Contact")
[![](/__ovh/common/img/icon-app-gear.png)
Espace Client](https://www.ovh.com/manager/ "Espace Client")

© Copyright 1999 [OVHcloud](https://www.ovhcloud.com/)

v1v2v3v4v5v6v7v8v9v10v11v12v13v14v15v16v17v18v19v20v21v22v23v24v25v26v27v28v29v30v31v32v33v34v35v36v37v38v39v40v41v42v43v44v45v46v47v48v49v50v51v52v53v54v55v56v57v58v59v60v61v62v63v64v65v66v67v68v69v70

u1u2u3u4u5u6u7u8u9u10u11u12u13u14u15u16u17u18u19u20u21u22u23u24u25u26u27u28u29u30u31u32u33u34u35u36u37u38u39u40u41u42u43u44u45u46u47u48u49u50u51u52u53u54u55u56u57u58u59u60u61u62u63u64u65u66u67u68u69

p1p2p3p4p5p6p7p8p9p10p11p12p13p14p15p16p17p18p19p20p21p22p23p24p25p26p27p28p29p30p31p32p33p34p35p36p37p38p39p40p41p42p43p44p45p46p47p48p49p50p51p52p53p54p55p56p57p58p59p60p61p62p63p64

e1e2e3e4e5e6e7e8e9e10e11e12e13e14e15e16e17e18e19e20e21e22e23e24e25e26e27e28e29e30e31e32e33e34e35e36e37e38e39e40e41e42e43e44e45e46e47e48e49e50e51e52e53

n1n2n3n4n5n6n7n8n9n10n11n12n13n14n15n16n17n18n19n20n21n22n23n24n25n26n27n28n29n30n31n32n33n34n35n36n37n38n39n40n41n42n43n44n45n46n47n48n49n50n51n52n53n54n55n56n57n58n59n60n61n62

---

c1c2c3c4c5c6c7c8c9c10c11c12c13c14c15c16c17c18c19c20c21c22c23c24c25c26c27c28c29c30c31c32c33c34c35c36c37c38c39c40c41c42c43c44c45c46c47c48c49c50c51

o1o2o3o4o5o6o7o8o9o10o11o12o13o14o15o16o17o18o19o20o21o22o23o24o25o26o27o28o29o30o31o32o33o34o35o36o37o38o39o40o41o42o43o44o45o46o47o48o49o50o51o52o53o54o55o56o57o58o59o60o61o62o63

m1m2m3m4m5m6m7m8m9m10m11m12m13m14m15m16m17m18m19m20m21m22m23m24m25m26m27m28m29m30m31m32m33m34m35m36m37m38m39m40m41m42m43m44m45m46m47m48m49m50m51m52m53m54m55m56m57m58m59m60m61



=== Content from www.mandriva.com_359a116a_20250125_174331.html ===


* [Tuxedo.org](https://tuxedo.org/ "Go to: Tuxedo")
* Store
* Mandriva Linux
* Enterprise Solutions
* Contact Us
* Language ![](/sites/all/themes/mandriva_customer/images/arrow-grey-bottom.gif)
  + English (International)
  + Français
  + Ð ÑÑÑÐºÐ¸Ð¹

# [Mandriva](/mandriva/)

* Download
* Mandriva Linux
* Community
* Help

## One

### The Linux desktopthat's easy to try and easy to keep

Download
![Mandriva One](/sites/all/themes/mandriva_customer/images/front/packshot_Mandriva_One.png)

## Powerpack

### Mandriva Linux- and more

Download
![Mandriva Linux Powerpack](/sites/all/themes/mandriva_customer/images/front/en-49.png)

## Mandriva Flash

### The mobile and installable Linux desktopon a USB key

Buy on Store
![Mandriva Flash](/sites/all/themes/mandriva_customer/images/front/mandriva-flash2.png)

### [Community](community)

* User Forums
* Support - FAQ
* Free Software
* Become a member

### Enterprise Solutions

* Enterprise Linux Products
* Asset Management Solution
* Professional Services
* Support & Maintenance

* Go to site »

### Mandriva Partners

* Worldwide offices
* Partner Program
* Technology Partners
* OEM
* Classmate PC with Mandriva Linux

### News

* Mandriva presents the launch of its new mobile desktop: Mandriva Flash 2008 Spring
* Speaking about Mandriva Linux 2008 Spring in media
* Speaking about Mandriva Linux 2008 Spring in media
* Mandriva presents its latest distribution: Mandriva Linux 2008 Spring
* Mandriva and Novatice Technologies present Edutice, The ready to use solution dedicated to educationand multimedia spaces
* # [Top 50 Online Casinos UK in 2023](https://montycasinos.com/online-casinos/)

more

* Download
  + Mandriva Linux 2008
  + Writing an ISO image
* Mandriva Linux
  + One
  + Powerpack
  + Mandriva Flash
* Community
  + Start
  + Register
  + Stay informed
  + Participate
  + Free software
* Help
  + Getting help
  + Knowledge Base
  + Documentation
  + Forums
  + Support Requests
  + Customer Care
  + Enterprise Support
* Enterprise Solutions
  + Products
  + Support
  + Services
  + Partners
  + Go to site »

Language
English (International)
Français
Ð ÑÑÑÐºÐ¸Ð¹

* © 2007 Mandriva S.A.
* About Us
* Legal Information
* Privacy Policy
* Contact Us



=== Content from www.ubuntu.com_6374398d_20250125_174336.html ===


Your submission was sent successfully!
*Close*

Thank you for contacting us. A member of our team will be in touch shortly.
*Close*

You have successfully unsubscribed!
*Close*

Thank you for signing up for our newsletter!

In these regular emails you will find the latest updates about
Ubuntu and upcoming events where you can meet our team.*Close*

Your preferences have been successfully updated. *Close*

[Canonical Ubuntu](/)

* [Menu](/navigation)

* [Products](/navigation#products-navigation)
* [Use cases](/navigation#use-case-navigation)
* [Support](/navigation#support-navigation)
* [Community](/navigation#community-navigation)
* [Get Ubuntu](/navigation#get-ubuntu-navigation)

[![](https://assets.ubuntu.com/v1/82818827-CoF_white.svg)

Security](/security)

* [ESM](/security/esm)
* [Livepatch](/security/livepatch)
* [Certifications & Hardening](/security/compliance-automation)
* [CVEs](/security/cves)
* [Notices](/security/notices)
* [Docker Images](/security/docker-images)

# USN-416-1: Linux kernel vulnerabilities

10 February 2007

Linux kernel vulnerabilities

### Reduce your security exposure

Ubuntu Pro provides ten-year security coverage to 25,000+ packages in Main and Universe repositories, and it is free for up to five machines.

[Learn more about Ubuntu Pro](/pro)

## Releases

* [Ubuntu 6.10](/security/notices?release=edgy)
* [Ubuntu 6.06](/security/notices?release=dapper)
* [Ubuntu 5.10](/security/notices?release=breezy)

## Details

Mark Dowd discovered that the netfilter iptables module did not

correcly handle fragmented IPv6 packets. By sending specially crafted

packets, a remote attacker could exploit this to bypass firewall

rules. This has has already been fixed for Ubuntu 6.10 in USN-395-1;

this is the corresponding fix for Ubuntu 6.06.([CVE-2006-4572](/security/CVE-2006-4572))

Doug Chapman discovered an improper lock handling in the mincore()

function. A local attacker could exploit this to cause an eternal hang

in the kernel, rendering the machine unusable. ([CVE-2006-4814](/security/CVE-2006-4814))

Al Viro reported that the ISDN PPP module did not initialize the reset

state timer. By sending specially crafted ISDN packets, a remote

attacker could exploit this to crash the kernel. ([CVE-2006-5749](/security/CVE-2006-5749))

Various syscalls (like listxattr()) misinterpreted the return value of

return\_EIO() when encountering bad inodes. By issuing particular

system calls on a malformed file system, a local attacker could

exploit this to crash the kernel. ([CVE-2006-5753](/security/CVE-2006-5753))

The task switching code did not save and restore EFLAGS of processes.

By starting a specially crafted executable, a local attacker could

exploit this to eventually crash many other running processes. This

only affects the amd64 platform. ([CVE-2006-5755](/security/CVE-2006-5755))

A race condition was found in the grow\_buffers() function. By mounting

a specially crafted ISO9660 or NTFS file system, a local attacker

could exploit this to trigger an infinite loop in the kernel,

rendering the machine unusable. ([CVE-2006-5757](/security/CVE-2006-5757))

A buffer overread was found in the zlib\_inflate() function. By

tricking an user into mounting a specially crafted file system which

uses zlib compression (such as cramfs), this could be exploited to

crash the kernel. ([CVE-2006-5823](/security/CVE-2006-5823))

The ext3 file system driver did not properly handle corrupted data

structures. By mounting a specially crafted ext3 file system, a local

attacker could exploit this to crash the kernel. ([CVE-2006-6053](/security/CVE-2006-6053))

The ext2 file system driver did not properly handle corrupted data

structures. By mounting a specially crafted ext2 file system, a local

attacker could exploit this to crash the kernel. ([CVE-2006-6054](/security/CVE-2006-6054))

The hfs file system driver did not properly handle corrupted data

structures. By mounting a specially crafted hfs file system, a local

attacker could exploit this to crash the kernel. This only affects

systems which enable SELinux (Ubuntu disables SELinux by default).

([CVE-2006-6056](/security/CVE-2006-6056))

Several vulnerabilities have been found in the GFS2 file system

driver. Since this driver has never actually worked in Ubuntu 6.10, it

has been disabled. This only affects Ubuntu 6.10. ([CVE-2006-6057](/security/CVE-2006-6057))

Marcel Holtman discovered several buffer overflows in the Bluetooth

driver. By sending Bluetooth packets with specially crafted CAPI

messages, a remote attacker could exploit these to crash the kernel.

([CVE-2006-6106](/security/CVE-2006-6106))

### Reduce your security exposure

Ubuntu Pro provides ten-year security coverage to 25,000+ packages in Main and Universe repositories, and it is free for up to five machines.

[Learn more about Ubuntu Pro](/pro)

## Update instructions

The problem can be corrected by updating your system to the following package versions:

##### Ubuntu 6.10

* linux-image-2.6.17-11-generic
  -
  2.6.17.1-11.35
* linux-image-2.6.17-11-server-bigiron
  -
  2.6.17.1-11.35
* linux-image-2.6.17-11-sparc64-smp
  -
  2.6.17.1-11.35
* linux-image-2.6.17-11-powerpc
  -
  2.6.17.1-11.35
* linux-image-2.6.17-11-386
  -
  2.6.17.1-11.35
* linux-image-2.6.17-11-powerpc-smp
  -
  2.6.17.1-11.35
* linux-image-2.6.17-11-sparc64
  -
  2.6.17.1-11.35
* linux-image-2.6.17-11-server
  -
  2.6.17.1-11.35
* linux-image-2.6.17-11-powerpc64-smp
  -
  2.6.17.1-11.35

##### Ubuntu 6.06

* linux-image-2.6.15-28-amd64-generic
  -
  2.6.15-28.51
* linux-image-2.6.15-28-powerpc-smp
  -
  2.6.15-28.51
* linux-image-2.6.15-28-amd64-k8
  -
  2.6.15-28.51
* linux-image-2.6.15-28-686
  -
  2.6.15-28.51
* linux-image-2.6.15-28-powerpc64-smp
  -
  2.6.15-28.51
* linux-image-2.6.15-28-server-bigiron
  -
  2.6.15-28.51
* linux-image-2.6.15-28-sparc64-smp
  -
  2.6.15-28.51
* linux-image-2.6.15-28-server
  -
  2.6.15-28.51
* linux-image-2.6.15-28-k7
  -
  2.6.15-28.51
* linux-image-2.6.15-28-amd64-server
  -
  2.6.15-28.51
* linux-image-2.6.15-28-amd64-xeon
  -
  2.6.15-28.51
* linux-image-2.6.15-28-386
  -
  2.6.15-28.51
* linux-image-2.6.15-28-powerpc
  -
  2.6.15-28.51
* linux-image-2.6.15-28-sparc64
  -
  2.6.15-28.51

##### Ubuntu 5.10

* linux-image-2.6.12-10-amd64-k8-smp
  -
  2.6.12-10.45
* linux-image-2.6.12-10-686
  -
  2.6.12-10.45
* linux-image-2.6.12-10-amd64-generic
  -
  2.6.12-10.45
* linux-image-2.6.12-10-686-smp
  -
  2.6.12-10.45
* linux-patch-ubuntu-2.6.12
  -
  2.6.12-10.45
* linux-image-2.6.12-10-k7-smp
  -
  2.6.12-10.45
* linux-image-2.6.12-10-amd64-k8
  -
  2.6.12-10.45
* linux-image-2.6.12-10-amd64-xeon
  -
  2.6.12-10.45
* linux-image-2.6.12-10-k7
  -
  2.6.12-10.45
* linux-image-2.6.12-10-powerpc
  -
  2.6.12-10.45
* linux-image-2.6.12-10-386
  -
  2.6.12-10.45
* linux-image-2.6.12-10-powerpc64-smp
  -
  2.6.12-10.45
* linux-image-2.6.12-10-powerpc-smp
  -
  2.6.12-10.45

After a standard system upgrade you need to reboot your computer to

effect the necessary changes.

ATTENTION: Due to an unavoidable ABI change the Ubuntu 6.06 and Ubuntu

6.10 kernel updates have been given a new version number, which

requires you to recompile and reinstall all third party kernel modules

you might have installed. If you use linux-restricted-modules, you

have to update that package as well to get modules which work with the

new kernel version. Unless you manually uninstalled the standard

kernel metapackages (linux-386, linux-powerpc, linux-amd64-generic), a

standard system upgrade will automatically perform this as well.

## References

* [CVE-2006-4572](/security/CVE-2006-4572)
* [CVE-2006-4814](/security/CVE-2006-4814)
* [CVE-2006-5749](/security/CVE-2006-5749)
* [CVE-2006-5753](/security/CVE-2006-5753)
* [CVE-2006-5755](/security/CVE-2006-5755)
* [CVE-2006-5757](/security/CVE-2006-5757)
* [CVE-2006-5823](/security/CVE-2006-5823)
* [CVE-2006-6053](/security/CVE-2006-6053)
* [CVE-2006-6054](/security/CVE-2006-6054)
* [CVE-2006-6056](/security/CVE-2006-6056)
* [CVE-2006-6057](/security/CVE-2006-6057)
* [CVE-2006-6106](/security/CVE-2006-6106)

## Related notices

* [USN-395-1](/security/notices/USN-395-1)

### Join the discussion

* [Ubuntu security updates mailing list](https://lists.ubuntu.com/mailman/listinfo/ubuntu-hardened)
* [Security announcements mailing list](https://lists.ubuntu.com/mailman/listinfo/ubuntu-security-announce)

### Need help with your security needs?

Ubuntu Pro provides up to ten-year security coverage for over 23,000 open-source packages within the Ubuntu Main and Universe repositories.

[Talk to an expert to find out what would work best for you](/contact-us/form?product=pro)

### Further reading

* *Loading...*

---

## [OpenStack](/openstack) [OpenStack](/openstack)

* [What is OpenStack](/openstack/what-is-openstack)
* [Features](/openstack/features)
* [Managed](/openstack/managed)
* [Consulting](/openstack/consulting)
* [Install](/openstack/install)
* [Support](/openstack/support)

---

## [Ceph](/ceph) [Ceph](/ceph)

* [What is Ceph](/ceph/what-is-ceph)
* [Managed](/ceph/managed)
* [Consulting](/ceph/consulting)
* [Docs](/ceph/docs)
* [Install](/ceph/install)

---

## [Kubernetes](/kubernetes) [Kubernetes](/kubernetes)

* [What is Kubernetes](/kubernetes/what-is-kubernetes)
* [Charmed Kubernetes](/kubernetes/charmed-k8s)
* [Managed](/kubernetes/managed)
* [Install](/kubernetes/install)
* [Docs](/kubernetes/docs)
* [Resources](/kubernetes/resources)

---

## [Managed Services](/managed) [Managed Services](/managed)

* [OpenStack](/openstack/managed)
* [Kubernetes](/kubernetes/managed)
* [Ceph](/ceph/managed)
* [Apps](/managed/apps)
* [Observability](/observability/managed)
* [Firefighting](/managed/firefighting-support)

---

## [AI / ML](/ai) [AI / ML](/ai)

* [MLOps](/ai/mlops)
* [Kubeflow](/ai/what-is-kubeflow)
* [MLflow](/ai/mlflow)
* [Consulting](/ai/consulting)
* [Data Science](/ai/data-science)
* [MLOps workshop](/ai/mlops-workshop)

---

## [Robotics](/robotics) [Robotics](/robotics)

* [What is ROS](/robotics/what-is-ros)
* [ROS ESM](/robotics/ros-esm)
* [Community](/robotics/community)
* [Docs](/robotics/docs)

---

## [IoT](/internet-of-things) [IoT](/internet-of-things)

* [App store](/internet-of-things/appstore)
* [Embedded Linux](/embedded)
* [Management](/internet-of-things/management)

---

## [Ubuntu Core](/core) [Ubuntu Core](/core)

* [Features](/core/features)
* [Success stories](/core/stories)
* [Services](/core/services)
* [Docs](/core/docs)

---

## [Ubuntu Desktop](/desktop) [Ubuntu Desktop](/desktop)

* [Organisations](/desktop/organisations)
* [Developers](/desktop/developers)
* [Flavours](/desktop/flavours)
* [WSL](/desktop/wsl)

---

## [Ubuntu Server](/server) [Ubuntu Server](/server)

* [Hyperscale](/server/hyperscale)
* [Docs](/server/docs)

---

## [Cloud](/cloud) [Cloud](/cloud)

* [What is cloud computing](/cloud/cloud-computing)
* [What is private cloud](/cloud/private-cloud)
* [What is hybrid cloud](/cloud/hybrid-cloud)
* [What is multi-cloud](/cloud/multi-cloud)
* [Public cloud](/cloud/public-cloud)

---

## [Security](/security) [Security](/security)

* [ESM](/security/esm)
* [Livepatch](/security/livepatch)
* [Certifications & Hardening](/security/compliance-automation)
* [CVEs](/security/cves)
* [Notices](/security/notices)
* [Docker Images](/security/docker-images)

---

## [Landscape](/landscape) [Landscape](/landscape)

* [Features](/landscape/features)
* [Managed](/landscape/managed)
* [Compare](/landscape/compare)
* [Install](/landscape/docs/quickstart-deployment)
* [Docs](/landscape/docs)
* [Log in to Landscape](https://landscape.canonical.com/)

---

## [Containers](/containers) [Containers](/containers)

* [What are containers](/containers/what-are-containers)
* [Chiseled Ubuntu](/containers/chiseled)
* [Chiseled and .NET](/containers/chiseled/dotnet)

---

## [Downloads](/download) [Downloads](/download)

* [Desktop](/download/desktop)
* [Server](/download/server)
* [Core](/download/core)
* [Cloud](/download/cloud)

---

## [Support](/support) [Support](/support)

* [Your subscriptions](/pro/dashboard)
* [Account users](/pro/users)
* [Pricing](/pricing/pro)
* [Discourse](https://discourse.ubuntu.com/c/project/ubuntu-pro/116/)

---

## [Observability](/observability) [Observability](/observability)

* [What is observability](/observability/what-is-observability)
* [Managed](/observability/managed)

---

## [Pricing](/pricing) [Pricing](/pricing)

* [Consulting](/pricing/consulting)
* [Desktops](/pricing/desktop)
* [Devices](/pricing/devices)

---

## Solutions

* [AI](https://canonical.com/solutions/ai)
* [Data](https://canonical.com/data)
* [Infrastructure](https://canonical.com/solutions/infrastructure)
* [Secure open source](https://canonical.com/solutions/secure-open-source)

---

## Sectors

* [Automotive](/automotive)
* [Industrial](/industrial)
* [Government](/gov)
* [Telco](/telco)
* [Finance](/financial-services)

---

[Contact us](/contact-us)

* [About us](/about)
* [Community](/community)
* [Careers](https://www.canonical.com/careers)
* [Blog](/blog)
* [Resources](/engage)
* [Press centre](/blog/press-centre)

---

© 2025 Canonical Ltd.

Ubuntu and Canonical are registered trademarks of Canonical Ltd.

---

* [Legal information](/legal)
* [Data privacy](/legal/data-privacy)
* Manage your tracker settings
* [Report a bug on this site](https://github.com/canonical/ubuntu.com/issues/new?template=ISSUE_TEMPLATE.yaml)

Back to top

Go to the top of the page



=== Content from bugzilla.redhat.com_4d9618bf_20250126_104113.html ===


* Login
  + Log in using an SSO provider:- [Fedora Account System](saml2_login.cgi?idp=Fedora%20Account%20System&target=show_bug.cgi%3Fid%3D205335)
    - [Red Hat Associate](saml2_login.cgi?idp=Red%20Hat%20Associate&target=show_bug.cgi%3Fid%3D205335)
    - [Red Hat Customer](saml2_login.cgi?idp=Red%20Hat%20Customer&target=show_bug.cgi%3Fid%3D205335)+ Login using a Red Hat Bugzilla account
  + Forgot Password
  + [Create an Account](createaccount.cgi)

Red Hat Bugzilla – Bug 205335

* [Home](./)
* [New](enter_bug.cgi)
* Search
  + [Simple Search](query.cgi?format=specific)
  + [Advanced Search](query.cgi?format=advanced)
* My Links
  + [Browse](describecomponents.cgi)
  + [Requests](request.cgi)
  + Reports
  + Current State
    - [Search](query.cgi)
    - [Tabular reports](query.cgi?format=report-table)
    - [Graphical reports](query.cgi?format=report-graph)
    - [Duplicates](duplicates.cgi)
  + Other Reports
    - [User Changes](https://bugzilla.redhat.com/page.cgi?id=user_activity.html)
  + Plotly Reports
    - [Bug Status](https://bugzilla.redhat.com/page.cgi?id=bug_status.html)
    - [Bug Severity](https://bugzilla.redhat.com/page.cgi?id=bug_severity.html)
    - [Non-Defaults](https://bugzilla.redhat.com/page.cgi?id=non_defaults.html)
* [Product Dashboard](page.cgi?id=productdashboard.html)

- Help
  * [Page Help!](docs/en/html/using/understanding.html)
  * [Bug Writing Guidelines](page.cgi?id=bug-writing.html)
  * [What's new](page.cgi?id=whats-new.html)
  * [Browser Support Policy](https://access.redhat.com/help/browsers)
  * [5.0.4.rh103 Release notes](page.cgi?id=release-notes.html)
  * [FAQ](page.cgi?id=faq.html)
  * [Guides index](docs/en/html/index.html)
  * [User guide](docs/en/html/using/index.html)
  * [Web Services](docs/en/html/integrating/api/Bugzilla/WebService/Bug.html)
  * [Contact](page.cgi?id=redhat/contact.html)
  * [Legal](page.cgi?id=terms-conditions.html)
- [[?]](page.cgi?id=quicksearch.html "Quicksearch Help")

This site requires JavaScript to be enabled to function correctly, please enable it.

[**Bug 205335**](show_bug.cgi?id=205335)
- [CVE-2006-4538](https://access.redhat.com/security/cve/CVE-2006-4538) Local DoS with corrupted ELF

[Summary:](page.cgi?id=fields.html#short_desc "The bug summary is a short sentence which succinctly describes what the bug is about.")
CVE-2006-4538 Local DoS with corrupted ELF

| | [Keywords](describekeywords.cgi): | Security | | --- | --- | | [Status](page.cgi?id=fields.html#bug_status): | CLOSED ERRATA | | [Alias:](page.cgi?id=fields.html#alias "A short, unique name assigned to a bug in order to assist with looking it up and referring to it in other places in Bugzilla.") | None | | [Product:](describecomponents.cgi "Bugs are categorised into Products and Components. Select a Classification to narrow down this list.") | Red Hat Enterprise Linux 4 | | [Classification:](page.cgi?id=fields.html#classification "Bugs are categorised into Classifications, Products and Components. classifications is the top-level categorisation.") | Red Hat | | [Component:](describecomponents.cgi?product=Red Hat Enterprise Linux 4 "Components are second-level categories; each belongs to a particular Product. Select a Product to narrow down this list.") | kernel | | [Sub Component:](page.cgi?id=fields.html#rh_sub_components "The sub component of a specific component") | --- | | [Version:](page.cgi?id=fields.html#version "The version field defines the version of the software the bug was found in.") | 4.0 | | [Hardware:](page.cgi?id=fields.html#rep_platform "The hardware platform the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | All | | [OS:](page.cgi?id=fields.html#op_sys "The operating system the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | Linux | | [Priority:](page.cgi?id=fields.html#priority) | medium | | [Severity:](page.cgi?id=fields.html#bug_severity) | medium | | [Target Milestone:](page.cgi?id=fields.html#target_milestone "The Target Milestone field is used to define when the engineer the bug is assigned to expects to fix it.") | --- | | [Target Release](page.cgi?id=fields.html#target_release): | --- | | [Assignee:](page.cgi?id=fields.html#assigned_to "The person in charge of resolving the bug.") | Dave Anderson | | [QA Contact:](page.cgi?id=fields.html#qa_contact "The person responsible for confirming this bug if it is unconfirmed, and for verifying the fix once the bug has been resolved.") | Brian Brock | | [Docs Contact:](page.cgi?id=fields.html#docs_contact "The person responsible for documenting once the bug has been resolved.") |  | | [URL:](page.cgi?id=fields.html#bug_file_loc "Bugs can have a URL associated with them - for example, a pointer to a web site where the problem is seen.") |  | | [Whiteboard:](page.cgi?id=fields.html#status_whiteboard "Each bug has a free-form single line text entry box for adding tags and status information.") | impact=moderate,reported=20060905,sou... | | [Depends On:](page.cgi?id=fields.html#dependson "The bugs listed here must be resolved before this bug can be resolved.") |  | | [Blocks:](page.cgi?id=fields.html#blocked "This bug must be resolved before the bugs listed in this field can be resolved.") | [CVE-2006-4538](show_bug.cgi?id=289151 "CLOSED ERRATA - CVE-2006-4538 kernel: Local DoS with corrupted ELF") | | TreeView+ | [depends on](buglist.cgi?bug_id=205335&bug_id_type=anddependson&format=tvp) / [blocked](buglist.cgi?bug_id=205335&bug_id_type=andblocked&format=tvp&tvp_dir=blocked) |  | |  | | [Reported:](page.cgi?id=fields.html#reporter) | 2006-09-06 05:49 UTC by Marcel Holtmann | | --- | --- | | [Modified:](page.cgi?id=fields.html#modified) | 2007-11-30 22:07 UTC ([History](show_activity.cgi?id=205335)) | | [CC List:](page.cgi?id=fields.html#cclist) | 2 users (show)  jbaron security-response-team | | Fixed In Version: | RHSA-2007-0014 | | | Doc Type: | Bug Fix | | | Doc Text: |  | | | Clone Of: |  | | | Environment: |  | | | Last Closed: | 2007-01-30 14:26:59 UTC | | | Target Upstream Version: |  | | | Embargoed: |  | | |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| --- | | |

| | Attachments | [(Terms of Use)](page.cgi?id=terms-conditions.html) | | | --- | --- | --- | | [**pre-compiled ia64 ELF file with corrupted PT\_LOAD segments.**](attachment.cgi?id=137132 "View the content of the attachment") (8.82 KB, application/octet-stream)  [2006-09-26 12:41 UTC](#attach_137132 "Go to the comment associated with the attachment"), Dave Anderson | *no flags* | [Details](attachment.cgi?id=137132&action=edit) | | [**generic binary file corrupter**](attachment.cgi?id=137133 "View the content of the attachment") (2.70 KB, text/plain)  [2006-09-26 12:46 UTC](#attach_137133 "Go to the comment associated with the attachment"), Dave Anderson | *no flags* | [Details](attachment.cgi?id=137133&action=edit) | | [View All](attachment.cgi?bugid=205335&action=viewall) | | |    Links | System | ID | Private | Priority | Status | Summary | Last Updated | | Red Hat Product Errata | [RHSA-2007:0014](https://access.redhat.com/errata/RHSA-2007%3A0014) | 0 | normal | SHIPPED\_LIVE | Important: kernel security update | 2007-01-30 14:25:00 UTC | |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |

| [Description](show_bug.cgi?id=205335#c0)  Marcel Holtmann    2006-09-06 05:49:40 UTC  ``` From Kirill Korotaev:  When running on IA64 or SPARC platforms, local users can cause a denial of service via a malformed ELF file and then triggered by cross-region mappings.  <http://lkml.org/lkml/2006/9/4/116>   ```  [Comment 2](show_bug.cgi?id=205335#c2)  Dave Anderson    2006-09-25 20:05:17 UTC  ```   Where's the reproducer?  I don't see any reference to it anywhere in the thread.   ```  [Comment 3](show_bug.cgi?id=205335#c3)  Marcel Holtmann    2006-09-25 20:15:21 UTC  ``` I don't have a reproducer for this one.   ```  [Comment 4](show_bug.cgi?id=205335#c4)  Dave Anderson    2006-09-25 20:19:49 UTC  ```  Jason,  What do you suggest in this case?  Cobble up a patch, compile it, and post it saying, "we don't have a reproducer"?    ```  [Comment 5](show_bug.cgi?id=205335#c5)  Dave Anderson    2006-09-26 12:39:14 UTC  ```  Cancel the needinfo -- I contacted Kirill Korotaev, and he forwarded me an ia64 reproducer (actually 2).  He response follows, and I will attach both the mangle.c program as well as his pre-compiled  :     Subject: Re: [PATCH] IA64,sparc: local DoS with corrupted ELFs     Date: Tue, 26 Sep 2006 10:24:21 +0400     From: Kirill Korotaev <dev>       To: Dave Anderson <anderson>  Dave,  > I just got assigned this CVE for a RHEL4 back-port. > By any chance do you have a pointer to a quick-and-dirty > reproducer for ia64?  Or instructions on how I could tinker > with an ia64 ELF header to reproduce the DOS?  ELF file is attached.  I'd recommend RedHat to incorporate the original test with a program which hacks ELF files randomly and run it on regular basis. This is what we do with OpenVZ.  The original test was from security from Dave Jones email:  ----- cut ----- 1. grab <http://www.digitaldwarf.be/products/mangle.c> 2. create a test.c which is..  #include <stdio.h> int main(void) {         printf ("Worked\n");         return 0; }  3. run this script.. #!/bin/bash while [ 1 ]; do         gcc test.c         ~/fuzz/mangle a.out $RANDOM         ./a.out done  4. wait, until this happens.. ----- cut -----  Thanks, Kirill                        Name: bad_ia64_elf    bad_ia64_elf      Type: unspecified type (application/octet-stream)                  Encoding: base64    ```  [Comment 6](show_bug.cgi?id=205335#c6)  Dave Anderson    2006-09-26 12:41:33 UTC  ``` Created [attachment 137132](attachment.cgi?id=137132 "pre-compiled ia64 ELF file with corrupted PT_LOAD segments.") [[details]](attachment.cgi?id=137132&action=edit "pre-compiled ia64 ELF file with corrupted PT_LOAD segments.") pre-compiled ia64 ELF file with corrupted PT_LOAD segments.   ```  [Comment 7](show_bug.cgi?id=205335#c7)  Dave Anderson    2006-09-26 12:46:56 UTC  ``` Created [attachment 137133](attachment.cgi?id=137133 "generic binary file corrupter") [[details]](attachment.cgi?id=137133&action=edit "generic binary file corrupter") generic binary file corrupter  Note that this program does not specifically attack the issue  addressed by this particular bug, but in a random attempt, may create a corrupt ELF header that does bump into it.   ```  [Comment 8](show_bug.cgi?id=205335#c8)  Dave Anderson    2006-09-29 14:57:41 UTC  ```  Proposed patch posted:  <http://post-office.corp.redhat.com/archives/rhkernel-list/2006-September/msg00929.html>   ```  [Comment 9](show_bug.cgi?id=205335#c9)  Jason Baron    2006-10-10 15:24:21 UTC  ``` committed in stream U5 build 42.17. A test kernel with this patch is available from <http://people.redhat.com/~jbaron/rhel4/>    ```  [Comment 10](show_bug.cgi?id=205335#c10)  Jason Baron    2006-12-18 21:37:33 UTC  ``` committed in stream E5 build 42.0.4   ```  [Comment 12](show_bug.cgi?id=205335#c12)  Mike Gahagan    2007-01-22 18:17:54 UTC  ``` verified with the attached reproducer, I also wasn't able to see any other problems with a few runs of fuzzing elf binaries.    ```  [Comment 14](show_bug.cgi?id=205335#c14)  Red Hat Bugzilla    2007-01-30 14:26:59 UTC  ```  An advisory has been issued which should help the problem described in this bug report. This report is therefore being closed with a resolution of ERRATA. For more information on the solution and/or where to find the updated files, please follow the link below. You may reopen this bug report if the solution does not work for you.  <http://rhn.redhat.com/errata/RHSA-2007-0014.html>    ``` |  |
| --- | --- |

---

| Note You need to [log in](show_bug.cgi?id=205335&GoAheadAndLogIn=1) before you can comment on or make changes to this bug. |
| --- |

---

[Privacy](page.cgi?id=redhat/privacy.html)
[Contact](page.cgi?id=redhat/contact.html)
[FAQ](page.cgi?id=faq.html)
[Legal](page.cgi?id=terms-conditions.html)



=== Content from secunia.com_eb554d6e_20250125_174320.html ===


[Skip to main content](#main-content)
[![Home](/themes/custom/flexera/images/logo.svg)](https://www.flexera.com/)

[![Home](/themes/custom/flexera/images/logo.svg)](https://www.flexera.com/)

Search

## Main navigation

* Solutions
  + Column 1
    - Business challenge
      * [Software renewals and audits](https://www.flexera.com/solutions/software-renewals-audits)
      * [Software license management and optimization](https://www.flexera.com/solutions/software-usage-costs)
      * [SaaS spend management](https://www.flexera.com/solutions/saas-spend)
      * [Cloud cost management](https://www.flexera.com/solutions/cloud-cost)
      * [IT asset lifecycle management](https://www.flexera.com/solutions/it-asset-lifecycle)
      * [CMDB data quality](https://www.flexera.com/solutions/cmdb-data-quality)
      * [Accurate IT inventory](https://www.flexera.com/solutions/it-inventory)
      * [Security and regulatory risk management](https://www.flexera.com/solutions/it-security-regulatory-risk)
      * [Sustainable IT](https://www.flexera.com/solutions/sustainable-it)
      * [AI-powered transformation](https://www.flexera.com/solutions/ai-powered-transformation)
      * [Public sector](https://www.flexera.com/solutions/public-sector)
  + Column 2
    - Spend management by vendor
      * [IBM](https://www.flexera.com/solutions/vendor/ibm)
      * [Oracle](https://www.flexera.com/solutions/vendor/oracle)
      * [Microsoft](https://www.flexera.com/solutions/vendor/microsoft)
      * [SAP](https://www.flexera.com/solutions/vendor/sap)
      * [VMware](https://www.flexera.com/solutions/vendor/vmware)
      * [ServiceNow](https://www.flexera.com/solutions/vendor/servicenow)
      * [AWS](https://www.flexera.com/solutions/vendor/aws)
      * [Salesforce](https://www.flexera.com/solutions/vendor/salesforce)
      * [BMC](https://www.flexera.com/solutions/cmdb-data-quality/bmc)
      * [Adobe](https://www.flexera.com/solutions/vendor/adobe)

  ### Achieve more through a united FinOps and ITAM function

  The future is hybrid. Break down the walls between ITAM and FinOps to drive more revenue, more customer growth and more innovation.

  [Discover More](https://www.flexera.com/resources/hybrid-itam-finops)
* Products
  + Column 1
    - [Flexera One](https://www.flexera.com/products/flexera-one)
      * [IT Visibility](https://www.flexera.com/products/flexera-one/it-visibility)
      * [ITAM](https://www.flexera.com/products/flexera-one/it-asset-management)
      * [SaaS Management](https://www.flexera.com/products/flexera-one/saas-management)
      * [FinOps](https://www.flexera.com/products/flexera-one/finops)
      * [Technology Intelligence Platform](https://www.flexera.com/products/flexera-one/technology-intelligence-platform)
  + Column 2
    - [Snow Atlas](https://www.flexera.com/products/snow-atlas)
      * [Snow Spend Optimizer](https://www.flexera.com/products/snow-atlas/snow-spend-optimizer)
      * [Snow SaaS Management](https://www.flexera.com/products/snow-atlas/snow-saas-management)
  + Column 3
    - Hide group
      * [Security](https://www.flexera.com/products/security)
      * [Application Readiness](https://www.flexera.com/products/adminstudio)
      * [All products](https://www.flexera.com/products)
      * [All Snow products](https://www.flexera.com/products/snow)
      * [Integrations](https://www.flexera.com/products/integrations)

  ### Flexera 2024 State of the Cloud Report

  What do transformative initiatives such as GenAI, machine learning and sustainability mean for the cloud? Check out the 2024 State of the Cloud Report to find the answer as well as all the latest cloud computing trends.

  [View Report](https://info.flexera.com/CM-REPORT-State-of-the-Cloud)
* Success
  + Column 1
    - [Customer success](https://www.flexera.com/customer-success)
      * Support
        + [Flexera support portal](https://community.flexera.com/s/support-hub)
        + [Flexera product documentation](https://docs.flexera.com)
        + [Snow product documentation](https://docs.snowsoftware.io/)
      * Services and training
        + [Services](https://www.flexera.com/customer-success/services)
        + [Training](https://www.flexera.com/customer-success/training)
  + Column 2
    - Hide group
      * [Technology Intelligence Awards](https://www.flexera.com/customer-success/awards)
      * [Flexera community](https://community.flexera.com/s/)

  ### Insights from Gartner®

  Find a curated series of actionable and objective insights for IT executives and their teams. Get expert insights from valued analysts, courtesy of Flexera.

  [Discover More](https://www.flexera.com/resources/gartner-analyst-research)
* Resources
  + Column 1
    - [Resources](https://www.flexera.com/resources)
      * [Webinars](https://www.flexera.com/resources?type%5Bwebinar%5D=webinar)
      * [Videos](https://www.flexera.com/resources?type%5Bvideo%5D=video)
      * [Datasheets](https://www.flexera.com/resources?type%5Bdatasheet%5D=datasheet)
      * [White papers & reports](https://www.flexera.com/resources?type%5Bwhite-paper-industry-report%5D=white-paper-industry-report)
  + Column 2
    - Hide group
      * [Blog](/blog/)
      * [Case studies](https://www.flexera.com/resources/case-studies)
      * [Events](https://www.flexera.com/resources?type%5Bevent%5D=event)
      * [Analyst Research](https://www.flexera.com/resources/gartner-analyst-research)
      * [Glossary](https://www.flexera.com/resources/glossary)
      * [Demos & trials](https://www.flexera.com/resources?type%5Bdemo-trials%5D=demo-trials)
      * [Business value calculator](https://www.flexera.com/resources/business-value-calculator)

  ### Flexera 2025 IT Priorities Report

  Insights from Flexera’s 2025 IT Priorities Report highlight what’s top of mind for IT decision makers in the year ahead. Discover the challenges, priorities and opportunities that will shape the future IT landscape.

  [View Report](https://info.flexera.com/ITV-REPORT-IT-Priorities)
* About
  + Column 1
    - [Company](https://www.flexera.com/about-us)
      * [About](https://www.flexera.com/about-us)
      * [Careers](https://www.flexera.com/about-us/careers)
      * [Contact](https://www.flexera.com/about-us/contact-us)
      * [Leadership](https://www.flexera.com/about-us/leadership)
    - [Partners](https://www.flexera.com/about-us/partners)
      * [Partner program](https://www.flexera.com/about-us/partners/partner-program)
      * [Partner directory](https://www.flexera.com/about-us/partners/directory)
  + Column 2
    - [Press center](https://www.flexera.com/about-us/press-center)
      * [Press releases](https://www.flexera.com/about-us/all-press-releases)
      * [Awards](https://www.flexera.com/about-us/press-center#awards)
      * [Articles](https://www.flexera.com/about-us/all-articles)
    - Hide group
      * Social responsibility
        + [ESG](https://www.flexera.com/about-us/environmental-social-governance)
        + [Diversity](https://www.flexera.com/about-us/diversity)

  ### More value with technology intelligence

  The unparalleled synergy of Flexera and Snow provides the Technology Intelligence you need for more efficiency, insight and governance than ever before.

  [Discover More](https://www.flexera.com/more-value-with-technology-intelligence)

Search

en

* [English](https://www.flexera.com/products/security/software-vulnerability-research/secunia-research?referrer=secunia)
* [Deutsch](https://www.flexera.de/products/security/software-vulnerability-research/secunia-research?referrer=secunia)

## External Links

* External Links
  + [Community](https://community.flexera.com/)
  + [Product Access](https://app.flexera.com/login)
  + [Partner Portal](https://flexera.channeltivity.com/Login)

[Book a demo](/about-us/contact-us?C_Interest1=sales)

# Secunia Research

## The world’s best vulnerability intelligence

The Secunia Research team from Flexera provides the most accurate and reliable source of vulnerability intelligence.

[Contact Us](https://www.flexera.com/about-us/contact-us?C_Interest1=sales&C_SolutionInterest=SVM)
Watch video (0:29)

Related links

* [Anatomy of a security advisory](https://www.flexera.com/resources/infographics/anatomy-of-a-security-advisory)
* [Software Vulnerability Research](https://www.flexera.com/products/software-vulnerability-research)
* [Software Vulnerability Manager](/products/software-vulnerability-manager)
* [Security advisories from Secunia Research](https://www.flexera.com/products/security/software-vulnerability-advisories)
* [Report a vulnerability](https://www.flexera.com/about-us/contact-us/report-vulnerability)

 ![Secunia Research](/sites/default/files/2022-04/hero-secunia-research-bg.jpg)

Featured Details

## Multiple ways to consume Secunia Research

Secunia delivers software security research that provides reliable, curated and actionable vulnerability intelligence. Organizations can expect to receive standardized, validated and enriched vulnerability research on a specific version of a software product. Secunia Research supports four solutions:

![Software Vulnerability Research](/sites/default/files/2022-04/icon-secunia-research-svr.svg)

### [Software Vulnerability Research](https://www.flexera.com/products/software-vulnerability-research)

Software Vulnerability Research utilizes Secunia Research to drive awareness of vulnerabilities matching your specified criteria

[Learn More](https://www.flexera.com/products/software-vulnerability-research)

![Software Vulnerability Manager](/sites/default/files/2022-04/icon-secunia-research-svm.svg)

### [Software Vulnerability Manager](/products/software-vulnerability-manager)

Software Vulnerability Manager uses Secunia Research data to identify, prioritize and patch known vulnerable software detected in your environment

[Learn More](/products/software-vulnerability-manager)

![Data Platform](/sites/default/files/2022-04/icon-secunia-research-dp.svg)

### [Data Platform](https://www.flexera.com/products/data-platform)

Data Platform leverages Secunia Research to provide high-level insights based on major or minor versions of software in your normalized inventory

[Learn More](https://www.flexera.com/products/data-platform)

![Flexera One](/sites/default/files/2022-04/icon-secunia-research-flexera-one.svg)

### [Flexera One](/flexera-one)

Flexera One utilizes Secunia Research (alongside public NVD data) to provide more granular matching of build-level versions of software in your normalized inventory within its IT Asset Management and IT Visibility solutions

[Learn More](/flexera-one)

How it works

## Accurate, reliable vulnerability insights at your fingertips

The Secunia Research team from Flexera is comprised of several security specialists who conduct vulnerability research in various products in addition to testing, verifying and validating public vulnerability reports. Since its inception in 2002, the goal of the Secunia Research team is to provide the most accurate and reliable source of vulnerability intelligence.

Delivering the world’s best vulnerability intelligence requires skill and passion. Team members continually develop their skills exploring various high-profile closed and open-source software using a variety of approaches, focusing chiefly on thorough code audits and binary analysis. The team has received industry recognition, including naming members to [Microsoft’s Most Valuable Security Researchers](https://msrc-blog.microsoft.com/2019/08/07/announcing-2019-msrc-most-valuable-security-researchers/) list.

Secunia researchers discover hard-to-find vulnerabilities that aren’t normally identified with techniques such as fuzzing, and the results have been impressive. Members of the Secunia Research team have discovered critical vulnerabilities in products from vendors including Microsoft, Symantec, IBM, Adobe, RealNetworks, Trend Micro, HP, Blue Coat, Samba, CA, Mozilla and Apple.

The team produces invaluable security advisories based on research of the vulnerabilities affecting any given software update. Sometimes a single update can address multiple vulnerabilities of varying criticalities and threats; but these advisories aggregate and distill findings down to a single advisory perfect for the prioritization of patching efforts within [Software Vulnerability Manager](/products/software-vulnerability-manager). Criticality scores are consistently applied along with details around attack vector and other valuable details within [Software Vulnerability Research](/products/software-vulnerability-research/secunia-research). Illegitimate vulnerability reports are also investigated and rejected so you can focus only on what truly matters.

Informing IT, Transforming IT

## Industry insights to help keep you informed

[#### Webinar

### Stay Ahead of Cyber Threats: Flexera's Latest Vulnerability Insights

Join us for this session where we'll explore the latest findings from the Flexera Monthly Vulnerability Insights Report.](https://info.flexera.com/SVM-WBNR-Vulnerability-Insights-Roundtable)

[#### Webinar

### Dive deeper into the Flexera Annual Vulnerability Insights

We'll explore the key findings from the Flexera Annual Vulnerability Insights Report. Learn about the latest cybersecurity trends, the most targeted industries, the types of vulnerabilities, plus management and mitigation strategies.](https://info.flexera.com/SVM-WBNR-Flexera-Annual-Vulnerability-Insights?lead_source=Website%20Visitor&id=Flexera.com-Resources)

#### Video

### Close the Risk Window with Software Vulnerability Manager

Stop reacting. Gain control. Stay secure. Build a more effective risk mitigation process leveraging Secunia Research vulnerability intelligence and the largest repository of third-party patch data in the industry.

Remote video URL

[#### Trial

### Software Vulnerability Manager Assessment free trial

Get access to the complete set of modules of Software Vulnerability Manager: Research, Assessment and Patching](https://info.flexera.com/SVM-EVAL-Software-Vulnerability-Manager)

[#### Datasheet

### Protect your ServiceNow® investment with the highest quality data

IT Visibility offers certified ServiceNow integrations that accelerate platform expansion, improve ROI and increase efficiencies across ITIL processes by delivering clean software and hardware asset data directly.](/sites/default/files/datasheet-itv-maximize-servicenow-investment.pdf)

[#### Blog

### Avoid missing crucial vulnerability intelligence amid NVD backlog

Recent developments regarding the National Vulnerability Database (NVD) have some technology leaders on edge. Since February, the U.S. National Institute of Standards and Technology (NIST) has almost completely stopped enriching software vulnerabi...](https://www.flexera.com/blog/vulnerability-management/avoid-missing-crucial-vulnerability-intelligence-amid-nvd-backlog/)

[View all resources](https://www.flexera.com/resources?category%5Bsoftware-vulnerability-management%5D=software-vulnerability-management)

## Footer Menu

* Column
  + Business challenge
    - [Software renewals and audits](https://www.flexera.com/solutions/software-renewals-audits)
    - [Software license management and optimization](https://www.flexera.com/solutions/software-usage-costs)
    - [SaaS spend management](https://www.flexera.com/solutions/saas-spend)
    - [Cloud cost management](https://www.flexera.com/solutions/cloud-cost)
    - [IT asset lifecycle management](https://www.flexera.com/solutions/it-asset-lifecycle)
    - [CMDB data quality](https://www.flexera.com/solutions/cmdb-data-quality)
    - [Accurate IT inventory](https://www.flexera.com/solutions/it-inventory)
    - [Security and regulatory risk management](https://www.flexera.com/solutions/it-security-regulatory-risk)
    - [Sustainable IT](https://www.flexera.com/solutions/sustainable-it)
    - [AI-powered transformation](https://www.flexera.com/solutions/ai-powered-transformation)
    - [Public sector](https://www.flexera.com/solutions/public-sector)
* Column
  + Spend management by vendor
    - [IBM](https://www.flexera.com/solutions/vendor/ibm)
    - [Oracle](https://www.flexera.com/solutions/vendor/oracle)
    - [Microsoft](https://www.flexera.com/solutions/vendor/microsoft)
    - [SAP](https://www.flexera.com/solutions/vendor/sap)
    - [VMware](https://www.flexera.com/solutions/vendor/vmware)
    - [ServiceNow](https://www.flexera.com/solutions/vendor/servicenow)
    - [AWS](https://www.flexera.com/solutions/vendor/aws)
    - [Salesforce](https://www.flexera.com/solutions/vendor/salesforce)
    - [BMC](https://www.flexera.com/solutions/cmdb-data-quality/bmc)
    - [Adobe](https://www.flexera.com/solutions/vendor/adobe)
* Column
  + Products
    - [Flexera One](https://www.flexera.com/products/flexera-one)
    - [Snow Atlas](https://www.flexera.com/products/snow-atlas)
    - [Security](https://www.flexera.com/products/security)
    - [Application Readiness](https://www.flexera.com/products/adminstudio)
    - [All products](https://www.flexera.com/products)
    - [All Snow products](https://www.flexera.com/products/snow)
    - [Integrations](https://www.flexera.com/products/integrations)
* Column
  + Company
    - [About](https://www.flexera.com/about-us)
    - [Careers](https://www.flexera.com/about-us/careers)
    - [Leadership](https://www.flexera.com/about-us/leadership)
    - [Contact us](https://www.flexera.com/about-us/contact-us)
    - [Media / press center](https://www.flexera.com/about-us/press-center)
    - [Revenera.com](https://www.revenera.com)

 +1.800.374.4353

en

* [English](https://www.flexera.com/products/security/software-vulnerability-research/secunia-research?referrer=secunia)
* [Deutsch](https://www.flexera.de/products/security/software-vulnerability-research/secunia-research?referrer=secunia)

 [![Home](/themes/custom/flexera/images/logo.svg)](https://www.flexera.com/)

© 2025 Flexera. All Rights Reserved.

## Footer

* [Privacy Policy](https://www.flexera.com/legal/privacy-policy)
* [Terms and conditions](https://www.flexera.com/legal)
* [Contact Us](https://www.flexera.com/about-us/contact-us)
* [Impressum](https://www.flexera.com/about-us/impressum)
* [Site Map](https://www.flexera.com/sitemap)

#####

×

...



=== Content from www.redhat.com_e1c2937d_20250126_104118.html ===


[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

**We're sorry but cve-details doesn't work properly without JavaScript enabled. Please enable it to continue.**

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2025 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from www.redhat.com_38ab34d1_20250126_104117.html ===


[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

**We're sorry but cve-details doesn't work properly without JavaScript enabled. Please enable it to continue.**

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2025 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from secunia.com_4e723429_20250125_174323.html ===


[Skip to main content](#main-content)
[![Home](/themes/custom/flexera/images/logo.svg)](https://www.flexera.com/)

[![Home](/themes/custom/flexera/images/logo.svg)](https://www.flexera.com/)

Search

## Main navigation

* Solutions
  + Column 1
    - Business challenge
      * [Software renewals and audits](https://www.flexera.com/solutions/software-renewals-audits)
      * [Software license management and optimization](https://www.flexera.com/solutions/software-usage-costs)
      * [SaaS spend management](https://www.flexera.com/solutions/saas-spend)
      * [Cloud cost management](https://www.flexera.com/solutions/cloud-cost)
      * [IT asset lifecycle management](https://www.flexera.com/solutions/it-asset-lifecycle)
      * [CMDB data quality](https://www.flexera.com/solutions/cmdb-data-quality)
      * [Accurate IT inventory](https://www.flexera.com/solutions/it-inventory)
      * [Security and regulatory risk management](https://www.flexera.com/solutions/it-security-regulatory-risk)
      * [Sustainable IT](https://www.flexera.com/solutions/sustainable-it)
      * [AI-powered transformation](https://www.flexera.com/solutions/ai-powered-transformation)
      * [Public sector](https://www.flexera.com/solutions/public-sector)
  + Column 2
    - Spend management by vendor
      * [IBM](https://www.flexera.com/solutions/vendor/ibm)
      * [Oracle](https://www.flexera.com/solutions/vendor/oracle)
      * [Microsoft](https://www.flexera.com/solutions/vendor/microsoft)
      * [SAP](https://www.flexera.com/solutions/vendor/sap)
      * [VMware](https://www.flexera.com/solutions/vendor/vmware)
      * [ServiceNow](https://www.flexera.com/solutions/vendor/servicenow)
      * [AWS](https://www.flexera.com/solutions/vendor/aws)
      * [Salesforce](https://www.flexera.com/solutions/vendor/salesforce)
      * [BMC](https://www.flexera.com/solutions/cmdb-data-quality/bmc)
      * [Adobe](https://www.flexera.com/solutions/vendor/adobe)

  ### Achieve more through a united FinOps and ITAM function

  The future is hybrid. Break down the walls between ITAM and FinOps to drive more revenue, more customer growth and more innovation.

  [Discover More](https://www.flexera.com/resources/hybrid-itam-finops)
* Products
  + Column 1
    - [Flexera One](https://www.flexera.com/products/flexera-one)
      * [IT Visibility](https://www.flexera.com/products/flexera-one/it-visibility)
      * [ITAM](https://www.flexera.com/products/flexera-one/it-asset-management)
      * [SaaS Management](https://www.flexera.com/products/flexera-one/saas-management)
      * [FinOps](https://www.flexera.com/products/flexera-one/finops)
      * [Technology Intelligence Platform](https://www.flexera.com/products/flexera-one/technology-intelligence-platform)
  + Column 2
    - [Snow Atlas](https://www.flexera.com/products/snow-atlas)
      * [Snow Spend Optimizer](https://www.flexera.com/products/snow-atlas/snow-spend-optimizer)
      * [Snow SaaS Management](https://www.flexera.com/products/snow-atlas/snow-saas-management)
  + Column 3
    - Hide group
      * [Security](https://www.flexera.com/products/security)
      * [Application Readiness](https://www.flexera.com/products/adminstudio)
      * [All products](https://www.flexera.com/products)
      * [All Snow products](https://www.flexera.com/products/snow)
      * [Integrations](https://www.flexera.com/products/integrations)

  ### Flexera 2024 State of the Cloud Report

  What do transformative initiatives such as GenAI, machine learning and sustainability mean for the cloud? Check out the 2024 State of the Cloud Report to find the answer as well as all the latest cloud computing trends.

  [View Report](https://info.flexera.com/CM-REPORT-State-of-the-Cloud)
* Success
  + Column 1
    - [Customer success](https://www.flexera.com/customer-success)
      * Support
        + [Flexera support portal](https://community.flexera.com/s/support-hub)
        + [Flexera product documentation](https://docs.flexera.com)
        + [Snow product documentation](https://docs.snowsoftware.io/)
      * Services and training
        + [Services](https://www.flexera.com/customer-success/services)
        + [Training](https://www.flexera.com/customer-success/training)
  + Column 2
    - Hide group
      * [Technology Intelligence Awards](https://www.flexera.com/customer-success/awards)
      * [Flexera community](https://community.flexera.com/s/)

  ### Insights from Gartner®

  Find a curated series of actionable and objective insights for IT executives and their teams. Get expert insights from valued analysts, courtesy of Flexera.

  [Discover More](https://www.flexera.com/resources/gartner-analyst-research)
* Resources
  + Column 1
    - [Resources](https://www.flexera.com/resources)
      * [Webinars](https://www.flexera.com/resources?type%5Bwebinar%5D=webinar)
      * [Videos](https://www.flexera.com/resources?type%5Bvideo%5D=video)
      * [Datasheets](https://www.flexera.com/resources?type%5Bdatasheet%5D=datasheet)
      * [White papers & reports](https://www.flexera.com/resources?type%5Bwhite-paper-industry-report%5D=white-paper-industry-report)
  + Column 2
    - Hide group
      * [Blog](/blog/)
      * [Case studies](https://www.flexera.com/resources/case-studies)
      * [Events](https://www.flexera.com/resources?type%5Bevent%5D=event)
      * [Analyst Research](https://www.flexera.com/resources/gartner-analyst-research)
      * [Glossary](https://www.flexera.com/resources/glossary)
      * [Demos & trials](https://www.flexera.com/resources?type%5Bdemo-trials%5D=demo-trials)
      * [Business value calculator](https://www.flexera.com/resources/business-value-calculator)

  ### Flexera 2025 IT Priorities Report

  Insights from Flexera’s 2025 IT Priorities Report highlight what’s top of mind for IT decision makers in the year ahead. Discover the challenges, priorities and opportunities that will shape the future IT landscape.

  [View Report](https://info.flexera.com/ITV-REPORT-IT-Priorities)
* About
  + Column 1
    - [Company](https://www.flexera.com/about-us)
      * [About](https://www.flexera.com/about-us)
      * [Careers](https://www.flexera.com/about-us/careers)
      * [Contact](https://www.flexera.com/about-us/contact-us)
      * [Leadership](https://www.flexera.com/about-us/leadership)
    - [Partners](https://www.flexera.com/about-us/partners)
      * [Partner program](https://www.flexera.com/about-us/partners/partner-program)
      * [Partner directory](https://www.flexera.com/about-us/partners/directory)
  + Column 2
    - [Press center](https://www.flexera.com/about-us/press-center)
      * [Press releases](https://www.flexera.com/about-us/all-press-releases)
      * [Awards](https://www.flexera.com/about-us/press-center#awards)
      * [Articles](https://www.flexera.com/about-us/all-articles)
    - Hide group
      * Social responsibility
        + [ESG](https://www.flexera.com/about-us/environmental-social-governance)
        + [Diversity](https://www.flexera.com/about-us/diversity)

  ### More value with technology intelligence

  The unparalleled synergy of Flexera and Snow provides the Technology Intelligence you need for more efficiency, insight and governance than ever before.

  [Discover More](https://www.flexera.com/more-value-with-technology-intelligence)

Search

en

* [English](https://www.flexera.com/products/security/software-vulnerability-research/secunia-research?referrer=secunia)
* [Deutsch](https://www.flexera.de/products/security/software-vulnerability-research/secunia-research?referrer=secunia)

## External Links

* External Links
  + [Community](https://community.flexera.com/)
  + [Product Access](https://app.flexera.com/login)
  + [Partner Portal](https://flexera.channeltivity.com/Login)

[Book a demo](/about-us/contact-us?C_Interest1=sales)

# Secunia Research

## The world’s best vulnerability intelligence

The Secunia Research team from Flexera provides the most accurate and reliable source of vulnerability intelligence.

[Contact Us](https://www.flexera.com/about-us/contact-us?C_Interest1=sales&C_SolutionInterest=SVM)
Watch video (0:29)

Related links

* [Anatomy of a security advisory](https://www.flexera.com/resources/infographics/anatomy-of-a-security-advisory)
* [Software Vulnerability Research](https://www.flexera.com/products/software-vulnerability-research)
* [Software Vulnerability Manager](/products/software-vulnerability-manager)
* [Security advisories from Secunia Research](https://www.flexera.com/products/security/software-vulnerability-advisories)
* [Report a vulnerability](https://www.flexera.com/about-us/contact-us/report-vulnerability)

 ![Secunia Research](/sites/default/files/2022-04/hero-secunia-research-bg.jpg)

Featured Details

## Multiple ways to consume Secunia Research

Secunia delivers software security research that provides reliable, curated and actionable vulnerability intelligence. Organizations can expect to receive standardized, validated and enriched vulnerability research on a specific version of a software product. Secunia Research supports four solutions:

![Software Vulnerability Research](/sites/default/files/2022-04/icon-secunia-research-svr.svg)

### [Software Vulnerability Research](https://www.flexera.com/products/software-vulnerability-research)

Software Vulnerability Research utilizes Secunia Research to drive awareness of vulnerabilities matching your specified criteria

[Learn More](https://www.flexera.com/products/software-vulnerability-research)

![Software Vulnerability Manager](/sites/default/files/2022-04/icon-secunia-research-svm.svg)

### [Software Vulnerability Manager](/products/software-vulnerability-manager)

Software Vulnerability Manager uses Secunia Research data to identify, prioritize and patch known vulnerable software detected in your environment

[Learn More](/products/software-vulnerability-manager)

![Data Platform](/sites/default/files/2022-04/icon-secunia-research-dp.svg)

### [Data Platform](https://www.flexera.com/products/data-platform)

Data Platform leverages Secunia Research to provide high-level insights based on major or minor versions of software in your normalized inventory

[Learn More](https://www.flexera.com/products/data-platform)

![Flexera One](/sites/default/files/2022-04/icon-secunia-research-flexera-one.svg)

### [Flexera One](/flexera-one)

Flexera One utilizes Secunia Research (alongside public NVD data) to provide more granular matching of build-level versions of software in your normalized inventory within its IT Asset Management and IT Visibility solutions

[Learn More](/flexera-one)

How it works

## Accurate, reliable vulnerability insights at your fingertips

The Secunia Research team from Flexera is comprised of several security specialists who conduct vulnerability research in various products in addition to testing, verifying and validating public vulnerability reports. Since its inception in 2002, the goal of the Secunia Research team is to provide the most accurate and reliable source of vulnerability intelligence.

Delivering the world’s best vulnerability intelligence requires skill and passion. Team members continually develop their skills exploring various high-profile closed and open-source software using a variety of approaches, focusing chiefly on thorough code audits and binary analysis. The team has received industry recognition, including naming members to [Microsoft’s Most Valuable Security Researchers](https://msrc-blog.microsoft.com/2019/08/07/announcing-2019-msrc-most-valuable-security-researchers/) list.

Secunia researchers discover hard-to-find vulnerabilities that aren’t normally identified with techniques such as fuzzing, and the results have been impressive. Members of the Secunia Research team have discovered critical vulnerabilities in products from vendors including Microsoft, Symantec, IBM, Adobe, RealNetworks, Trend Micro, HP, Blue Coat, Samba, CA, Mozilla and Apple.

The team produces invaluable security advisories based on research of the vulnerabilities affecting any given software update. Sometimes a single update can address multiple vulnerabilities of varying criticalities and threats; but these advisories aggregate and distill findings down to a single advisory perfect for the prioritization of patching efforts within [Software Vulnerability Manager](/products/software-vulnerability-manager). Criticality scores are consistently applied along with details around attack vector and other valuable details within [Software Vulnerability Research](/products/software-vulnerability-research/secunia-research). Illegitimate vulnerability reports are also investigated and rejected so you can focus only on what truly matters.

Informing IT, Transforming IT

## Industry insights to help keep you informed

[#### Webinar

### Stay Ahead of Cyber Threats: Flexera's Latest Vulnerability Insights

Join us for this session where we'll explore the latest findings from the Flexera Monthly Vulnerability Insights Report.](https://info.flexera.com/SVM-WBNR-Vulnerability-Insights-Roundtable)

[#### Webinar

### Dive deeper into the Flexera Annual Vulnerability Insights

We'll explore the key findings from the Flexera Annual Vulnerability Insights Report. Learn about the latest cybersecurity trends, the most targeted industries, the types of vulnerabilities, plus management and mitigation strategies.](https://info.flexera.com/SVM-WBNR-Flexera-Annual-Vulnerability-Insights?lead_source=Website%20Visitor&id=Flexera.com-Resources)

#### Video

### Close the Risk Window with Software Vulnerability Manager

Stop reacting. Gain control. Stay secure. Build a more effective risk mitigation process leveraging Secunia Research vulnerability intelligence and the largest repository of third-party patch data in the industry.

Remote video URL

[#### Trial

### Software Vulnerability Manager Assessment free trial

Get access to the complete set of modules of Software Vulnerability Manager: Research, Assessment and Patching](https://info.flexera.com/SVM-EVAL-Software-Vulnerability-Manager)

[#### Datasheet

### Protect your ServiceNow® investment with the highest quality data

IT Visibility offers certified ServiceNow integrations that accelerate platform expansion, improve ROI and increase efficiencies across ITIL processes by delivering clean software and hardware asset data directly.](/sites/default/files/datasheet-itv-maximize-servicenow-investment.pdf)

[#### Blog

### Avoid missing crucial vulnerability intelligence amid NVD backlog

Recent developments regarding the National Vulnerability Database (NVD) have some technology leaders on edge. Since February, the U.S. National Institute of Standards and Technology (NIST) has almost completely stopped enriching software vulnerabi...](https://www.flexera.com/blog/vulnerability-management/avoid-missing-crucial-vulnerability-intelligence-amid-nvd-backlog/)

[View all resources](https://www.flexera.com/resources?category%5Bsoftware-vulnerability-management%5D=software-vulnerability-management)

## Footer Menu

* Column
  + Business challenge
    - [Software renewals and audits](https://www.flexera.com/solutions/software-renewals-audits)
    - [Software license management and optimization](https://www.flexera.com/solutions/software-usage-costs)
    - [SaaS spend management](https://www.flexera.com/solutions/saas-spend)
    - [Cloud cost management](https://www.flexera.com/solutions/cloud-cost)
    - [IT asset lifecycle management](https://www.flexera.com/solutions/it-asset-lifecycle)
    - [CMDB data quality](https://www.flexera.com/solutions/cmdb-data-quality)
    - [Accurate IT inventory](https://www.flexera.com/solutions/it-inventory)
    - [Security and regulatory risk management](https://www.flexera.com/solutions/it-security-regulatory-risk)
    - [Sustainable IT](https://www.flexera.com/solutions/sustainable-it)
    - [AI-powered transformation](https://www.flexera.com/solutions/ai-powered-transformation)
    - [Public sector](https://www.flexera.com/solutions/public-sector)
* Column
  + Spend management by vendor
    - [IBM](https://www.flexera.com/solutions/vendor/ibm)
    - [Oracle](https://www.flexera.com/solutions/vendor/oracle)
    - [Microsoft](https://www.flexera.com/solutions/vendor/microsoft)
    - [SAP](https://www.flexera.com/solutions/vendor/sap)
    - [VMware](https://www.flexera.com/solutions/vendor/vmware)
    - [ServiceNow](https://www.flexera.com/solutions/vendor/servicenow)
    - [AWS](https://www.flexera.com/solutions/vendor/aws)
    - [Salesforce](https://www.flexera.com/solutions/vendor/salesforce)
    - [BMC](https://www.flexera.com/solutions/cmdb-data-quality/bmc)
    - [Adobe](https://www.flexera.com/solutions/vendor/adobe)
* Column
  + Products
    - [Flexera One](https://www.flexera.com/products/flexera-one)
    - [Snow Atlas](https://www.flexera.com/products/snow-atlas)
    - [Security](https://www.flexera.com/products/security)
    - [Application Readiness](https://www.flexera.com/products/adminstudio)
    - [All products](https://www.flexera.com/products)
    - [All Snow products](https://www.flexera.com/products/snow)
    - [Integrations](https://www.flexera.com/products/integrations)
* Column
  + Company
    - [About](https://www.flexera.com/about-us)
    - [Careers](https://www.flexera.com/about-us/careers)
    - [Leadership](https://www.flexera.com/about-us/leadership)
    - [Contact us](https://www.flexera.com/about-us/contact-us)
    - [Media / press center](https://www.flexera.com/about-us/press-center)
    - [Revenera.com](https://www.revenera.com)

 +1.800.374.4353

en

* [English](https://www.flexera.com/products/security/software-vulnerability-research/secunia-research?referrer=secunia)
* [Deutsch](https://www.flexera.de/products/security/software-vulnerability-research/secunia-research?referrer=secunia)

 [![Home](/themes/custom/flexera/images/logo.svg)](https://www.flexera.com/)

© 2025 Flexera. All Rights Reserved.

## Footer

* [Privacy Policy](https://www.flexera.com/legal/privacy-policy)
* [Terms and conditions](https://www.flexera.com/legal)
* [Contact Us](https://www.flexera.com/about-us/contact-us)
* [Impressum](https://www.flexera.com/about-us/impressum)
* [Site Map](https://www.flexera.com/sitemap)

#####

×

...



=== Content from bugzilla.redhat.com_25982f4d_20250126_104124.html ===


* Login
  + Log in using an SSO provider:- [Fedora Account System](saml2_login.cgi?idp=Fedora%20Account%20System&target=show_bug.cgi%3Fid%3D206328)
    - [Red Hat Associate](saml2_login.cgi?idp=Red%20Hat%20Associate&target=show_bug.cgi%3Fid%3D206328)
    - [Red Hat Customer](saml2_login.cgi?idp=Red%20Hat%20Customer&target=show_bug.cgi%3Fid%3D206328)+ Login using a Red Hat Bugzilla account
  + Forgot Password
  + [Create an Account](createaccount.cgi)

Red Hat Bugzilla – Bug 206328

* [Home](./)
* [New](enter_bug.cgi)
* Search
  + [Simple Search](query.cgi?format=specific)
  + [Advanced Search](query.cgi?format=advanced)
* My Links
  + [Browse](describecomponents.cgi)
  + [Requests](request.cgi)
  + Reports
  + Current State
    - [Search](query.cgi)
    - [Tabular reports](query.cgi?format=report-table)
    - [Graphical reports](query.cgi?format=report-graph)
    - [Duplicates](duplicates.cgi)
  + Other Reports
    - [User Changes](https://bugzilla.redhat.com/page.cgi?id=user_activity.html)
  + Plotly Reports
    - [Bug Status](https://bugzilla.redhat.com/page.cgi?id=bug_status.html)
    - [Bug Severity](https://bugzilla.redhat.com/page.cgi?id=bug_severity.html)
    - [Non-Defaults](https://bugzilla.redhat.com/page.cgi?id=non_defaults.html)
* [Product Dashboard](page.cgi?id=productdashboard.html)

- Help
  * [Page Help!](docs/en/html/using/understanding.html)
  * [Bug Writing Guidelines](page.cgi?id=bug-writing.html)
  * [What's new](page.cgi?id=whats-new.html)
  * [Browser Support Policy](https://access.redhat.com/help/browsers)
  * [5.0.4.rh103 Release notes](page.cgi?id=release-notes.html)
  * [FAQ](page.cgi?id=faq.html)
  * [Guides index](docs/en/html/index.html)
  * [User guide](docs/en/html/using/index.html)
  * [Web Services](docs/en/html/integrating/api/Bugzilla/WebService/Bug.html)
  * [Contact](page.cgi?id=redhat/contact.html)
  * [Legal](page.cgi?id=terms-conditions.html)
- [[?]](page.cgi?id=quicksearch.html "Quicksearch Help")

This site requires JavaScript to be enabled to function correctly, please enable it.

[**Bug 206328**](show_bug.cgi?id=206328)
- [CVE-2006-5757](https://access.redhat.com/security/cve/CVE-2006-5757) Linux kernel Filesystem Mount Dead Loop

[Summary:](page.cgi?id=fields.html#short_desc "The bug summary is a short sentence which succinctly describes what the bug is about.")
CVE-2006-5757 Linux kernel Filesystem Mount Dead Loop

| | [Keywords](describekeywords.cgi): | Security | | --- | --- | | [Status](page.cgi?id=fields.html#bug_status): | CLOSED ERRATA | | [Alias:](page.cgi?id=fields.html#alias "A short, unique name assigned to a bug in order to assist with looking it up and referring to it in other places in Bugzilla.") | None | | [Product:](describecomponents.cgi "Bugs are categorised into Products and Components. Select a Classification to narrow down this list.") | Red Hat Enterprise Linux 4 | | [Classification:](page.cgi?id=fields.html#classification "Bugs are categorised into Classifications, Products and Components. classifications is the top-level categorisation.") | Red Hat | | [Component:](describecomponents.cgi?product=Red Hat Enterprise Linux 4 "Components are second-level categories; each belongs to a particular Product. Select a Product to narrow down this list.") | kernel | | [Sub Component:](page.cgi?id=fields.html#rh_sub_components "The sub component of a specific component") | --- | | [Version:](page.cgi?id=fields.html#version "The version field defines the version of the software the bug was found in.") | 4.0 | | [Hardware:](page.cgi?id=fields.html#rep_platform "The hardware platform the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | All | | [OS:](page.cgi?id=fields.html#op_sys "The operating system the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | Linux | | [Priority:](page.cgi?id=fields.html#priority) | medium | | [Severity:](page.cgi?id=fields.html#bug_severity) | low | | [Target Milestone:](page.cgi?id=fields.html#target_milestone "The Target Milestone field is used to define when the engineer the bug is assigned to expects to fix it.") | --- | | [Target Release](page.cgi?id=fields.html#target_release): | --- | | [Assignee:](page.cgi?id=fields.html#assigned_to "The person in charge of resolving the bug.") | Eric Sandeen | | [QA Contact:](page.cgi?id=fields.html#qa_contact "The person responsible for confirming this bug if it is unconfirmed, and for verifying the fix once the bug has been resolved.") | Brian Brock | | [Docs Contact:](page.cgi?id=fields.html#docs_contact "The person responsible for documenting once the bug has been resolved.") |  | | [URL:](page.cgi?id=fields.html#bug_file_loc "Bugs can have a URL associated with them - for example, a pointer to a web site where the problem is seen.") |  | | [Whiteboard:](page.cgi?id=fields.html#status_whiteboard "Each bug has a free-form single line text entry box for adding tags and status information.") | impact=low,source=lkml,reported=20060... | | [Depends On:](page.cgi?id=fields.html#dependson "The bugs listed here must be resolved before this bug can be resolved.") |  | | [Blocks:](page.cgi?id=fields.html#blocked "This bug must be resolved before the bugs listed in this field can be resolved.") |  | | TreeView+ | [depends on](buglist.cgi?bug_id=206328&bug_id_type=anddependson&format=tvp) / [blocked](buglist.cgi?bug_id=206328&bug_id_type=andblocked&format=tvp&tvp_dir=blocked) |  | |  | | [Reported:](page.cgi?id=fields.html#reporter) | 2006-09-13 18:05 UTC by Marcel Holtmann | | --- | --- | | [Modified:](page.cgi?id=fields.html#modified) | 2007-11-30 22:07 UTC ([History](show_activity.cgi?id=206328)) | | [CC List:](page.cgi?id=fields.html#cclist) | 3 users (show)  esandeen jbaron security-response-team | | Fixed In Version: | RHSA-2007-0014 | | | Doc Type: | Bug Fix | | | Doc Text: |  | | | Clone Of: |  | | | Environment: |  | | | Last Closed: | 2007-01-30 14:27:34 UTC | | | Target Upstream Version: |  | | | Embargoed: |  | | |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| --- | | |

| | Attachments | [(Terms of Use)](page.cgi?id=terms-conditions.html) | | | --- | --- | --- | |  | | |    Links | System | ID | Private | Priority | Status | Summary | Last Updated | | Red Hat Product Errata | [RHSA-2007:0014](https://access.redhat.com/errata/RHSA-2007%3A0014) | 0 | normal | SHIPPED\_LIVE | Important: kernel security update | 2007-01-30 14:25:00 UTC | |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |

| [Description](show_bug.cgi?id=206328#c0)  Marcel Holtmann    2006-09-13 18:05:53 UTC  ``` Reported by ADLab, Venustech info Ltd CHINA:  There is a vulnerability in function __getblk(). When mount a file system image with malformed block value, Linux kernel will fall in a dead loop. It will lead to a kernel hang and denying further service.  Function __getblk() is used to seek a corresponding buffer_head of a block in a specific block device. When processing a block with a block number more than 4G and not to be mapped to buffer pages (__find_get_block will return NULL), __getblk_slow will always run and never return.  1478 struct buffer_head * 1479 __getblk(struct block_device *bdev, sector_t block, int size) 1480 { 1481         struct buffer_head *bh = __find_get_block(bdev, block, size); 1482 1483         might_sleep(); 1484         if (bh == NULL) 1485                 bh = __getblk_slow(bdev, block, size); 1486         return bh; 1487 }  The endless for loop only has a exit point (at line 1213). It terminate only when __find_get_block return a non-NULL value. If the block is not mapped to buffer pages, the first __find_get_block calling will return a NULL bh and the function grow_buffers() will be called subsequently.  1194 __getblk_slow(struct block_device *bdev, sector_t block, int size) 1195 { 1196         /* Size must be multiple of hard sectorsize */ 1197         if (unlikely(size & (bdev_hardsect_size(bdev)-1) || 1198                         (size < 512 || size > PAGE_SIZE))) { 1199                 printk(KERN_ERR "getblk(): invalid block size %d requested\n", 1200                                         size); 1201                 printk(KERN_ERR "hardsect size: %d\n", 1202                                         bdev_hardsect_size(bdev)); 1203 1204                 dump_stack(); 1205                 return NULL; 1206         } 1207 1208         for (;;) { 1209                 struct buffer_head * bh; 1210 1211                 bh = __find_get_block(bdev, block, size);	 1212                 if (bh) 1213                         return bh; 1214 1215                 if (!grow_buffers(bdev, block, size))		 1216                         free_more_memory(); 1217         } 1218 }  The function grow_buffers() is responsible for construct the relationships among page, buffer_head and block. On the 32-bit platform, the length of block and index are 64-bit and 32-bit respectively. After the operations at line 1201 and 1202, the high 32 bits of block will lost. Consequently, when the block number is beyond 4G, new block number would be differently with the original.  1189 static inline int 1190 grow_buffers(struct block_device *bdev, sector_t block, int size) 1191 { 1192         struct page *page; 1193         pgoff_t index; 1194         int sizebits; 1195 1196         sizebits = -1; 1197         do { 1198                 sizebits++; 1199         } while ((size << sizebits) < PAGE_SIZE); 1200 1201         index = block >> sizebits; 1202         block = index << sizebits; 1203 1204         /* Create a page with the proper size buffers.. */ 1205         page = grow_dev_page(bdev, block, index, size); 1206         if (!page) 1207                 return 0; 1208         unlock_page(page); 1209         page_cache_release(page); 1210         return 1; 1211 }  Follow the call sequence (grow_dev_page ==> init_page_buffers ==> init_page_buffers). In init_page_buffers(), a new buffer_head will be initialized, it's block number (bh->b_blocknr) corresponding to mapped block is assigned with the new block number.  static void init_page_buffers(struct page *page, struct block_device *bdev,                         sector_t block, int size) { 	... 	...          do {                 if (!buffer_mapped(bh)) {		                         init_buffer(bh, NULL, NULL);                         bh->b_bdev = bdev;                         bh->b_blocknr = block;                         if (uptodate)                                 set_buffer_uptodate(bh);                         set_buffer_mapped(bh);                 }                 block++;                 bh = bh->b_this_page;         } while (bh != head); }   However, __find_get_block seeks buffer head base on the original block number in __getblk_slow (). Because of wrong block number argument, __find_get_block will always return NULL. As results, system will fall in a dead loop and consume resource endlessly.   1194 __getblk_slow(struct block_device *bdev, sector_t block, int size) 1195 { 	... 	... 1207 1208         for (;;) { 1209                 struct buffer_head * bh; 1210 1211                 bh = __find_get_block(bdev, block, size);	 1212                 if (bh) 1213                         return bh; 1214 1215                 if (!grow_buffers(bdev, block, size))		 1216                         free_more_memory(); 1217         } 1218 }  The vulnerability can be triggered by mount a malformed Reiser filesystem image, the arguments of __getblk() are:  __getblk(0xcd0ed0c0, 0xffffffffa10020d9, 0x1000)  sys_mount -> do_mount -> do_kern_mount -> get_super_block -> get_sb_bdev  -> reiserfs_fill_super -> reiserfs_read_locked_inode -> search_by_key -> __getblk -> __find_get_block   ```  [Comment 8](show_bug.cgi?id=206328#c8)  Eric Sandeen    2006-11-06 22:43:57 UTC  ``` Whoops.  Actually this upstream patch already resolves the issue: <http://git.kernel.org/git/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commitdiff;h=e5657933863f43cc6bb76a54d659303dafaa9e58;hp=e0ab2928cc2202f13f0574d4c6f567f166d307eb>  Text of the patch is attached to [bug 214288](show_bug.cgi?id=214288 "CLOSED ERRATA - CVE-2006-5757 ISO9660 __find_get_block_slow() denial of service").   ```  [Comment 9](show_bug.cgi?id=206328#c9)  Eric Sandeen    2006-11-07 04:33:52 UTC  ``` patch sent to rhkernel-list on 11/6/06   ```  [Comment 10](show_bug.cgi?id=206328#c10)  Marcel Holtmann    2006-11-22 20:49:34 UTC  ``` This is the same as [bug 214288](show_bug.cgi?id=214288 "CLOSED ERRATA - CVE-2006-5757 ISO9660 __find_get_block_slow() denial of service") and so it has also the same CVE name.   ```  [Comment 11](show_bug.cgi?id=206328#c11)  Jason Baron    2006-12-11 22:33:51 UTC  ``` committed in stream U5 build 42.24. A test kernel with this patch is available from <http://people.redhat.com/~jbaron/rhel4/>   ```  [Comment 12](show_bug.cgi?id=206328#c12)  Jason Baron    2006-12-18 21:43:20 UTC  ``` committed in stream E5 build 42.0.4   ```  [Comment 14](show_bug.cgi?id=206328#c14)  Mike Gahagan    2007-01-16 22:37:53 UTC  ``` I was not able to reproduce the problem with <http://projects.info-pull.com/mokb/bug-files/MOKB-05-11-2006.iso.bz2> using the -42 kernel  however I can confirm that the changes needed to fix this are in the 42.0.6 kernel.     ```  [Comment 16](show_bug.cgi?id=206328#c16)  Red Hat Bugzilla    2007-01-30 14:27:34 UTC  ```  An advisory has been issued which should help the problem described in this bug report. This report is therefore being closed with a resolution of ERRATA. For more information on the solution and/or where to find the updated files, please follow the link below. You may reopen this bug report if the solution does not work for you.  <http://rhn.redhat.com/errata/RHSA-2007-0014.html>    ``` |  |
| --- | --- |

---

| Note You need to [log in](show_bug.cgi?id=206328&GoAheadAndLogIn=1) before you can comment on or make changes to this bug. |
| --- |

---

[Privacy](page.cgi?id=redhat/privacy.html)
[Contact](page.cgi?id=redhat/contact.html)
[FAQ](page.cgi?id=faq.html)
[Legal](page.cgi?id=terms-conditions.html)



=== Content from www.redhat.com_520400f8_20250126_104122.html ===


[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

**We're sorry but cve-details doesn't work properly without JavaScript enabled. Please enable it to continue.**

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2025 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from bugzilla.redhat.com_1277fed9_20250126_104116.html ===


* Login
  + Log in using an SSO provider:- [Fedora Account System](saml2_login.cgi?idp=Fedora%20Account%20System&target=show_bug.cgi%3Fid%3D213921)
    - [Red Hat Associate](saml2_login.cgi?idp=Red%20Hat%20Associate&target=show_bug.cgi%3Fid%3D213921)
    - [Red Hat Customer](saml2_login.cgi?idp=Red%20Hat%20Customer&target=show_bug.cgi%3Fid%3D213921)+ Login using a Red Hat Bugzilla account
  + Forgot Password
  + [Create an Account](createaccount.cgi)

Red Hat Bugzilla – Bug 213921

* [Home](./)
* [New](enter_bug.cgi)
* Search
  + [Simple Search](query.cgi?format=specific)
  + [Advanced Search](query.cgi?format=advanced)
* My Links
  + [Browse](describecomponents.cgi)
  + [Requests](request.cgi)
  + Reports
  + Current State
    - [Search](query.cgi)
    - [Tabular reports](query.cgi?format=report-table)
    - [Graphical reports](query.cgi?format=report-graph)
    - [Duplicates](duplicates.cgi)
  + Other Reports
    - [User Changes](https://bugzilla.redhat.com/page.cgi?id=user_activity.html)
  + Plotly Reports
    - [Bug Status](https://bugzilla.redhat.com/page.cgi?id=bug_status.html)
    - [Bug Severity](https://bugzilla.redhat.com/page.cgi?id=bug_severity.html)
    - [Non-Defaults](https://bugzilla.redhat.com/page.cgi?id=non_defaults.html)
* [Product Dashboard](page.cgi?id=productdashboard.html)

- Help
  * [Page Help!](docs/en/html/using/understanding.html)
  * [Bug Writing Guidelines](page.cgi?id=bug-writing.html)
  * [What's new](page.cgi?id=whats-new.html)
  * [Browser Support Policy](https://access.redhat.com/help/browsers)
  * [5.0.4.rh103 Release notes](page.cgi?id=release-notes.html)
  * [FAQ](page.cgi?id=faq.html)
  * [Guides index](docs/en/html/index.html)
  * [User guide](docs/en/html/using/index.html)
  * [Web Services](docs/en/html/integrating/api/Bugzilla/WebService/Bug.html)
  * [Contact](page.cgi?id=redhat/contact.html)
  * [Legal](page.cgi?id=terms-conditions.html)
- [[?]](page.cgi?id=quicksearch.html "Quicksearch Help")

This site requires JavaScript to be enabled to function correctly, please enable it.

[**Bug 213921**](show_bug.cgi?id=213921)
- SAN file systems becoming read-only

[Summary:](page.cgi?id=fields.html#short_desc "The bug summary is a short sentence which succinctly describes what the bug is about.")
SAN file systems becoming read-only

| | [Keywords](describekeywords.cgi): |  | | --- | --- | | [Status](page.cgi?id=fields.html#bug_status): | CLOSED ERRATA | | [Alias:](page.cgi?id=fields.html#alias "A short, unique name assigned to a bug in order to assist with looking it up and referring to it in other places in Bugzilla.") | None | | [Product:](describecomponents.cgi "Bugs are categorised into Products and Components. Select a Classification to narrow down this list.") | Red Hat Enterprise Linux 4 | | [Classification:](page.cgi?id=fields.html#classification "Bugs are categorised into Classifications, Products and Components. classifications is the top-level categorisation.") | Red Hat | | [Component:](describecomponents.cgi?product=Red Hat Enterprise Linux 4 "Components are second-level categories; each belongs to a particular Product. Select a Product to narrow down this list.") | kernel | | [Sub Component:](page.cgi?id=fields.html#rh_sub_components "The sub component of a specific component") | --- | | [Version:](page.cgi?id=fields.html#version "The version field defines the version of the software the bug was found in.") | 4.4 | | [Hardware:](page.cgi?id=fields.html#rep_platform "The hardware platform the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | All | | [OS:](page.cgi?id=fields.html#op_sys "The operating system the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | Linux | | [Priority:](page.cgi?id=fields.html#priority) | urgent | | [Severity:](page.cgi?id=fields.html#bug_severity) | high | | [Target Milestone:](page.cgi?id=fields.html#target_milestone "The Target Milestone field is used to define when the engineer the bug is assigned to expects to fix it.") | --- | | [Target Release](page.cgi?id=fields.html#target_release): | --- | | [Assignee:](page.cgi?id=fields.html#assigned_to "The person in charge of resolving the bug.") | Tom Coughlan | | [QA Contact:](page.cgi?id=fields.html#qa_contact "The person responsible for confirming this bug if it is unconfirmed, and for verifying the fix once the bug has been resolved.") | Brian Brock | | [Docs Contact:](page.cgi?id=fields.html#docs_contact "The person responsible for documenting once the bug has been resolved.") |  | | [URL:](page.cgi?id=fields.html#bug_file_loc "Bugs can have a URL associated with them - for example, a pointer to a web site where the problem is seen.") |  | | [Whiteboard:](page.cgi?id=fields.html#status_whiteboard "Each bug has a free-form single line text entry box for adding tags and status information.") |  | | Duplicates (2): | [207109](show_bug.cgi?id=207109) [208879](show_bug.cgi?id=208879 "CLOSED DUPLICATE - file system goes READ-only")  ([view as bug list](buglist.cgi?bug_id=207109,208879)) | | [Depends On:](page.cgi?id=fields.html#dependson "The bugs listed here must be resolved before this bug can be resolved.") |  | | [Blocks:](page.cgi?id=fields.html#blocked "This bug must be resolved before the bugs listed in this field can be resolved.") | [195232](show_bug.cgi?id=195232) [216986](show_bug.cgi?id=216986) [221291](show_bug.cgi?id=221291) [221293](show_bug.cgi?id=221293) | | TreeView+ | [depends on](buglist.cgi?bug_id=213921&bug_id_type=anddependson&format=tvp) / [blocked](buglist.cgi?bug_id=213921&bug_id_type=andblocked&format=tvp&tvp_dir=blocked) |  | |  | | [Reported:](page.cgi?id=fields.html#reporter) | 2006-11-03 19:31 UTC by Issue Tracker | | --- | --- | | [Modified:](page.cgi?id=fields.html#modified) | 2018-10-27 13:01 UTC ([History](show_activity.cgi?id=213921)) | | [CC List:](page.cgi?id=fields.html#cclist) | 36 users (show)  agk andrew.vasquez andriusb apuch bdonahue berthiaume\_wayne bob.smith cevich chris.mason clalance clevio.watanuki coldwell craig\_bogovich dhand djuran emcnabb esandeen fernando.canales gary.r.hicks hgarcia jbacik jdeverea jmoyer josef.carlin jplans kearnan\_keith laurie.barry levy\_jerome mdmann nayfield qlogic-redhat-ext rick.beldin rkenna sghosh tao tdunnon | | Fixed In Version: | RHSA-2007-0014 | | | Doc Type: | Bug Fix | | | Doc Text: |  | | | Clone Of: |  | | | Environment: |  | | | Last Closed: | 2007-01-30 14:37:00 UTC | | | Target Upstream Version: |  | | | Embargoed: |  | | |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| --- | | |

| | Attachments | [(Terms of Use)](page.cgi?id=terms-conditions.html) | | | --- | --- | --- | | [**metadata test script**](attachment.cgi?id=140585 "View the content of the attachment") (1.12 KB, application/octet-stream)  [2006-11-07 19:45 UTC](#attach_140585 "Go to the comment associated with the attachment"), Chris Evich | *no flags* | [Details](attachment.cgi?id=140585&action=edit) | | [**Script to handle running of multiple instances of IOZone**](attachment.cgi?id=140586 "View the content of the attachment") (1.63 KB, application/octet-stream)  [2006-11-07 19:47 UTC](#attach_140586 "Go to the comment associated with the attachment"), Chris Evich | *no flags* | [Details](attachment.cgi?id=140586&action=edit) | | [**Previous version that doesn't include random delays**](attachment.cgi?id=140588 "View the content of the attachment") (1.60 KB, application/x-gzip)  [2006-11-07 19:48 UTC](#attach_140588 "Go to the comment associated with the attachment"), Chris Evich | *no flags* | [Details](attachment.cgi?id=140588&action=edit) | | [**version w/o random delays in loop.**](attachment.cgi?id=140598 "View the content of the attachment") (1.60 KB, application/octet-stream)  [2006-11-07 20:19 UTC](#attach_140598 "Go to the comment associated with the attachment"), Chris Evich | *no flags* | [Details](attachment.cgi?id=140598&action=edit) | | [**One of the switch logs from testing done yesterday.**](attachment.cgi?id=140912 "View the content of the attachment") (68.06 KB, text/plain)  [2006-11-10 17:50 UTC](#attach_140912 "Go to the comment associated with the attachment"), Chris Evich | *no flags* | [Details](attachment.cgi?id=140912&action=edit) | | [**Other switch's error log from testing yesterday.**](attachment.cgi?id=140913 "View the content of the attachment") (69.16 KB, text/plain)  [2006-11-10 17:51 UTC](#attach_140913 "Go to the comment associated with the attachment"), Chris Evich | *no flags* | [Details](attachment.cgi?id=140913&action=edit) | | [**instrument end\_buffer\_read\_sync**](attachment.cgi?id=142617 "View the content of the attachment") (601 bytes, patch)  [2006-12-01 20:31 UTC](#attach_142617 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=142617&action=edit) | [Diff](attachment.cgi?id=142617&action=diff) | | [**instrument end\_buffer\_read\_sync; fix missing semicolon**](attachment.cgi?id=142618 "View the content of the attachment") (602 bytes, patch)  [2006-12-01 20:36 UTC](#attach_142618 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=142618&action=edit) | [Diff](attachment.cgi?id=142618&action=diff) | | [**memory hog**](attachment.cgi?id=143176 "View the content of the attachment") (1.77 KB, application/x-gzip)  [2006-12-08 17:43 UTC](#attach_143176 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=143176&action=edit) | | [**metadata test script take 2**](attachment.cgi?id=143187 "View the content of the attachment") (2.44 KB, application/octet-stream)  [2006-12-08 19:32 UTC](#attach_143187 "Go to the comment associated with the attachment"), Chris Evich | *no flags* | [Details](attachment.cgi?id=143187&action=edit) | | [**Install jprobes in end\_bio\_bh\_io\_sync and end\_buffer\_read\_sync**](attachment.cgi?id=143188 "View the content of the attachment") (8.11 KB, text/plain)  [2006-12-08 19:46 UTC](#attach_143188 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=143188&action=edit) | | [**Install jprobes in end\_bio\_bh\_io\_sync and end\_buffer\_read\_sync**](attachment.cgi?id=143334 "View the content of the attachment") (8.72 KB, text/plain)  [2006-12-11 21:28 UTC](#attach_143334 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=143334&action=edit) | | [**probe ext3\_get\_block\_handle in 2.6.9-34.EL x86\_64**](attachment.cgi?id=143456 "View the content of the attachment") (7.23 KB, text/plain)  [2006-12-12 22:09 UTC](#attach_143456 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=143456&action=edit) | | [**program to read directory inode dump (gcc -o readdir readdir.c)**](attachment.cgi?id=143555 "View the content of the attachment") (1.13 KB, text/plain)  [2006-12-13 20:56 UTC](#attach_143555 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=143555&action=edit) | | [**program to read directory inode dump (gcc -o readdir readdir.c)**](attachment.cgi?id=143556 "View the content of the attachment") (1.13 KB, text/plain)  [2006-12-13 21:01 UTC](#attach_143556 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=143556&action=edit) | | [**probe ext3\_bread (2.6.9-34.ELsmp x86\_64)**](attachment.cgi?id=143567 "View the content of the attachment") (8.05 KB, application/octet-stream)  [2006-12-13 22:18 UTC](#attach_143567 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=143567&action=edit) | | [**use submit\_bh instead of ll\_rw\_block**](attachment.cgi?id=143633 "View the content of the attachment") (532 bytes, patch)  [2006-12-14 14:41 UTC](#attach_143633 "Go to the comment associated with the attachment"), Chris Mason | *no flags* | [Details](attachment.cgi?id=143633&action=edit) | [Diff](attachment.cgi?id=143633&action=diff) | | [**more verbose check**](attachment.cgi?id=143648 "View the content of the attachment") (1.07 KB, patch)  [2006-12-14 16:05 UTC](#attach_143648 "Go to the comment associated with the attachment"), Chris Mason | *no flags* | [Details](attachment.cgi?id=143648&action=edit) | [Diff](attachment.cgi?id=143648&action=diff) | | [**probe ext3\_bread every which way (2.6.9-34.ELsmp.x86\_64)**](attachment.cgi?id=143707 "View the content of the attachment") (8.46 KB, text/plain)  [2006-12-14 22:18 UTC](#attach_143707 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=143707&action=edit) | | [**probe ext3\_bread and end\_bio\_bh\_io\_sync (2.6.9-34.ELsmp.x86\_64)**](attachment.cgi?id=143795 "View the content of the attachment") (9.37 KB, text/plain)  [2006-12-15 18:28 UTC](#attach_143795 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=143795&action=edit) | | [**touchup the logic in the end\_bio\_bh\_io\_sync jprobe**](attachment.cgi?id=143801 "View the content of the attachment") (9.37 KB, text/plain)  [2006-12-15 18:41 UTC](#attach_143801 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=143801&action=edit) | | [**verbose logging in end\_bio\_bh\_io\_sync**](attachment.cgi?id=143921 "View the content of the attachment") (9.68 KB, text/plain)  [2006-12-18 18:40 UTC](#attach_143921 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=143921&action=edit) | | [**turn off read-ahead in ext3\_readdir**](attachment.cgi?id=143938 "View the content of the attachment") (401 bytes, patch)  [2006-12-18 20:00 UTC](#attach_143938 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=143938&action=edit) | [Diff](attachment.cgi?id=143938&action=diff) | | [**Fix ext3\_bread and ext3\_find\_entry**](attachment.cgi?id=144006 "View the content of the attachment") (1.58 KB, patch)  [2006-12-19 15:05 UTC](#attach_144006 "Go to the comment associated with the attachment"), Chris Mason | *no flags* | [Details](attachment.cgi?id=144006&action=edit) | [Diff](attachment.cgi?id=144006&action=diff) | | [**commit d8733c2956968a01394a4d2a9e97a8b431a78776 from Linus' git tree**](attachment.cgi?id=144007 "View the content of the attachment") (4.88 KB, patch)  [2006-12-19 15:29 UTC](#attach_144007 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=144007&action=edit) | [Diff](attachment.cgi?id=144007&action=diff) | | [**Fail all READA I/Os**](attachment.cgi?id=144044 "View the content of the attachment") (566 bytes, patch)  [2006-12-19 21:47 UTC](#attach_144044 "Go to the comment associated with the attachment"), Jeff Moyer | *no flags* | [Details](attachment.cgi?id=144044&action=edit) | [Diff](attachment.cgi?id=144044&action=diff) | | [**Fail all READA I/Os**](attachment.cgi?id=144045 "View the content of the attachment") (566 bytes, patch)  [2006-12-19 21:48 UTC](#attach_144045 "Go to the comment associated with the attachment"), Jeff Moyer | *no flags* | [Details](attachment.cgi?id=144045&action=edit) | [Diff](attachment.cgi?id=144045&action=diff) | | [**This is the upstream patch from attachment 144007 adjusted to apply to RHEL4 kernels**](attachment.cgi?id=144802 "View the content of the attachment") (4.05 KB, patch)  [2007-01-04 15:26 UTC](#attach_144802 "Go to the comment associated with the attachment"), Chip Coldwell | *no flags* | [Details](attachment.cgi?id=144802&action=edit) | [Diff](attachment.cgi?id=144802&action=diff) | | [**Patch to replace all READAs with normal READs**](attachment.cgi?id=145256 "View the content of the attachment") (377 bytes, patch)  [2007-01-10 14:47 UTC](#attach_145256 "Go to the comment associated with the attachment"), Chris Evich | *no flags* | [Details](attachment.cgi?id=145256&action=edit) | [Diff](attachment.cgi?id=145256&action=diff) | | [Show Obsolete](#a0) (17) [View All](attachment.cgi?bugid=213921&action=viewall&hide_obsolete=1) | | |    Links | System | ID | Private | Priority | Status | Summary | Last Updated | | Red Hat Product Errata | [RHSA-2007:0014](https://access.redhat.com/errata/RHSA-2007%3A0014) | 0 | normal | SHIPPED\_LIVE | Important: kernel security update | 2007-01-30 14:25:00 UTC | |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |

| [Description](show_bug.cgi?id=213921#c0)  Issue Tracker    2006-11-03 19:31:10 UTC  ``` Escalated to Bugzilla from IssueTracker   ```  [Comment 1](show_bug.cgi?id=213921#c1)  Chris Snook    2006-11-03 21:04:05 UTC  ``` We've received several reports of ext3 filesystems on SAN storage repeatedly going read-only, often different filesystems, or on different arrays, or on different hosts attached to the same arrays.  This happens with a single path, with dm-multipath, or with EMC PowerPath.  It seems to only happen on active/active arrays, such as EMC Symmetrix, and not happen on active/passive arrays, such as EMC Clariion in the same environment, but it is unclear whether this is due to the multipathing or simply the I/O load.  Setting ql2xprocessrscn=1 (qla2xxx) or lpfc_use_adisc=1 (lpfc) helps in some of these cases.  As of RHEL 4 U4, the problem is not known to still occur with lpfc when lpfc_use_adisc=1 is set.  Both the RHEL 4 U4 version of the qla2xxx driver, and version 8.01.06 from qlogic.com seem to be affected, though we also have one report of 8.01.06 fixing the problem, so it may be an improvement, but not a complete fix.  Currently, signs point to an inefficiency in handling RSCNs in the qla2xxx driver, which causes SCSI timeouts, which eventually propagate up the stack to cause an ext3 error.   ```  [Comment 2](show_bug.cgi?id=213921#c2)  Chris Evich    2006-11-07 19:45:55 UTC  ``` Created [attachment 140585](attachment.cgi?id=140585 "metadata test script") [[details]](attachment.cgi?id=140585&action=edit "metadata test script") metadata test script   ```  [Comment 3](show_bug.cgi?id=213921#c3)  Chris Evich    2006-11-07 19:47:28 UTC  ``` Created [attachment 140586](attachment.cgi?id=140586 "Script to handle running of multiple instances of IOZone") [[details]](attachment.cgi?id=140586&action=edit "Script to handle running of multiple instances of IOZone") Script to handle running of multiple instances of IOZone   ```  [Comment 5](show_bug.cgi?id=213921#c5)  Chris Evich    2006-11-07 20:19:47 UTC  ``` Created [attachment 140598](attachment.cgi?id=140598 "version w/o random delays in loop.") [[details]](attachment.cgi?id=140598&action=edit "version w/o random delays in loop.") version w/o random delays in loop.  I don't as of yet have my hands on the customer's switch logs.	Attached is a copy of the ioloadgen script version they're actually using (w/o the random delays as is in the later version).  I sent a note to the customer requesting the switch logs if they still have them.  Also, just to remind everyone, now that this is a public bug, please be sensitive to sharing customer data.  For sensitive items, we can e-mail them, or I can look into making this bug private again for only the people on the cc list.  So, if your not on the cc list yet, please add your self.  Thanks.   ```  [Comment 7](show_bug.cgi?id=213921#c7)  Andrew Vasquez    2006-11-07 21:51:42 UTC  ``` Just to be clear on the 'logs' request, QLogic would like to see qla2xxx driver logs (with extended_error_logging enabled), not switch logs, so that we can better understand the failure as well as any relevant contributing precursors   ```  [Comment 8](show_bug.cgi?id=213921#c8)  Chris Evich    2006-11-08 16:40:19 UTC  ``` e-mailed emc grab from 106 to EMC and QLogic folks.  Customer working on providing another one from 007 as well.   ```  [Comment 9](show_bug.cgi?id=213921#c9)  Chris Evich    2006-11-08 16:46:19 UTC  ``` Testing on 007 didn't happen last night due to scheduling issues.  Toure is working with the customer to get the 007 testing kicked off right now.   ```  [Comment 10](show_bug.cgi?id=213921#c10)  Chris Evich    2006-11-08 17:30:07 UTC  ``` Also, just to be clear, the emc grab I e-mailed out was taken post-failure on 106 while testing under the following conditions:  New QLogic driver. Oracle running normally. New metadata script. Same ioloadgen script as before. PP in RE mode.   ```  [Comment 11](show_bug.cgi?id=213921#c11)  Chris Evich    2006-11-08 17:59:54 UTC  ``` Just sent out grab from 007, test over the weekend was run with w/o any multipath software loaded/running.   ```  [Comment 12](show_bug.cgi?id=213921#c12)  Chris Evich    2006-11-08 18:07:35 UTC  ``` Plan:  If current testing of 007 (dm-multipath in multibus mode) goes read-only, we need to validate the secondary path.  To find which port is the primary one, block it with dm-multipath running.  Then use "multipath -ll" output to determine if that was the primary or secondary.    Make sure the primary is blocked for the test.  Disable all multipath software on 007, and test down the secondary path only.  Pass/fail of that test will determine if we need to look at dm-multipath or PowerPath further.  Our thinking: They may be intercepting and blocking us from seeing low-level I/O failures.  If possible, then we will start instrumenting dm-multipath code.   ```  [Comment 13](show_bug.cgi?id=213921#c13)  Chris Evich    2006-11-08 18:51:59 UTC  ``` Revised plan:  Test 007 as above, but also kick-off a similar test on 106 (with the new QLogic driver).  Later on, if 106 fails, then we'll know that 007 might have also failed if given that same amount of time.  This could save us a headache down the road while providing flexability of terminitating a potentially non-failing test on 007 tomorrow morning.  Given a failure on 007 under dm-multipath tomorrow morning, the next step is as above- validate no-multipath and I/O down the secondary path.  Leave 106 running if it doesn't fail.   ```  [Comment 14](show_bug.cgi?id=213921#c14)  Chris Evich    2006-11-08 18:53:54 UTC  ``` QLogic/EMC:  When you have any status on your testing, if you could post it along with your respective setups, that would be helpful for tracking purposes.   ```  [Comment 15](show_bug.cgi?id=213921#c15)  Chris Evich    2006-11-08 20:35:26 UTC  ``` From Andrew:  """Could you or the customer perhaps shed some light on when the first failure occurred (date/time) along with a description of which events precipitated the 'failure' --  I'm just trying to get a baseline here, as from what I can see, the last driver load before the weekend run occurred on November 3rd:  	... 	Nov  3 10:37:30 chln106 kernel: QLogic Fibre Channel HBA Driver 	...  with the additional noise of the LUNZ luns (sda, sdb, sdk, sdt) being inaccessible:  	... 	Nov  3 10:37:36 chln106 kernel: sdt: asking for cache data failed 	Nov  3 10:37:36 chln106 kernel: sdt: assuming drive cache: write through 	Nov  3 10:37:36 chln106 kernel: sdt : READ CAPACITY failed. 	Nov  3 10:37:36 chln106 kernel: sdt : status=1, message=00, host=0, driver=08  	... 	Nov  4 10:40:04 chln106 kernel: end_request: I/O error, dev sdb, sector 0 	Nov  4 10:40:04 chln106 kernel: Buffer I/O error on device sdb, logical block 0 	Nov  4 10:40:04 chln106 kernel: end_request: I/O error, dev sdb, sector 0 	Nov  4 10:40:04 chln106 kernel: Buffer I/O error on device sdb, logical block 0 	Nov  4 10:40:04 chln106 kernel: end_request: I/O error, dev sdb, sector 0 	Nov  4 10:40:04 chln106 kernel: Buffer I/O error on device sdb, logical block 0  and finally a sudden ext3-error 2.5 days later:  	... 	Nov  6 01:29:02 chln106 kernel: EXT3-fs error (device dm-18): ext3_readdir: directory #2342945 contains a hole at offset 163840 	Nov  6 01:29:02 chln106 kernel: Aborting journal on device dm-18. 	Nov  6 01:29:02 chln106 kernel: ext3_abort called. 	Nov  6 01:29:02 chln106 kernel: EXT3-fs error (device dm-18): ext3_journal_start_sb: Detected aborted journal 	Nov  6 01:29:02 chln106 kernel: Remounting filesystem read-only 	Nov  6 01:29:02 chln106 kernel: EXT3-fs error (device dm-18) in start_transaction: Journal has aborted 	Nov  6 01:29:33 chln106 last message repeated 575 times 	...  I'm also trying to drill down to the exact scsi device used with the dm-18 device, am I correct in interpreting the logs in that dm-18 is actually part of /dev/emcpowerb -- which raw scsi-devices are part of that physical volume?  In any case, there do not appear to be *any* fabric related entries logged by the device driver (or for that matter, anything) immediately before or in the near vicinity of the ext3 FS going read only.  The last driver entries were those logged during init-time (three days earlier).  If in fact there were any RSCNs from the switch the driver would have logged something like the following to the messages file:  	... 	scsi(0): Asynchronous RSCR UPDATE. 	scsi(0): RSCN database changed -- 0070 0000 	... """   ```  [Comment 16](show_bug.cgi?id=213921#c16)  Chris Evich    2006-11-08 20:36:48 UTC  ``` From Jerry:  """emcpowerb is:  Pseudo name=emcpowerb Symmetrix ID=000190101044 Logical device ID=00E3 state=alive; policy=SymmOpt; priority=0; queued-IOs=1 ======================================================================== ====== ---------------- Host ---------------   - Stor -   -- I/O Path -  -- Stats --- ### HW Path                 I/O Paths    Interf.   Mode    State  Q-IOs Errors ======================================================================== ======    0 qla2xxx                   sdi       FA  7aB   active  alive      0 0    1 qla2xxx                   sdr       FA 10aB   active  alive      1 0   """   ```  [Comment 17](show_bug.cgi?id=213921#c17)  Chris Evich    2006-11-08 20:56:54 UTC  ``` Andrew, to your question about context:  That was the failure which occured on 106 in the middle of the night, with the 8.01.06 QLogic driver, and while _not_ deliberatly testing/stressing anything.    No testing was done on 106 between the Friday reboot and the read-only at 1:29 Monday Morning.  (Weather or not the system was stressed because of some automated Oracle/System activity is another question.)   ```  [Comment 18](show_bug.cgi?id=213921#c18)  Andrew Vasquez    2006-11-08 23:21:33 UTC  ``` Unfortunately, the driver was loaded without the extended_error_logging parameter enabled during driver load:  	Nov  3 10:10:10 chln007 kernel: qla2xxx: Unknown parameter `q12xfailover' 	Nov  3 10:10:10 chln007 kernel: QLogic Fibre Channel HBA Driver 	Nov  3 10:10:10 chln007 kernel: ACPI: PCI interrupt 0000:05:08.0[A] -> GSI 32 (level, low) -> IRQ 233 	Nov  3 10:10:11 chln007 kernel: qla2300 0000:05:08.0: Found an ISP2312, irq 233, iobase 0xf8822000 	Nov  3 10:10:11 chln007 kernel: qla2300 0000:05:08.0: Configuring PCI space... 	Nov  3 10:10:11 chln007 kernel: qla2300 0000:05:08.0: Configure NVRAM parameters... 	Nov  3 10:10:11 chln007 kernel: qla2300 0000:05:08.0: Verifying loaded RISC code... 	Nov  3 10:10:11 chln007 kernel: qla2300 0000:05:08.0: Waiting for LIP to complete... 	Nov  3 10:10:11 chln007 kernel: qla2300 0000:05:08.0: LOOP UP detected (2 Gbps). 	Nov  3 10:10:11 chln007 kernel: qla2300 0000:05:08.0: Topology - (F_Port), Host Loop address 0xffff 	Nov  3 10:10:11 chln007 kernel: scsi0 : qla2xxx 	Nov  3 10:10:11 chln007 kernel: qla2300 0000:05:08.0:  	Nov  3 10:10:11 chln007 kernel:  QLogic Fibre Channel HBA Driver: 8.01.04-d7 	Nov  3 10:10:11 chln007 kernel:   QLogic QLA2342 -  	Nov  3 10:10:11 chln007 kernel:   ISP2312: PCI-X (100 MHz) @ 0000:05:08.0 hdma+, host#=0, fw=3.03.20 IPX  if it had been, there would have been an '-debug' appended to the driver version.  Some time later, the midlayer in fact reports some failed SCSI I/O with a return status of DID_BUS_BUSY (0x20000), where the first began at 4:06pm:  	Nov  5 16:06:01 chln007 kernel: SCSI error : <0 0 2 28> return code = 0x20000 	Nov  5 16:06:01 chln007 kernel: end_request: I/O error, dev sdh, sector 128520408 	Nov  5 16:06:01 chln007 kernel: end_request: I/O error, dev sdh, sector 128520416 	Nov  5 16:06:01 chln007 kernel: SCSI error : <0 0 2 28> return code = 0x20000 	... 	Nov  5 16:43:54 chln007 kernel: end_request: I/O error, dev sdd, sector 88879880 	Nov  5 16:43:54 chln007 kernel: end_request: I/O error, dev sdd, sector 88879888 	Nov  5 16:43:54 chln007 kernel: SCSI error : <0 0 2 28> return code = 0x20000 	Nov  5 16:43:54 chln007 kernel: end_request: I/O error, dev sdh, sector 72414784 	Nov  5 16:43:54 chln007 kernel: end_request: I/O error, dev sdh, sector 72414792 	Nov  5 16:43:54 chln007 kernel: SCSI error : <0 0 2 14> return code = 0x20000 	Nov  5 16:43:54 chln007 kernel: end_request: I/O error, dev sdd, sector 145749192 	Nov  5 16:43:54 chln007 kernel: end_request: I/O error, dev sdd, sector 145749200 	Nov  5 16:43:54 chln007 kernel: SCSI error : <0 0 2 14> return code = 0x20000 	Nov  5 16:43:54 chln007 kernel: end_request: I/O error, dev sdd, sector 88879920  against luns sdh, sdg, sdd.  This continues until the first relevant 'EXT3 goes read-only failure' occurs at 6:43pm:  	Nov  5 18:43:12 chln007 kernel: EXT3-fs error (device dm-7): ext3_readdir: directory #1020212 contains a hole at offset 45056 	Nov  5 18:43:12 chln007 kernel: Aborting journal on device dm-7.  	Nov  5 18:43:12 chln007 kernel: EXT3-fs error (device dm-7) in start_transaction: Readonly filesystem 	Nov  5 18:43:12 chln007 kernel: Aborting journal on device dm-7.   Unfortunately, since extended_error_logging wasn't enabled, I can't with certainty why the commands are being returned to the midlayer with a DID_BUS_BUSY status.  Some possibilities include:  - SAN activity, causing the driver to want to recycle   commands until SNS scans complete. - Commands timeout, storage not responding - Storage logged-out of the initiator (LOGO) - Dropped frames, FC frame failures.  In any case, for each of the commands, if the fast-fail bit is set (typically is when DM/MD is involved), then the midlayer will *not* retry the command, but instead return the failed status to the upper layers, eventually propagating to the block-layer caller.  Now if the fast-fail bit is cleared (unset), then retries are perhaps being exhausted, as typically the midlayer should retry the commands in hopes the SAN is quiesced.  If I could get a good failure with 8.01.04-d7 and extended_error_logging enabled, we'd have much more confidence is suggesting next steps.  At this point, all that's known is that for some reason the driver is returning back commands with DID_BUS_BUSY statuses.  Note again, this is a different signature than that of the 106 run with 8.01.06 and extended_error_logging enabled.   ```  [Comment 20](show_bug.cgi?id=213921#c20)  Chris Evich    2006-11-09 16:21:55 UTC  ``` One comment on #18 above:  That system was being exercised at that time with IOZone, the metadata script, and having someone blocking/unblocking a port within the same zone on the SAN (to trigger RSCNs).  It's unfortunate extended error logging was not working, they have confirmed with me the option is there.  It's possible that the initial ram disk wasn't rebuilt (as required) and so the option never made it into the module as it was loaded.  I'm following up with the customer on this last point.   ```  [Comment 21](show_bug.cgi?id=213921#c21)  Issue Tracker    2006-11-09 16:35:17 UTC  ``` All,      Just for the record, the plan for 007:  Run with _no_ multipath with the primary path disabled (seem my note below)  for 106:  Run with dm-multipath, the new QLogic driver, IOZone, metadata-test, and normal Oracle load for as long as possible (preferrably through the weekend if possible, understanding this is a production box).     This event sent from IssueTracker by cevich   issue 97316   ```  [Comment 22](show_bug.cgi?id=213921#c22)  Chris Evich    2006-11-09 18:48:45 UTC  ``` Current status:  No failure occurred under dm-multipath on 007 after 16+ hours of testing.  We've verified the extended error logging is turned on now and functional on 007.  Configuration issues prevented testing on 106, though they are being fixed now.  We hope to kick off a long-running test on 106 with normal Oracle Load + new QLogic driver + metadata script + ioloadgen script  Plan: 007 switched back to PowerPath in RE mode and back to the original version of the metadata script.  We're doing this to both validate possibly reproducing a failure faster with the old script (as was done 4 times before); and, to confirm that we can reproduce on 007 in RE mode with the old QLogic driver.  If the old script proves to reproduce faster, I will be posting that information in addition to a copy of the old script to this BZ.  Good news from EMC: They were successful in reproducing a read-only condition after 14 hours of testing using the (attached) metadata script in addition to IOZOne load generation but without Oracle.   Do we have any status or updates on reproduction efforts from the QLogic side?    ```  [Comment 23](show_bug.cgi?id=213921#c23)  Chris Evich    2006-11-09 20:48:44 UTC  ``` Customer recreated the failure on 007 using PowerPath in RE mode, with the latest metadata test script, and an older version of the load generator script.  This was a misscommunication, but is informative none-the-less.  It validates that we can recreate the issue with PP in RE mode on 007.  It validates that we can recreate with the new metadata script.  It also further confirms that it can be recreated without Oracle.  I will be e-mailing out the EMC grabs and other data shortly.   ```  [Comment 24](show_bug.cgi?id=213921#c24)  Dave Wagner    2006-11-09 23:05:52 UTC  ``` Will try the metadata script attached to see if problem can be reproduced here. So far we haven't been able to reproduce it.   ```  [Comment 25](show_bug.cgi?id=213921#c25)  Chris Evich    2006-11-10 14:54:48 UTC  ``` Re: #24, you'll also want to run the IOZone based load test.  So far, we've only seen this problem occur under extremely high load conditions (both system and SAN).   ```  [Comment 26](show_bug.cgi?id=213921#c26)  Andrew Vasquez    2006-11-10 17:32:16 UTC  ``` Re: #20, If there's a script switching ports on and off in the fabric (to generate RSCNs), then I have a feeling the I/Os are being returned with BUS_BUSY due to:  	- SAN activity, causing the driver to want to recycle 	  commands until SNS scans complete.  As I mentioned before:  	In any case, for each of the commands, if the fast-fail bit 	is set (typically is when DM/MD is involved), then the 	midlayer will *not* retry the command, but instead return 	the failed status to the upper layers, eventually 	propagating to the block-layer caller.  Are the commands being issued with the fast-fail bit set? If so, then that would certainly account for the journaling errors as the data is never being written/read, as the DID_BUS_BUSY statuses are being directly funneled to the upper-layers without the request retry being done...  8.01.06 has some changes in the semantics of command handling during SAN scanning (as was mentioned before), commands will be returned with DID_IMM_RETRY, instead of DID_BUS_BUSY, as to avoid issues surrounding DM/MD's use of fast-fail and its effects of premature markings of 'failure' to a given I/O.    ```  [Comment 27](show_bug.cgi?id=213921#c27)  Chris Evich    2006-11-10 17:37:39 UTC  ```  Update: Overnight testing with dm-multipath on 106 and 007 did not reproduce any failures.  Testing on 106 will be stopped EOB today.   Testing on 007 will continue through the weekend.  We identified the problem that was preventing the qla module from turning on extended error logging.  The options line contained "q12xfailover=0" instead of "ql2xfailover=0" (one vs. an "l" (ell)).  This has been fixed, ramdisk rebuilt, and test restarted.   ```  [Comment 28](show_bug.cgi?id=213921#c28)  Chris Evich    2006-11-10 17:40:56 UTC  ``` Re: #26, Thanks for the details.  Is it your recommendation that the "fast fail" bit not be set under these circumstances?  Is anyone aware of possible consequences when not setting it?  Is there a requirement for this bit to be set when multipath is in use vs. normal use, or against local SCSI disks?   ```  [Comment 29](show_bug.cgi?id=213921#c29)  Chris Evich    2006-11-10 17:50:13 UTC  ``` Created [attachment 140912](attachment.cgi?id=140912 "One of the switch logs from testing done yesterday.") [[details]](attachment.cgi?id=140912&action=edit "One of the switch logs from testing done yesterday.") One of the switch logs from testing done yesterday.   ```  [Comment 30](show_bug.cgi?id=213921#c30)  Chris Evich    2006-11-10 17:51:36 UTC  ``` Created [attachment 140913](attachment.cgi?id=140913 "Other switch's error log from testing yesterday.") [[details]](attachment.cgi?id=140913&action=edit "Other switch's error log from testing yesterday.") Other switch's error log from testing yesterday.   ```  [Comment 31](show_bug.cgi?id=213921#c31)  Josef Bacik    2006-11-10 18:36:09 UTC  ``` If they are using dm_emc then the REQ_FAILFAST bit is used, else it's not.   But my question is if this was a problem with dm multipathing failing too  quickly, then wouldn't this problem occur on dm multipathing?  From what I've  seen it's not reproduced with DM, and if it does it takes much longer than PP.   I would agree that REQ_FAILFAST would be contributing to the problem, but only  if we were seeing lots of failures with DM.   ```  [Comment 32](show_bug.cgi?id=213921#c32)  Andrew Vasquez    2006-11-10 18:45:16 UTC  ``` Regarding the latest 007 logs (from yesterday):  These 007 logs from yesterday contain a run with the driver still not having extended error logging enabled:          Nov  9 09:58:39 chln007 kernel: qla2300 0000:05:08.1:          Nov  9 09:58:39 chln007 kernel:  QLogic Fibre Channel HBA Driver: 8.01.04-d7         Nov  9 09:58:39 chln007 kernel:   QLogic QLA2342 -          Nov  9 09:58:39 chln007 kernel:   ISP2312: PCI-X (100 MHz) @ 0000:05:08.1 hdma+, host#=1, fw=3.03.20 IPX  Note, no '-debug' suffix.  This is irrelevent though as the block  layer *should* have logged some sort of 'failure' message (if the  failure began from a block-layer device) before the sudden 'goes  read-only':          Nov  9 14:19:48 chln007 kernel: EXT3-fs error (device dm-7): ext3_readdir: directory #1216813 contains a hole at offset 159744          Nov  9 14:19:48 chln007 kernel: Aborting journal on device dm-7.         Nov  9 14:19:48 chln007 kernel: ext3_abort called.         Nov  9 14:19:48 chln007 kernel: EXT3-fs error (device dm-7): ext3_journal_start_sb: Detected aborted journal  Instead, there nothing of the sort.  Quite unlike the previous logs  where ports on the SAN were being disabled and enabled (causing RSCNs to be pushed to the HBA (initiator).   ```  [Comment 33](show_bug.cgi?id=213921#c33)  Andrew Vasquez    2006-11-10 18:53:22 UTC  ``` Re: #31,  From a block-driver perspective, I can't say which type of I/Os are failing from the November 5th run, either data or meta-data (journaling), as the midlayer is simply reporting some failure, probably due to fast-fail and the LLDD (qla2xxx) returning back DID_BUS_BUSY during SAN disruptions (again this is best-guess given descriptions of what was occuring from emails [no extended_error_logging]) to recycle the command.  There appear to be *many* failures before ext3 goes readonly:  	Nov  5 16:06:01 chln007 kernel: SCSI error : <0 0 2 28> return code = 0x20000 	Nov  5 16:06:01 chln007 kernel: end_request: I/O error, dev sdh, sector 128520408 	Nov  5 16:06:01 chln007 kernel: end_request: I/O error, dev sdh, sector 128520416 	Nov  5 16:06:01 chln007 kernel: SCSI error : <0 0 2 28> return code = 0x20000  	Nov  5 16:06:01 chln007 kernel: end_request: I/O error, dev sdh, sector 128520456 	Nov  5 16:06:01 chln007 kernel: end_request: I/O error, dev sdh, sector 128520464 	... 	Nov  5 16:06:02 chln007 kernel: end_request: I/O error, dev sdh, sector 128520720 	Nov  5 16:06:02 chln007 kernel: end_request: I/O error, dev sdh, sector 128520728 	Nov  5 16:06:02 chln007 kernel: SCSI error : <0 0 2 28> return code = 0x20000 	... 	Nov  5 16:32:33 chln007 kernel: end_request: I/O error, dev sdg, sector 13741104 	Nov  5 16:32:33 chln007 kernel: end_request: I/O error, dev sdg, sector 13741112 	Nov  5 16:32:33 chln007 kernel: SCSI error : <0 0 2 27> return code = 0x20000 	Nov  5 16:32:33 chln007 kernel: end_request: I/O error, dev sdg, sector 13741136 	Nov  5 16:32:33 chln007 kernel: SCSI error : <0 0 2 27> return code = 0x20000 	... 	Nov  5 18:08:47 chln007 kernel: SCSI error : <0 0 2 27> return code = 0x20000 	Nov  5 18:08:47 chln007 kernel: end_request: I/O error, dev sdg, sector 17729784 	Nov  5 18:08:47 chln007 kernel: end_request: I/O error, dev sdg, sector 17729792 	Nov  5 18:16:55 chln007 su(pam_unix)[23001]: session closed for user root 	Nov  5 18:16:57 chln007 sshd(pam_unix)[19572]: session closed for user lidn4nj 	Nov  5 18:43:12 chln007 kernel: EXT3-fs error (device dm-7): ext3_readdir: directory #1020212 contains a hole at offset 45056 	Nov  5 18:43:12 chln007 kernel: Aborting journal on device dm-7. 	Nov  5 18:43:12 chln007 kernel: EXT3-fs error (device dm-7) in start_transaction: Readonly filesystem 	Nov  5 18:43:12 chln007 kernel: Aborting journal on device dm-7.  actually 2hrs.    ```  [Comment 34](show_bug.cgi?id=213921#c34)  Chris Evich    2006-11-10 19:41:15 UTC  ``` Re: #32, please see update in #27, problem caused by a typo on options line (using a 1 (one) instead of an l (ell).  On-site tech verified dmesg output on 007 after fixing this and confirmed extended error loging is now enabled.   ```  [Comment 35](show_bug.cgi?id=213921#c35)  Wayne Berthiaume    2006-11-13 13:11:10 UTC  ``` In response to comments [26](show_bug.cgi?id=213921#c26), [27](show_bug.cgi?id=213921#c27), and 31 form PP engineering:  It does or at least it does as recently as PowerPath 4.5.1.  But so do all instances of dm-multipath that work on all storage systems.  Possibly the "queue_if_no_path" dm-multipath feature is enabled which is preventing the error from surfacing to ext3 in the dm-multipath case.  From reading the Red Hat bugzilla entry, this seems like a problem in the handling of the DID_BUS_BUSY host portion of a SCSI command error since a DID_BUS_BUSY used to be "infinitely retryable" and now receives no retries due to the use of REQ_FAILFAST.  It certainly could happen that each path used by PowerPath is failing simply due to the LLD returning DID_BUS_BUSY.    ```  [Comment 36](show_bug.cgi?id=213921#c36)  Chip Coldwell    2006-11-13 16:45:29 UTC  ``` (In reply to [comment #18](show_bug.cgi?id=213921#c18)) > This continues until the first > relevant 'EXT3 goes read-only failure' occurs at 6:43pm: >  > 	Nov  5 18:43:12 chln007 kernel: EXT3-fs error (device dm-7): ext3_readdir: > directory #1020212 contains a hole at offset 45056  That error message is giving the inode number and offset for a hole in a directory inode -- that's what's causing the filesystem to go readonly.  It would be interesting to run debugfs on the filesystem *before* fscking it to verify that there is a hole there -- that would tell us if the problem is on magnetic media or if it is in the transport of data from the media to the VFS layer.  Chip    ```  [Comment 37](show_bug.cgi?id=213921#c37)  Chip Coldwell    2006-11-13 18:42:03 UTC  ``` (In reply to [comment #36](show_bug.cgi?id=213921#c36)) > (In reply to [comment #18](show_bug.cgi?id=213921#c18)) > > This continues until the first > > relevant 'EXT3 goes read-only failure' occurs at 6:43pm: > >  > > 	Nov  5 18:43:12 chln007 kernel: EXT3-fs error (device dm-7): ext3_readdir: > > directory #1020212 contains a hole at offset 45056 >  > That error message is giving the inode number and offset for a hole in a > directory inode -- that's what's causing the filesystem to go readonly.  It > would be interesting to run debugfs on the filesystem *before* fscking it to > verify that there is a hole there -- that would tell us if the problem is on > magnetic media or if it is in the transport of data from the media to the VFS layer.  BTW, the same type of failure happened on both hosts (007 and 106).  I repost the error message from 106 below  Nov  6 01:29:02 chln106 kernel: EXT3-fs error (device dm-18): ext3_readdir: directory #2342945 contains a hole at offset 163840  and from 007  Nov  5 18:43:12 chln007 kernel: EXT3-fs error (device dm-7): ext3_readdir: directory #1020212 contains a hole at offset 45056  Is this "directory inode contains a hole" failure common to all of the crashes?  Chip    ```  [Comment 38](show_bug.cgi?id=213921#c38)  Chip Coldwell    2006-11-13 19:14:01 UTC  ``` (In reply to [comment #31](show_bug.cgi?id=213921#c31)) > If they are using dm_emc then the REQ_FAILFAST bit is used, else it's not.    Are you sure?  I found this in drivers/block/ll_rw_blk.c:__make_request          /*          * inherit FAILFAST from bio (for read-ahead, and explicit FAILFAST)          */         if (bio_rw_ahead(bio) || bio_failfast(bio))                 req->flags |= REQ_FAILFAST;  from which it looks like all read-ahead bios are marked to fail fast.  Chip    ```  [Comment 39](show_bug.cgi?id=213921#c39)  Chip Coldwell    2006-11-13 19:17:17 UTC  ``` (In reply to [comment #37](show_bug.cgi?id=213921#c37)) >  > BTW, the same type of failure happened on both hosts (007 and 106).  I repost > the error message from 106 below >  > Nov  6 01:29:02 chln106 kernel: EXT3-fs error (device dm-18): ext3_readdir: > directory #2342945 contains a hole at offset 163840 >  > and from 007 >  > Nov  5 18:43:12 chln007 kernel: EXT3-fs error (device dm-7): ext3_readdir: > directory #1020212 contains a hole at offset 45056 >  > Is this "directory inode contains a hole" failure common to all of the crashes?  Looks like it is; this is from [comment 32](show_bug.cgi?id=213921#c32) above  Nov  9 14:19:48 chln007 kernel: EXT3-fs error (device dm-7): ext3_readdir: directory #1216813 contains a hole at offset 159744   Chip    ```  [Comment 40](show_bug.cgi?id=213921#c40)  Keith Kearnan    2006-11-15 16:40:13 UTC  ``` I wanted to report that we have reproduced this 3 times now.  The latest was  this morning:  Nov 15 07:09:16 L8 kernel: EXT3-fs error (device emcpowera1): ext3_readdir:  directory #4505601 contains a hole at offset 12288 Nov 15 07:09:16 L8 kernel: Aborting journal on device emcpowera1. Nov 15 07:09:16 L8 kernel: ext3_abort called. Nov 15 07:09:16 L8 kernel: EXT3-fs error (device emcpowera1):  ext3_journal_start_sb: Detected aborted journal Nov 15 07:09:16 L8 kernel: Remounting filesystem read-only Nov 15 07:09:16 L8 kernel: EXT3-fs error (device emcpowera1) in  start_transaction: Journal has aborted    The first test took 17 hours, the second 5 and the third 60 hours.  All of the  errors occurred on the file system with the "tpsreport.sh" script.  There are  no errors in the messages file previous to the file system going read-only and  no fabric activity.  Our environment: HP DL385 (AMD) DMX2000, McData ED64M 2x QLogic PCI to Fibre Channel Host Adapter for QLA2342 Driver version 8.01.02-d4 RHEL4u3, 2.6.9-34.ELsmp PowerPath 4.5.1  The current test is running with PowerPath debugging turned up.   ```  [Comment 41](show_bug.cgi?id=213921#c41)  Keith Kearnan    2006-11-15 19:35:55 UTC  ``` OK the tpsreport.sh generated another ext3 read-only error:  ----------- Wed Nov 15 12:24:12 EST 2006 looping ----------- Wed Nov 15 12:24:12 EST 2006 creating files ::::::::>Error - 1 Create failure  on /test2/metadata/0/9/metadata_14055_5626.tmp, Wed Nov 15 12:41:49 EST 2006 End Time:        Wed Nov 15 12:41:49 EST 2006  We see from the script that this is generated from an attempted write into this  file:  <snip>       while [ ${NUM} -le ${NUM_FILES} ]; do         FILE=${FILE_PREV}_${RAN}_${NUM}.tmp         echo 'hello world' >  ${FILE}         checkRC $? "Create failure on ${FILE}" <snip>  This file is actually present (but empty) in the file system.  [root@L8 9]# pwd /test2/metadata/0/9 [root@L8 9]# ls -ial metadata_14055_5626.tmp 6334315 -rw-r--r--  1 root root 0 Nov 15 12:41 metadata_14055_5626.tmp [root@L8 9]# cat metadata_14055_5626.tmp  The previous file is fine:  [root@L8 9]# ls -ial metadata_14055_5625.tmp 6334314 -rw-r--r--  1 root root 12 Nov 15 12:41 metadata_14055_5625.tmp [root@L8 9]# cat metadata_14055_5625.tmp hello world  The error is curious though:  Nov 15 12:41:49 L8 kernel: EXT3-fs error (device emcpowerb1): ext3_readdir:  directory #5750785 contains a hole at offset 4096 Nov 15 12:41:49 L8 kernel: Aborting journal on device emcpowerb1. Nov 15 12:41:49 L8 kernel: ext3_abort called. Nov 15 12:41:49 L8 kernel: EXT3-fs error (device emcpowerb1):  ext3_journal_start_sb: Detected aborted journal Nov 15 12:41:49 L8 kernel: Remounting filesystem read-only Nov 15 12:41:49 L8 kernel: EXT3-fs error (device emcpowerb1) in  start_transaction: Journal has aborted  This is not the directory for our "problem" file.  [root@L8 ~]# debugfs /dev/emcpowerb1 debugfs 1.35 (28-Feb-2004) debugfs:  cd <5750785> debugfs:  pwd [pwd]   INODE: 5750785  PATH: /metadata/3/6 [root]  INODE:      2  PATH: / debugfs:  stat <5750785> Inode: 5750785   Type: directory    Mode:  0755   Flags: 0x0   Generation:  1681403964 User:     0   Group:     0   Size: 1916928 File ACL: 11469322    Directory ACL: 0 Links: 2   Blockcount: 3760 Fragment:  Address: 0    Number: 0    Size: 0 ctime: 0x455b486c -- Wed Nov 15 12:03:40 2006 atime: 0x455b515d -- Wed Nov 15 12:41:49 2006 mtime: 0x455b486c -- Wed Nov 15 12:03:40 2006 BLOCKS: (0-11):11528192-11528203, (IND):11528204, (12-79):11528205-11528272,  (80):11528285, (81):11528414, (82):11528543, (83):1152867 2, (84):11528801, (85):11528930, (86):11529059, (87):11529188, (88):11529317,  (89):11529446, (90):11529575, (91):11529704, (92 ):11529833, (93):11529962, (94):11530091, (95):11530220, (96):11530349,  (97):11530478, (98):11530607, (99):11530736, (100):115 30865, (101):11530994, (102):11531123, (103):11531252, (104):11531381,  (105):11531510, (106):11531639, (107):11531768, (108):1 1531897, (109):11532026, (110):11532155, (111):11532284, (112):11532413,  (113):11532542, (114):11532671, (115):11532800, (116) :11532929, (117):11533058, (118):11533187, (119):11533316, (120):11533445,  (121):11533574, (122):11533703, (123):11533832, (12 4):11533961, (125):11534090, (126):11534219, (127):11534872, (128-156):11534988- 11535016, (157-467):11535024-11535334 TOTAL: 469  Chip...Is there any specific debugfs (logdump?) command I can run to provide  additional "useful" information?   ```  [Comment 42](show_bug.cgi?id=213921#c42)  Tom Coughlan    2006-11-15 22:13:59 UTC  ``` Keith,  I have set up a system in our lab to try to reproduce the problem. I don't have exactly the same HW (no Symmetrix), but I do have a multipath active/active array. I would like to know exactly how you are running the tests to reproduce the problem.    I have:  ioloadgen-1.3.tgz (runs iozone-3-271) tpsreport.sh (metadata exerciser)  Based on what I read in the BZ, I am running these both on two LUNs, each with a separate ext3 fs. Is that all you are doing? Any more than two LUNs needed?  My test ran until the disk was full. It filled up because  tpsreport.sh has quotes around the path name:     rm -rf "${BASE}/*"  so files never get deleted between loops. Did you change this test script?  If you have any more details or suggestions on the best way to reproduce the problem, please let us know.  Tom   ```  [Comment 43](show_bug.cgi?id=213921#c43)  Keith Kearnan    2006-11-16 13:42:12 UTC  ``` Hi Tom,  I did not change the script and I noticed that the file system does fill up  after 48 hours or so in my environment, I simply restart it.    I have two LUNs also (73GB).  Initially I executed tpsreport.sh on one and  ioloadgen on the other.  After 14 hours (not 17 my mistake) the one running  tpsreport.sh went read only.  The other three times it was also the  tpsreport.sh script that went read-only.  Yesterday I combined running both  scripts against the same LUN and it went read-only in about 2 hours.  I left  this LUN in a read-only state for investigation.  I have run both scripts on  the other LUN and it is still running (19 hours and counting).  -Keith   ```  [Comment 44](show_bug.cgi?id=213921#c44)  Chris Snook    2006-11-16 17:41:46 UTC  ``` I've looked at e2images from a couple other customers experiencing the same problem, and they have *not* had null pages on disk, with the exception of one case with a very badly mangled powerpath installation.  In general, it seems we get the "hole" message because ext3 sees an empty buffer that was never filled due to an I/O error.   ```  [Comment 45](show_bug.cgi?id=213921#c45)  Eric Sandeen    2006-11-16 21:23:09 UTC  ``` Can we test this with slightly modified ext3 code?  Unfortunately the "hole" message could be more helpful, if nothing else it could print the block number & device it encountered the problem on... also it would be good to know if ext3_get_blocks_handle or ext3_bread is what failed just ahead of the message.  -Eric   ```  [Comment 46](show_bug.cgi?id=213921#c46)  Keith Kearnan    2006-11-17 19:37:31 UTC  ``` I am willing to test with modified ext3 code.  However, the error does indicate  the device, directory and offset already.  The block number would be nice.  Nov 15 12:41:49 L8 kernel: EXT3-fs error (device emcpowerb1): ext3_readdir:  directory #5750785 contains a hole at offset 4096  In this test emcpowerb1 a meta volume on a DMX that is seen down two paths.  Pseudo name=emcpowerb Symmetrix ID=000187490063 Logical device ID=01B9 state=alive; policy=SymmOpt; priority=0; queued-IOs=0 ============================================================================== ---------------- Host ---------------   - Stor -   -- I/O Path -  -- Stats --- ### HW Path                 I/O Paths    Interf.   Mode    State  Q-IOs Errors ==============================================================================    0 qla2xxx                   sdb       FA  3aA   active  alive      0      0    1 qla2xxx                   sdd       FA  4aA   active  alive      0      0  At this time we are focusing on generating a vmcore.  I have not seen the  problem in the lab since Nov 15 12:41:49.   ```  [Comment 47](show_bug.cgi?id=213921#c47)  Keith Kearnan    2006-11-17 21:35:49 UTC  ``` We experienced another read-only error today at approximately 15:33.  EXT3-fs error (device emcpowera1): ext3_readdir: directory #6225921 contains a  hole at offset 4096  I have placed the log, vmcore and System map files here: ftp://ftp.emc.com/outgoing/213921/   ```  [Comment 48](show_bug.cgi?id=213921#c48)  Chip Coldwell    2006-11-17 21:40:18 UTC  ``` (In reply to [comment #47](show_bug.cgi?id=213921#c47)) > We experienced another read-only error today at approximately 15:33. >  > EXT3-fs error (device emcpowera1): ext3_readdir: directory #6225921 contains a  > hole at offset 4096 >  > I have placed the log, vmcore and System map files here: > ftp://ftp.emc.com/outgoing/213921/  Excellent.  I'm downloading this now, and will post an analysis as soon as I have one.  Chip     ```  [Comment 49](show_bug.cgi?id=213921#c49)  Tom Coughlan    2006-11-20 19:43:04 UTC  ``` I have tried to reporduce the problem using dm-multipath and a Dot Hill RAID box. This is not as performant as the Symmetrix, but is its Active/Active. I have run four over-night runs with a number of configurations, but have not reproduced the failure. I plan to add more adapters and continue testing. It would help me if anyone who has seen this problem on dm-multipath send me the result of:  multipath -ll ls -l /dev/mpath/  I will use that to set up my configuration to match as closely as possible.    ```  [Comment 51](show_bug.cgi?id=213921#c51)  Chip Coldwell    2006-11-20 22:14:44 UTC  ``` (In reply to [comment #48](show_bug.cgi?id=213921#c48)) > (In reply to [comment #47](show_bug.cgi?id=213921#c47)) > > We experienced another read-only error today at approximately 15:33. > >  > > EXT3-fs error (device emcpowera1): ext3_readdir: directory #6225921 contains a  > > hole at offset 4096 > >  > > I have placed the log, vmcore and System map files here: > > ftp://ftp.emc.com/outgoing/213921/ >  > Excellent.  I'm downloading this now, and will post an analysis as soon as I > have one.  I've done some preliminary work on this core.  The panic happened in process context; an "ls" command forked from the script "tpsreport.sh".  The error in the kernel log   EXT3-fs error (device emcpowera1): ext3_readdir: directory #6225921 contains a hole at offset 4096  gives the inode number of a directory inode, and the file position within that directory inode that could not be written.  The error message comes from fs/ext3/dir.c:134 in the function ext3_readdir.  Essentially, what this function was doing when the error occurred is iterating down the inode one buffer (block) at a time and doing an ext3_bread on each buffer.  When ext3_bread returns NULL, it indicates that it was not able to read the buffer, so ext3_readdir generates the message and panics.  As can be seen from the source, there are two ways the ext3_bread function can return NULL:  struct buffer_head *ext3_bread(handle_t *handle, struct inode * inode, 			       int block, int create, int *err) { 	struct buffer_head * bh; 	int prev_blocks;  	prev_blocks = inode->i_blocks;  	bh = ext3_getblk (handle, inode, block, create, err); 	if (!bh) 		return bh; 	if (buffer_uptodate(bh)) 		return bh; 	ll_rw_block (READ, 1, &bh); 	wait_on_buffer (bh); 	if (buffer_uptodate(bh)) 		return bh; 	brelse (bh); 	*err = -EIO; 	return NULL; }  The first is if ext3_getblk itself returns NULL, the second is if after starting the I/O with ll_rw_block(READ, 1, &bh) and waiting for the I/O to complete, the buffer is still not up to date.  In the second case, the value pointed to by the err argument is set to -EIO.  -EIO is -5, or 0xfffffffb in 32-bit hexadecimal.  Since err in ext3_readdir is an automatic variable, it is allocated on the stack, and this stack address is passed in to ext3_bread.  Therefore, if this value was set, it should appear on the stack frame for ext3_readdir, and indeed it does:  #16 [1002c461e00] ext3_readdir at ffffffffa00b4be5     1002c461e08: 0000000000000001 0000000000000000      1002c461e18: 000001007fd3b800 0000000000000000      1002c461e28: 0000000000000000 ffffffff80189618      1002c461e38: 000001002c461f38 fffffffb00000002      1002c461e48: 000001003f082d40 000001007f850a00      1002c461e58: 0000010072f2acc0 ffffffff801d1f8b   crash> rd -32 1002c461e44      1002c461e44:  fffffffb                              ....  Furthermore disassembly of ext3_readdir shows the position of the err variable on the stack to be at offset 0x3c (N.B. x86-64 calling convention puts the first six arguments in %rdi, %rsi, %rdx, %rcx, %r8, %r9, respectively):  0xffffffffa00b4ba0 <ext3_readdir+0x245>:        lea    0x3c(%rsp),%r8  and, indeed, subtracting 0x3c from the address 0x1002c461e44 gives the base of the stack for ext3_readdir  crash> eval 1002c461e44 - 3c hexadecimal: 1002c461e08    (return address is at stack base - 0x8).  This increases my confidence that the code path through ext3_break went via ll_rw_block and wait_on_buffer; additional evidence for this is the presence of io_schedule in the stack trace -- the function wait_on_buffer is an inline around io_schedule.  Conclusion so far: ext3_bread failed because the block could not be read.  At this point, we can find the address of the buffer_head on the stack for ext3_bread; it is at 0x10061c68ea0:  crash> buffer_head 0x10061c68ea0 struct buffer_head {   b_state = 0x18,    b_this_page = 0x10061c68ea0, <== points back to the same buffer_head   b_page = 0x100409932b8,    b_count = {     counter = 0x1   },    b_size = 0x1000, <== (0x1000 == 4096); entire page   b_blocknr = 0xbe7801,    b_data = 0x1006b931000 "",    b_bdev = 0x1003fde4640,    b_end_io = 0xffffffff80178cb2 <end_buffer_read_sync>,    b_private = 0x0,    b_assoc_buffers = {     next = 0x10061c68ee8,      prev = 0x10061c68ee8   } }  From the b_size and b_this_page fields we can see that this block is 4096 bytes, so we are dealing with a blocks that are equal in size to pages (this can vary depending on the block device); blocks exist in 1-1 correspondence with pages.  Furthermore, from the offset in the error message, we can see that this is the second block in the directory inode.  Also note that ll_rw_block sets b_end_io to <end_buffer_read_sync>, further evidence that the code path went via ll_rw_block.  ll_rw_block would have submitted the read request to the block subsystem by calling the submit_bh function, which allocates a bio and sets bio->bi_private to the address of the buffer_head.  So if the bio has not already been recycled, we should be able to locate it by searching kernel memory for occurances of the buffer_head address:  crash> search -k 0000010061c68ea0 1002c461d68: 10061c68ea0 1002c461d98: 10061c68ea0 1002c461dc8: 10061c68ea0 1002c461de8: 10061c68ea0 100409932c8: 10061c68ea0 10040e21580: 10061c68ea0  10061c68ea8: 10061c68ea0 <=== buffer_head itself 1007ffcd260: 10061c68ea0 <=== in the 1-k slab cache  I haven't been able to back-cast any of these addresses into a struct bio (with offset 0x58).  So the bio might already have been recycled when the dump started; I'm still poking around.  Chip   ```  [Comment 52](show_bug.cgi?id=213921#c52)  Tom Coughlan    2006-11-21 14:33:08 UTC  ``` The files from chln106 show  mpath25 -> ../dm-7  and   mpath25 uses hwhandler="1 emc" and is composed of  sda sdb sdk sdt   An earlier sysreport from this system shows these devices are   DGC      Model: LUNZ  Those are Clariion pseudo devices, not legitimate storage devices.   Earlier failure reports in the IT show errors on this device:  Jul 31 12:59:23 chln106 kernel: EXT3-fs error (device dm-7): ext3_readdir: directory #869102 contains a hole at offset 262144  (More recent failures on chln007 also show dm-7. Are these systems identical?)  If this is the current configuration, they should not be doing I/O to dm-7.   On our phone call we heard about two recent failures with dm-multipath on chln106, 11/13 and 11/20. Please post a current sysreport and the logs showing both of these errors.     ```  [Comment 56](show_bug.cgi?id=213921#c56)  Chip Coldwell    2006-11-21 21:39:08 UTC  ``` (In reply to [comment #51](show_bug.cgi?id=213921#c51))  > we should be able to locate it by searching kernel memory for occurances of the > buffer_head address: >  > crash> search -k 0000010061c68ea0 > 1002c461d68: 10061c68ea0 > 1002c461d98: 10061c68ea0 > 1002c461dc8: 10061c68ea0 > 1002c461de8: 10061c68ea0 > 100409932c8: 10061c68ea0 > 10040e21580: 10061c68ea0  > 10061c68ea8: 10061c68ea0 <=== buffer_head itself > 1007ffcd260: 10061c68ea0 <=== in the 1-k slab cache  I've made some more progress in deciphering these:  1002c461d68: 10061c68ea0 <=== bh_wait_queue on kernel stack in io_schedule 1002c461d98: 10061c68ea0 <=== bh_wait_queue on kernel stack in io_schedule 1002c461dc8: 10061c68ea0 <=== close to ffffffffa00b8810 (t) ext3_bread+0x72 1002c461de8: 10061c68ea0 <=== close to ffffffffa00b4be5 (t) ext3_readdir+0x28a 100409932c8: 10061c68ea0 10040e21580: 10061c68ea0  10061c68ea8: 10061c68ea0 <=== buffer_head->b_this_page of the buffer_head itself 1007ffcd260: 10061c68ea0 <=== per-cpu cache in buffer_head slab cache (not interesting)  One thing that's puzzling is that there are *two* bh_wait_queues on the kernel stack in io_schedule.  Chip    ```  [Comment 57](show_bug.cgi?id=213921#c57)  Chip Coldwell    2006-11-21 21:43:47 UTC  ``` (In reply to [comment #56](show_bug.cgi?id=213921#c56)) > 1002c461dc8: 10061c68ea0 <=== close to ffffffffa00b8810 (t) ext3_bread+0x72 > 1002c461de8: 10061c68ea0 <=== close to ffffffffa00b4be5 (t) ext3_readdir+0x28a  These two are just places where the buffer_head was pushed on the kernel stack.  Chip     ```  [Comment 58](show_bug.cgi?id=213921#c58)  Chip Coldwell    2006-11-22 19:16:43 UTC  ``` (In reply to [comment #56](show_bug.cgi?id=213921#c56)) >  > I've made some more progress in deciphering these: >  > 1002c461d68: 10061c68ea0 <=== bh_wait_queue on kernel stack in io_schedule > 1002c461d98: 10061c68ea0 <=== bh_wait_queue on kernel stack in io_schedule  [...]  > One thing that's puzzling is that there are *two* bh_wait_queues on the kernel > stack in io_schedule.  Closer examination of these bh_wait_queues makes them look even more mysterious.  Here's the first one:  crash> bh_wait_queue 1002c461d68 struct bh_wait_queue {   bh = 0x10061c68ea0,    wait = {     flags = 0x0,      task = 0x10007b347f0,      func = 0xffffffff80178ad2 <bh_wake_function>,      task_list = {       next = 0x1002c461db8,        prev = 0x1002c461db8     }   } }  and the second one  crash> bh_wait_queue 1002c461d98 struct bh_wait_queue {   bh = 0x10061c68ea0,    wait = {     flags = 0x0,      task = 0x10007b347f0,      func = 0xffffffff80178ad2 <bh_wake_function>,      task_list = {       next = 0x1002c461db8,        prev = 0x1002c461db8     }   } }  These two are identical copies.  In the case of the second one, the task_list indicates that it is the only element of the list: next == prev == 1002c461d98 + 0x20, where 1002c461d98 is the address of the bh_wait_queue and 0x20 is the offset of the task_list in the bh_wait_queue.  This is what you would expect after a LIST_HEAD_INIT macro.  However, the first bh_wait_queue is identical, but at a different address on the stack.  That seems to indicate a list with two entries on it, namely the first and second bh_wait_queues.  So the two list entries are inconsistent, and I can't figure out how there got to be two of them on the stack yet, anyway.  Chip    ```  [Comment 59](show_bug.cgi?id=213921#c59)  Chris Evich    2006-11-27 19:43:25 UTC  ``` Re: "I can't figure out how there got to be two of them on the stack yet, anyway."  Could it have anything to do with two background "ls -R" processes running simultaneously?  What if they were running on separate CPUs and just happened to be looking at the same block at the same time?    (please forgive my ignorance if this is completely impossible given the kernel code which I don't fully understand).   ```  [Comment 60](show_bug.cgi?id=213921#c60)  Chris Evich    2006-11-28 20:34:47 UTC  ``` Thinking about it some more, I see that my question is impossible as two processes wouldn't share a stack.  Would instrumenting ext3_bread() be of any help in tracking down the source of the duplicate and/or failure mode?   ```  [Comment 61](show_bug.cgi?id=213921#c61)  Fabio Olive Leite    2006-11-28 22:29:50 UTC  ``` Could the two seemingly identical bh_wait_queues be the result of improper clean up before re-issuing a block operation that returned a recoverable error?  Something like a block read times out, ext3 retries it but instead of reusing the bh_wait_queue it allocates a new one and does not initialize it properly. Perhaps some part of the error recovery path was done assuming bh reuse and another part assuming a fresh bh, and the kernel ends up with a new but only partly initialized bh.  Or maybe I should just keep quiet. :)   ```  [Comment 62](show_bug.cgi?id=213921#c62)  Chris Evich    2006-11-29 14:23:38 UTC  ``` I was thinking along the same lines as well, but in this core (triggered upon a failure) the bh data is identical.  If it where as you suggest, I would expect the data to be different.    However, that's not to say- What if different parts of the kernel are looking at the two different bh structs.  At some point, one is considered temporary and freed (leaving the data in memory but not valid).  Subsequently, the in memory data changes (due to another allocation) and freaks out the kernel.  However, also in this case, I would expect to see the two in memory structs data be different, not identical.  Either way, it seems like instrumenting ext3_bread() may give us helpful information, especially since we're fairly sure at what point it's failing.     ```  [Comment 63](show_bug.cgi?id=213921#c63)  Chip Coldwell    2006-11-29 15:35:27 UTC  ``` (In reply to [comment #61](show_bug.cgi?id=213921#c61)) > Could the two seemingly identical bh_wait_queues be the result of improper clean > up before re-issuing a block operation that returned a recoverable error?  No.  First, it's important to understand that the bh_wait_queues are allocated on the stack.  So as soon as we return from the function __wait_on_buffer they should be automatically deallocated by the stack adjustment.  These are local automatic variables on the stack, not kmalloc-ed data on the heap.  So all I can think of is that the compiler did the defer-stack-adjustment optimization.  I'm going to have a look at the assembly so see if that theory makes any sense.  Chip    ```  [Comment 64](show_bug.cgi?id=213921#c64)  Chris Evich    2006-11-29 16:13:45 UTC  ``` Ahh, okay, so it could be that ext3_bread() was called twice on the same block, the stack moved and the previous data while not in use, still existed in memory.  Either way, it's starting to sound as if having these two coppies may be a red herring, no?   ```  [Comment 65](show_bug.cgi?id=213921#c65)  Chris Evich    2006-11-29 17:16:49 UTC  ``` All,       Here's a summary of the vendor call:  +Setting /proc/sys/vm/vfs_cache_pressure to 500 will help force more frequent filesystem metadata flushes. +3 Likely failure scenarios:      1) An Actual underlying I/O error that's not being reported for whatever reason.      2) An error between the driver and filesystem layers.      3) An error related to metadata cache and/or cache read-ahead (FAST FAIL bit set). +Problem has been reproduced at EMC w/ PowerPath and _only_ metadata test script (tpsreport.sh). +Problem seems more easily reproducible when multiple tests are run in parallel on multiple SAN filesystems: +Customer setup-  SAN LUN's -> PVs -> 1 VG -> 16 LVs -> ext3 -> two ioloadgen and one tpsreport instance(s) on each. +At this point, we need to generate/analyze as many vmcores as possible (produced with ext3 error=panic). +Suggested customer testing: disable dm_multipath queue_if_no_path, everything else the same. +Suggested vendor testing: dm_multipath, multiple filesystems, multiple tpsreport instances on each.  (Please remind me if I've left anything out)   ```  [Comment 66](show_bug.cgi?id=213921#c66)  Issue Tracker    2006-11-29 20:24:27 UTC  ``` multipath.conf file for testing against Symetrix should look like this:  devnode_blacklist { 	devnode "^(ram|raw|loop|fd|md|dm-|sr|scd|st)[0-9]*" 	devnode "^hd[a-z][0-9]*" 	devnode "^cciss!c[0-9]d[0-9]*" }  defaults { 	user_friendly_names yes }  devices {        device { 		vendor                  "EMC" 		product                 "SYMMETRIX" 		path_grouping_policy    multibus 		path_checker		    tur 		getuid_callout          "/sbin/scsi_id -g -u -p0x80 -s /block/%n" 		#feature			    "1 queue_if_no_path" 		no_path_retry		    fail 		failback		        immediate        } }   This event sent from IssueTracker by cevich   issue 97316   ```  [Comment 67](show_bug.cgi?id=213921#c67)  Chip Coldwell    2006-11-29 20:42:23 UTC  ``` (In reply to [comment #63](show_bug.cgi?id=213921#c63)) > (In reply to [comment #61](show_bug.cgi?id=213921#c61)) > > Could the two seemingly identical bh_wait_queues be the result of improper clean > > up before re-issuing a block operation that returned a recoverable error? >  > No.  First, it's important to understand that the bh_wait_queues are allocated > on the stack.  So as soon as we return from the function __wait_on_buffer they > should be automatically deallocated by the stack adjustment.  These are local > automatic variables on the stack, not kmalloc-ed data on the heap. >  > So all I can think of is that the compiler did the defer-stack-adjustment > optimization.  I'm going to have a look at the assembly so see if that theory > makes any sense.  Curiouser and curiouser.  The automatic variables in __wait_on_buffer are  	wait_queue_head_t *wqh = bh_waitq_head(bh); 	DEFINE_BH_WAIT(wait, bh);  (the second line is a macro that expands into an automatic variable declaration).  The variable 'wqh' is allocated a register (%r12), and so occupies no space on the stack.  The DEFINE_BH_WAIT macro expands into  	struct bh_wait_queue name = {					\ 		.bh	= b,						\ 		.wait	= {						\ 				.task	= current,			\ 				.flags	= f,				\ 				.func	= bh_wake_function,		\ 				.task_list =				\ 					LIST_HEAD_INIT(name.wait.task_list),\ 			},						\ 	}  The struct has size 0x30 (48 bytes)  crash> bh_wait_queue -o struct bh_wait_queue {    [0x0] struct buffer_head *bh;    [0x8] wait_queue_t wait; } SIZE: 0x30  but the function allocates 0x60 (96 bytes) for the wait queue head:  crash> dis __wait_on_buffer 0xffffffff80178bcf <__wait_on_buffer>:          push   %r12 0xffffffff80178bd1 <__wait_on_buffer+2>:        push   %rbp 0xffffffff80178bd2 <__wait_on_buffer+3>:        push   %rbx 0xffffffff80178bd3 <__wait_on_buffer+4>:        mov    %rdi,%rbx 0xffffffff80178bd6 <__wait_on_buffer+7>:        sub    $0x60,%rsp  [ ... snip ... ]  0xffffffff80178c5e <__wait_on_buffer+143>:      add    $0x60,%rsp 0xffffffff80178c62 <__wait_on_buffer+147>:      pop    %rbx 0xffffffff80178c63 <__wait_on_buffer+148>:      pop    %rbp 0xffffffff80178c64 <__wait_on_buffer+149>:      pop    %r12 0xffffffff80178c66 <__wait_on_buffer+151>:      retq     /me scratches head.  Chip  >  > Chip >      ```  [Comment 68](show_bug.cgi?id=213921#c68)  Chip Coldwell    2006-11-29 21:43:09 UTC  ``` Never underestimate the compiler's capacity to come up with weird sh*t.  I've been studying the disassembled code for __wait_on_buffer and yes, indeed it does allocate *two* bh_wait_queue structs on the stack, then fills in the first one with this:  0xffffffff80178be2 <__wait_on_buffer+19>:       mov    %rbx,(%rsp) 0xffffffff80178be6 <__wait_on_buffer+23>:       movl   $0x0,0x8(%rsp) 0xffffffff80178bee <__wait_on_buffer+31>:       mov    %gs:0x0,%rax 0xffffffff80178bf7 <__wait_on_buffer+40>:       lea    0x30(%rsp),%rdi 0xffffffff80178bfc <__wait_on_buffer+45>:       mov    %rax,0x10(%rsp) 0xffffffff80178c01 <__wait_on_buffer+50>:       movq   $0xffffffff80178ad2,0x18(%rsp) 0xffffffff80178c0a <__wait_on_buffer+59>:       mov    %rsp,%rsi 0xffffffff80178c0d <__wait_on_buffer+62>:       mov    $0xc,%ecx <== set up repz 0xffffffff80178c12 <__wait_on_buffer+67>:       lea    0x20(%rdi),%rax 0xffffffff80178c16 <__wait_on_buffer+71>:       cld     0xffffffff80178c17 <__wait_on_buffer+72>:       mov    %rax,0x20(%rsp) 0xffffffff80178c1c <__wait_on_buffer+77>:       mov    %rax,0x28(%rsp)  and then copies it all into the second one with this:  0xffffffff80178c21 <__wait_on_buffer+82>:       repz movsl %ds:(%esi),%es:(%edi)  ??     ```  [Comment 69](show_bug.cgi?id=213921#c69)  Chip Coldwell    2006-11-29 22:04:43 UTC  ``` (In reply to [comment #64](show_bug.cgi?id=213921#c64)) > Ahh, okay, so it could be that ext3_bread() was called twice on the same block, > the stack moved and the previous data while not in use, still existed in memory. >  Either way, it's starting to sound as if having these two coppies may be a red > herring, no?  You're right, my conclusion is that this is a red herring.  The two copies of the bh_wait_queue on the __wait_on_buffer stack are just an artifact of some weird stuff that the compiler did.  The second of the two copies at 0x30(%rsp) is the real one, and that is the one that is passed in to prepare_to_wait and finish_wait.  Chip     ```  [Comment 70](show_bug.cgi?id=213921#c70)  Chris Evich    2006-11-30 15:23:06 UTC  ``` Though it is curious, is that struct passed-by-value anywhere?  That could also explain two coppies of it, the original one and the one local to a function somewhere.  Either way, could we maybe add some instrumentation just before "brelse (bh);" that would help validate the contents of bh?    Also, I find it curious that we've not been able to repro. this anywhere against a local disk, only SAN devices, and maybe Symetrix SANs exclusivly.  In my mind, that suggests the issue logically _must_ have something to do with driver or hardware interaction somewhere along the way.  Perhaps we should re-re-validate this cannot be reproduced on a local disk (using a beefy system).  On an unrelated note: Wouldn't eliminating the coppying of bh provide us with a performance boost in high metadata load situations?   ```  [Comment 72](show_bug.cgi?id=213921#c72)  Chris Evich    2006-12-01 14:33:29 UTC  ``` Just to summarize:  The focus now is on the following lines of code within ext3_bread():  	ll_rw_block (READ, 1, &bh); 	wait_on_buffer (bh); 	if (buffer_uptodate(bh)) 		return bh; 	brelse (bh); 	*err = -EIO; 	return NULL;  We know err is being set to -EIO, therefor buffer_uptodate(bh) == FALSE.  To me, this reads like a failure with:  1) ll_rw_block() not doing it's job for some reason -and/or- 2) wait_on_buffer() not waiting long enough, or otherwise doing something that results in a difference between the contents of bh and on-disk data -and/or- 3) buffer_uptodate() returning a false-positive when in fact everything is in sync.  Am I missing anything here?    Assuming this issue is definately not reproducable on local disks, what about the behavior of a SAN and/or HBA drivers could cause these functions/macros to not behave expectidly?  Could we instrument the kernel to give us more information on any of these (or other lower-level) conditions?   ```  [Comment 73](show_bug.cgi?id=213921#c73)  Tom Coughlan    2006-12-01 16:08:50 UTC  ``` > Assuming this issue is definately not reproducable on local disks, what about > the behavior of a SAN and/or HBA drivers could cause these functions/macros to > not behave expectidly?  I have been going on the assumption that multipath is integral to this problem. Multipath is exceedingly rare on local, non FC, storage.  Multipath code that is common to PowerPath and dm-multipath is the top candidate.     ```  [Comment 74](show_bug.cgi?id=213921#c74)  Chip Coldwell    2006-12-01 17:15:55 UTC  ``` (In reply to [comment #72](show_bug.cgi?id=213921#c72)) > Just to summarize:  The focus now is on the following lines of code within > ext3_bread(): >  > 	ll_rw_block (READ, 1, &bh); > 	wait_on_buffer (bh); > 	if (buffer_uptodate(bh)) > 		return bh; > 	brelse (bh); > 	*err = -EIO; > 	return NULL; >  > We know err is being set to -EIO, therefor buffer_uptodate(bh) == FALSE.  Yes, exactly.  > To me, this reads like a failure with: >  > 1) ll_rw_block() not doing it's job for some reason  My top suspicion  > -and/or- > 2) wait_on_buffer() not waiting long enough, or otherwise doing something that > results in a difference between the contents of bh and on-disk data  Unlikely, but not impossible.  > -and/or- > 3) buffer_uptodate() returning a false-positive when in fact everything is in sync.  It's just a macro testing a flag, so it's unlikely.  > Could we instrument the kernel to give us more information on any of these (or > other lower-level) conditions?  Yes, and perhaps I'm being a little too careful about this.  There are still some things about the stack trace that I don't completely understand.  Take a look at this:  #13 [1002c461d10] ext3_error at ffffffffa00be647 #14 [1002c461d40] io_schedule at ffffffff803053ef #15 [1002c461de0] ext3_bread at ffffffffa00b8810 #16 [1002c461e00] ext3_readdir at ffffffffa00b4be5  From the code, I would have expected  io_schedule __wait_on_buffer ext3_bread ext3_readdir  or  ext3_error ext3_readdir  so there must be some deferred stack adjustments that are muddying the waters.  I know from the disassembled code that __wait_on_buffer cleans up its stack; that may be why it doesn't appear in the backtrace.  If we want to tackle this bug from another direction, Tom is right; we should look at the multipath code and try to figure out a way for ext3_bread to fail.  It's strange that it only fails for directories, though.  Chip    ```  [Comment 75](show_bug.cgi?id=213921#c75)  Chris Snook    2006-12-01 17:35:37 UTC  ``` It's probably failing for both directories and normal files, but read() will return EIO to userspace, which will then (hopefully) retry the operation.  The problem is that readdir() and getdents() do not have the option of returning EIO to userspace, unless we want to "extend" POSIX in a non-portable fashion.  Thus, the error has to be handled by the kernel (somehow) instead of passing it through to userspace.  We might be able to make this go away by changing how ext3 responds to EIO, but if there's an underlying bug that's causing that, we're just papering over it.   ```  [Comment 76](show_bug.cgi?id=213921#c76)  Chip Coldwell    2006-12-01 17:39:26 UTC  ``` (In reply to [comment #75](show_bug.cgi?id=213921#c75)) > It's probably failing for both directories and normal files, but read() will > return EIO to userspace, which will then (hopefully) retry the operation.  Good point.  Chip    ```  [Comment 77](show_bug.cgi?id=213921#c77)  Chip Coldwell    2006-12-01 18:32:46 UTC  ``` OK, here's what I propose.  Even though Chris Snook's argument in [comment #75](show_bug.cgi?id=213921#c75) is indisputable, I think we should still restrict our instrumentation to catch the failure to read a directory inode since otherwise we risk being overwhelmed with false positives.  So I will instrument the function end_buffer_read_sync to check if the buffer_head is associated with a directory inode and panic if the read operation failed.  That will at least inch us closer to the problem.  Chip    ```  [Comment 78](show_bug.cgi?id=213921#c78)  Chip Coldwell    2006-12-01 20:31:23 UTC  ``` Created [attachment 142617](attachment.cgi?id=142617&action=diff "instrument end_buffer_read_sync") [[details]](attachment.cgi?id=142617&action=edit "instrument end_buffer_read_sync") instrument end_buffer_read_sync   ```  [Comment 79](show_bug.cgi?id=213921#c79)  Chip Coldwell    2006-12-01 20:36:12 UTC  ``` Created [attachment 142618](attachment.cgi?id=142618&action=diff "instrument end_buffer_read_sync; fix missing semicolon") [[details]](attachment.cgi?id=142618&action=edit "instrument end_buffer_read_sync; fix missing semicolon") instrument end_buffer_read_sync; fix missing semicolon   ```  [Comment 82](show_bug.cgi?id=213921#c82)  Chip Coldwell    2006-12-06 21:23:57 UTC  ``` I took a look at the core from the instrumented kernel.  It's definitely the same bug -- ext3_readdir finds a hole in a directory.  The surprising thing is that the  panic came from the ext3_error function ("errors=panic" mount option), not the bugcheck that I added to end_buffer_read_sync.  I verified that the bugcheck was there by disassembling the code for that function in the core.  There are at least two possible explanations for this:  1.  There's something wrong with the instrumentation/bugcheck that I added. 2.  end_buffer_read_sync did not run before the process that was woken up.  If the latter, then this would explain why the process wakes up and the buffer still isn't marked up-to-date -- one of the things end_buffer_read_sync does is to set that flag.  I'm going to double check the logic in my bugcheck.  Chip    ```  [Comment 83](show_bug.cgi?id=213921#c83)  Rick Beldin    2006-12-07 22:37:08 UTC  ``` Just a thought here... if we are wondering if end_buffer_read_sync() has run, is there a way, perhaps using a flag variable or array of some sort, to check if it has run recently?   Would logging the buffer head (bh) and the current jiffies be meaningful?   It might, as we get a panic, give us some detail of the recent operations.     Just a thought at the end of the day.   Quite possibly a silly one... ;-)      ```  [Comment 84](show_bug.cgi?id=213921#c84)  Chip Coldwell    2006-12-08 17:43:41 UTC  ``` Created [attachment 143176](attachment.cgi?id=143176 "memory hog") [[details]](attachment.cgi?id=143176&action=edit "memory hog") memory hog  This is the source code for the memory hog program.  Usage is simple:  # ./memhog 95  (must be run as root!) will consume 95% of available physical memory.  Note that it runs as a daemon, so your command prompt will return immediately, but "top" followed by "M" should show the program memhog with an RSS consuming 95% of available memory.   ```  [Comment 85](show_bug.cgi?id=213921#c85)  Chip Coldwell    2006-12-08 17:51:31 UTC  ``` Some ideas about reproducing this bug:  In every core so far, the problem has been that a low-level block I/O submitted by ext3_readdir to read a directory inode from disk has failed.  So I propose that we modify our strategy to exercise this code path as much as possible.  What we want are directories containing *lots* of files (a wide, not necessarily deep directory hierarchy), and enough memory pressure to prevent all of the directory inodes from sitting in the page cache.  That is the purpose of the memhog program above; you can shrink the page cache by running another program that consumes a large percentage of physical memory.  I also suggest that every "ls -R" should be followed by a "sync" to empty the cache.  Since we could very well be dealing with a synchronization problem, it would be a good idea to have processes creating directory entries at the same time that other processes are listing the directory contents.  Chip    ```  [Comment 86](show_bug.cgi?id=213921#c86)  Chip Coldwell    2006-12-08 18:02:46 UTC  ``` (In reply to [comment #84](show_bug.cgi?id=213921#c84)) > Created an attachment (id=143176) [edit] > memory hog >  > This is the source code for the memory hog program.  Usage is simple: >  > # ./memhog 95  This program should come with a warning label.  It's not hard at all to bring your system to its knees if you specify a percentage that's too high.  Chip    ```  [Comment 87](show_bug.cgi?id=213921#c87)  Eric Sandeen    2006-12-08 18:09:47 UTC  ``` FWIW sync won't empty the cache, it just flushes modified pages to disk, leaving them cached.  But this might help, and force a re-read:  drop_caches -----------  Writing to this will cause the kernel to drop clean caches, dentries and inodes from memory, causing that memory to become free.  To free pagecache:         echo 1 > /proc/sys/vm/drop_caches To free dentries and inodes:         echo 2 > /proc/sys/vm/drop_caches To free pagecache, dentries and inodes:         echo 3 > /proc/sys/vm/drop_caches  As this is a non-destructive operation and dirty objects are not freeable, the user should run `sync' first.   ```  [Comment 88](show_bug.cgi?id=213921#c88)  Rod Nayfield    2006-12-08 19:20:13 UTC  ``` >drop_caches  IIRC this was not in RHEL4, needs RHEL5 or later     ```  [Comment 89](show_bug.cgi?id=213921#c89)  Chris Evich    2006-12-08 19:32:32 UTC  ``` Created [attachment 143187](attachment.cgi?id=143187 "metadata test script take 2") [[details]](attachment.cgi?id=143187&action=edit "metadata test script take 2") metadata test script take 2  An almost complete re-write of the script.  I think you'll find that it spends a great deal more time doing directoy listings.   However, there's only so much testing I can do on my little 1 CPU laptop.  So, please double-check that it's doing what we want it to and feel free to fix it as needed.   ```  [Comment 90](show_bug.cgi?id=213921#c90)  Chip Coldwell    2006-12-08 19:37:22 UTC  ``` (In reply to [comment #87](show_bug.cgi?id=213921#c87)) > FWIW sync won't empty the cache, it just flushes modified pages to disk, leaving > them cached.  Too bad.  But the memhog will empty the cache.  Chip     ```  [Comment 91](show_bug.cgi?id=213921#c91)  Chip Coldwell    2006-12-08 19:46:34 UTC  ``` Created [attachment 143188](attachment.cgi?id=143188 "Install jprobes in end_bio_bh_io_sync and end_buffer_read_sync") [[details]](attachment.cgi?id=143188&action=edit "Install jprobes in end_bio_bh_io_sync and end_buffer_read_sync") Install jprobes in end_bio_bh_io_sync and end_buffer_read_sync  Run this shell script to build and load a jprobe module that will instrument the two functions end_bio_bh_io_sync and end_buffer_read_sync.	We'll get printk output any time the I/O completes unsuccessfully.  My recommendation is to turn off all the other device driver and SCSI midlayer debugging messages for the time being so that we can quickly find the output from the instrumentation in the system logs.  If the script succeeds, the last message it emits is "module loaded".  Otherwise, something went wrong so let me know.  Chip   ```  [Comment 92](show_bug.cgi?id=213921#c92)  Chip Coldwell    2006-12-08 19:50:37 UTC  ``` (In reply to [comment #91](show_bug.cgi?id=213921#c91)) > Created an attachment (id=143188) [edit] > Install jprobes in end_bio_bh_io_sync and end_buffer_read_sync  Another quick note -- this is to be used instead of the debugging kernel posted earlier.  That debugging kernel failed to correctly identify a directory inode; i.e. my instrumentation contained a bug.  Chip    ```  [Comment 93](show_bug.cgi?id=213921#c93)  Chip Coldwell    2006-12-08 20:50:34 UTC  ``` I had a look at the directory inode from the Nov 17 crash (Eric Sandeen is also taking a look) and it certainly does not seem to have a hole at offset 4096 (== 0x1000).  It might also be worth pointing out that this directory was quite large, the inode is 2.5 MiB.  However the failure happened when ext3_readdir was reading the second block.  Chip    ```  [Comment 95](show_bug.cgi?id=213921#c95)  Chris Evich    2006-12-11 18:03:19 UTC  ``` All,       Hot off the press-  EMC reproduced the problem a half-hour before our call.  There were no other reports of reproducing the issue from testing over the weekend.  Keith had some interesting observations of what happened this morning:  0) EMC PowerPath + QLogic test system running w/o jprobes. 1) Running 4 instances of the "old" tpsreport.sh script for the last 3 weeks, no memhog. 2) One instance of tpsreport.sh script was replaced with the "new" version (in bugzilla) at 8:30am EST today. 3) Some time later, Keith logged in to the X console of the box. 4) The system appeared to "Hang" partway through the GNOME splash screen (where it starts up the panel, applets, etc.) 5) System experienced read-only problem shortly thereafter and dumped core at aprox. 11am EST.  We theorized that this repro. might have been "helped" by the extra memory pressure placed on the system by logging into a GNOME session.  Keith will be posting information on obtaining the core (and other details) directly to the Bugzilla.  Chip has been working on tweaking the jprobes for this issue as there appear to be some unintended problems.  He is asking that any tests being restarted with the new "recipe" (below) wait for the new jprobes he is going to post into the bugzilla.  The old jprobes appear to be generating some "false-positive" data.  There was a question regarding using these jprobes in customer production environments and the possible impact.  While not specifically designed to cause crashes, they should be reasonably safe, though may introduce a very slight performance degradation.  However, on production systems _not_ also running with SAN filesystems set to error=panic, having the jprobes (kernel module) loaded will be less useful.  Chip said that nevertheless, it will still provide slightly helpful information if customers understand the above.  Testing update: EMC: Gathering data, will restart testing with new recipe (below) QLogic: testing with QLogic + dm-multipath, no failures, will restart with new recipe. Red Hat: Testing on Clariion + PowerPath, no failures.  Testing with dm-multipath, no failures. Customer Labs: Various test cases, no failures.  Latest test recipe: +Wait for chip to post new jprobes to the Bugzilla +Install new jprobes on test system(s) +Completely disable swap on test system(s) +For test systems with > 4 CPUs and > 4 tpsreport.sh test instances:   -Lower "LISTING_RATIO" to 1, or 2 at the most.   -Concern is that large number of "ls -laR" process will overload the system. +Wait for tpsreport.sh test(s) and system load to "settle down" +Start "inching" up memhog _slowly_:   -Consume "most" of the remaining system memory   -Leave some breathing room   -It's __very__ easy to start triggering the OOM killer. +Go get some coffee (or tea).    ```  [Comment 96](show_bug.cgi?id=213921#c96)  Keith Kearnan    2006-12-11 18:10:08 UTC  ``` We experienced another crash at approximately 10:55AM EST today.  The vmcore  and associated files are located here: ftp://ftp.emc.com/outgoing/213921-2/  This appears almost identical to the Nov 17 crash.  The one exception being the  following in the log immediately before the panic:  warning: many lost ticks. Your time source seems to be instable or some driver is hogging interupts rip __do_softirq+0x4d/0xd0  I assume we can attribute this to the running of the new metadata script from  [comment #89](show_bug.cgi?id=213921#c89) which was running on another file system.   ```  [Comment 97](show_bug.cgi?id=213921#c97)  Chip Coldwell    2006-12-11 21:28:28 UTC  ``` Created [attachment 143334](attachment.cgi?id=143334 "Install jprobes in end_bio_bh_io_sync and end_buffer_read_sync") [[details]](attachment.cgi?id=143334&action=edit "Install jprobes in end_bio_bh_io_sync and end_buffer_read_sync") Install jprobes in end_bio_bh_io_sync and end_buffer_read_sync  This is the updated version of the jprobe module.  It is recommended that this module should only be used with PowerPath; in our experiments dm-multipath will generate tons of spurious output with this module loaded.  Chip   ```  [Comment 98](show_bug.cgi?id=213921#c98)  Keith Kearnan    2006-12-12 13:50:40 UTC  ``` We experienced another crash at approximately 19:05PM EST last night.  The new  jprobe from [comment #97](show_bug.cgi?id=213921#c97) was installed.  The vmcore, log, messages file and dump  of the directory can be located here: ftp://ftp.emc.com/outgoing/213921-3/  end_bio_bh_io_sync: bio 000001002cb00b80 bh 000001005080fdf0 bytes_done  4096err -11 sector 98697767end_buffer_read_sync: page 0000010040682fe0 mapping  000001003f5f5260 inode 000001003f5f5140 uptodate 0 EXT3-fs error (device emcpowerb1): ext3_readdir: directory #6160385 contains a  hole at offset 241664 Kernel panic - not syncing: EXT3-fs (device emcpowerb1): panic forced after  error     ```  [Comment 99](show_bug.cgi?id=213921#c99)  Chris Evich    2006-12-12 15:06:45 UTC  ``` My account reported the following error on a QLogic+PP box they were setting up. Does this error come from the same code-path that we're investigating in this bug?   Dec  7 19:50:38 xxxx299 kernel: EXT3-fs error (device dm-7): ext3_find_entry: reading directory #2444902 offset 1   ```  [Comment 100](show_bug.cgi?id=213921#c100)  Keith Kearnan    2006-12-12 15:52:46 UTC  ``` This appears to be a different area of code (namei.c) that is doing the same  thing (!buffer_uptodate(bh)):      872                 if (!buffer_uptodate(bh)) {     873                         /* read error, skip block & hope for the best */     874                         ext3_error(sb, __FUNCTION__, "reading directory  #%lu "     875                                    "offset %lu\n", dir->i_ino, block);     876                         brelse(bh);     877                         goto next;     878                 }    ```  [Comment 101](show_bug.cgi?id=213921#c101)  Chris Evich    2006-12-12 16:27:24 UTC  ``` Thanks Keith.  The SAN filesystem in question is being used to house revision control data.  I'd immaging that means it's got lots of directories and lots of files in them.  It's good to know there are other ways of hitting the problem via different code-paths as well.  Hopefully analysis of your latest reproductions vmcore/jprobes data will also be fruitful.   ```  [Comment 102](show_bug.cgi?id=213921#c102)  Chip Coldwell    2006-12-12 18:58:59 UTC  ``` (In reply to [comment #99](show_bug.cgi?id=213921#c99)) > My account reported the following error on a QLogic+PP box they were setting up. > Does this error come from the same code-path that we're investigating in this bug? >  >  > Dec  7 19:50:38 xxxx299 kernel: EXT3-fs error (device dm-7): ext3_find_entry: > reading directory #2444902 offset 1  "device dm-7" makes me think this is the device mapper, not PP.  Chip     ```  [Comment 103](show_bug.cgi?id=213921#c103)  Keith Kearnan    2006-12-12 19:02:21 UTC  ``` Hi Chip, To me this just means they have PowerPath devices configured under LVM.  I have  seen this before as well.  A quick "vgdisplay -v" and a review of the /dev tree  will tell the story. -Keith   ```  [Comment 104](show_bug.cgi?id=213921#c104)  Chip Coldwell    2006-12-12 19:33:48 UTC  ``` (In reply to [comment #103](show_bug.cgi?id=213921#c103)) > Hi Chip, > To me this just means they have PowerPath devices configured under LVM.   Oh.  Of course.  Nevermind.  Chip    ```  [Comment 105](show_bug.cgi?id=213921#c105)  Chip Coldwell    2006-12-12 20:30:42 UTC  ``` An examination of the latest core from EMC (which had the jprobe module loaded) indicates that I have been barking up the wrong tree.  Here's what I can say for certain:  1.  The "int err" automatic variable on the stack of the ext3_readdir function contains the value -EIO (0xfffffffb). 2.  The I/O error comes from ext3_bread. 3.  ext3_bread does not follow the code path through ll_rw_block and wait_on_buffer.  The conclusion is that the call to ext3_getblk in ext3_bread is returning NULL, and setting err = -EIO.  I believe the only way that can happen is if ext3_get_block_handle fails, so I would like to instrument this function next.  Chip    ```  [Comment 106](show_bug.cgi?id=213921#c106)  Chris Evich    2006-12-12 21:15:51 UTC  ``` Chip, assuming your writing a new jprobe for ext3_get_block_handle?   ```  [Comment 107](show_bug.cgi?id=213921#c107)  Chip Coldwell    2006-12-12 22:09:59 UTC  ``` Created [attachment 143456](attachment.cgi?id=143456 "probe ext3_get_block_handle in 2.6.9-34.EL x86_64") [[details]](attachment.cgi?id=143456&action=edit "probe ext3_get_block_handle in 2.6.9-34.EL x86_64") probe ext3_get_block_handle in 2.6.9-34.EL x86_64  This jprobe/kprobe combination instruments the function ext3_get_block_handle.  It will cause a kernel panic in that function if the kernel is failing in ext3_get_block_handle.	This version is only for kernel 2.6.9-34.EL on x86_64 (the version EMC has been reproducing on).  I can provide modules for other kernels/archs if there is interest.  Chip   ```  [Comment 108](show_bug.cgi?id=213921#c108)  Keith Kearnan    2006-12-12 23:47:39 UTC  ``` Thanks Chip!  The new jprobe is in and running.  Dec 12 17:57:13 L8 kernel: plant jprobe at ffffffffa00b7c3e  crash> dis ffffffffa00b7c3e 0xffffffffa00b7c3e <ext3_get_block_handle>:     int3   ```  [Comment 111](show_bug.cgi?id=213921#c111)  Keith Kearnan    2006-12-13 12:34:27 UTC  ``` We experienced another crash at approximately 03:45PM EST this morning.  The  new jprobe from [comment #107](show_bug.cgi?id=213921#c107) was installed.  The vmcore, log, messages file and  dump of the directory can be located here: ftp://ftp.emc.com/outgoing/213921-4/  Please note that I had turned up PowerPath debug for most of yesterday so there  are some messages in the log.  I turned off PowerPath debug soon after  installing the new jprobe (18:55PM EST).  While some of the PowerPath debug  messages may seem ominous ("MpIodone error" & "Deadlock potential!") they can  be considered normal with debugging turned on.  As you can see from the large  messages file I've included on the ftp site they log continuously.    <2>EXT3-fs error (device emcpowera1): ext3_readdir: directory #2064385 contains  a hole at offset 4096 Kernel panic - not syncing: EXT3-fs (device emcpowera1): panic forced after  error  This file system was running the "new" tps script.  -Keith   ```  [Comment 112](show_bug.cgi?id=213921#c112)  Keith Kearnan    2006-12-13 16:00:33 UTC  ``` We experienced another crash at approximately 09:24PM EST this morning.  The  new jprobe from [comment #107](show_bug.cgi?id=213921#c107) was installed.  The vmcore, log, messages file and  dump of the directory can be located here: ftp://ftp.emc.com/outgoing/213921-5/  EXT3-fs error (device emcpowerb1): ext3_readdir: directory #6127617 contains a  hole at offset 8192 Kernel panic - not syncing: EXT3-fs (device emcpowerb1): panic forced after  error  -Keith   ```  [Comment 113](show_bug.cgi?id=213921#c113)  Chip Coldwell    2006-12-13 20:50:49 UTC  ``` (In reply to [comment #112](show_bug.cgi?id=213921#c112)) > We experienced another crash at approximately 09:24PM EST this morning.  The  > new jprobe from [comment #107](show_bug.cgi?id=213921#c107) was installed.  The vmcore, log, messages file and  > dump of the directory can be located here: ftp://ftp.emc.com/outgoing/213921-5/ >  > EXT3-fs error (device emcpowerb1): ext3_readdir: directory #6127617 contains a  > hole at offset 8192 > Kernel panic - not syncing: EXT3-fs (device emcpowerb1): panic forced after  > error  From this panic and the previous one, I think I'm still barking up the wrong tree.  It should have panic'd before this, in the jprobe module.  I will turn another rev on that and get it out ASAP.  Also, I wrote a quick and dirty program for reading the directory blocks that you're dumping with debugfs; I'll attach the source code.  Chip    ```  [Comment 114](show_bug.cgi?id=213921#c114)  Chip Coldwell    2006-12-13 20:56:45 UTC  ``` Created [attachment 143555](attachment.cgi?id=143555 "program to read directory inode dump (gcc -o readdir readdir.c)") [[details]](attachment.cgi?id=143555&action=edit "program to read directory inode dump (gcc -o readdir readdir.c)") program to read directory inode dump (gcc -o readdir readdir.c)   ```  [Comment 115](show_bug.cgi?id=213921#c115)  Chip Coldwell    2006-12-13 21:01:25 UTC  ``` Created [attachment 143556](attachment.cgi?id=143556 "program to read directory inode dump (gcc -o readdir readdir.c)") [[details]](attachment.cgi?id=143556&action=edit "program to read directory inode dump (gcc -o readdir readdir.c)") program to read directory inode dump (gcc -o readdir readdir.c)   ```  [Comment 116](show_bug.cgi?id=213921#c116)  Chip Coldwell    2006-12-13 22:18:47 UTC  ``` Created [attachment 143567](attachment.cgi?id=143567 "probe ext3_bread (2.6.9-34.ELsmp x86_64)") [[details]](attachment.cgi?id=143567&action=edit "probe ext3_bread (2.6.9-34.ELsmp x86_64)") probe ext3_bread (2.6.9-34.ELsmp x86_64)  This version probes farther upstream, in ext3_bread.  I'm quite certain that ext3_bread is returning NULL to ext3_readdir, but there are two ways it could do so.	This module sets a probe on each of those two ways, and will bugcheck if either of them happens.  The bugcheck will indicate which one it was.  Chip   ```  [Comment 117](show_bug.cgi?id=213921#c117)  Keith Kearnan    2006-12-14 00:59:22 UTC  ``` Thanks Chip!  The new jprobes/kprobes are in and running.  Dec 13 19:56:01 L8 kernel: plant jprobe at ffffffffa00b879e Dec 13 19:56:01 L8 kernel: plant kprobe at ffffffffa00b87a7 Dec 13 19:56:01 L8 kernel: plant kprobe at ffffffffa00b880b  -Keith    ```  [Comment 118](show_bug.cgi?id=213921#c118)  Keith Kearnan    2006-12-14 10:50:57 UTC  ``` We experienced another crash at approximately 00:47AM EST this morning.  The  new jprobe/kprobe from [comment #116](show_bug.cgi?id=213921#c116) was installed.  The vmcore and log, can be  located here: ftp://ftp.emc.com/outgoing/213921-6/  Kernel BUG at jprobe:22  RIP: 0010:[<ffffffffa03ee045>] <ffffffffa03ee045> {:jprobe:ext3_bread_before_brelse+9}    ```  [Comment 119](show_bug.cgi?id=213921#c119)  Chris Mason    2006-12-14 14:41:16 UTC  ``` Created [attachment 143633](attachment.cgi?id=143633&action=diff "use submit_bh instead of ll_rw_block") [[details]](attachment.cgi?id=143633&action=edit "use submit_bh instead of ll_rw_block") use submit_bh instead of ll_rw_block  This is untested and has not been compiled.  One often (by me anyway) forgotten ll_rw_block feature is that it skips locked buffers, assuming they are already in flight under IO.  It seems possible some part of the kernel is breaking this rule, and ext3_getblk seems like as good a suspect as any.  So, if someone is locking a buffer without starting io on it, ext3_bread may return before any IO has actually been done.  I've no proof this is happening, we haven't been able to reproduce it yet at Oracle.   ```  [Comment 120](show_bug.cgi?id=213921#c120)  Chip Coldwell    2006-12-14 15:20:33 UTC  ``` (In reply to [comment #119](show_bug.cgi?id=213921#c119)) > Created an attachment (id=143633) [edit] > use submit_bh instead of ll_rw_block >  > This is untested and has not been compiled.  One often (by me anyway) forgotten > ll_rw_block feature is that it skips locked buffers, assuming they are already > in flight under IO. >  > It seems possible some part of the kernel is breaking this rule, and > ext3_getblk seems like as good a suspect as any.  So, if someone is locking a > buffer without starting io on it, ext3_bread may return before any IO has > actually been done.  I've no proof this is happening, we haven't been able to > reproduce it yet at Oracle.  It's an interesting idea.  The upstream kernel has introduced a "READ_META" (and additional flag) to indicate that the ll_rw_block is a metadata read.  I haven't found how this is handled differently, yet.  Chip     ```  [Comment 121](show_bug.cgi?id=213921#c121)  Keith Kearnan    2006-12-14 15:26:41 UTC  ``` Hi Chris, Before testing any fixes I'd like to test with additional jprobes/kprobes to  nail down the root cause.  The main reason is that in some cases it takes days  for a repro to occur.  How long to we run with a fix before declaring it  valid?    Also, based on the latest vmcore we are getting past a "wait_on_buffer (bh)"  inside of ext3_bread.  Shouldn't that wait for the locked buffer to complete  its I/O?   ```  [Comment 122](show_bug.cgi?id=213921#c122)  Chris Evich    2006-12-14 15:46:34 UTC  ``` Kearnan_Keith wrote: > Hi folks, >  > With the latest vmore we panic in the jprobe. >  > Kernel BUG at jprobe:22 > invalid operand: 0000 [1] SMP > CPU 3 > Modules linked in: jprobe(U) parport_pc lp parport netconsole netdump autofs4 i2c_dev i2c_core sunrpc ds yenta_socket pcmcia_c > ore emcphr(U) emcpmpap(U) emcpmpaa(U) emcpmpc(U) emcpmp(U) emcp(U) emcplib(U) button battery ac md5 ipv6 ohci_hcd hw_random tg > 3 floppy dm_snapshot dm_zero dm_mirror ext3 jbd dm_mod qla2300 qla2xxx scsi_transport_fc cciss sd_mod scsi_mod > Pid: 3991, comm: ls Tainted: P      2.6.9-34.ELsmp > RIP: 0010:[<ffffffffa03ee045>] <ffffffffa03ee045>{:jprobe:ext3_bread_before_brelse+9} >  > I know the remaining possibilities seem to be: >  > 2) wait_on_buffer() not waiting long enough, or otherwise doing something that > results in a difference between the contents of bh and on-disk data  > -and/or- > 3) buffer_uptodate() returning a false-positive when in fact everything is in sync. >  > Could there be a 4th possibility where in between the following: >  >     926         wait_on_buffer (bh); >     927         if (buffer_uptodate(bh)) >  > the bh is getting altered?  Should a lock_buffer(bh) be inserted here? >  > The __wait_on_buffer comment seems to indicate this is a possibility. >  >     149 /* >     150  * Block until a buffer comes unlocked.  This doesn't stop it >     151  * from becoming locked again - you have to lock it yourself >     152  * if you want to preserve its state. >     153  */ >     154 void __wait_on_buffer(struct buffer_head * bh) >     155 { >     156         wait_queue_head_t *wqh = bh_waitq_head(bh); >     157         DEFINE_BH_WAIT(wait, bh); >     158 >     159         do { >     160                 prepare_to_wait(wqh, &wait.wait, TASK_UNINTERRUPTIBLE); >     161                 if (buffer_locked(bh)) { >     162                         sync_buffer(bh); >     163                         io_schedule(); >     164                 } >     165         } while (buffer_locked(bh)); >     166         finish_wait(wqh, &wait.wait); >     167 } >  > static inline int buffer_uptodate(struct buffer_head * bh) { return test_bit(BH_Uptodate, &bh-&gtb_state); } >  > ... no locking? it's atomic, but no MP protection.   I seem to recall Chip saying that bh is supposed to be locked before the call to ext3_bread, but I could be mistaken.  Either way, I have a good feeling about this line of thinking.  Could this be one of those nassssssty tricksie little Hobbitsesss: wherein locking higher up the call stack is irrelivent because we need to lock in ext3_bread (it may be running concurrently somehow) because the higher up call has already unlocked. ???    Another thing, is there any way the buffer could become unlocked inbetween line 161 and 163 above?  (I'm assuming this lock on bh is some type of mutex and not a "> 1" semephore right?)   ```  [Comment 123](show_bug.cgi?id=213921#c123)  Chip Coldwell    2006-12-14 15:51:17 UTC  ``` (In reply to [comment #121](show_bug.cgi?id=213921#c121)) > Hi Chris, > Before testing any fixes I'd like to test with additional jprobes/kprobes to  > nail down the root cause.  The patch Chris submitted could be considered as a diagnostic.  Basically, it implements the same logic as ll_rw_block, with one important difference.  ll_rw_block skips the buffer_head if it is locked, Chris' version skips the buffer_head if it is up-to-date.  If the bug reproduces with Chris' patch installed, then we know that the problem really is low-level I/O and not buffer locking/synchronization.  Chip   ```  [Comment 124](show_bug.cgi?id=213921#c124)  Chris Mason    2006-12-14 15:54:23 UTC  ``` It seemed strange that we suddenly stopped getting errors from the device  layer.  I just double checked and the end_request: I/O error message only  comes out at the default log level.  Has the console log level been increased to the max on boxes where this has  been reproduced recently?  Otherwise we may be missing messages that point  away from the filesystem.   ```  [Comment 125](show_bug.cgi?id=213921#c125)  Chip Coldwell    2006-12-14 16:04:20 UTC  ``` (In reply to [comment #123](show_bug.cgi?id=213921#c123))  > The patch Chris submitted could be considered as a diagnostic.  Basically, it > implements the same logic as ll_rw_block, with one important difference.  > ll_rw_block skips the buffer_head if it is locked, Chris' version skips the > buffer_head if it is up-to-date.  This thought deserves some fleshing out.  If a buffer is locked, that means an I/O is pending.  When the I/O completes, the buffer will be up-to-date unless the I/O failed.  That, at least, is how it is supposed to work (ref the function end_buffer_read_sync near line 198 of fs/buffer.c).  The ll_rw_block call in ext3_bread will not submit an I/O if the buffer is already locked.  The logic there is correct; if there is already an I/O pending on the buffer, there is no point in submitting another one.  Whether the pending I/O is a read or a write, when it completes the buffer should be up-to-date, unless the I/O fails for some reason.  So we have two possibilities here:  1.  The buffer locking and synchronization is somehow broken. 2.  The I/Os are failing for some reason.  The probability of the second possibility is much higher, since the buffer locking/synchronization is used by all I/O subsystems, not just SANs.  We are only seeing this bug on SANs.  Chip   ```  [Comment 126](show_bug.cgi?id=213921#c126)  Chris Mason    2006-12-14 16:05:01 UTC  ``` Created [attachment 143648](attachment.cgi?id=143648&action=diff "more verbose check") [[details]](attachment.cgi?id=143648&action=edit "more verbose check") more verbose check  This patch is similar, (and also untested/compiled), but if it finds a locked buffer that is not up to date, and the buffer is still not up to date after just waiting on it, a log message will be printed:  ext3 wait after failed lock, not uptodate  It then locks the buffer and tries the read.  If the read produces an up to date buffer, another message is printed.  This way we'll be able to tell if we're hitting this potential bug.  Please review this carefully before using it.   ```  [Comment 127](show_bug.cgi?id=213921#c127)  Keith Kearnan    2006-12-14 16:09:04 UTC  ``` (In reply to [comment #123](show_bug.cgi?id=213921#c123)) > (In reply to [comment #121](show_bug.cgi?id=213921#c121)) > > Hi Chris, > > Before testing any fixes I'd like to test with additional jprobes/kprobes  to  > > nail down the root cause. > The patch Chris submitted could be considered as a diagnostic.  Basically, it > implements the same logic as ll_rw_block, with one important difference.  > ll_rw_block skips the buffer_head if it is locked, Chris' version skips the > buffer_head if it is up-to-date. > If the bug reproduces with Chris' patch installed, then we know that the  problem > really is low-level I/O and not buffer locking/synchronization. > Chip  The only reason I can't totally agree with your conclusion here is because the  patch also adds buffer locking.  So if it fixes it we cannot jump to the  conclusion that the root cause is low-level I/O.   ```  [Comment 128](show_bug.cgi?id=213921#c128)  Chip Coldwell    2006-12-14 16:14:15 UTC  ``` (In reply to [comment #127](show_bug.cgi?id=213921#c127)) > > The only reason I can't totally agree with your conclusion here is because the  > patch also adds buffer locking.  So if it fixes it we cannot jump to the  > conclusion that the root cause is low-level I/O.  It's the same locking that's in ll_rw_block, ported up to ext3_bread.  In fact, you could think of the patch as being a re-implementation of ll_rw_block in ext3_bread for the case of interest (nr == 1, rw == READ), with the one difference I described in [comment #123](show_bug.cgi?id=213921#c123).  However, like I said in [comment #125](show_bug.cgi?id=213921#c125), I think it is more likely that the problem is caused by failing I/O than a buffer locking/synchronization problem, if only because every I/O device in the kernel uses the same buffer synchronization methods.  We could implement the patch from [comment #126](show_bug.cgi?id=213921#c126) in the next kprobe/jprobe version, which might be interesting.  Chip   Chip   ```  [Comment 129](show_bug.cgi?id=213921#c129)  Chris Mason    2006-12-14 16:17:21 UTC  ``` RE: [comment #125](show_bug.cgi?id=213921#c125)  Yes, if a buffer is locked it is supposed to mean an IO is pending.  But, you  only need one caller that thinks locking a buffer means excluding other users  to trigger the problem.  ext3_getblk looks very suspect to me.  It probably is  not possible to trigger that particular bug due to inode semaphores, but  still.  With all of that said, problems at the lower layers are much more likely.   Earlier in the bug it looked like you had jprobes in the end_io routines that  were being called with up_to_date = 0, and then later on we were only able to  see errors higher up the stack in ext3.  Is this true?   ```  [Comment 130](show_bug.cgi?id=213921#c130)  Chip Coldwell    2006-12-14 16:28:55 UTC  ``` (In reply to [comment #129](show_bug.cgi?id=213921#c129)) > RE: [comment #125](show_bug.cgi?id=213921#c125) >  > Yes, if a buffer is locked it is supposed to mean an IO is pending.  But, you  > only need one caller that thinks locking a buffer means excluding other users  > to trigger the problem.  ext3_getblk looks very suspect to me.  Comment above journal_get_create_access in fs/jbd/transaction.c:  /*  * When the user wants to journal a newly created buffer_head  * (ie. getblk() returned a new buffer and we are going to populate it  * manually rather than reading off disk), then we need to keep the  * buffer_head locked until it has been completely filled with new  * data.   The branch in ext3_getblk that executes lock_buffer(bh) is protected by  if (buffer_new(&dummy)).  The logic is contorted, but I think it's correct.  > With all of that said, problems at the lower layers are much more likely.   > Earlier in the bug it looked like you had jprobes in the end_io routines that  > were being called with up_to_date = 0, and then later on we were only able to  > see errors higher up the stack in ext3.  Is this true?  Yes, it is.  But one should never rule out the possibility of bugs in my jprobes ....  Chip    ```  [Comment 131](show_bug.cgi?id=213921#c131)  Keith Kearnan    2006-12-14 16:35:27 UTC  ``` (In reply to [comment #128](show_bug.cgi?id=213921#c128)) > (In reply to [comment #127](show_bug.cgi?id=213921#c127)) > > > > The only reason I can't totally agree with your conclusion here is because  the  > > patch also adds buffer locking.  So if it fixes it we cannot jump to the  > > conclusion that the root cause is low-level I/O. > It's the same locking that's in ll_rw_block, ported up to ext3_bread.  In  fact, > you could think of the patch as being a re-implementation of ll_rw_block in > ext3_bread for the case of interest (nr == 1, rw == READ), with the one > difference I described in [comment #123](show_bug.cgi?id=213921#c123). > However, like I said in [comment #125](show_bug.cgi?id=213921#c125), I think it is more likely that the  problem > is caused by failing I/O than a buffer locking/synchronization problem, if  only > because every I/O device in the kernel uses the same buffer synchronization  methods. > We could implement the patch from [comment #126](show_bug.cgi?id=213921#c126) in the next kprobe/jprobe > version, which might be interesting. > Chip > Chip  OK, I see it.  I look forward to the next jprobe.   ```  [Comment 132](show_bug.cgi?id=213921#c132)  Barry Donahue    2006-12-14 20:56:51 UTC  ``` Keith, I was wondering if I could get a little more information on your configuration and the load you're running.      How much memeory does the system have? Are you running only the exact script that you put in an earlier attachment? Did you add any options to the filesystem other than the default .e.g. the number of inodes?     I would just like to align what I'm running with what has successfully reproduced this in the past.     thanks,   ```  [Comment 133](show_bug.cgi?id=213921#c133)  Keith Kearnan    2006-12-14 21:09:53 UTC  ``` (In reply to [comment #132](show_bug.cgi?id=213921#c132)) > Keith, I was wondering if I could get a little more information on your > configuration and the load you're running.  >    How much memeory does the system have?   2GB  > Are you running only the exact script that you put in an earlier attachment?   I have run a variety of different jobs and combinations but the most  common "set" is below:  I have two LUNs that are configured down two paths each.  One one LUN I run the  script from [comment #89](show_bug.cgi?id=213921#c89) in addition to a single ioloadgen job.  On the second LUN I run the original metadata test script "tpsreport.sh" with  the modification from [comment #42](show_bug.cgi?id=213921#c42).  I also run a single ioloadgen job.  I have tried other thing in order to induce a failure quicker but nothing seems  to really make it happen quicker.  >Did you add any options to the filesystem other than the default .e.g. the  number of inodes?  No, the command I used to create the filesystem: mkfs.ext3 -j /dev/emcpowera1 The command used to mount: mount -o errors=panic /dev/emcpowera1 /test1  >    I would just like to align what I'm running with what has successfully > reproduced this in the past. >    thanks,     ```  [Comment 134](show_bug.cgi?id=213921#c134)  Chip Coldwell    2006-12-14 21:59:47 UTC  ``` (In reply to [comment #126](show_bug.cgi?id=213921#c126)) > Created an attachment (id=143648) [edit] > more verbose check >  > This patch is similar, (and also untested/compiled), but if it finds a locked > buffer that is not up to date, and the buffer is still not up to date after > just waiting on it, a log message will be printed: >  > ext3 wait after failed lock, not uptodate >  > It then locks the buffer and tries the read.  If the read produces an up to > date buffer, another message is printed.  This way we'll be able to tell if > we're hitting this potential bug. >  > Please review this carefully before using it.  +	if (buffer_uptodate(bh)) { +		if (long_wait) +			printk(KERN_CRIT "ext3 after failed lock, now good\n"); +		unlock_buffer(bh); +		return bh; +	}  Unlocking the buffer here instead of in the I/O completion routine seems wrong to me.  On deeper reflection, I'm not sure what we're trying to catch here.  Referring to the original version of ext3_bread, if the buffer we get from ext3_getblk is locked and not uptodate, then ll_rw_block is a no-op, but wait_on_buffer will sleep until the other guy's pending I/O completes.  That's how it should work, right?  We can detect if the buffer is locked before the call to ll_rw_block, but even if it is, it doesn't necessarily indicate a problem.  It just means somebody else started an I/O to the same block first.  Chip     ```  [Comment 135](show_bug.cgi?id=213921#c135)  Chip Coldwell    2006-12-14 22:18:50 UTC  ``` Created [attachment 143707](attachment.cgi?id=143707 "probe ext3_bread every which way (2.6.9-34.ELsmp.x86_64)") [[details]](attachment.cgi?id=143707&action=edit "probe ext3_bread every which way (2.6.9-34.ELsmp.x86_64)") probe ext3_bread every which way (2.6.9-34.ELsmp.x86_64)  This module drops some additional kprobes in the ext3_bread function to determine if it calls ll_rw_block with a locked buffer head, and to determine if the failure of this function is due to an underlying I/O failure or a buffer synchronization problem.  Chip   ```  [Comment 136](show_bug.cgi?id=213921#c136)  Keith Kearnan    2006-12-14 23:37:08 UTC  ``` Thanks Chip! The new jprobe/kprobe (from [comment #135](show_bug.cgi?id=213921#c135)) is installed and running.  Dec 14 18:31:41 L8 kernel: plant kprobe at ffffffffa00b87b8 Dec 14 18:31:41 L8 kernel: plant kprobe at ffffffffa00b87cd Dec 14 18:31:41 L8 kernel: plant kprobe at ffffffffa00b8802 -Keith    ```  [Comment 137](show_bug.cgi?id=213921#c137)  Chris Mason    2006-12-15 01:27:40 UTC  ``` RE: [comment 134](show_bug.cgi?id=213921#c134).  The buffer is always unlocked in the end_io call.  I'm unlocking it inside the  if (buffer_uptodate(bh)) check because no new io is started, and because the  buffer was locked above (either by test_set_buffer_locked or lock_buffer).  You're right, there's no significance to a buffer being locked before  ll_rw_block.  It only matters if it was locked, we wait on it, and it is not  up to date after the wait returns.  That will trigger the first printk.  printk(KERN_CRIT "ext3 wait after failed lock, not uptodate\n");  But, this doesn't indicate an FS error either.  The buffer may not be up to  date because of IO error (block layer bug) or because of someone breaking the  buffer locking rules (probably FS level bug).  In the patch I go ahead and submit the IO again, and do another print if that  produces an up to date buffer.  But, even this doesn't prove an FS bug because  the storage array may have just come back online, or the lower paths may have  worked out whatever problems they had.  The only way to be 100% sure of the IO error is to instrument the end_io  call(s), or lower down the stack.  And please make sure the kernel log level  is set high enough to catch all the messages.   ```  [Comment 138](show_bug.cgi?id=213921#c138)  Keith Kearnan    2006-12-15 01:54:37 UTC  ``` So far...  Dec 14 18:31:41 L8 kernel: plant kprobe at ffffffffa00b87b8 Dec 14 18:31:41 L8 kernel: plant kprobe at ffffffffa00b87cd Dec 14 18:31:41 L8 kernel: plant kprobe at ffffffffa00b8802 Dec 14 18:32:17 L8 kernel: buffer_head 000001005b0a6920 locked before  ll_rw_block <snip> Dec 14 20:51:51 L8 kernel: buffer_head 0000010035936348 locked before  ll_rw_block Dec 14 20:51:51 L8 kernel: buffer_head 00000100359362f0 locked before  ll_rw_block  [root@L8 jprobe-2.6.9-34.EL.x86_64]# cat /var/log/messages | grep buffer_head |  wc -l 321  Not as many as I would have expected.    ```  [Comment 139](show_bug.cgi?id=213921#c139)  Keith Kearnan    2006-12-15 03:08:11 UTC  ``` We experienced a crash at approximately 21:408PM EST.  The new jprobe/kprobe  from [comment #135](show_bug.cgi?id=213921#c135) was installed.  The vmcore and log can be located here:  ftp://ftp.emc.com/outgoing/213921-7/  buffer_head 0000010028986fa8 locked before ll_rw_block buffer_head 0000010028986fa8 not uptodate after wait_on_buffer inode  000001001a06fb18 EXT3-fs error (device emcpowera1): ext3_readdir: directory #7045121 contains a  hole at offset 4096 Kernel panic - not syncing: EXT3-fs (device emcpowera1): panic forced after  error  -Keith    ```  [Comment 141](show_bug.cgi?id=213921#c141)  Chip Coldwell    2006-12-15 14:38:29 UTC  ``` (In reply to [comment #139](show_bug.cgi?id=213921#c139)) > We experienced a crash at approximately 21:408PM EST.  The new jprobe/kprobe  > from [comment #135](show_bug.cgi?id=213921#c135) was installed.  The vmcore and log can be located here:  > ftp://ftp.emc.com/outgoing/213921-7/ >  > buffer_head 0000010028986fa8 locked before ll_rw_block > buffer_head 0000010028986fa8 not uptodate after wait_on_buffer inode  > 000001001a06fb18 > EXT3-fs error (device emcpowera1): ext3_readdir: directory #7045121 contains a  > hole at offset 4096 > Kernel panic - not syncing: EXT3-fs (device emcpowera1): panic forced after  > error  Interesting.  In light of [comment #138](show_bug.cgi?id=213921#c138), we see that having a locked buffer in ext3_bread before issuing ll_rw_block happened harmlessly some hundreds of times.  The at the end it was a precursor to reproducing our bug.  We still don't know if it always happens like this, but it did this time.  Chip    ```  [Comment 142](show_bug.cgi?id=213921#c142)  Eric Sandeen    2006-12-15 14:48:49 UTC  ``` It might possibly be interesting to add the buffer head tracing patch, then if we get this locked buffer and a subsequent problem, we can ASSERT and get a history of where that buffer has been - see if it truly was locked for IO or for some other reason.   ```  [Comment 143](show_bug.cgi?id=213921#c143)  Chris Mason    2006-12-15 14:49:26 UTC  ``` I don't believe the printks from the latest hang rule out io errors from the  device.  I can almost but not quite explain what we're seeing here.  ext3_readdir will do ll_rw_block(READA) for readahead on directory blocks.   READA requests may fail in various ways.  With normal disk setups, most of the  failures are synchronous, the buffer would be locked and unlocked with the  directory semaphore/mutex held, and it would be very difficult to race in and  wait on the buffer during the READA request.  But, the dm/multipath code are much less careful (but still safe) with  bio_rw_ahead() requests, and these also have the fast fail bit set (as noted  earlier here).  The page cache does readahead for files, but it is generally much more careful  about retrying when there are failures.  The ext3/ll_rw_block method is prone  to transient errors like these.  The fix would be my original patch, but I would suggest instrumentation to  make sure these are the failures we're seeing.  The best place to probe would  be the bio_end_io handler used by submit_bh.  One problem with my theory is that it doesn't explain why the probe into the  end_io funcs didn't see the error or why we aren't seeing the end_request I/O  error printk.  Is the EMC driver setting REQ_QUIET on failfast or readahead  bios that fail?  That would at least explain the printk.   ```  [Comment 144](show_bug.cgi?id=213921#c144)  Chris Evich    2006-12-15 14:55:17 UTC  ``` Fascinating.  So does that mean whatever locked the buffer either did so inappropriately, and/or failed to actually sync the disk/buffer, and/or failed to set the flag indicating the buffer is up to date?  If I'm reading this right, doesn't it points to a synchronization problem higher up since we're not seeing the printk's lower down?   ```  [Comment 145](show_bug.cgi?id=213921#c145)  Chris Mason    2006-12-15 15:02:00 UTC  ``` The short answer is...I don't know.  It all makes really good sense except the  part where we don't get printks from ll_rw_block.c.  If we can't explain that,  then the best course is to put unlock tracing into the buffer heads, recording  the eip of the last 5 or 6 people to call unlock_buffer.  I looked this morning for people improperly unlocking buffers without marking  them up to date, but the directory semaphore makes those kinds of races very  very hard to hit.  The fact that we consistently see this on directories makes  readahead sound like a pretty good theory to me.     ```  [Comment 146](show_bug.cgi?id=213921#c146)  Chip Coldwell    2006-12-15 15:08:46 UTC  ``` (In reply to [comment #143](show_bug.cgi?id=213921#c143)) > I don't believe the printks from the latest hang rule out io errors from the  > device.  Certainly not.  > ext3_readdir will do ll_rw_block(READA) for readahead on directory blocks.   > READA requests may fail in various ways.  With normal disk setups, most of the  > failures are synchronous, the buffer would be locked and unlocked with the  > directory semaphore/mutex held, and it would be very difficult to race in and  > wait on the buffer during the READA request. >  > But, the dm/multipath code are much less careful (but still safe) with  > bio_rw_ahead() requests, and these also have the fast fail bit set (as noted  > earlier here).  Well, ext3_bread is definitely waiting for somebody else's I/O to complete, and when it finishes, the I/O has failed.  I think there's a good chance that it's a read-ahead with the fast-fail bit set (the read-ahead issued by ext3_readdir itself seems likely to me, too).  > The fix would be my original patch,  I provisionally disagree.  The upstream kernel has a READ_META flag set in ext3_bread's ll_rw_block.  I'd prefer to emulate the upstream version of the function if the problem doesn't exist there.  > One problem with my theory is that it doesn't explain why the probe into the  > end_io funcs didn't see the error or why we aren't seeing the end_request I/O  > error printk.  Is the EMC driver setting REQ_QUIET on failfast or readahead  > bios that fail?  That would at least explain the printk.  We should clear that flag.  It might also be interesting to plant a probe that printks the addresses of buffer_heads as we submit requests for read-ahead in ext3_readdir.  However, that is likely to generate a lot of output.  Chip   ```  [Comment 147](show_bug.cgi?id=213921#c147)  Chip Coldwell    2006-12-15 15:15:03 UTC  ``` (In reply to [comment #145](show_bug.cgi?id=213921#c145)) > > The fact that we consistently see this on directories makes  > readahead sound like a pretty good theory to me.  We could take out the read-ahead.  Yes, that will change timings and possibly mask the bug, but I still think it would be interesting.  Chip    ```  [Comment 149](show_bug.cgi?id=213921#c149)  Chris Mason    2006-12-15 15:23:53 UTC  ``` As a next course of action I would suggest:  * getting confirmation from EMC about the REQ_QUIET flag * Checking the dmesg buffer in the crash dump for the printks * Instrumenting fs/buffer.c:end_bio_bh_io_sync().  There you can look for  bio_rw_ahead requests that are failing and print the buffer head address.  I would leave the READA in so we can confirm things.   ```  [Comment 150](show_bug.cgi?id=213921#c150)  Chip Coldwell    2006-12-15 15:33:26 UTC  ``` (In reply to [comment #149](show_bug.cgi?id=213921#c149)) > As a next course of action I would suggest: > > * Instrumenting fs/buffer.c:end_bio_bh_io_sync().  There you can look for  > bio_rw_ahead requests that are failing and print the buffer head address.  Good idea.  Chip    ```  [Comment 151](show_bug.cgi?id=213921#c151)  Keith Kearnan    2006-12-15 15:54:48 UTC  ``` (In reply to [comment #149](show_bug.cgi?id=213921#c149)) > As a next course of action I would suggest: > * getting confirmation from EMC about the REQ_QUIET flag  PowerPath 4.5.x does not set the REQ_QUIET flag.     ```  [Comment 152](show_bug.cgi?id=213921#c152)  Chris Mason    2006-12-15 16:53:28 UTC  ``` From [comment #98](show_bug.cgi?id=213921#c98):  end_bio_bh_io_sync: bio 000001002cb00b80 bh 000001005080fdf0 bytes_done  4096 err -11 sector 98697767 end_buffer_read_sync: page 0000010040682fe0  mapping 000001003f5f5260  EIO is -5, -11 is EAGAIN.  Not sure if that is coming from powerpath, qlogic  or the scsi layer.   ```  [Comment 153](show_bug.cgi?id=213921#c153)  Chris Mason    2006-12-15 17:04:48 UTC  ``` ftp://ftp.emc.com/outgoing/213921-3/ still has the data in it.  The EAGAINs  may be coming from __make_request (it uses EWOULDBLOCK which is the same as  EAGAIN).  There are a bunch of these end_bio_bh_io_sync errors, it may be  worthwhile to look in the dump and see if any of them correspond to the hole  bh.   ```  [Comment 154](show_bug.cgi?id=213921#c154)  Chip Coldwell    2006-12-15 18:28:37 UTC  ``` Created [attachment 143795](attachment.cgi?id=143795 "probe ext3_bread and end_bio_bh_io_sync (2.6.9-34.ELsmp.x86_64)") [[details]](attachment.cgi?id=143795&action=edit "probe ext3_bread and end_bio_bh_io_sync (2.6.9-34.ELsmp.x86_64)") probe ext3_bread and end_bio_bh_io_sync (2.6.9-34.ELsmp.x86_64)  This version keeps the kprobes in ext3_bread from the previous version, and adds a jprobe in end_bio_bh_io_sync the drops a printk if a read-ahead completes with -EIO.   ```  [Comment 155](show_bug.cgi?id=213921#c155)  Keith Kearnan    2006-12-15 18:34:17 UTC  ``` Thanks Chip! The jprobe/kprobe from [comment#154](show_bug.cgi?id=213921#c154) is now running. Dec 15 13:32:25 L8 kernel: plant kprobe at ffffffffa00b87b8 Dec 15 13:32:25 L8 kernel: plant kprobe at ffffffffa00b87cd Dec 15 13:32:25 L8 kernel: plant kprobe at ffffffffa00b8802 Dec 15 13:32:25 L8 kernel: plant jprobe at ffffffff80179fbc -Keith   ```  [Comment 156](show_bug.cgi?id=213921#c156)  Chip Coldwell    2006-12-15 18:41:50 UTC  ``` Created [attachment 143801](attachment.cgi?id=143801 "touchup the logic in the end_bio_bh_io_sync jprobe") [[details]](attachment.cgi?id=143801&action=edit "touchup the logic in the end_bio_bh_io_sync jprobe") touchup the logic in the end_bio_bh_io_sync jprobe  Fixup of 143795   ```  [Comment 157](show_bug.cgi?id=213921#c157)  Chris Mason    2006-12-15 19:30:26 UTC  ``` There's only one way I can see to explain this as a READA related bug (without  EIO in end_bio_bh_io_sync)  Somewhere in the path from ll_rw_block(READA) to end_bio_bh_io_sync getting  error -11, the lower layers is putting the IO onto a deferred queue.  One place this happens is while device mapper is taking a snapshot.  If you  snapshot /dev/mapper/foo, all new io to /dev/mapper/foo goes onto a queue  while the the snapshot is being created.  Then the queued io is run from a  different process context than the original submission.   ```  [Comment 158](show_bug.cgi?id=213921#c158)  Keith Kearnan    2006-12-16 16:52:04 UTC  ``` Ugh.  I missed the e-mail regarding the new jprobe from [comment #156](show_bug.cgi?id=213921#c156).  The server crashed at approximately 11:04AM EST this morning with the  jprobe/kprobe from [comment #154](show_bug.cgi?id=213921#c154).  The vmcore and log is here:  ftp://ftp.emc.com/outgoing/213921-8/  buffer_head 00000100297add40 locked before ll_rw_block buffer_head 00000100297add40 not uptodate after wait_on_buffer inode  0000010039b96548 EXT3-fs error (device emcpowera1): ext3_readdir: directory #2588673 contains a  hole at offset 4096 Kernel panic - not syncing: EXT3-fs (device emcpowera1): panic forced after  error  I'll update the bugzilla when I start the test with the touched up jprobe.   ```  [Comment 159](show_bug.cgi?id=213921#c159)  Keith Kearnan    2006-12-16 19:46:31 UTC  ``` The jprobe/kprobe from [comment #156](show_bug.cgi?id=213921#c156) is now running. Dec 16 14:42:59 L8 kernel: plant kprobe at ffffffffa00b87b8 Dec 16 14:42:59 L8 kernel: plant kprobe at ffffffffa00b87cd Dec 16 14:42:59 L8 kernel: plant kprobe at ffffffffa00b8802 Dec 16 14:42:59 L8 kernel: plant jprobe at ffffffff80179fbc -Keith   ```  [Comment 160](show_bug.cgi?id=213921#c160)  Chris Mason    2006-12-16 20:10:45 UTC  ``` From the logs: dm_snapshot and dm_mirror are both linked in.  Is device mapper  (or lvm) being used on the filesystems being exercised?  Are there snapshots  happening on the box during the run (on any ext3 fs)?   ```  [Comment 161](show_bug.cgi?id=213921#c161)  Keith Kearnan    2006-12-17 01:37:43 UTC  ``` (In reply to [comment #160](show_bug.cgi?id=213921#c160)) > From the logs: dm_snapshot and dm_mirror are both linked in.    It is the standard RHEL4u3 install with no modifications to dm.  > Is device mapper (or lvm) being used on the filesystems being exercised?    No.  >Are there snapshots happening on the box during the run (on any ext3 fs)?  No.  [root@L8 ~]# lsmod | grep dm dm_snapshot            18689  0 dm_zero                 3649  0 dm_mirror              29017  0 dm_mod                 67457  6 dm_snapshot,dm_zero,dm_mirror  Just two PowerPath devices:  [root@L8 ~]# powermt display dev=all Pseudo name=emcpowerb Symmetrix ID=000187490063 Logical device ID=01B1 state=alive; policy=SymmOpt; priority=0; queued-IOs=0 ============================================================================== ---------------- Host ---------------   - Stor -   -- I/O Path -  -- Stats --- ### HW Path                 I/O Paths    Interf.   Mode    State  Q-IOs Errors ==============================================================================    0 qla2xxx                   sda       FA  3aA   active  alive      0      0    1 qla2xxx                   sdc       FA  4aA   active  alive      0      0  Pseudo name=emcpowera Symmetrix ID=000187490063 Logical device ID=01B9 state=alive; policy=SymmOpt; priority=0; queued-IOs=3 ============================================================================== ---------------- Host ---------------   - Stor -   -- I/O Path -  -- Stats --- ### HW Path                 I/O Paths    Interf.   Mode    State  Q-IOs Errors ==============================================================================    0 qla2xxx                   sdb       FA  3aA   active  alive      0      0    1 qla2xxx                   sdd       FA  4aA   active  alive      3      0   [root@L8 ~]# df -k | grep emc /dev/emcpowera1       69591480   5635004  60421376   9% /test1 /dev/emcpowerb1       69591480    300692  65755688   1% /test2  [root@L8 ~]# mount | grep emc /dev/emcpowera1 on /test1 type ext3 (rw,errors=panic) /dev/emcpowerb1 on /test2 type ext3 (rw,errors=panic)  -Keith     ```  [Comment 162](show_bug.cgi?id=213921#c162)  Chip Coldwell    2006-12-17 12:47:42 UTC  ``` (In reply to [comment #160](show_bug.cgi?id=213921#c160)) > From the logs: dm_snapshot and dm_mirror are both linked in.  Is device mapper  > (or lvm) being used on the filesystems being exercised?  Are there snapshots  > happening on the box during the run (on any ext3 fs)?  You're referring to your [comment #157](show_bug.cgi?id=213921#c157) here to try to explain why the end_bio_bh_io_sync jprobe didn't fire?  I should point out that the unretouched probe module would only have caught an -EIO failure in end_bio_bh_io_sync.  The touched up version will catch anything but an -EAGAIN (-EWOULDBLOCK) failure, since there are so many of those and we believe they are harmless.  I think we should flog this theory (READA failing fast and causing ext3_bread to fail) a bit more before we give up on it.  However it does seem to be a repeat of our expierence with the jprobe from [comment #91](show_bug.cgi?id=213921#c91).  Chip     ```  [Comment 163](show_bug.cgi?id=213921#c163)  Keith Kearnan    2006-12-17 12:49:57 UTC  ``` Chip...we suffered a mid-air collision a minute ago  :)  We experienced a crash this morning at approximately 01:35AM EST.  The vmcore  and log are here: ftp://ftp.emc.com/outgoing/213921-9/ the jprobe/kprobe from  [comment #156](show_bug.cgi?id=213921#c156) was installed.  buffer_head 0000010014483ce8 locked before ll_rw_block buffer_head 0000010014483ce8 not uptodate after wait_on_buffer inode  000001002f5b8c58 EXT3-fs error (device emcpowera1): ext3_readdir: directory #2080769 contains a  hole at offset 4096 Kernel panic - not syncing: EXT3-fs (device emcpowera1): panic forced after  error  -Keith    ```  [Comment 164](show_bug.cgi?id=213921#c164)  Chris Mason    2006-12-17 14:32:22 UTC  ``` RE: [comment #162](show_bug.cgi?id=213921#c162), I agree the probes right now seem to indicate the only  failures we're getting are -EAGAINs.  I think we need to instrument  the -EAGAINS to see if they are causing the hole panics.  If they are, the only explanation I can see is some kind of deferred  processing from powerpath.     ```  [Comment 166](show_bug.cgi?id=213921#c166)  Chip Coldwell    2006-12-18 18:40:45 UTC  ``` Created [attachment 143921](attachment.cgi?id=143921 "verbose logging in end_bio_bh_io_sync") [[details]](attachment.cgi?id=143921&action=edit "verbose logging in end_bio_bh_io_sync") verbose logging in end_bio_bh_io_sync  This does more verbose logging of failures in end_bio_bh_io_sync.  With a healthy system under I/O load, I get a ton of these:  end_bio_bh_io_sync err = -11 bi_rw = 2 bio 000001001cad5c00 buffer_head 000001001919ff50 page 00000100015be0a8 mapping 000001003750fba0 inode 000001003750fa80 isdir 0  What would be interesting is if one of these came up with "isdir 1" and the inode address is the same as the one reported by the kprobe in ext3_bread. Note that there might be some distance in the log between the two messages.  Chip   ```  [Comment 167](show_bug.cgi?id=213921#c167)  Chip Coldwell    2006-12-18 18:44:00 UTC  ``` (In reply to [comment #166](show_bug.cgi?id=213921#c166)) > > end_bio_bh_io_sync err = -11 bi_rw = 2 bio 000001001cad5c00 buffer_head > 000001001919ff50 page 00000100015be0a8 mapping 000001003750fba0 inode > 000001003750fa80 isdir 0  BTW, this inode is in the kernel-internal bdev filesystem.  I could check for inode->i_ino == 0 to suppress these messages, but maybe it's better to just let it go.  Chip    ```  [Comment 168](show_bug.cgi?id=213921#c168)  Chip Coldwell    2006-12-18 20:00:18 UTC  ``` Created [attachment 143938](attachment.cgi?id=143938&action=diff "turn off read-ahead in ext3_readdir") [[details]](attachment.cgi?id=143938&action=edit "turn off read-ahead in ext3_readdir") turn off read-ahead in ext3_readdir   ```  [Comment 169](show_bug.cgi?id=213921#c169)  Chip Coldwell    2006-12-18 20:02:59 UTC  ``` I built a kernel with the patch in [comment #168](show_bug.cgi?id=213921#c168) for x86_64; it's up at  <http://people.redhat.com/coldwell/bugs/kernel/213921/x86_64/>  I'll cook up another one for i686hugemem.  Chip    ```  [Comment 170](show_bug.cgi?id=213921#c170)  Keith Kearnan    2006-12-18 20:51:14 UTC  ``` Now running with the jprobe/kprobe from [comment #166](show_bug.cgi?id=213921#c166). Dec 18 15:43:01 L8 kernel: plant kprobe at ffffffffa00b87b8 Dec 18 15:43:01 L8 kernel: plant kprobe at ffffffffa00b87cd Dec 18 15:43:01 L8 kernel: plant kprobe at ffffffffa00b8802 Dec 18 15:43:01 L8 kernel: plant jprobe at ffffffff80179fbc -Keith   ```  [Comment 171](show_bug.cgi?id=213921#c171)  Chip Coldwell    2006-12-18 21:30:34 UTC  ``` (In reply to [comment #169](show_bug.cgi?id=213921#c169)) > I built a kernel with the patch in [comment #168](show_bug.cgi?id=213921#c168) for x86_64; it's up at >  > <http://people.redhat.com/coldwell/bugs/kernel/213921/x86_64/> >  > I'll cook up another one for i686hugemem.  <http://people.redhat.com/coldwell/bugs/kernel/213921/i686-hugemem/>    ```  [Comment 172](show_bug.cgi?id=213921#c172)  Keith Kearnan    2006-12-19 13:23:34 UTC  ``` We experienced a crash last night at approximately 20:49 last night.  The  vmcore and log are located here: ftp://ftp.emc.com/outgoing/213921-10/ The jprobe/kprobe from [comment #166](show_bug.cgi?id=213921#c166) was installed.  buffer_head 0000010067d62190 locked before ll_rw_block buffer_head 000001001beea088 locked before ll_rw_block end_bio_bh_io_sync err = -11 bi_rw = 2 bio 000001005759a900 buffer_head  00000100245a7ad8 page 0000010040775378 mapping 00000100332c0820 inode  00000100332c0700 isdir 0 buffer_head 00000100171191e8 locked before ll_rw_block buffer_head 0000010013ecde48 locked before ll_rw_block buffer_head 000001004dfa7ce8 locked before ll_rw_block end_bio_bh_io_sync err = -11 bi_rw = 2 bio 0000010003cd9780 buffer_head  00000100530b11e8 page 0000010040cd4d38 mapping 00000100332c0820 inode  00000100332c0700 isdir 0 buffer_head 0000010006763088 locked before ll_rw_block end_bio_bh_io_sync err = -11 bi_rw = 2 bio 0000010071eb4200 buffer_head  0000010006763088 page 0000010040683b78 mapping 00000100332c0820 inode  00000100332c0700 isdir 0 buffer_head 0000010006763088 not uptodate after wait_on_buffer inode  00000100732f5300 EXT3-fs error (device emcpowera1): ext3_readdir: directory #294914 contains a  hole at offset 4096 Kernel panic - not syncing: EXT3-fs (device emcpowera1): panic forced after  error  -Keith   ```  [Comment 173](show_bug.cgi?id=213921#c173)  Chris Mason    2006-12-19 14:06:58 UTC  ``` Fairly good news I think, this is as close as we can get to showing the failed  buffer. came from a reada.   ```  [Comment 174](show_bug.cgi?id=213921#c174)  Chip Coldwell    2006-12-19 14:36:39 UTC  ``` (In reply to [comment #172](show_bug.cgi?id=213921#c172)) > > buffer_head 0000010006763088 locked before ll_rw_block > end_bio_bh_io_sync err = -11 bi_rw = 2 bio 0000010071eb4200 buffer_head  > 0000010006763088 page 0000010040683b78 mapping 00000100332c0820 inode  > 00000100332c0700 isdir 0 > buffer_head 0000010006763088 not uptodate after wait_on_buffer inode  > 00000100732f5300 > EXT3-fs error (device emcpowera1): ext3_readdir: directory #294914 contains a  > hole at offset 4096 > Kernel panic - not syncing: EXT3-fs (device emcpowera1): panic forced after  > error  This is the important part here -- the buffer head address matches in all three probes (in ext3_bread before ll_rw_block, in end_bio_bh_io_sync, and back in ext3_bread after wait_on_buffer.  And we know it was a read-ahead from the value in bi_rw.  So this is the smoking gun.  Chip    ```  [Comment 175](show_bug.cgi?id=213921#c175)  Chip Coldwell    2006-12-19 14:44:38 UTC  ``` (In reply to [comment #172](show_bug.cgi?id=213921#c172))  > buffer_head 0000010006763088 locked before ll_rw_block > end_bio_bh_io_sync err = -11 bi_rw = 2 bio 0000010071eb4200 buffer_head  > 0000010006763088 page 0000010040683b78 mapping 00000100332c0820 inode  > 00000100332c0700 isdir 0  In fact, this also explains why the previous jprobe didn't catch the error in end_bio_bh_io_sync.  I was only dropping a printk when the inode chased down via   	struct buffer_head *bh = bio->bi_private; 	struct page *page = bh ? bh->b_page : NULL; 	struct address_space *mapping = page ? page->mapping : NULL; 	struct inode *inode = mapping ? mapping->host : NULL;  satisfied S_ISDIR(inode->i_mode).  Of course, it never does, because it is an inode in the kernel-interal bdev filesystem.  So it was a bug in my jprobe.  Chip    ```  [Comment 176](show_bug.cgi?id=213921#c176)  Chris Mason    2006-12-19 15:05:39 UTC  ``` Created [attachment 144006](attachment.cgi?id=144006&action=diff "Fix ext3_bread and ext3_find_entry") [[details]](attachment.cgi?id=144006&action=edit "Fix ext3_bread and ext3_find_entry") Fix ext3_bread and ext3_find_entry  Looking through the other ll_rw_block callers and wait_on_buffer users in ext3, I think these two are the ones that need fixing to deal with failed READAs.  We'll put this patch through paces here, but I wanted to post for review because the error cases will rarely be run.  The smaller alternative fix is to use READ instead of READA in ext3/dir.c.  This will have some performance impact though.   ```  [Comment 177](show_bug.cgi?id=213921#c177)  Chip Coldwell    2006-12-19 15:11:42 UTC  ``` From <http://kerneltrap.org/node/6110>  Ext3 and Read Ahead Posted by saisuman on Friday, January 27, 2006 - 06:54  Was writing a block driver, on which we intended some filesystem to run. So while testing out with ext3, found an interesting problem. While using the filesystem, it threw errors such as:  Directory #11 has a hole at offset 8192. Remounting as read-only  This problem is specific to the way read-ahead is handled by the block layer, and the way the ext3 filesystem uses it.  Read-ahead is an optimisation intended by the filesystem, and a block driver comes to know of it by checking the bio->bi_rw flag. It should be "READA". Now, in 2.6, in case the system is under heavy load, a READA bio can return "EAGAIN" (through the bio_end_io callback) so that the request may be retried.  So sometimes, we do run into this situation. But the problem is that ext3 never expects to handle this problem, because it uses the old ll_rw_block routine, and never checks for EAGAIN. Ideally, it should be patched to use submit_bio, and check for an EAGAIN return value in the callback.  The moral of the story is, if you're writing a filesystem, expect to handle EAGAIN as an error condition if you're using READA for submitting block I/O requests.   ```  [Comment 178](show_bug.cgi?id=213921#c178)  Chris Evich    2006-12-19 15:18:10 UTC  ``` Let's not forget there are likely similar code paths within other filesystem code (i.e. ext2).  Though Chris's proposed patch, if not the methodology at least, seems it would address them AFAIK.  Since we know what to look for in the code, let's be careful there aren't any potential corner cases.  Seems to me the best course of action is to:  A) Wrap our brains around the upstream code. B) Weigh weather or not a fix should diverge/converge/complement upstream C) In parallel to A and B, test the hell out of any and all potential fixes.   ```  [Comment 179](show_bug.cgi?id=213921#c179)  Chip Coldwell    2006-12-19 15:22:02 UTC  ``` On Linus' git tree:  commit d8733c2956968a01394a4d2a9e97a8b431a78776 Author: Andrew Morton <akpm> Date:   Thu Mar 23 03:00:11 2006 -0800      [PATCH] ext3_readdir: use generic readahead          Linus points out that ext3_readdir's readahead only cuts in when     ext3_readdir() is operating at the very start of the directory.  So for large     directories we end up performing no readahead at all and we suck.          So take it all out and use the core VM's page_cache_readahead().  This means     that ext3 directory reads will use all of readahead's dynamic sizing goop.          Note that we're using the directory's filp->f_ra to hold the readahead state,     but readahead is actually being performed against the underlying blockdev's     address_space.  Fortunately the readahead code is all set up to handle this.          Tested with printk.  It works.  I was struggling to find a real workload which     actually cared.          (The patch also exports page_cache_readahead() to GPL modules)          Cc: "Stephen C. Tweedie" <sct>     Signed-off-by: Andrew Morton <akpm>     Signed-off-by: Linus Torvalds <torvalds>   ```  [Comment 180](show_bug.cgi?id=213921#c180)  Chip Coldwell    2006-12-19 15:29:40 UTC  ``` Created [attachment 144007](attachment.cgi?id=144007&action=diff "commit d8733c2956968a01394a4d2a9e97a8b431a78776 from Linus' git tree") [[details]](attachment.cgi?id=144007&action=edit "commit d8733c2956968a01394a4d2a9e97a8b431a78776 from Linus' git tree") commit d8733c2956968a01394a4d2a9e97a8b431a78776 from Linus' git tree  This is the upstream patch from Linus' git tree.  Chip   ```  [Comment 181](show_bug.cgi?id=213921#c181)  Jeff Moyer    2006-12-19 15:33:16 UTC  ``` $ grep READA fs/*/*.c fs/ext3/dir.c:                          ll_rw_block (READA, num, bha); fs/reiserfs/stree.c:        ll_rw_block(READA, 1, bh + j); fs/udf/dir.c:                           ll_rw_block(READA, num, bha); fs/udf/directory.c:                             ll_rw_block(READA, num, bha);  We don't support reiserfs.  I think we do support UDF, though. This looks familiar:  struct buffer_head * udf_bread(struct inode * inode, int block, 	int create, int * err) { 	struct buffer_head * bh = NULL;  	bh = udf_getblk(inode, block, create, err); 	if (!bh) 		return NULL;  	if (buffer_uptodate(bh)) 		return bh; 	ll_rw_block(READ, 1, &bh); 	wait_on_buffer(bh); 	if (buffer_uptodate(bh)) 		return bh; 	brelse(bh); 	*err = -EIO; 	return NULL; }  So maybe we should try to fix this, too.   ```  [Comment 182](show_bug.cgi?id=213921#c182)  Chris Evich    2006-12-19 15:39:08 UTC  ``` Beautiful! I'm assuming that using the more generic page_cache_readahead() would also solve the EIO/EAGAIN issue?   ```  [Comment 183](show_bug.cgi?id=213921#c183)  Chip Coldwell    2006-12-19 15:41:57 UTC  ``` (In reply to [comment #180](show_bug.cgi?id=213921#c180)) > Created an attachment (id=144007) [edit] > commit d8733c2956968a01394a4d2a9e97a8b431a78776 from Linus' git tree >  > This is the upstream patch from Linus' git tree.  This applies to the RHEL-4 head with some fuzz.  I'm building kernels for x86_64 and i686-hugemem.  Would appreciate some test coverage.  Chip   ```  [Comment 184](show_bug.cgi?id=213921#c184)  Chris Mason    2006-12-19 15:51:20 UTC  ``` reiserfs is also affected, I sent this bug number along to the novell guys so  they can fix it up.  For udf, I would just s/READA/READ.   ```  [Comment 185](show_bug.cgi?id=213921#c185)  Jeff Moyer    2006-12-19 15:54:18 UTC  ``` (In reply to [comment #184](show_bug.cgi?id=213921#c184)) > reiserfs is also affected, I sent this bug number along to the novell guys so  > they can fix it up.  For udf, I would just s/READA/READ.  Yes, I'd agree with that solution.   ```  [Comment 186](show_bug.cgi?id=213921#c186)  Chris Mason    2006-12-19 16:05:22 UTC  ``` RE: Using Linus' patch.  I'm not against it, but it is a bigger change than it looks on first glance.   The existing code does logical readahead of the directory.  It maps in the  first set of blocks in the directory and reads those blocks, even if they are  not sequential.  Linus' patch does readahead on the block device.  So, it starts reading at a  specific block on the disk and it reads the disk sequentially.  The blocks it  reads may or may not correspond to the directory.  In some workloads, his patch will perform better, and in others it will be  worse.   ```  [Comment 187](show_bug.cgi?id=213921#c187)  Chip Coldwell    2006-12-19 16:15:00 UTC  ``` (In reply to [comment #186](show_bug.cgi?id=213921#c186)) > RE: Using Linus' patch. >  > In some workloads, his patch will perform better, and in others it will be  > worse.  Andrew Morton's comment, "I was struggling to find a real workload which actually cared" seems to indicate that the performance improvement due to any read-ahead on directories is small.  At any rate, the culture around here is to emulate the mainline kernel as far as possible, so in order to get your patch accepted by our kernel maintainers, I would first have to get is accepted by Anrew Morton and Linus Torvalds.  It's easier to just take the patch they've already included.  Chip    ```  [Comment 188](show_bug.cgi?id=213921#c188)  Chris Mason    2006-12-19 16:32:27 UTC  ``` Yes, Linus' motivation was probably git performance, which isn't typical.  The  existing code really just tries to read small directories all at once, and the  patch is something different.  I'm fine with either patch, just wanted to make sure people ack'd the whole  change.   ```  [Comment 189](show_bug.cgi?id=213921#c189)  Chip Coldwell    2006-12-19 20:56:40 UTC  ``` Sorry this is taking so long.  The first test kernel based off of 2.6.9-34.EL.x86_64 is available at  <http://people.redhat.com/coldwell/bugs/kernel/213921/x86_64/2.6.9-34.EL/kernel-smp-2.6.9-34.213921.x86_64.rpm>  This is the one EMC was most interested in.  I'll post the rest as the builds complete.  Chip   ```  [Comment 190](show_bug.cgi?id=213921#c190)  Keith Kearnan    2006-12-19 21:43:34 UTC  ``` Thanks Chip! I have installed the kernel from [comment #189](show_bug.cgi?id=213921#c189):  [root@L8 ~]# uname -a Linux L8.lss.emc.com 2.6.9-34.213921smp #1 SMP Tue Dec 19 15:10:56 EST 2006  x86_64 x86_64 x86_64 GNU/Linux  I will run with this for a while, I still mounted the file systems with "-o  errors=panic".   ```  [Comment 191](show_bug.cgi?id=213921#c191)  Jeff Moyer    2006-12-19 21:47:42 UTC  ``` Created [attachment 144044](attachment.cgi?id=144044&action=diff "Fail all READA I/Os") [[details]](attachment.cgi?id=144044&action=edit "Fail all READA I/Os") Fail all READA I/Os  This patch may induce the failure more quickly than otherwise possible.  I was certain that I'd be able to reproduce the problem on a local test system using it, but have not been successful thus far.  Could someone at EMC give this patch a try on a known bad kernel to see if the error is triggered more quickly?  If that is the case, then I would recommend adding this patch to the latest kernel that Chip provided in order to more quickly verify that the bug is fixed.   ```  [Comment 192](show_bug.cgi?id=213921#c192)  Jeff Moyer    2006-12-19 21:48:13 UTC  ``` Created [attachment 144045](attachment.cgi?id=144045&action=diff "Fail all READA I/Os") [[details]](attachment.cgi?id=144045&action=edit "Fail all READA I/Os") Fail all READA I/Os  This patch may induce the failure more quickly than otherwise possible.  I was certain that I'd be able to reproduce the problem on a local test system using it, but have not been successful thus far.  Could someone at EMC give this patch a try on a known bad kernel to see if the error is triggered more quickly?  If that is the case, then I would recommend adding this patch to the latest kernel that Chip provided in order to more quickly verify that the bug is fixed.   ```  [Comment 193](show_bug.cgi?id=213921#c193)  Chip Coldwell    2006-12-19 22:02:32 UTC  ``` (In reply to [comment #189](show_bug.cgi?id=213921#c189))  > I'll post the rest as the builds complete.  The rest of the kernels are up under  <http://people.redhat.com/coldwell/bugs/kernel/213921/>  Chip    ```  [Comment 194](show_bug.cgi?id=213921#c194)  Tom Coughlan    2006-12-20 16:14:59 UTC  ``` One remaining question is where the -EAGAIN failure is coming from.   Keith, please ask the PowerPath people to determine if there are any situations where they might generate this.  There were a few reports of the ext3 read-only bug that involved dm-multipath and not PowerPath. We looked at the dm code and did not see the READA/EAGAIN returns, other than the snapshot case that Chris Mason already mentioned. It would be helpful for anyone who is familliar with the dm-multipath cases to find out whether they also had dm snapshot active.   ```  [Comment 195](show_bug.cgi?id=213921#c195)  Chris Mason    2006-12-20 18:49:10 UTC  ``` Jeff's patch in [comment #192](show_bug.cgi?id=213921#c192) should make it fail faster.  We're only doing RA on the first 16 or so blocks, and we start by doing a  bread on the first block.  On a mostly empty filesystem the directory blocks  will probably be sequential, and so all the reada requests will get merged  back into the original bio, and the reada bit will get dropped.  So, if you want to trigger it w/Jeff's patch, completely fill a small FS with  4k files, delete 16 of them, create empty files in a new directory until the  disk is full, unmount, mount, ls -laR  I think I see one other case where dm-multipath will trigger.  It checks for  bio_rw_ahead and will not retry a failed readahead IO on a different path.   This is much less likely to happen, but if ql2xprocessrscn=1 isn't on it might  be easier to hit...    ```  [Comment 196](show_bug.cgi?id=213921#c196)  Chris Evich    2006-12-20 20:50:40 UTC  ``` My customer needs a 32bit i686 2.6.9-42.0.3.ELsmp kernel build with the "upstream patch" applied for testing.   ```  [Comment 198](show_bug.cgi?id=213921#c198)  Keith Kearnan    2006-12-20 21:34:02 UTC  ``` The patched kernel from [comment #189](show_bug.cgi?id=213921#c189) has now been running for 24 hours without  a problem.    I have a system running RHEL4u4 2.6.9-42.0.3.ELsmp x86_64/AMD that should be  available for testing in a day or so.  I'd like a kernel build for that please. Thanks!   ```  [Comment 199](show_bug.cgi?id=213921#c199)  Chip Coldwell    2006-12-20 23:51:07 UTC  ``` (In reply to [comment #196](show_bug.cgi?id=213921#c196)) > My customer needs a 32bit i686 2.6.9-42.0.3.ELsmp kernel build with the > "upstream patch" applied for testing.  <http://people.redhat.com/coldwell/bugs/kernel/213921/i686/2.6.9-42.0.3.EL/>  Chip   ```  [Comment 200](show_bug.cgi?id=213921#c200)  Chip Coldwell    2006-12-20 23:53:48 UTC  ``` (In reply to [comment #198](show_bug.cgi?id=213921#c198)) > The patched kernel from [comment #189](show_bug.cgi?id=213921#c189) has now been running for 24 hours without  > a problem.   >  > I have a system running RHEL4u4 2.6.9-42.0.3.ELsmp x86_64/AMD that should be  > available for testing in a day or so.  I'd like a kernel build for that please. > Thanks!  <http://people.redhat.com/coldwell/bugs/kernel/213921/x86_64/2.6.9-42.0.3.EL/>  Chip     ```  [Comment 201](show_bug.cgi?id=213921#c201)  Chip Coldwell    2006-12-21 15:18:34 UTC  ``` (In reply to [comment #195](show_bug.cgi?id=213921#c195)) > Jeff's patch in [comment #192](show_bug.cgi?id=213921#c192) should make it fail faster. >  > We're only doing RA on the first 16 or so blocks, and we start by doing a  > bread on the first block.  On a mostly empty filesystem the directory blocks  > will probably be sequential, and so all the reada requests will get merged  > back into the original bio, and the reada bit will get dropped.  Good point.  Another reason why this bug was hard to reproduce.  Chip   ```  [Comment 202](show_bug.cgi?id=213921#c202)  Chris Evich    2006-12-21 15:45:23 UTC  ```  Chip mentioned that the "real world" performance impact of not doing any READA's should be fairly minimal.  Behind fixing this bug, customer's data integrity should be our next highest concern.  We need to maintain an extremely low chance of any data-corruptors creeping in.  Customers are also asking for a fix *fast* given the business impact to-date.  Therefor, I'd like to toss this out as an idea:    What if we attempt to measure the performance impact of stripping out READAs?  If it's is extremely low (<1%); then, it's a no-brainer: Get them out of there!  Alternatively, we could add a kernel tunable to switch on/off READAs as needed.  It seems to me, this might be a faster/safer route to solving this bug; and at the same time, avoid introduction of other bugs.  Even if there's a 5% performance trade off, I think many customers would opt against READAs since that will avoid this bug with 100% certainty.  Thoughts?    ```  [Comment 203](show_bug.cgi?id=213921#c203)  Chris Mason    2006-12-21 17:01:28 UTC  ``` With the mainline patch, I believe the risk of corruption is small.  Turning  off the READAs is always an option.  The best case for the reada code would be  doing a single 64k bio for the whole directory instead of 16 4k bios with  reada off.  On my sata drive here, reading sequentially in 64k chunks goes at 51MB/s.   Reading in 4k chunks runs at 15MB/s.  The actual impact will vary greatly with  disk layout and workload, but the most common place people will see it is  while running backups.  If you want to make a hotfix tomorrow that you are sure is 100% safe, turning  off directory readahead isn't a bad option.  For something longer term I think  the mainline patch is a better choice.    ```  [Comment 204](show_bug.cgi?id=213921#c204)  Chris Evich    2006-12-21 18:23:47 UTC  ``` Chris,      I don't mean to sound like I'm attacking your opinion, rather I'm just throwing out potential alternatives.  From the looks of it, stripping out or adding a reada tunable should be fast and easy.  It also wouldn't preclude parallel work on the other option(s).  The crucial bit it would buy us is: time.  From our calls, lots of it will be needed to properly analyze and test with the somewhat "unknown" behavior of the upstream code.  My customers would prefer a fix tomorrow that comes with 100% certainty; as opposed to, a fix a month from now with unknowns.  Also, the behavior of removing reada's will be entirely different on SAN storage.  SAN data is heavily cached on the storage side so the latency should be much lower.  Especially compared to a SATA disk with maybe 16meg of cache.    ```  [Comment 205](show_bug.cgi?id=213921#c205)  Chris Mason    2006-12-21 18:57:39 UTC  ``` I think we all have the same goal of making the customers happy fast, so I'm  only trying to provide some data to help you decide (sorry if it came across  otherwise)  Turning off directory readahead in a hotfix kernel would be acceptable I  think.  It may actually hurt more on the SAN machines than the sata drive  because sending bios down the sata pipe is relatively lightweight.  But it  depends on how quickly the san boxes start their own readahead and other load  for those spindles.  One problem with the tunable is that it doesn't really reduce the testing  load.  It still needs to be verified with readahead on before it can be  shipped.  I would do either the reada off or the mainline patch, but I'll  support whatever decision people here feel is best.      ```  [Comment 206](show_bug.cgi?id=213921#c206)  Keith Kearnan    2006-12-21 21:36:23 UTC  ``` The patched kernel from [comment #189](show_bug.cgi?id=213921#c189) has now been running for 48 hours without  a problem.      ```  [Comment 207](show_bug.cgi?id=213921#c207)  Chris Evich    2006-12-22 19:18:34 UTC  ``` ---------------------- Root cause has been identified after several rounds of focused instrumentation. An upstream patch has been applied to RHEL4 U4 and is currently under heavy testing at EMC and Red Hat. The problem has not been seen in test in over 48 hours, which is promising. (note: EMC was previously able to reproduce the issue within 4-6hours).   However, a longer test period and full regression testing is needed before we can declare victory and approve fixes for production use. In the first week of January, EMC and Red Hat will assess if and in which form the suggested patch will be distributed. ----------------------   ```  [Comment 208](show_bug.cgi?id=213921#c208)  Josef Carlin    2007-01-02 15:47:35 UTC  ``` Thanks to everyone who worked so hard to identify and address this issue. Has it been decided to "emulate the mainline kernel as far as possible, so in order to get your patch accepted by our kernel maintainers?" Where is RedHat at on releasing a patch (or new kernel RPM's) for this issue?    ```  [Comment 209](show_bug.cgi?id=213921#c209)  Chris Evich    2007-01-02 16:02:59 UTC  ```  Efforts over the holidays yielded 9 hours of failure-free testing with the upstream patch.  However, given the impact of this issue, we'd really like to give the fix an extra special pounding.  The next step is to implement another testing-only kernel patch designed to aggravate the original problem.  Once we confirm that the problem is reproducible with it (should only take several seconds), we will apply the upstream fix.  The goal here is to really make sure that we can't hit the same problem via a different route and while under worse-case conditions.   ```  [Comment 210](show_bug.cgi?id=213921#c210)  Chip Coldwell    2007-01-02 16:54:04 UTC  ``` (In reply to [comment #209](show_bug.cgi?id=213921#c209)) > Efforts over the holidays yielded 9 hours of failure-free testing with the > upstream patch.  You mean 9 days, not 9 hours.  Chip    ```  [Comment 211](show_bug.cgi?id=213921#c211)  Chip Coldwell    2007-01-02 16:57:28 UTC  ``` (In reply to [comment #208](show_bug.cgi?id=213921#c208)) > Thanks to everyone who worked so hard to identify and address this issue. Has it > been decided to "emulate the mainline kernel as far as possible, so in order to > get your patch accepted by our kernel maintainers?"  I believe that is the consensus.  Also, the mainline kernel patch presumably will also improve performance.  Chip    ```  [Comment 214](show_bug.cgi?id=213921#c214)  Chris Evich    2007-01-02 18:38:56 UTC  ``` (In reply to [comment #210](show_bug.cgi?id=213921#c210)) > (In reply to [comment #209](show_bug.cgi?id=213921#c209)) > > Efforts over the holidays yielded 9 hours of failure-free testing with the > > upstream patch. >  > You mean 9 days, not 9 hours. >  > Chip >   Yes, sorry about that, my brain is still on a holiday.  9 days of testing is correct.  Our internal tests ran for 11 days with a similar setup, though against a Clariion.     ```  [Comment 216](show_bug.cgi?id=213921#c216)  Chip Coldwell    2007-01-04 15:26:47 UTC  ``` Created [attachment 144802](attachment.cgi?id=144802&action=diff "This is the upstream patch from attachment 144007 adjusted to apply to RHEL4 kernels") [[details]](attachment.cgi?id=144802&action=edit "This is the upstream patch from attachment 144007 adjusted to apply to RHEL4 kernels") This is the upstream patch from [attachment 144007](attachment.cgi?id=144007&action=diff "commit d8733c2956968a01394a4d2a9e97a8b431a78776 from Linus' git tree") [[details]](attachment.cgi?id=144007&action=edit "commit d8733c2956968a01394a4d2a9e97a8b431a78776 from Linus' git tree") adjusted to apply to RHEL4 kernels   ```  [Comment 219](show_bug.cgi?id=213921#c219)  Jay Turner    2007-01-04 16:46:39 UTC  ``` QE ack for RHEL4.5.   ```  [Comment 221](show_bug.cgi?id=213921#c221)  Chris Evich    2007-01-05 17:29:54 UTC  ```  I Built i686 kernels (building x86_64 next) with the "Fail all read-aheads" patch from [comment #192](show_bug.cgi?id=213921#c192).  These kernels should should be able to reproduce on local as well as SAN filesystems.  ALL ext3 read-aheads will fail with this kernel!  Make sure all your non-test filesystems are mounted as ext2 or you probably won't be able to boot.  Please use this kernel in combination with the filesystem setup instructions in [comment #195](show_bug.cgi?id=213921#c195) to verify the problem can be reproduced.    Once that's done, I'll build another round of kernels with both the [comment #192](show_bug.cgi?id=213921#c192) patch and the [attachment #144007](attachment.cgi?id=144007&action=diff "commit d8733c2956968a01394a4d2a9e97a8b431a78776 from Linus' git tree") [[details]](attachment.cgi?id=144007&action=edit "commit d8733c2956968a01394a4d2a9e97a8b431a78776 from Linus' git tree") patch.  Then we'll see for once and for all if it truly fixes the problem for certain.  Kernels are at: <http://people.redhat.com/cevich/stuff/kernel-smp-2.6.9-42.0.3_bz213921c192.EL.i686.rpm> <http://people.redhat.com/cevich/stuff/kernel-hugemem-2.6.9-42.0.3_bz213921c192.EL.i686.rpm>    ```  [Comment 222](show_bug.cgi?id=213921#c222)  Chris Evich    2007-01-05 17:32:22 UTC  ```  Kernel source package at: <http://people.redhat.com/cevich/stuff/kernel-2.6.9-42.0.3_bz213921c192.EL.src.rpm>   ```  [Comment 223](show_bug.cgi?id=213921#c223)  Chris Evich    2007-01-05 18:47:35 UTC  ``` And here are the 64bit packages:  <http://people.redhat.com/cevich/stuff/kernel-2.6.9-42.0.3_bz213921c192.EL.x86_64.rpm> <http://people.redhat.com/cevich/stuff/kernel-smp-2.6.9-42.0.3_bz213921c192.EL.x86_64.rpm>   ```  [Comment 224](show_bug.cgi?id=213921#c224)  Keith Kearnan    2007-01-05 20:04:48 UTC  ``` I installed the kernel from [comment #223](show_bug.cgi?id=213921#c223) and I experienced a crash almost  immediately.  EXT3-fs error (device emcpowerb1): ext3_readdir: directory #6520835 contains a  hole at offset 4096 Kernel panic - not syncing: EXT3-fs (device emcpowerb1): panic forced after  error  ----------- [cut here ] --------- [please bite here ] --------- Kernel BUG at panic:75 invalid operand: 0000 [1] SMP CPU 2 Modules linked in: emcphr(U) emcpmpap(U) emcpmpaa(U) emcpmpc(U) emcpmp(U) emcp (U) emcplib(U) parport_pc lp parport netconsole netdump autofs4 i2c_dev  i2c_core sunrpc ds yenta_socket pcmcia_core button battery ac md5 ipv6 ohci_hcd  hw_random tg3 floppy dm_snapshot dm_zero dm_mirror ext3 jbd dm_mod qla2300  qla2xxx scsi_transport_fc cciss sd_mod scsi_mod Pid: 8512, comm: ls Tainted: P      2.6.9-42.0.3_bz213921c192.ELsmp RIP: 0010:[<ffffffff8013794e>] <ffffffff8013794e>{panic+211} RSP: 0000:0000010041785c18  EFLAGS: 00010286 RAX: 0000000000000056 RBX: ffffffffa00c9e89 RCX: 0000000000000246 RDX: 0000000000009cd3 RSI: 0000000000000246 RDI: ffffffff803e2080 RBP: 0000010025e7f400 R08: 0000000000000004 R09: ffffffffa00c9e89 R10: 0000000000000000 R11: 0000000000000001 R12: 000001007e4bd400 R13: 0000000000000000 R14: 0000010041785f38 R15: 0000010057997488 FS:  0000002a9557e580(0000) GS:ffffffff804e5300(0000) knlGS:00000000f7fd76c0 CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b CR2: 0000000000527070 CR3: 000000003f1b2000 CR4: 00000000000006e0 Process ls (pid: 8512, threadinfo 0000010041784000, task 00000100285917f0) Stack: 0000003000000010 0000010041785cf8 0000010041785c38 ffffffff80138552        0000003000000008 000001007e4bd640 000001003bac0000 0000000000000246        0000000000000004 ffffffffa00c8c95 Call Trace:<ffffffff80138552>{printk+141} <ffffffff8013827a> {release_console_sem+369}        <ffffffff801384a8>{vprintk+498} <ffffffffa00c158b> {:ext3:ext3_handle_error+69}        <ffffffffa00c1718>{:ext3:ext3_error+193} <ffffffff8030ab57> {io_schedule+38}        <ffffffff8017a562>{bh_wake_function+0} <ffffffff8017a562> {bh_wake_function+0}        <ffffffffa00bb810>{:ext3:ext3_bread+114} <ffffffffa00b7be5> {:ext3:ext3_readdir+650}        <ffffffff8018b1c4>{filldir64+0} <ffffffff801d4055> {selinux_file_permission+298}        <ffffffff801859a8>{path_release+12} <ffffffff8018b1c4>{filldir64+0}        <ffffffff8018af03>{vfs_readdir+155} <ffffffff8018b2f4> {sys_getdents64+118}        <ffffffff8011026a>{system_call+126}  Code: 0f 0b 0f e6 31 80 ff ff ff ff 4b 00 31 ff e8 17 c0 fe ff e8 RIP <ffffffff8013794e>{panic+211} RSP <0000010041785c18>    ```  [Comment 225](show_bug.cgi?id=213921#c225)  Chris Evich    2007-01-05 20:08:45 UTC  ``` Great!  Does "almost immediately" mean you went through the filesystem setup and it crashed on an "ls" or that the system crashed on boot?   ```  [Comment 226](show_bug.cgi?id=213921#c226)  Keith Kearnan    2007-01-05 20:15:10 UTC  ``` (In reply to [comment #225](show_bug.cgi?id=213921#c225)) > Great!  Does "almost immediately" mean you went through the filesystem setup  and > it crashed on an "ls" or that the system crashed on boot?  I actually kicked of all the jobs from my usual reproduction steps ([comment  #133](show_bug.cgi?id=213921#c133)).  This is the first time I have seen it crash so quickly so I would say  the "aggravation change" works well.    ```  [Comment 227](show_bug.cgi?id=213921#c227)  Chris Evich    2007-01-05 20:31:29 UTC  ``` Thanks!   I'm building kernels with both patches applied now.  Will post them when done.   ```  [Comment 228](show_bug.cgi?id=213921#c228)  Chip Coldwell    2007-01-05 21:09:13 UTC  ``` (In reply to [comment #195](show_bug.cgi?id=213921#c195)) > Jeff's patch in [comment #192](show_bug.cgi?id=213921#c192) should make it fail faster. >  > We're only doing RA on the first 16 or so blocks, and we start by doing a  > bread on the first block.  On a mostly empty filesystem the directory blocks  > will probably be sequential, and so all the reada requests will get merged  > back into the original bio, and the reada bit will get dropped. >  > So, if you want to trigger it w/Jeff's patch, completely fill a small FS with  > 4k files, delete 16 of them, create empty files in a new directory until the  > disk is full, unmount, mount, ls -laR  I tried it, and much to my surprise I could not reproduce the bug.  I also tried some variations on the formula: remove the first 16 4k files, remove the last 16 4k files, remove 16 random 4k files, remove two groups of 8 4k files, etc. and still no joy (there's an unmount, mke2fs -j, mount, etc in between each of these attempts).  Am I missing something?  Chip   >  > I think I see one other case where dm-multipath will trigger.  It checks for  > bio_rw_ahead and will not retry a failed readahead IO on a different path.   > This is much less likely to happen, but if ql2xprocessrscn=1 isn't on it might  > be easier to hit... >    ```  [Comment 229](show_bug.cgi?id=213921#c229)  Chris Evich    2007-01-05 23:25:46 UTC  ``` (Probably should have picked a faster box to compile these on)  Here are kernels build with both patches applied:  <http://people.redhat.com/cevich/stuff/kernel-smp-2.6.9-42.0.3_bz213921c192c216.EL.i686.rpm> <http://people.redhat.com/cevich/stuff/kernel-hugemem-2.6.9-42.0.3_bz213921c192c216.EL.i686.rpm> <http://people.redhat.com/cevich/stuff/kernel-2.6.9-42.0.3_bz213921c192c216.EL.x86_64.rpm> <http://people.redhat.com/cevich/stuff/kernel-smp-2.6.9-42.0.3_bz213921c192c216.EL.x86_64.rpm>    ```  [Comment 230](show_bug.cgi?id=213921#c230)  Keith Kearnan    2007-01-06 21:56:52 UTC  ``` (In reply to [comment #229](show_bug.cgi?id=213921#c229)) > (Probably should have picked a faster box to compile these on)  Here are  kernels...  Thanks Chris!  I kicked off a test with the kernel from [comment #229](show_bug.cgi?id=213921#c229).  [root@L8 ~]# uname -a Linux L8.lss.emc.com 2.6.9-42.0.3_bz213921c192c216.ELsmp #1 SMP Fri Jan 5  15:47:27 EST 2007 x86_64 x86_64 x86_64 GNU/Linux     ```  [Comment 231](show_bug.cgi?id=213921#c231)  Chris Evich    2007-01-08 19:30:30 UTC  ``` (In reply to [comment #230](show_bug.cgi?id=213921#c230)) > I kicked off a test with the kernel from [comment #229](show_bug.cgi?id=213921#c229).  Is it safe to assume this test ran failure-free for the weekend?  Anyone else have results of testing with this worst-case, testing-only kernel  ( [Comment #229](show_bug.cgi?id=213921#c229) )?    ```  [Comment 232](show_bug.cgi?id=213921#c232)  Keith Kearnan    2007-01-08 19:35:43 UTC  ``` (In reply to [comment #231](show_bug.cgi?id=213921#c231)) > (In reply to [comment #230](show_bug.cgi?id=213921#c230)) > Is it safe to assume this test ran failure-free for the weekend?  Yes.  It is still running. -Keith   ```  [Comment 234](show_bug.cgi?id=213921#c234)  Jason Baron    2007-01-09 21:15:10 UTC  ``` *** [Bug 208879](show_bug.cgi?id=208879 "CLOSED DUPLICATE - file system goes READ-only") has been marked as a duplicate of this bug. ***   ```  [Comment 235](show_bug.cgi?id=213921#c235)  Chris Evich    2007-01-10 14:47:34 UTC  ``` Created [attachment 145256](attachment.cgi?id=145256&action=diff "Patch to replace all READAs with normal READs") [[details]](attachment.cgi?id=145256&action=edit "Patch to replace all READAs with normal READs") Patch to replace all READAs with normal READs  For the record, we've decided not to go with the [comment #216](show_bug.cgi?id=213921#c216) patch as some further discussion illustrated it as moderately risky.	In weighing the critically of this issue, our desire is to fix the problem while introducing the smallest possible risk.  The attached patch accomplishes the high-level intent of the original patch, though in a much safer way.  To summarize, all it does is replace read-ahead requests with normal read requests.	Thus some optimization is preserved while still allowing the requests to fail gracefully thus preventing the "directory hole read-only" condition.  Testing with this patch is currently underway and we believe the outcome will be successful.  Any and all who can test this patch are encouraged to do so.  I will post a link to the kernel packages as well as start building other architecture kernels as time permits.   ```  [Comment 236](show_bug.cgi?id=213921#c236)  Chris Evich    2007-01-10 16:15:17 UTC  ``` Kernel source package including patch from [comment #235](show_bug.cgi?id=213921#c235)  <http://people.redhat.com/cevich/stuff/kernel-2.6.9-42.0.3_bz213921c235.EL.src.rpm>   ```  [Comment 237](show_bug.cgi?id=213921#c237)  Chris Evich    2007-01-10 16:28:10 UTC  ``` Kernel source package including patches from [comment #235](show_bug.cgi?id=213921#c235) and [comment #216](show_bug.cgi?id=213921#c216)  THIS KERNEL IS FOR TESTING ONLY - ALL ext3 READA REQUESTS WILL FAIL (HOWEVER, FILESYSTEMS SHOULD NOT GO READ-ONLY)  <http://people.redhat.com/cevich/stuff/kernel-2.6.9-42.0.3_bz213921c235c216.EL.src.rpm>   ```  [Comment 238](show_bug.cgi?id=213921#c238)  Chris Mason    2007-01-10 19:08:10 UTC  ``` Could someone please summarize the objections to the page cache readahead  patch?  I do agree that s/READA/READ is safe, but I'm curious to hear the  objections.   ```  [Comment 239](show_bug.cgi?id=213921#c239)  Jason Baron    2007-01-10 19:11:41 UTC  ``` committed in stream U5 build 42.40. A test kernel with this patch is available from <http://people.redhat.com/~jbaron/rhel4/>    ```  [Comment 240](show_bug.cgi?id=213921#c240)  Chip Coldwell    2007-01-10 19:23:25 UTC  ``` (In reply to [comment #238](show_bug.cgi?id=213921#c238)) > Could someone please summarize the objections to the page cache readahead  > patch?  I do agree that s/READA/READ is safe, but I'm curious to hear the  > objections.  Stephen Tweedie is quoted below.  On Fri, 2007-01-05 at 14:05 -0500, Jason Baron wrote:  > can you be more specific about what is making you nervous...performance  > issues from too much readahead? I'm trying to better assess the risk of  > this patch for possible inclusion in an asynchronous securrity erratum.  It totally changes the way we're accessing cache for directory buffers. Possible interactions include interference with journal code, or with user code accessing the cache at the same time (eg. dump(8).)  I can't see any reason why it *should* have any problems, but it's precisely the unforeseen problems which get you.  :-)  It's really such a big change in the internal way we do directory reads that I can't see it qualifying as a low-risk change.  --Stephen     ```  [Comment 241](show_bug.cgi?id=213921#c241)  Chris Evich    2007-01-10 19:34:13 UTC  ``` A few compiled kernel packages as per my above comments:  <http://people.redhat.com/cevich/stuff/kernel-smp-2.6.9-42.0.3_bz213921c235.EL.i686.rpm> <http://people.redhat.com/cevich/stuff/kernel-smp-2.6.9-42.0.3_bz213921c235.EL.x86_64.rpm>  and  <http://people.redhat.com/cevich/stuff/kernel-smp-2.6.9-42.0.3_bz213921c235c216.EL.x86_64.rpm> (Both testing and fix patches applied)   ```  [Comment 242](show_bug.cgi?id=213921#c242)  Chris Evich    2007-01-11 14:23:40 UTC  ``` All,       I have been hearing about some confusion regarding the sudden and apparent "last-minute" changes in our approach here.  Please all me to clarify the situation bit further.  It is very important to us and everyone affected by this bug, that we get the fix "right".  After testing the "upstream patch" for this problem, it was determined that it opened up some substantial areas for concern.  More specifically, these are not concerns which translate to the upstream code because the context is different (e.g. there are many other changes as well).  Additionally, there was found to be evidence the "upstream patch" actually causes a rare, but much more severe problem.  Therefor, we felt it best to delay release of the fix such that we can perform additional testing on a _much_ safer fix to this problem.  We are aiming for a much shorter test cycle with this fix because of it's perceived safety.  On that note, testing is underway with the [comment #241](show_bug.cgi?id=213921#c241) kernels, and so far looks promising.  Any and all additional help in testing these kernels is much appreciated.   ```  [Comment 243](show_bug.cgi?id=213921#c243)  Chris Evich    2007-01-11 17:11:06 UTC  ``` (In reply to [comment #241](show_bug.cgi?id=213921#c241)) > A few compiled kernel packages as per my above comments: >  > <http://people.redhat.com/cevich/stuff/kernel-smp-2.6.9-42.0.3_bz213921c235.EL.i686.rpm> > <http://people.redhat.com/cevich/stuff/kernel-smp-2.6.9-42.0.3_bz213921c235.EL.x86_64.rpm> >  > and >  > <http://people.redhat.com/cevich/stuff/kernel-smp-2.6.9-42.0.3_bz213921c235c216.EL.x86_64.rpm> > (Both testing and fix patches applied)  Just to clarify, ignore the first two.  They're the same as what's available from [comment #239](show_bug.cgi?id=213921#c239) and I've removed the files from my people page.  The last one "[bz213921](show_bug.cgi?id=213921 "CLOSED ERRATA - SAN file systems becoming read-only")c235c216", is still there.  The key difference is it has both the fix and the testing-only "fail all READAs" patch applied.  Presumably, the failure should not be reproducable with the former; more importantly, nothing else should break with the later.   ```  [Comment 244](show_bug.cgi?id=213921#c244)  Andrius Benokraitis    2007-01-12 15:32:43 UTC  ``` *** [Bug 207109](show_bug.cgi?id=207109) has been marked as a duplicate of this bug. ***   ```  [Comment 252](show_bug.cgi?id=213921#c252)  Keith Kearnan    2007-01-19 16:19:14 UTC  ``` I have not seen a file system go read-only with any of the kernels that I have  been asked to test: 2.6.9-42.0.3_bz213921c192c216.ELsmp (64 hours) 2.6.9-42.39.ELsct (3 days) 2.6.9-42.0.6 (4 days) Today I am going to start testing with 2.6.9-42.0.7. -Keith   ```  [Comment 255](show_bug.cgi?id=213921#c255)  Andrius Benokraitis    2007-01-24 15:01:18 UTC  ``` FYI, the following public KBASE article has been released as well:  <http://kbase.redhat.com/faq/FAQ_85_9610>   ```  [Comment 261](show_bug.cgi?id=213921#c261)  Red Hat Bugzilla    2007-01-30 14:37:00 UTC  ```  An advisory has been issued which should help the problem described in this bug report. This report is therefore being closed with a resolution of ERRATA. For more information on the solution and/or where to find the updated files, please follow the link below. You may reopen this bug report if the solution does not work for you.  <http://rhn.redhat.com/errata/RHSA-2007-0014.html>    ```  [Comment 270](show_bug.cgi?id=213921#c270)  laurie barry    2007-02-27 19:11:02 UTC  ``` the aforementioned lpfc driver parameter variables did not produce  statistically significant results and are considered unrelated to this issue.   Any driver configuration variable changes should be cleared through the  storage and/or adapter providers.   ```  [Comment 284](show_bug.cgi?id=213921#c284)  Issue Tracker    2007-07-04 10:04:46 UTC  ``` Internal Status set to 'Resolved' Status set to: Closed by Tech Resolution set to: 'Security Errata'  This event sent from IssueTracker by sputhenp   issue 111261   ```  [Comment 288](show_bug.cgi?id=213921#c288)  Craig Bogovich    2007-11-09 20:53:08 UTC  ``` We are experiencing a similar issue.  File systems from both clarion and  symmetrix SANs go readonly from time to time.  The syslogs show the following  errors:    Aug 21 00:02:28 lndb004 EXT3-fs error (device dm-9) in  start_transaction: Journal has aborted.  We are on version 2.6.9-42.0.3.ELsmp.  How do we confirm we are experiencing this bug?  Is there a test case we can  use to attempt to reproduce so that we know the fix works?    ```  [Comment 289](show_bug.cgi?id=213921#c289)  Chris Evich    2007-11-09 21:44:58 UTC  ``` Craig,       A filesystem can go readonly for many reasons.  This bug documents discovery and resolution of one particular problem within the kernel's ext3 code.  I recommend updating to a later kernel, if the problem doesn't go away then please contact support.  They will be able to assist in determining weather or not this bug is your underlying problem or not.   ```  [Comment 290](show_bug.cgi?id=213921#c290)  Chris Snook    2007-11-10 00:09:37 UTC  ``` Craig,  If you're not seeing any errors near that message, you're probably hitting something else.  Temporally speaking, there should be other errors before it if you're hitting this bug, but since the message you've quoted would probably come from a different thread from the one actually hitting the bug directly, the error messages could end up out of order in the log.  This bug is fixed in 2.6.9-42.0.8.EL, so if you're still having the problem on that kernel or later, it's definitely something else.  If the problem is occurring inside VMware guests, it may be due to a different bug which is fixed in the U5 kernel, version 2.6.9-55.EL.   ```  [Comment 291](show_bug.cgi?id=213921#c291)  Chris Snook    2007-11-10 00:17:13 UTC  ``` I forgot to mention, if you want to try reproducing this bug, try running the multi-instance iozone script and the metadata test script attached to this bug.  Basically, if you create an intense I/O load, and then do a whole lot of metadata operations, and keep doing this for a very long time, you'll eventually hit this bug, if your systems are susceptible to it.  In lab testing it took anywhere from an hour to a day to trigger.   ``` |  |
| --- | --- |

---

| Note You need to [log in](show_bug.cgi?id=213921&GoAheadAndLogIn=1) before you can comment on or make changes to this bug. |
| --- |

---

[Privacy](page.cgi?id=redhat/privacy.html)
[Contact](page.cgi?id=redhat/contact.html)
[FAQ](page.cgi?id=faq.html)
[Legal](page.cgi?id=terms-conditions.html)



=== Content from rhn.redhat.com_3706ea5b_20250125_174319.html ===

Note: Our personalized web services require that your browser be enabled for JavaScript and cookies

[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

[Red Hat Product Errata](/errata)
RHSA-2007:0014 - Security Advisory

Issued:
2007-01-30
Updated:
2007-01-30
# RHSA-2007:0014 - Security Advisory

* [Overview](#overview)
* [Updated Packages](#packages)

## Synopsis

Important: kernel security update

## Type/Severity

Security Advisory: Important

## Red Hat Insights patch analysis

Identify and remediate systems affected by this advisory.

[View affected systems](https://console.redhat.com/insights/patch/advisories/RHSA-2007%3A0014)

## Topic

Updated kernel packages that fix several security issues in the Red Hat
Enterprise Linux 4 kernel are now available.

This security advisory has been rated as having important security impact
by the Red Hat Security Response Team.

## Description

The Linux kernel handles the basic functions of the operating system.

These new kernel packages contain fixes for the security issues described
below:

* a flaw in the get\_fdb\_entries function of the network bridging support

that allowed a local user to cause a denial of service (crash) or allow a
potential privilege escalation (CVE-2006-5751, Important)

* an information leak in the \_block\_prepare\_write function that allowed a

local user to read kernel memory (CVE-2006-4813, Important)

* an information leak in the copy\_from\_user() implementation on s390 and

s390x platforms that allowed a local user to read kernel memory
(CVE-2006-5174, Important)

* a flaw in the handling of /proc/net/ip6\_flowlabel that allowed a local

user to cause a denial of service (infinite loop) (CVE-2006-5619, Important)

* a flaw in the AIO handling that allowed a local user to cause a denial of

service (panic) (CVE-2006-5754, Important)

* a race condition in the mincore system core that allowed a local user to

cause a denial of service (system hang) (CVE-2006-4814, Moderate)

* a flaw in the ELF handling on ia64 and sparc architectures which

triggered a cross-region memory mapping and allowed a local user to cause a
denial of service (CVE-2006-4538, Moderate)

* a flaw in the dev\_queue\_xmit function of the network subsystem that

allowed a local user to cause a denial of service (data corruption)
(CVE-2006-6535, Moderate)

* a flaw in the handling of CAPI messages over Bluetooth that allowed a

remote system to cause a denial of service or potential code execution.
This flaw is only exploitable if a privileged user establishes a connection
to a malicious remote device (CVE-2006-6106, Moderate)

* a flaw in the listxattr system call that allowed a local user to cause a

denial of service (data corruption) or potential privilege escalation. To
successfully exploit this flaw the existence of a bad inode is required
first (CVE-2006-5753, Moderate)

* a flaw in the \_\_find\_get\_block\_slow function that allowed a local

privileged user to cause a denial of service (CVE-2006-5757, Low)

* various flaws in the supported filesystems that allowed a local

privileged user to cause a denial of service (CVE-2006-5823, CVE-2006-6053,
CVE-2006-6054, CVE-2006-6056, Low)

In addition to the security issues described above, fixes for the following
bugs were included:

* initialization error of the tg3 driver with some BCM5703x network card
* a memory leak in the audit subsystem
* x86\_64 nmi watchdog timeout is too short
* ext2/3 directory reads fail intermittently

Red Hat would like to thank Dmitriy Monakhov and Kostantin Khorenko for
reporting issues fixed in this erratum.

All Red Hat Enterprise Linux 4 users are advised to upgrade their kernels
to the packages associated with their machine architecture and
configurations as listed in this erratum.

## Solution

Before applying this update, make sure all previously released errata
relevant to your system have been applied.

This update is available via Red Hat Network. To use Red Hat Network,
launch the Red Hat Update Agent with the following command:

up2date

This will start an interactive process that will result in the appropriate
RPMs being upgraded on your system.

## Affected Products

* Red Hat Enterprise Linux Server 4 x86\_64
* Red Hat Enterprise Linux Server 4 ia64
* Red Hat Enterprise Linux Server 4 i386
* Red Hat Enterprise Linux Workstation 4 x86\_64
* Red Hat Enterprise Linux Workstation 4 ia64
* Red Hat Enterprise Linux Workstation 4 i386
* Red Hat Enterprise Linux Desktop 4 x86\_64
* Red Hat Enterprise Linux Desktop 4 i386
* Red Hat Enterprise Linux for IBM z Systems 4 s390x
* Red Hat Enterprise Linux for IBM z Systems 4 s390
* Red Hat Enterprise Linux for Power, big endian 4 ppc

## Fixes

* [BZ - 180663](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=180663)
  - CVE-2006-4814 Race condition in mincore can cause "ps -ef" to hang
* [BZ - 205335](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=205335)
  - CVE-2006-4538 Local DoS with corrupted ELF
* [BZ - 206328](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=206328)
  - CVE-2006-5757 Linux kernel Filesystem Mount Dead Loop
* [BZ - 207463](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=207463)
  - CVE-2006-4813 Information leak in \_\_block\_prepare\_write()
* [BZ - 209435](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=209435)
  - CVE-2006-5174 copy\_from\_user information leak on s390
* [BZ - 212144](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=212144)
  - CVE-2006-6535 unbalanced local\_bh\_enable() in dev\_queue\_xmit()
* [BZ - 213214](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=213214)
  - CVE-2006-5619 Lockup via /proc/net/ip6\_flowlabel
* [BZ - 213921](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=213921)
  - SAN file systems becoming read-only
* [BZ - 214288](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=214288)
  - CVE-2006-5757 ISO9660 \_\_find\_get\_block\_slow() denial of service
* [BZ - 216452](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=216452)
  - CVE-2006-5751 Linux kernel get\_fdb\_entries() integer overflow
* [BZ - 216958](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=216958)
  - CVE-2006-5823 zlib\_inflate memory corruption
* [BZ - 217011](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=217011)
  - CVE-2006-6056 SELinux superblock\_doinit denial of service
* [BZ - 217021](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=217021)
  - CVE-2006-6054 ext2\_check\_page denial of service
* [BZ - 217030](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=217030)
  - CVE-2006-6053 ext3fs\_dirhash denial of service
* [BZ - 218602](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=218602)
  - CVE-2006-6106 Multiple problems in net/bluetooth/cmtp/capi.c
* [BZ - 220677](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=220677)
  - CVE-2006-5753 listxattr syscall can corrupt user space programs
* [BZ - 220971](https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=220971)
  - CVE-2006-5754 kernel panic in aio\_free\_ring()

## CVEs

* [CVE-2006-5174](https://www.redhat.com/security/data/cve/CVE-2006-5174.html)
* [CVE-2006-5754](https://www.redhat.com/security/data/cve/CVE-2006-5754.html)
* [CVE-2006-5823](https://www.redhat.com/security/data/cve/CVE-2006-5823.html)
* [CVE-2006-5757](https://www.redhat.com/security/data/cve/CVE-2006-5757.html)
* [CVE-2006-5751](https://www.redhat.com/security/data/cve/CVE-2006-5751.html)
* [CVE-2006-4538](https://www.redhat.com/security/data/cve/CVE-2006-4538.html)
* [CVE-2006-5753](https://www.redhat.com/security/data/cve/CVE-2006-5753.html)
* [CVE-2006-6106](https://www.redhat.com/security/data/cve/CVE-2006-6106.html)
* [CVE-2006-6535](https://www.redhat.com/security/data/cve/CVE-2006-6535.html)
* [CVE-2006-4813](https://www.redhat.com/security/data/cve/CVE-2006-4813.html)
* [CVE-2006-4814](https://www.redhat.com/security/data/cve/CVE-2006-4814.html)
* [CVE-2006-6056](https://www.redhat.com/security/data/cve/CVE-2006-6056.html)
* [CVE-2006-6054](https://www.redhat.com/security/data/cve/CVE-2006-6054.html)
* [CVE-2006-5619](https://www.redhat.com/security/data/cve/CVE-2006-5619.html)
* [CVE-2006-6053](https://www.redhat.com/security/data/cve/CVE-2006-6053.html)

## References

* <http://www.redhat.com/security/updates/classification/#important>

**Note:**
More recent versions of these packages may be available.
Click a package name for more details.
## Red Hat Enterprise Linux Server 4

| SRPM | |
| --- | --- |
| kernel-2.6.9-42.0.8.EL.src.rpm | SHA-256: 04f89560ebcf9ccbc7816962f4ba56d7d3a7e503905430e6f27b3ac3be5bec4d |
| x86\_64 | |
| kernel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 0b85cd2fcd040cdc1c2a3e907dc5fabce84b2618b917dfd8092715438706a6b5 |
| kernel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 0b85cd2fcd040cdc1c2a3e907dc5fabce84b2618b917dfd8092715438706a6b5 |
| kernel-devel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 7e06c434ba1113f0d401b4a2b1165bf3198ca846cccc05de79247ee8408e4614 |
| kernel-devel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 7e06c434ba1113f0d401b4a2b1165bf3198ca846cccc05de79247ee8408e4614 |
| kernel-doc-2.6.9-42.0.8.EL.noarch.rpm | SHA-256: 19b3f04d8fb04090d3636127c7b4df52a8a0368d4ed902e1ef8da87c302c7d2a |
| kernel-doc-2.6.9-42.0.8.EL.noarch.rpm | SHA-256: 19b3f04d8fb04090d3636127c7b4df52a8a0368d4ed902e1ef8da87c302c7d2a |
| kernel-largesmp-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 83502949f6e8db53fb02ab0e27ad80927f7578b3727fc64a98bcaf01628e17e2 |
| kernel-largesmp-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 83502949f6e8db53fb02ab0e27ad80927f7578b3727fc64a98bcaf01628e17e2 |
| kernel-largesmp-devel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: fe8a4fdc7182ce1fc788bb6fedc04f130bf9524304feb81e5065c1438bf3c69e |
| kernel-largesmp-devel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: fe8a4fdc7182ce1fc788bb6fedc04f130bf9524304feb81e5065c1438bf3c69e |
| kernel-smp-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: caf3309015646bc169523340580701931ea0d249d2694eaf40c76dac94b9eca7 |
| kernel-smp-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: caf3309015646bc169523340580701931ea0d249d2694eaf40c76dac94b9eca7 |
| kernel-smp-devel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 60dbe3afc71c1c30e051dfa0ab9e0ade1341d1e6aed5334ca8ef682fcdb9db2f |
| kernel-smp-devel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 60dbe3afc71c1c30e051dfa0ab9e0ade1341d1e6aed5334ca8ef682fcdb9db2f |
| ia64 | |
| kernel-2.6.9-42.0.8.EL.ia64.rpm | SHA-256: a014cc51b9e9f7efad338eaefd52c5bfe51ad8f97a8fe546e8a9ed9018bc8706 |
| kernel-2.6.9-42.0.8.EL.ia64.rpm | SHA-256: a014cc51b9e9f7efad338eaefd52c5bfe51ad8f97a8fe546e8a9ed9018bc8706 |
| kernel-devel-2.6.9-42.0.8.EL.ia64.rpm | SHA-256: bb0c183aebc5665b0609d1800acbaeeda6e45ce2ed529defb71f16a22a2832d3 |
| kernel-devel-2.6.9-42.0.8.EL.ia64.rpm | SHA-256: bb0c183aebc5665b0609d1800acbaeeda6e45ce2ed529defb71f16a22a2832d3 |
| kernel-doc-2.6.9-42.0.8.EL.noarch.rpm | SHA-256: 19b3f04d8fb04090d3636127c7b4df52a8a0368d4ed902e1ef8da87c302c7d2a |
| kernel-doc-2.6.9-42.0.8.EL.noarch.rpm | SHA-256: 19b3f04d8fb04090d3636127c7b4df52a8a0368d4ed902e1ef8da87c302c7d2a |
| kernel-largesmp-2.6.9-42.0.8.EL.ia64.rpm | SHA-256: 0482df94019a990e65424b1a0c848c79fec651325f7a56c7305a115d68d0f830 |
| kernel-largesmp-2.6.9-42.0.8.EL.ia64.rpm | SHA-256: 0482df94019a990e65424b1a0c848c79fec651325f7a56c7305a115d68d0f830 |
| kernel-largesmp-devel-2.6.9-42.0.8.EL.ia64.rpm | SHA-256: 512f6aae1c63d1e76261fbe78d6a962f87cef5f68e32a6335b13dd4d25870fe2 |
| kernel-largesmp-devel-2.6.9-42.0.8.EL.ia64.rpm | SHA-256: 512f6aae1c63d1e76261fbe78d6a962f87cef5f68e32a6335b13dd4d25870fe2 |
| i386 | |
| kernel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 250d817d28677bd5cb6f5564188a28c05fce622f0bd23145f5cd607223dbc62c |
| kernel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 250d817d28677bd5cb6f5564188a28c05fce622f0bd23145f5cd607223dbc62c |
| kernel-devel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: ceefec8531004b5d25ffc733ea8323ee062a6bf929a8636cd209f2542aa24370 |
| kernel-devel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: ceefec8531004b5d25ffc733ea8323ee062a6bf929a8636cd209f2542aa24370 |
| kernel-doc-2.6.9-42.0.8.EL.noarch.rpm | SHA-256: 19b3f04d8fb04090d3636127c7b4df52a8a0368d4ed902e1ef8da87c302c7d2a |
| kernel-doc-2.6.9-42.0.8.EL.noarch.rpm | SHA-256: 19b3f04d8fb04090d3636127c7b4df52a8a0368d4ed902e1ef8da87c302c7d2a |
| kernel-hugemem-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 3e1f3164f1fb38fd2300fbe0c12d69ac418f53b64f1cd8f8dde60aa3ae90e6f8 |
| kernel-hugemem-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 3e1f3164f1fb38fd2300fbe0c12d69ac418f53b64f1cd8f8dde60aa3ae90e6f8 |
| kernel-hugemem-devel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 73e5a35bebb58408ce85dd0f5e83d26514eeb400d2c8c8977865eb3d7516cc5d |
| kernel-hugemem-devel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 73e5a35bebb58408ce85dd0f5e83d26514eeb400d2c8c8977865eb3d7516cc5d |
| kernel-smp-2.6.9-42.0.8.EL.i686.rpm | SHA-256: fa2144d86ab7cec34fbea6b2499a21a8f5d94bbda49c7703189f61ac1857d14a |
| kernel-smp-2.6.9-42.0.8.EL.i686.rpm | SHA-256: fa2144d86ab7cec34fbea6b2499a21a8f5d94bbda49c7703189f61ac1857d14a |
| kernel-smp-devel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 496602a4d1d43419acbee05b416306634f41db3636ad9661a93f40070f2f63dc |
| kernel-smp-devel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 496602a4d1d43419acbee05b416306634f41db3636ad9661a93f40070f2f63dc |

## Red Hat Enterprise Linux Workstation 4

| SRPM | |
| --- | --- |
| kernel-2.6.9-42.0.8.EL.src.rpm | SHA-256: 04f89560ebcf9ccbc7816962f4ba56d7d3a7e503905430e6f27b3ac3be5bec4d |
| x86\_64 | |
| kernel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 0b85cd2fcd040cdc1c2a3e907dc5fabce84b2618b917dfd8092715438706a6b5 |
| kernel-devel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 7e06c434ba1113f0d401b4a2b1165bf3198ca846cccc05de79247ee8408e4614 |
| kernel-doc-2.6.9-42.0.8.EL.noarch.rpm | SHA-256: 19b3f04d8fb04090d3636127c7b4df52a8a0368d4ed902e1ef8da87c302c7d2a |
| kernel-largesmp-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 83502949f6e8db53fb02ab0e27ad80927f7578b3727fc64a98bcaf01628e17e2 |
| kernel-largesmp-devel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: fe8a4fdc7182ce1fc788bb6fedc04f130bf9524304feb81e5065c1438bf3c69e |
| kernel-smp-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: caf3309015646bc169523340580701931ea0d249d2694eaf40c76dac94b9eca7 |
| kernel-smp-devel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 60dbe3afc71c1c30e051dfa0ab9e0ade1341d1e6aed5334ca8ef682fcdb9db2f |
| ia64 | |
| kernel-2.6.9-42.0.8.EL.ia64.rpm | SHA-256: a014cc51b9e9f7efad338eaefd52c5bfe51ad8f97a8fe546e8a9ed9018bc8706 |
| kernel-devel-2.6.9-42.0.8.EL.ia64.rpm | SHA-256: bb0c183aebc5665b0609d1800acbaeeda6e45ce2ed529defb71f16a22a2832d3 |
| kernel-doc-2.6.9-42.0.8.EL.noarch.rpm | SHA-256: 19b3f04d8fb04090d3636127c7b4df52a8a0368d4ed902e1ef8da87c302c7d2a |
| kernel-largesmp-2.6.9-42.0.8.EL.ia64.rpm | SHA-256: 0482df94019a990e65424b1a0c848c79fec651325f7a56c7305a115d68d0f830 |
| kernel-largesmp-devel-2.6.9-42.0.8.EL.ia64.rpm | SHA-256: 512f6aae1c63d1e76261fbe78d6a962f87cef5f68e32a6335b13dd4d25870fe2 |
| i386 | |
| kernel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 250d817d28677bd5cb6f5564188a28c05fce622f0bd23145f5cd607223dbc62c |
| kernel-devel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: ceefec8531004b5d25ffc733ea8323ee062a6bf929a8636cd209f2542aa24370 |
| kernel-doc-2.6.9-42.0.8.EL.noarch.rpm | SHA-256: 19b3f04d8fb04090d3636127c7b4df52a8a0368d4ed902e1ef8da87c302c7d2a |
| kernel-hugemem-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 3e1f3164f1fb38fd2300fbe0c12d69ac418f53b64f1cd8f8dde60aa3ae90e6f8 |
| kernel-hugemem-devel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 73e5a35bebb58408ce85dd0f5e83d26514eeb400d2c8c8977865eb3d7516cc5d |
| kernel-smp-2.6.9-42.0.8.EL.i686.rpm | SHA-256: fa2144d86ab7cec34fbea6b2499a21a8f5d94bbda49c7703189f61ac1857d14a |
| kernel-smp-devel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 496602a4d1d43419acbee05b416306634f41db3636ad9661a93f40070f2f63dc |

## Red Hat Enterprise Linux Desktop 4

| SRPM | |
| --- | --- |
| kernel-2.6.9-42.0.8.EL.src.rpm | SHA-256: 04f89560ebcf9ccbc7816962f4ba56d7d3a7e503905430e6f27b3ac3be5bec4d |
| x86\_64 | |
| kernel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 0b85cd2fcd040cdc1c2a3e907dc5fabce84b2618b917dfd8092715438706a6b5 |
| kernel-devel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 7e06c434ba1113f0d401b4a2b1165bf3198ca846cccc05de79247ee8408e4614 |
| kernel-doc-2.6.9-42.0.8.EL.noarch.rpm | SHA-256: 19b3f04d8fb04090d3636127c7b4df52a8a0368d4ed902e1ef8da87c302c7d2a |
| kernel-largesmp-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 83502949f6e8db53fb02ab0e27ad80927f7578b3727fc64a98bcaf01628e17e2 |
| kernel-largesmp-devel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: fe8a4fdc7182ce1fc788bb6fedc04f130bf9524304feb81e5065c1438bf3c69e |
| kernel-smp-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: caf3309015646bc169523340580701931ea0d249d2694eaf40c76dac94b9eca7 |
| kernel-smp-devel-2.6.9-42.0.8.EL.x86\_64.rpm | SHA-256: 60dbe3afc71c1c30e051dfa0ab9e0ade1341d1e6aed5334ca8ef682fcdb9db2f |
| i386 | |
| kernel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 250d817d28677bd5cb6f5564188a28c05fce622f0bd23145f5cd607223dbc62c |
| kernel-devel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: ceefec8531004b5d25ffc733ea8323ee062a6bf929a8636cd209f2542aa24370 |
| kernel-doc-2.6.9-42.0.8.EL.noarch.rpm | SHA-256: 19b3f04d8fb04090d3636127c7b4df52a8a0368d4ed902e1ef8da87c302c7d2a |
| kernel-hugemem-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 3e1f3164f1fb38fd2300fbe0c12d69ac418f53b64f1cd8f8dde60aa3ae90e6f8 |
| kernel-hugemem-devel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 73e5a35bebb58408ce85dd0f5e83d26514eeb400d2c8c8977865eb3d7516cc5d |
| kernel-smp-2.6.9-42.0.8.EL.i686.rpm | SHA-256: fa2144d86ab7cec34fbea6b2499a21a8f5d94bbda49c7703189f61ac1857d14a |
| kernel-smp-devel-2.6.9-42.0.8.EL.i686.rpm | SHA-256: 496602a4d1d43419acbee05b416306634f41db3636ad9661a93f40070f2f63dc |

## Red Hat Enterprise Linux for IBM z Systems 4

| SRPM | |
| --- | --- |
| kernel-2.6.9-42.0.8.EL.src.rpm | SHA-256: 04f89560ebcf9ccbc7816962f4ba56d7d3a7e503905430e6f27b3ac3be5bec4d |
| s390x | |
| kernel-2.6.9-42.0.8.EL.s390x.rpm | SHA-256: 4b417937c9220f3b10aad83675b2b500888a206352d92bcff5d550e7123ab2f0 |
| kernel-devel-2.6.9-42.0.8.EL.s390x.rpm | SHA-256: 3b6e92ef2367ade72bbc5d1860ee5debd1d04898f352ae8aa347ba995ad0b06d |
| kernel-doc-2.6.9-42.0.8.EL.noarch.rpm | SHA-256: 19b3f04d8fb04090d3636127c7b4df52a8a0368d4ed902e1ef8da87c302c7d2a |
| s390 | |
| kernel-2.6.9-42.0.8.EL.s390.rpm | SHA-256: 1f25397d4dfe37c1acc71cac31a8b4c336b6d66a3cd596ea6ebb26c1ef9bcaed |
| kernel-devel-2.6.9-42.0.8.EL.s390.rpm | SHA-256: f368c3647588aeb4f8f666a69026dd86ca5cc1335a8971261d3ccd33c6b62a30 |
| kernel-doc-2.6.9-42.0.8.EL.noarch.rpm | SHA-256: 19b3f04d8fb04090d3636127c7b4df52a8a0368d4ed902e1ef8da87c302c7d2a |

## Red Hat Enterprise Linux for Power, big endian 4

| SRPM | |
| --- | --- |
| kernel-2.6.9-42.0.8.EL.src.rpm | SHA-256: 04f89560ebcf9ccbc7816962f4ba56d7d3a7e503905430e6f27b3ac3be5bec4d |
| ppc | |
| kernel-2.6.9-42.0.8.EL.ppc64.rpm | SHA-256: f2cd9816fc517cee1b4aacc19280dfcbbeff9c14f0de8eff10a236bd5ced8525 |
| kernel-2.6.9-42.0.8.EL.ppc64iseries.rpm | SHA-256: 1a2dd77a1d11e8d65731b46d4cc851098c847b24c9012540c49188a35e6d604c |
| kernel-devel-2.6.9-42.0.8.EL.ppc64.rpm | SHA-256: f1bcd1dd4540f102c776fd2bcc8fe48c08ed6d396f4074b0f4a35d0548bba4eb |
| kernel-devel-2.6.9-42.0.8.EL.ppc64iseries.rpm | SHA-256: e272cb6e962a3607e28f8e4d9ee7a3e5b740fe711ffb812a59007a2500489eaf |
| kernel-doc-2.6.9-42.0.8.EL.noarch.rpm | SHA-256: 19b3f04d8fb04090d3636127c7b4df52a8a0368d4ed902e1ef8da87c302c7d2a |
| kernel-largesmp-2.6.9-42.0.8.EL.ppc64.rpm | SHA-256: f0c10a2d7731dcc36d261d03678b5ab8708ae2c991e39b99e296594abbdf0691 |
| kernel-largesmp-devel-2.6.9-42.0.8.EL.ppc64.rpm | SHA-256: 72ff80568de5b4cf06a7fbf211d706da7f2bb421b080c9c89c667d3ceb2523f7 |

The Red Hat security contact is secalert@redhat.com.
More contact details at <https://access.redhat.com/security/team/contact/>.

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2025 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from bugzilla.redhat.com_80e00cbc_20250126_104125.html ===


* Login
  + Log in using an SSO provider:- [Fedora Account System](saml2_login.cgi?idp=Fedora%20Account%20System&target=show_bug.cgi%3Fid%3D207463)
    - [Red Hat Associate](saml2_login.cgi?idp=Red%20Hat%20Associate&target=show_bug.cgi%3Fid%3D207463)
    - [Red Hat Customer](saml2_login.cgi?idp=Red%20Hat%20Customer&target=show_bug.cgi%3Fid%3D207463)+ Login using a Red Hat Bugzilla account
  + Forgot Password
  + [Create an Account](createaccount.cgi)

Red Hat Bugzilla – Bug 207463

* [Home](./)
* [New](enter_bug.cgi)
* Search
  + [Simple Search](query.cgi?format=specific)
  + [Advanced Search](query.cgi?format=advanced)
* My Links
  + [Browse](describecomponents.cgi)
  + [Requests](request.cgi)
  + Reports
  + Current State
    - [Search](query.cgi)
    - [Tabular reports](query.cgi?format=report-table)
    - [Graphical reports](query.cgi?format=report-graph)
    - [Duplicates](duplicates.cgi)
  + Other Reports
    - [User Changes](https://bugzilla.redhat.com/page.cgi?id=user_activity.html)
  + Plotly Reports
    - [Bug Status](https://bugzilla.redhat.com/page.cgi?id=bug_status.html)
    - [Bug Severity](https://bugzilla.redhat.com/page.cgi?id=bug_severity.html)
    - [Non-Defaults](https://bugzilla.redhat.com/page.cgi?id=non_defaults.html)
* [Product Dashboard](page.cgi?id=productdashboard.html)

- Help
  * [Page Help!](docs/en/html/using/understanding.html)
  * [Bug Writing Guidelines](page.cgi?id=bug-writing.html)
  * [What's new](page.cgi?id=whats-new.html)
  * [Browser Support Policy](https://access.redhat.com/help/browsers)
  * [5.0.4.rh103 Release notes](page.cgi?id=release-notes.html)
  * [FAQ](page.cgi?id=faq.html)
  * [Guides index](docs/en/html/index.html)
  * [User guide](docs/en/html/using/index.html)
  * [Web Services](docs/en/html/integrating/api/Bugzilla/WebService/Bug.html)
  * [Contact](page.cgi?id=redhat/contact.html)
  * [Legal](page.cgi?id=terms-conditions.html)
- [[?]](page.cgi?id=quicksearch.html "Quicksearch Help")

This site requires JavaScript to be enabled to function correctly, please enable it.

[**Bug 207463**](show_bug.cgi?id=207463)
- [CVE-2006-4813](https://access.redhat.com/security/cve/CVE-2006-4813) Information leak in \_\_block\_prepare\_write()

[Summary:](page.cgi?id=fields.html#short_desc "The bug summary is a short sentence which succinctly describes what the bug is about.")
CVE-2006-4813 Information leak in \_\_block\_prepare\_write()

| | [Keywords](describekeywords.cgi): | Security | | --- | --- | | [Status](page.cgi?id=fields.html#bug_status): | CLOSED ERRATA | | [Alias:](page.cgi?id=fields.html#alias "A short, unique name assigned to a bug in order to assist with looking it up and referring to it in other places in Bugzilla.") | None | | [Product:](describecomponents.cgi "Bugs are categorised into Products and Components. Select a Classification to narrow down this list.") | Red Hat Enterprise Linux 4 | | [Classification:](page.cgi?id=fields.html#classification "Bugs are categorised into Classifications, Products and Components. classifications is the top-level categorisation.") | Red Hat | | [Component:](describecomponents.cgi?product=Red Hat Enterprise Linux 4 "Components are second-level categories; each belongs to a particular Product. Select a Product to narrow down this list.") | kernel | | [Sub Component:](page.cgi?id=fields.html#rh_sub_components "The sub component of a specific component") | --- | | [Version:](page.cgi?id=fields.html#version "The version field defines the version of the software the bug was found in.") | 4.4 | | [Hardware:](page.cgi?id=fields.html#rep_platform "The hardware platform the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | All | | [OS:](page.cgi?id=fields.html#op_sys "The operating system the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | Linux | | [Priority:](page.cgi?id=fields.html#priority) | medium | | [Severity:](page.cgi?id=fields.html#bug_severity) | high | | [Target Milestone:](page.cgi?id=fields.html#target_milestone "The Target Milestone field is used to define when the engineer the bug is assigned to expects to fix it.") | --- | | [Target Release](page.cgi?id=fields.html#target_release): | --- | | [Assignee:](page.cgi?id=fields.html#assigned_to "The person in charge of resolving the bug.") | Eric Sandeen | | [QA Contact:](page.cgi?id=fields.html#qa_contact "The person responsible for confirming this bug if it is unconfirmed, and for verifying the fix once the bug has been resolved.") | Brian Brock | | [Docs Contact:](page.cgi?id=fields.html#docs_contact "The person responsible for documenting once the bug has been resolved.") |  | | [URL:](page.cgi?id=fields.html#bug_file_loc "Bugs can have a URL associated with them - for example, a pointer to a web site where the problem is seen.") |  | | [Whiteboard:](page.cgi?id=fields.html#status_whiteboard "Each bug has a free-form single line text entry box for adding tags and status information.") | impact=important,source=bugzilla,repo... | | [Depends On:](page.cgi?id=fields.html#dependson "The bugs listed here must be resolved before this bug can be resolved.") |  | | [Blocks:](page.cgi?id=fields.html#blocked "This bug must be resolved before the bugs listed in this field can be resolved.") |  | | TreeView+ | [depends on](buglist.cgi?bug_id=207463&bug_id_type=anddependson&format=tvp) / [blocked](buglist.cgi?bug_id=207463&bug_id_type=andblocked&format=tvp&tvp_dir=blocked) |  | |  | | [Reported:](page.cgi?id=fields.html#reporter) | 2006-09-21 08:52 UTC by Vasily Averin | | --- | --- | | [Modified:](page.cgi?id=fields.html#modified) | 2008-01-09 17:30 UTC ([History](show_activity.cgi?id=207463)) | | [CC List:](page.cgi?id=fields.html#cclist) | 5 users (show)  dev dmonakhov jbaron khorenko security-response-team | | Fixed In Version: | RHSA-2007-0014 | | | Doc Type: | Bug Fix | | | Doc Text: |  | | | Clone Of: |  | | | Environment: |  | | | Last Closed: | 2007-01-30 14:27:49 UTC | | | Target Upstream Version: |  | | | Embargoed: |  | | |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| --- | | |

| | Attachments | [(Terms of Use)](page.cgi?id=terms-conditions.html) | | | --- | --- | --- | | [**reproducer testcase**](attachment.cgi?id=136834 "View the content of the attachment") (620 bytes, text/plain)  [2006-09-21 08:58 UTC](#attach_136834 "Go to the comment associated with the attachment"), Vasily Averin | *no flags* | [Details](attachment.cgi?id=136834&action=edit) | | [**reproducer preapre script**](attachment.cgi?id=136835 "View the content of the attachment") (222 bytes, text/plain)  [2006-09-21 08:59 UTC](#attach_136835 "Go to the comment associated with the attachment"), Vasily Averin | *no flags* | [Details](attachment.cgi?id=136835&action=edit) | | [**reproducer testcase script**](attachment.cgi?id=136836 "View the content of the attachment") (539 bytes, text/plain)  [2006-09-21 08:59 UTC](#attach_136836 "Go to the comment associated with the attachment"), Vasily Averin | *no flags* | [Details](attachment.cgi?id=136836&action=edit) | | [**patch against your lastest public kernel**](attachment.cgi?id=147354 "View the content of the attachment")  (1009 bytes, patch)  [2007-02-05 13:33 UTC](#attach_147354 "Go to the comment associated with the attachment"), Monakhov Dmitriy | *no flags* | [Details](attachment.cgi?id=147354&action=edit) | [Diff](attachment.cgi?id=147354&action=diff) | | [View All](attachment.cgi?bugid=207463&action=viewall) | | |    Links | System | ID | Private | Priority | Status | Summary | Last Updated | | Red Hat Product Errata | [RHSA-2007:0014](https://access.redhat.com/errata/RHSA-2007%3A0014) | 0 | normal | SHIPPED\_LIVE | Important: kernel security update | 2007-01-30 14:25:00 UTC | |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |

| [Description](show_bug.cgi?id=207463#c0)  Vasily Averin    2006-09-21 08:52:00 UTC  ``` Dmitriy Monakhov from SWsoft Virtuozzo/OpenVZ Linux Team has noticed an information leak in __block_prepare_write() affected RHEL4 kernels: __block_prepare_write() does not clear properly the data buffers during error recovery and therefore content of previously unliked files is accessible.  It is known issue and it is fixed in mainstream by following patch: <http://www.kernel.org/git/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commit;h=152becd26e0563aefdbc4fd1fe491928efe92d1f>   ```  [Comment 1](show_bug.cgi?id=207463#c1)  Vasily Averin    2006-09-21 08:53:37 UTC  ``` #uname -r 2.6.9-42.0.2.EL  to reproduce:  gcc -Wall ./open_write.c -o /tmp/open_write sh ./prep.sh sh ./info_leack_test.sh  test result: #sh  /tmp/info_leack_test.sh stat: cannot stat `/mnt/file': No such file or directory 00000000  53 53 53 53 53 53 53 53  53 53 53 53 53 53 53 53  |SSSSSSSSSSSSSSSS| * ########## content from unlinked file visible.      ^^^^^^^^^^^^^^^^^^^^^^^^^^^ ########## must be zeros here  00000800  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................| * 00001000  6e                                                |n| 00001001   ```  [Comment 2](show_bug.cgi?id=207463#c2)  Vasily Averin    2006-09-21 08:58:07 UTC  ``` Created [attachment 136834](attachment.cgi?id=136834 "reproducer testcase") [[details]](attachment.cgi?id=136834&action=edit "reproducer testcase") reproducer testcase   ```  [Comment 3](show_bug.cgi?id=207463#c3)  Vasily Averin    2006-09-21 08:59:00 UTC  ``` Created [attachment 136835](attachment.cgi?id=136835 "reproducer preapre script") [[details]](attachment.cgi?id=136835&action=edit "reproducer preapre script") reproducer preapre script   ```  [Comment 4](show_bug.cgi?id=207463#c4)  Vasily Averin    2006-09-21 08:59:38 UTC  ``` Created [attachment 136836](attachment.cgi?id=136836 "reproducer testcase script") [[details]](attachment.cgi?id=136836&action=edit "reproducer testcase script") reproducer testcase script   ```  [Comment 5](show_bug.cgi?id=207463#c5)  Marcel Holtmann    2006-09-21 14:06:43 UTC  ``` an you elaborate a little bit more on this issue. The reproduce needs root rights to fully work and a root-only information leak is not a security issue.    ```  [Comment 6](show_bug.cgi?id=207463#c6)  Vasily Averin    2006-09-21 17:20:25 UTC  ``` root permission in this reproducer needs for filesystem preparing only. then root (or any another user) may write some files, then delete it. Then any another user have a chance to get content of _any_  previously deleted files.   ```  [Comment 7](show_bug.cgi?id=207463#c7)  Vasily Averin    2006-09-22 08:08:12 UTC  ``` please show:  -bash-3.00# cd /tmp -bash-3.00# ls prepvvs.sh -al -rw-r--r--  1 root root 653 Sep 22 11:46 prepvvs.sh  -bash-3.00# cat prepvvs.sh ############# DEV=/tmp/FS_test MNT=/tmp/mnt mkdir $MNT  #preparing a filesystem; it should have 1k or 2k blocksize dd if=/dev/zero of=$DEV bs=1M count=128  mkfs.ext2 -b1024 -m0 -q  -F $DEV mount $DEV $MNT -oloop  #make filesystem pubic accessible chmod 777 $MNT  # create private root directory mkdir $MNT/root chmod 700 $MNT/root  # write to file top secret data for(( i = 0; i< 96; i++ ))         do                 echo "top secret root  file content  " >> $MNT/root/ROOT_FILE         done #fill up the filesystem dd if=/dev/zero of=$MNT/root/BIG bs=1k sync  #unlink root's file unlink  $MNT/root/ROOT_FILE sync # now filesystem has 3 free data blocks with content of unlinked ROOT_FILE  -bash-3.00# sh ./prepvvs.sh 128+0 records in 128+0 records out dd: writing `/tmp/mnt/root/BIG': No space left on device 124887+0 records in 124886+0 records out   -bash-3.00# su testuser  [testuser@dmon tmp]$ ls -al ./userscript.sh -rw-r--r--  1 testuser testuser 218 Sep 22 11:40 ./userscript.sh  [testuser@dmon tmp]$ cat userscript.sh ## create sparse file dd if=/dev/zero of=/tmp/mnt/userfile seek=4096 count=1 bs=1 ## and fill it dd if=/dev/zero of=/tmp/mnt/userfile bs=4k count=1 conv=notrunc ## now look what we get hexdump  -C /tmp/mnt/userfile  [testuser@dmon tmp]$ sh ./userscript.sh 1+0 records in 1+0 records out dd: writing `/tmp/mnt/userfile': No space left on device 1+0 records in 0+0 records out 00000000  74 6f 70 20 73 65 63 72  65 74 20 72 6f 6f 74 20  |top secret root | 00000010  20 66 69 6c 65 20 63 6f  6e 74 65 6e 74 20 20 0a  | file content  .| 00000020  74 6f 70 20 73 65 63 72  65 74 20 72 6f 6f 74 20  |top secret root | 00000030  20 66 69 6c 65 20 63 6f  6e 74 65 6e 74 20 20 0a  | file content  .| 00000040  74 6f 70 20 73 65 63 72  65 74 20 72 6f 6f 74 20  |top secret root | 00000050  20 66 69 6c 65 20 63 6f  6e 74 65 6e 74 20 20 0a  | file content  .| ... 000007a0  74 6f 70 20 73 65 63 72  65 74 20 72 6f 6f 74 20  |top secret root | 000007b0  20 66 69 6c 65 20 63 6f  6e 74 65 6e 74 20 20 0a  | file content  .| 000007c0  74 6f 70 20 73 65 63 72  65 74 20 72 6f 6f 74 20  |top secret root | 000007d0  20 66 69 6c 65 20 63 6f  6e 74 65 6e 74 20 20 0a  | file content  .| 000007e0  74 6f 70 20 73 65 63 72  65 74 20 72 6f 6f 74 20  |top secret root | 000007f0  20 66 69 6c 65 20 63 6f  6e 74 65 6e 74 20 20 0a  | file content  .| 00000800  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................| * 00001000  00                                                |.| 00001001   ```  [Comment 10](show_bug.cgi?id=207463#c10)  Marcel Holtmann    2006-09-22 09:53:59 UTC  ``` The patch is public since June, 23th 2005, but the security implication is not wide spreaded. Do you mind keeping this embargoed for 1-2 weeks and me sending this information (including reproducer) to vendor-sec?   ```  [Comment 11](show_bug.cgi?id=207463#c11)  Vasily Averin    2006-09-22 10:29:01 UTC  ``` I'm agree, I would like to add that information may leaks even when user is limited by disk quota.    ```  [Comment 12](show_bug.cgi?id=207463#c12)  Eric Sandeen    2006-10-02 19:44:53 UTC  ``` Backported patch sent to rhkernel-list on 10/2/06   ```  [Comment 13](show_bug.cgi?id=207463#c13)  Vasily Averin    2006-10-03 06:46:40 UTC  ``` Eric, can I take a look at this patch somehow please? Is it possible to get subscribed to rhkernel-list@? We (Virtuozzo/OpenVZ team) report bugs to RHEL kernels and could provide much better level of cooperation and feedback (including patches) having an access to this mailing list. Whom can I ask for it?     ```  [Comment 14](show_bug.cgi?id=207463#c14)  Marcel Holtmann    2006-10-03 07:24:42 UTC  ``` Vasily, if they are security related, I prefer you post the information to vendor-sec. This allows all distributions to comment on it and I can pick them up from there.  I spoke with Kir Kolyshkin at IBLOC about it and once I am back, I am going to write something up. I first have to check what is possible and what not.    ```  [Comment 15](show_bug.cgi?id=207463#c15)  Jason Baron    2006-10-16 15:52:19 UTC  ``` committed in stream U5 build 42.19. A test kernel with this patch is available from <http://people.redhat.com/~jbaron/rhel4/>    ```  [Comment 16](show_bug.cgi?id=207463#c16)  RHEL Program Management    2006-10-20 17:48:48 UTC  ``` This request was evaluated by Red Hat Product Management for inclusion in a Red Hat Enterprise Linux maintenance release.  Product Management has requested further review of this request by Red Hat Engineering, for potential inclusion in a Red Hat Enterprise Linux Update release for currently deployed products.  This request is not yet committed for inclusion in an Update release.   ```  [Comment 17](show_bug.cgi?id=207463#c17)  Jay Turner    2006-11-21 12:45:25 UTC  ``` QE ack for 4.5.   ```  [Comment 18](show_bug.cgi?id=207463#c18)  Jason Baron    2006-12-18 21:39:44 UTC  ``` committed in stream E5 build 42.0.4   ```  [Comment 20](show_bug.cgi?id=207463#c20)  Mike Gahagan    2007-01-17 16:22:16 UTC  ``` sucessfully tested with the second rendition of the test case (the first didn't seem to work). no deleted files were visable with the 42.0.6 kernel.    ```  [Comment 22](show_bug.cgi?id=207463#c22)  Red Hat Bugzilla    2007-01-30 14:27:49 UTC  ```  An advisory has been issued which should help the problem described in this bug report. This report is therefore being closed with a resolution of ERRATA. For more information on the solution and/or where to find the updated files, please follow the link below. You may reopen this bug report if the solution does not work for you.  <http://rhn.redhat.com/errata/RHSA-2007-0014.html>    ```  [Comment 23](show_bug.cgi?id=207463#c23)  Monakhov Dmitriy    2007-02-05 12:26:50 UTC  ``` patch you applied is _incorrect_. Actually __block_prepare_write err path was broken in two places:  A)clear_buffer_new() was called too early and result in information leak. [you have fixed it.]  B)after get_block has failed original code  jump to "out" label and return without waiting for issued read requests to complete, and may later unlock page.  We must just do "break" here, and wait until IO-layer reading complete. Otherwise later access to page cause unpredictable result, because IO-layer may modify this page at this moment. So this place have to looks like this: =-=-=-=-=-=-= --- linux-2.6.9/fs/buffer.c.orig +++ linux-2.6.9/fs/buffer.c @@ -2029,9 +2029,8 @@ static int __block_prepare_write(struct   		if (!buffer_mapped(bh)) {  			err = get_block(inode, block, bh, 1);  			if (err) -				goto out; +				break;  			if (buffer_new(bh)) { -				clear_buffer_new(bh);  				unmap_underlying_metadata(bh->b_bdev,  							bh->b_blocknr);  				if (PageUptodate(page)) { =-=-=-=-=-= I haven't sufficient right access, so than let's someone else REOPEN it.   ```  [Comment 24](show_bug.cgi?id=207463#c24)  Monakhov Dmitriy    2007-02-05 13:33:15 UTC  ``` Created [attachment 147354](attachment.cgi?id=147354&action=diff "patch against your lastest public kernel") [[details]](attachment.cgi?id=147354&action=edit "patch against your lastest public kernel") patch against your lastest public kernel   This patch fix broken error handling path as it was done in original mainstream patch. Waiting for issued read requests to complete.   ```  [Comment 25](show_bug.cgi?id=207463#c25)  Eric Sandeen    2007-02-05 14:29:34 UTC  ``` Thanks, I'll look at this today.   ```  [Comment 26](show_bug.cgi?id=207463#c26)  Eric Sandeen    2007-02-05 15:32:29 UTC  ``` Ok, so it looks like we're missing <http://www2.kernel.org/git/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commitdiff;h=f3ddbdc6267c32223035ea9bb8456a2d86f65ba1>   Fix a race where __block_prepare_write can leak out an in-flight read against a bh if get_block returns an error.  This can lead to the page becoming unlocked while the buffer is locked and the read still in flight. __mpage_writepage BUGs on this condition.  BUG sighted on a 2-way Itanium2 system with 16K PAGE_SIZE running  	fsstress -v -d $DIR/tmp -n 1000 -p 1000 -l 2  where $DIR is a new ext2 filesystem with 4K blocks that is quite small (causing get_block to fail often with -ENOSPC).  Signed-off-by: Nick Piggin <nickpiggin.au>     ```  [Comment 27](show_bug.cgi?id=207463#c27)  Marcel Holtmann    2007-02-05 16:02:58 UTC  ``` This is a regression with an issue solved through an errata. If the fix in the errata was incomplete, we need to open a new bug for it. Don't re-open this one.    ```  [Comment 28](show_bug.cgi?id=207463#c28)  Eric Sandeen    2007-02-05 16:42:38 UTC  ``` Dmitriy,  It's my understanding that by putting the patch in as we did, we DID fix one problem case, but still did not fix a 2nd case.  I don't think that we have made anything -worse- (i.e. the errata patch did not cause a regression) and the case we missed has been in the RHEL4 kernel since it was released.  I think that this 2nd problem does have some security implications, although it is not as severe as the problem which was addressed with the first patch.  Do you agree with this assessment?  Thanks, -Eric   ```  [Comment 29](show_bug.cgi?id=207463#c29)  Monakhov Dmitriy    2007-02-05 16:49:02 UTC  ``` yes.   ``` |  |
| --- | --- |

---

| Note You need to [log in](show_bug.cgi?id=207463&GoAheadAndLogIn=1) before you can comment on or make changes to this bug. |
| --- |

---

[Privacy](page.cgi?id=redhat/privacy.html)
[Contact](page.cgi?id=redhat/contact.html)
[FAQ](page.cgi?id=faq.html)
[Legal](page.cgi?id=terms-conditions.html)



=== Content from support.avaya.com_196861c7_20250125_174328.html ===


---

kernel security update (RHSA-2007-0014)

Original Release Date: February 16, 2007

Last Revised: February 13, 2009

Number: ASA-2007-063

Risk Level: Medium

Advisory Version: 6.0

Advisory Status: Final

---

## 1. Overview:

The Linux kernel manages the communication between software and
hardware as
well as the hardware resources of a computer running the Linux operating
system.

Red Hat has issued an updated version of the kernel packages for
Enterprise
Linux 4. Below is a list of the security issues fixed in the update as
reported
by Red Hat:

* a flaw in the get\_fdb\_entries function of the network bridging
  support
  that allowed a local user to cause a denial of service (crash) or allow
  a
  potential privilege escalation.
* an information leak in the \_block\_prepare\_write function that
  allowed
  a local user to read kernel memory.
* an information leak in the copy\_from\_user() implementation on s390
  and
  s390x platforms that allowed a local user to read kernel memory.
* a flaw in the handling of /proc/net/ip6\_flowlabel that allowed a
  local
  user to cause a denial of service (infinite loop).
* a flaw in the AIO handling that allowed a local user to cause a
  denial
  of service (panic).
* a race condition in the mincore system core that allowed a local
  user to
  cause a denial of service (system hang).
* a flaw in the ELF handling on ia64 and sparc architectures which
  triggered a cross-region memory mapping and allowed a local user to
  cause a
  denial of service.
* a flaw in the dev\_queue\_xmit function of the network subsystem that
  allowed a local user to cause a denial of service (data
  corruption).
* a flaw in the handling of CAPI messages over Bluetooth that allowed
  a
  remote system to cause a denial of service or potential code execution.
  This flaw is only exploitable if a privileged user establishes a
  connection
  to a malicious remote device.
* a flaw in the listxattr system call that allowed a local user to
  cause a
  denial of service (data corruption) or potential privilege escalation.
  To
  successfully exploit this flaw the existence of a bad inode is required
  first.
* a flaw in the \_\_find\_get\_block\_slow function that allowed a local
  privileged user to cause a denial of service.
* various flaws in the supported filesystems that allowed a local
  privileged user to cause a denial of service.

The Common Vulnerabilities and Exposures project (cve.mitre.org) has
assigned
the names
[CVE-2006-5751](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-5751),
[CVE-2006-4813](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-4813),
[CVE-2006-5174](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-5174),
[CVE-2006-5619](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-5619),
[CVE-2006-5754](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-5754),
[CVE-2006-4814](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-4814),
[CVE-2006-4538](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-4538),
[CVE-2006-6535](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-6535),
[CVE-2006-6106](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-6106),
[CVE-2006-5753](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-5753),
[CVE-2006-5757](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-5757),
[CVE-2006-5823](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-5823),
[CVE-2006-6053](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-6053),
[CVE-2006-6054](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-6054), and
[CVE-2006-6056](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-6056) to these issues.

While this advisory deals with the kernel package from RedHat
Enterprise
Linux 4, the vulnerabilities in this advisory have been assessed against
currently supported versions of Avaya Communications Manager (CM). As
such,
some of the responses may include versions of Avaya Communications
Manager that
do not run on RedHat Enterprise Linux 4 or on a 2.6 series kernel.

CM 2.x and CM 3.0, which use a 2.4 series Linux kernel, are only
vulnerable
to the mincore race condition
([CVE-2006-4814](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-4814))
listed above. As there is no known exploit for this issue and it would
require
someone with access to a user account on CM, Avaya has chosen to rate
the impact
of this ASA to CM 2.x and CM 3.0 as a Low Risk Level.

CM 3.1.x, which uses a 2.6 series Linux kernel, is vulnerable to all
of the
issues in this advisory including the potential privilege escalations in
the
get\_fdb\_entries issue
([CVE-2006-5751](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-5751))
and the listxattr-system-call issue
([CVE-2006-5753](http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2006-5753))
listed above.

Avaya Messaging Storage Server has been marked as having a Low Risk
Level
as shell access is not available in an Avaya recommended default
configuration.

More information about these vulnerabilities can be found in the
security
advisory issued by RedHat Linux:

* <https://rhn.redhat.com/errata/RHSA-2007-0014.html>

## 2. Avaya System Products with kernel installed:

| Product: | Affected Version(s): | Risk Level: | Actions: |
| --- | --- | --- | --- |
| Avaya S87XX/S8500/S8300 | CM 2.x, CM 3.0,CM 3.1.3 and earlier, CM 4.0 | LowMedium | For CM versions 2.x and 3.0, upgrade to CM 3.1.4 or a later version in the 3.1.x series. For CM 3.1.3 and earlier releases in the CM 3.1.x series, upgrade to CM 3.1.4 or a later version in the 3.1.x series. For CM 4.0, upgrade to CM 4.0.1 or later. |
| Avaya Messaging Storage Server | MSS 3.x | Low | Upgrade to MSS 4.0 or later. |
| Avaya CCS/SES | SES 2.0 - 3.x | Medium | Upgrade to SES 4.0 or later. |
| Avaya AES | AES 4.0 | Medium | Upgrade to AES 4.0.1 or later. |

**Recommended Actions:**
For all system products which use
vulnerable
versions of the kernel, Avaya recommends that customers restrict local
and
network access to the server. This restriction should be enforced
through the
use of physical security, firewalls, ACLs, VPNs, and other
generally-accepted
networking practices until such time as an update becomes available and
can
be installed.

## 3. Avaya Software-Only Products:

Avaya software-only products operate on general-purpose operating
systems.
Occasionally vulnerabilities may be discovered in the underlying
operating
system or applications that come with the operating system. These
vulnerabilities often do not impact the software-only product directly
but
may threaten the integrity of the underlying platform.

In the case of this advisory Avaya software-only products are not
affected by
the vulnerability directly but the underlying Linux platform may be.
Customers should determine on which Linux operating system the product
was
installed and then follow that vendors guidance.

## 4. Software-Only Products:

| Product: | Affected Version(s): | Risk Level: | Actions: |
| --- | --- | --- | --- |
| CVLAN | All | None | Depending on the Operating System provided by customers, the affected package may be installed on the underlying Operating System supporting the CVLAN application. The CVLAN application does not require the software described in this advisory. |
| Avaya Integrated Management Suite(IMS) | All | None | Depending on the Operating System provided by customers, the affected package may be installed on the underlying Operating System supporting the IMS application. The IMS application does not require the software described in this advisory. |

**Recommended Actions:**
Avaya recommends that customers follow
recommended actions supplied by RedHat Linux.

## 5. Additional Information:

Additional information may also be available via the Avaya support
[website](http://support.avaya.com) and through your Avaya
account
representative. Please contact your Avaya product support
representative, or
dial 1-800-242-2121, with any questions.

## 6. Disclaimer:

ALL INFORMATION IS BELIEVED TO BE CORRECT AT THE TIME OF PUBLICATION
AND IS
PROVIDED "AS IS". AVAYA INC., ON BEHALF ITSELF AND ITS SUBSIDIARIES AND
AFFILIATES (HEREINAFTER COLLECTIVELY REFERRED TO AS "AVAYA"), DISCLAIMS
ALL
WARRANTIES, EITHER EXPRESS OR IMPLIED, INCLUDING THE WARRANTIES OF
MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE AND FURTHERMORE,
AVAYA
MAKES NO REPRESENTATIONS OR WARRANTIES THAT THE STEPS RECOMMENDED WILL
ELIMINATE SECURITY OR VIRUS THREATS TO CUSTOMERS' SYSTEMS. IN NO EVENT
SHALL
AVAYA BE LIABLE FOR ANY DAMAGES WHATSOEVER ARISING OUT OF OR IN
CONNECTION
WITH THE INFORMATION OR RECOMMENDED ACTIONS PROVIDED HEREIN, INCLUDING
DIRECT, INDIRECT, CONSEQUENTIAL DAMAGES, LOSS OF BUSINESS PROFITS OR
SPECIAL
DAMAGES, EVEN IF AVAYA HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH
DAMAGES.

THE INFORMATION PROVIDED HERE DOES NOT AFFECT THE SUPPORT AGREEMENTS
IN PLACE
FOR AVAYA PRODUCTS. SUPPORT FOR AVAYA PRODUCTS CONTINUES TO BE EXECUTED
AS
PER EXISTING AGREEMENTS WITH AVAYA.

## 7. Revision History:

V 1.0 - February 19, 2007 - Initial Statement issued.

V 2.0 - March 12, 2007 - Updated MSS Risk Level to Low based on further
review.
Changed affected AES version from 3.1 to 4.0 based on further review.
Clarified
the issues that affect the different versions of CM and changed the Risk
Level
rating of CM 2.x and CM 3.0 to Low.

V 3.0 - May 14, 2007 - Updated Communication Manager Recommended Actions
to
indicate a fix is available for this advisory in CM 3.1.4 and later.

V 4.0 - October 9, 2007 - Updated Recommended Actions for Communication
Manager
and AES.

V 5.0 - February 11, 2008 - Updated Recommended Actions for Avaya
CCS/SES.

V 6.0 - February 13, 2009 - Updated Recommended Actions for MSS and ASA
status to final.

Send information regarding any discovered security problems with
Avaya
products to either the contact noted in the product's documentation or
securityalerts@avaya.com.

© 2007 Avaya Inc. All Rights Reserved. All trademarks identified
by the
® or ™ are registered trademarks or trademarks, respectively,
of
Avaya Inc. All other trademarks are the property of their respective
owners.



=== Content from bugzilla.redhat.com_67f8d615_20250126_104120.html ===


* Login
  + Log in using an SSO provider:- [Fedora Account System](saml2_login.cgi?idp=Fedora%20Account%20System&target=show_bug.cgi%3Fid%3D216452)
    - [Red Hat Associate](saml2_login.cgi?idp=Red%20Hat%20Associate&target=show_bug.cgi%3Fid%3D216452)
    - [Red Hat Customer](saml2_login.cgi?idp=Red%20Hat%20Customer&target=show_bug.cgi%3Fid%3D216452)+ Login using a Red Hat Bugzilla account
  + Forgot Password
  + [Create an Account](createaccount.cgi)

Red Hat Bugzilla – Bug 216452

* [Home](./)
* [New](enter_bug.cgi)
* Search
  + [Simple Search](query.cgi?format=specific)
  + [Advanced Search](query.cgi?format=advanced)
* My Links
  + [Browse](describecomponents.cgi)
  + [Requests](request.cgi)
  + Reports
  + Current State
    - [Search](query.cgi)
    - [Tabular reports](query.cgi?format=report-table)
    - [Graphical reports](query.cgi?format=report-graph)
    - [Duplicates](duplicates.cgi)
  + Other Reports
    - [User Changes](https://bugzilla.redhat.com/page.cgi?id=user_activity.html)
  + Plotly Reports
    - [Bug Status](https://bugzilla.redhat.com/page.cgi?id=bug_status.html)
    - [Bug Severity](https://bugzilla.redhat.com/page.cgi?id=bug_severity.html)
    - [Non-Defaults](https://bugzilla.redhat.com/page.cgi?id=non_defaults.html)
* [Product Dashboard](page.cgi?id=productdashboard.html)

- Help
  * [Page Help!](docs/en/html/using/understanding.html)
  * [Bug Writing Guidelines](page.cgi?id=bug-writing.html)
  * [What's new](page.cgi?id=whats-new.html)
  * [Browser Support Policy](https://access.redhat.com/help/browsers)
  * [5.0.4.rh103 Release notes](page.cgi?id=release-notes.html)
  * [FAQ](page.cgi?id=faq.html)
  * [Guides index](docs/en/html/index.html)
  * [User guide](docs/en/html/using/index.html)
  * [Web Services](docs/en/html/integrating/api/Bugzilla/WebService/Bug.html)
  * [Contact](page.cgi?id=redhat/contact.html)
  * [Legal](page.cgi?id=terms-conditions.html)
- [[?]](page.cgi?id=quicksearch.html "Quicksearch Help")

This site requires JavaScript to be enabled to function correctly, please enable it.

[**Bug 216452**](show_bug.cgi?id=216452)
(CVE-2006-5751)
- [CVE-2006-5751](https://access.redhat.com/security/cve/CVE-2006-5751) Linux kernel get\_fdb\_entries() integer overflow

[Summary:](page.cgi?id=fields.html#short_desc "The bug summary is a short sentence which succinctly describes what the bug is about.")
CVE-2006-5751 Linux kernel get\_fdb\_entries() integer overflow

| | [Keywords](describekeywords.cgi): | Security | | --- | --- | | [Status](page.cgi?id=fields.html#bug_status): | CLOSED ERRATA | | [Alias:](page.cgi?id=fields.html#alias "A short, unique name assigned to a bug in order to assist with looking it up and referring to it in other places in Bugzilla.") | CVE-2006-5751 | | [Product:](describecomponents.cgi "Bugs are categorised into Products and Components. Select a Classification to narrow down this list.") | Security Response | | [Classification:](page.cgi?id=fields.html#classification "Bugs are categorised into Classifications, Products and Components. classifications is the top-level categorisation.") | Other | | [Component:](describecomponents.cgi?product=Security Response "Components are second-level categories; each belongs to a particular Product. Select a Product to narrow down this list.") | vulnerability | | [Sub Component:](page.cgi?id=fields.html#rh_sub_components "The sub component of a specific component") | --- | | [Version:](page.cgi?id=fields.html#version "The version field defines the version of the software the bug was found in.") | unspecified | | [Hardware:](page.cgi?id=fields.html#rep_platform "The hardware platform the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | All | | [OS:](page.cgi?id=fields.html#op_sys "The operating system the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | Linux | | [Priority:](page.cgi?id=fields.html#priority) | medium | | [Severity:](page.cgi?id=fields.html#bug_severity) | high | | [Target Milestone:](page.cgi?id=fields.html#target_milestone "The Target Milestone field is used to define when the engineer the bug is assigned to expects to fix it.") | --- | | [Assignee:](page.cgi?id=fields.html#assigned_to "The person in charge of resolving the bug.") | Thomas Graf | | [QA Contact:](page.cgi?id=fields.html#qa_contact "The person responsible for confirming this bug if it is unconfirmed, and for verifying the fix once the bug has been resolved.") | Brian Brock | | [Docs Contact:](page.cgi?id=fields.html#docs_contact "The person responsible for documenting once the bug has been resolved.") |  | | [URL:](page.cgi?id=fields.html#bug_file_loc "Bugs can have a URL associated with them - for example, a pointer to a web site where the problem is seen.") |  | | [Whiteboard:](page.cgi?id=fields.html#status_whiteboard "Each bug has a free-form single line text entry box for adding tags and status information.") |  | | [Depends On:](page.cgi?id=fields.html#dependson "The bugs listed here must be resolved before this bug can be resolved.") |  | | [Blocks:](page.cgi?id=fields.html#blocked "This bug must be resolved before the bugs listed in this field can be resolved.") |  | | TreeView+ | [depends on](buglist.cgi?bug_id=216452&bug_id_type=anddependson&format=tvp) / [blocked](buglist.cgi?bug_id=216452&bug_id_type=andblocked&format=tvp&tvp_dir=blocked) |  | |  | | [Reported:](page.cgi?id=fields.html#reporter) | 2006-11-20 16:24 UTC by Marcel Holtmann | | --- | --- | | [Modified:](page.cgi?id=fields.html#modified) | 2021-11-12 19:35 UTC ([History](show_activity.cgi?id=216452)) | | [CC List:](page.cgi?id=fields.html#cclist) | 4 users (show)  eteo jbaron rkhan security-response-team | | Fixed In Version: | RHSA-2007-0014 | | | Doc Type: | Bug Fix | | | Doc Text: |  | | | Clone Of: |  | | | Environment: |  | | | Last Closed: | 2007-01-30 14:42:02 UTC | | | Embargoed: |  | | |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| --- | | |

| | Attachments | [(Terms of Use)](page.cgi?id=terms-conditions.html) | | | --- | --- | --- | |  | | |    Links | System | ID | Private | Priority | Status | Summary | Last Updated | | Red Hat Product Errata | [RHSA-2007:0014](https://access.redhat.com/errata/RHSA-2007%3A0014) | 0 | normal | SHIPPED\_LIVE | Important: kernel security update | 2007-01-30 14:25:00 UTC | |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |

| [Description](show_bug.cgi?id=216452#c0)  Marcel Holtmann    2006-11-20 16:24:26 UTC  ``` From Eugene Teo:  A potential security vulnerability has been found in the Linux kernel in the get_fdb_entries() function code. Successful exploitation may potentially allow execution of arbitrary code with escalated privileges.  The vulnerable code resides in net/bridge/br_ioctl.c:   56 static _nt get_fdb_entries(struct net_bridge *br, void __user *userbuf,  57                            unsigned long maxnum, unsigned long offset)  58 {  59         int num;  60         void *buf;  61         size_t size = maxnum * sizeof(struct __fdb_entry);  62  63         if (size > PAGE_SIZE) {  64                 size = PAGE_SIZE;  65                 maxnum = PAGE_SIZE/sizeof(struct __fdb_entry);  66         }  67  68         buf = kmalloc(size, GFP_USER);  69         if (!buf)  70                 return -ENOMEM;  71  72         num = br_fdb_fillbuf(br, buf, maxnum, offset);  By supplying a sufficiently large value to maxnum, we can control the amount of memory to allocate to buf (i.e. 32 bytes).  net/bridge/br_fdb.c:  219 int br_fdb_fillbuf(struct net_bridge *br, void *buf, 220                    unsigned long maxnum, unsigned long skip) 221 { 222         struct __fdb_entry *fe = buf; /* ... */ 227         memset(buf, 0, maxnum*sizeof(struct __fdb_entry)); 228 229         rcu_read_lock(); 230         for (i = 0; i < BR_HASH_SIZE; i++) { 231                 hlist_for_each_entry_rcu(f, h, &br->hash[i], hlist) { 232                         if (num >= maxnum) 233                                 goto out; 234 235                         if (has_expired(br, f)) 236                                 continue; 237 238                         if (skip) { 239                                 --skip; 240                                 continue; 241                         } 242 243                         /* convert from internal format to API */ 244                         memcpy(fe->mac_addr, f->addr.addr, ETH_ALEN); 245                         fe->port_no = f->dst->port_no; 246                         fe->is_local = f->is_local; 247                         if (!f->is_static) 248                                 fe->ageing_timer_value = jiffies_to_clock_t(jiffies - f->ageing_timer); 249                         ++fe; 250                         ++num; 251                 } 252         }  because fe = buf, and buf can be allocated with only 32 bytes, if one bridge has more than two interfaces added, memcpy will be able to overwrite other slab objects, which can be exploited to execute arbitrary code.   ```  [Comment 6](show_bug.cgi?id=216452#c6)  Jason Baron    2006-12-11 22:13:56 UTC  ``` committed in stream U5 build 42.30. A test kernel with this patch is available from <http://people.redhat.com/~jbaron/rhel4/>    ```  [Comment 7](show_bug.cgi?id=216452#c7)  Jason Baron    2006-12-18 21:50:22 UTC  ``` committed in stream E5 build 42.0.4. A test kernel with this patch is available from <http://people.redhat.com/~jbaron/rhel4/>    ```  [Comment 15](show_bug.cgi?id=216452#c15)  Mike Gahagan    2007-01-24 20:48:21 UTC  ``` fix for this is in 42.0.8.     ```  [Comment 17](show_bug.cgi?id=216452#c17)  Red Hat Bugzilla    2007-01-30 14:42:02 UTC  ```  An advisory has been issued which should help the problem described in this bug report. This report is therefore being closed with a resolution of ERRATA. For more information on the solution and/or where to find the updated files, please follow the link below. You may reopen this bug report if the solution does not work for you.  <http://rhn.redhat.com/errata/RHSA-2007-0014.html>    ``` |  |
| --- | --- |

---

| Note You need to [log in](show_bug.cgi?id=216452&GoAheadAndLogIn=1) before you can comment on or make changes to this bug. |
| --- |

---

[Privacy](page.cgi?id=redhat/privacy.html)
[Contact](page.cgi?id=redhat/contact.html)
[FAQ](page.cgi?id=faq.html)
[Legal](page.cgi?id=terms-conditions.html)



=== Content from secunia.com_46e65489_20250125_174324.html ===


[Skip to main content](#main-content)
[![Home](/themes/custom/flexera/images/logo.svg)](https://www.flexera.com/)

[![Home](/themes/custom/flexera/images/logo.svg)](https://www.flexera.com/)

Search

## Main navigation

* Solutions
  + Column 1
    - Business challenge
      * [Software renewals and audits](https://www.flexera.com/solutions/software-renewals-audits)
      * [Software license management and optimization](https://www.flexera.com/solutions/software-usage-costs)
      * [SaaS spend management](https://www.flexera.com/solutions/saas-spend)
      * [Cloud cost management](https://www.flexera.com/solutions/cloud-cost)
      * [IT asset lifecycle management](https://www.flexera.com/solutions/it-asset-lifecycle)
      * [CMDB data quality](https://www.flexera.com/solutions/cmdb-data-quality)
      * [Accurate IT inventory](https://www.flexera.com/solutions/it-inventory)
      * [Security and regulatory risk management](https://www.flexera.com/solutions/it-security-regulatory-risk)
      * [Sustainable IT](https://www.flexera.com/solutions/sustainable-it)
      * [AI-powered transformation](https://www.flexera.com/solutions/ai-powered-transformation)
      * [Public sector](https://www.flexera.com/solutions/public-sector)
  + Column 2
    - Spend management by vendor
      * [IBM](https://www.flexera.com/solutions/vendor/ibm)
      * [Oracle](https://www.flexera.com/solutions/vendor/oracle)
      * [Microsoft](https://www.flexera.com/solutions/vendor/microsoft)
      * [SAP](https://www.flexera.com/solutions/vendor/sap)
      * [VMware](https://www.flexera.com/solutions/vendor/vmware)
      * [ServiceNow](https://www.flexera.com/solutions/vendor/servicenow)
      * [AWS](https://www.flexera.com/solutions/vendor/aws)
      * [Salesforce](https://www.flexera.com/solutions/vendor/salesforce)
      * [BMC](https://www.flexera.com/solutions/cmdb-data-quality/bmc)
      * [Adobe](https://www.flexera.com/solutions/vendor/adobe)

  ### Achieve more through a united FinOps and ITAM function

  The future is hybrid. Break down the walls between ITAM and FinOps to drive more revenue, more customer growth and more innovation.

  [Discover More](https://www.flexera.com/resources/hybrid-itam-finops)
* Products
  + Column 1
    - [Flexera One](https://www.flexera.com/products/flexera-one)
      * [IT Visibility](https://www.flexera.com/products/flexera-one/it-visibility)
      * [ITAM](https://www.flexera.com/products/flexera-one/it-asset-management)
      * [SaaS Management](https://www.flexera.com/products/flexera-one/saas-management)
      * [FinOps](https://www.flexera.com/products/flexera-one/finops)
      * [Technology Intelligence Platform](https://www.flexera.com/products/flexera-one/technology-intelligence-platform)
  + Column 2
    - [Snow Atlas](https://www.flexera.com/products/snow-atlas)
      * [Snow Spend Optimizer](https://www.flexera.com/products/snow-atlas/snow-spend-optimizer)
      * [Snow SaaS Management](https://www.flexera.com/products/snow-atlas/snow-saas-management)
  + Column 3
    - Hide group
      * [Security](https://www.flexera.com/products/security)
      * [Application Readiness](https://www.flexera.com/products/adminstudio)
      * [All products](https://www.flexera.com/products)
      * [All Snow products](https://www.flexera.com/products/snow)
      * [Integrations](https://www.flexera.com/products/integrations)

  ### Flexera 2024 State of the Cloud Report

  What do transformative initiatives such as GenAI, machine learning and sustainability mean for the cloud? Check out the 2024 State of the Cloud Report to find the answer as well as all the latest cloud computing trends.

  [View Report](https://info.flexera.com/CM-REPORT-State-of-the-Cloud)
* Success
  + Column 1
    - [Customer success](https://www.flexera.com/customer-success)
      * Support
        + [Flexera support portal](https://community.flexera.com/s/support-hub)
        + [Flexera product documentation](https://docs.flexera.com)
        + [Snow product documentation](https://docs.snowsoftware.io/)
      * Services and training
        + [Services](https://www.flexera.com/customer-success/services)
        + [Training](https://www.flexera.com/customer-success/training)
  + Column 2
    - Hide group
      * [Technology Intelligence Awards](https://www.flexera.com/customer-success/awards)
      * [Flexera community](https://community.flexera.com/s/)

  ### Insights from Gartner®

  Find a curated series of actionable and objective insights for IT executives and their teams. Get expert insights from valued analysts, courtesy of Flexera.

  [Discover More](https://www.flexera.com/resources/gartner-analyst-research)
* Resources
  + Column 1
    - [Resources](https://www.flexera.com/resources)
      * [Webinars](https://www.flexera.com/resources?type%5Bwebinar%5D=webinar)
      * [Videos](https://www.flexera.com/resources?type%5Bvideo%5D=video)
      * [Datasheets](https://www.flexera.com/resources?type%5Bdatasheet%5D=datasheet)
      * [White papers & reports](https://www.flexera.com/resources?type%5Bwhite-paper-industry-report%5D=white-paper-industry-report)
  + Column 2
    - Hide group
      * [Blog](/blog/)
      * [Case studies](https://www.flexera.com/resources/case-studies)
      * [Events](https://www.flexera.com/resources?type%5Bevent%5D=event)
      * [Analyst Research](https://www.flexera.com/resources/gartner-analyst-research)
      * [Glossary](https://www.flexera.com/resources/glossary)
      * [Demos & trials](https://www.flexera.com/resources?type%5Bdemo-trials%5D=demo-trials)
      * [Business value calculator](https://www.flexera.com/resources/business-value-calculator)

  ### Flexera 2025 IT Priorities Report

  Insights from Flexera’s 2025 IT Priorities Report highlight what’s top of mind for IT decision makers in the year ahead. Discover the challenges, priorities and opportunities that will shape the future IT landscape.

  [View Report](https://info.flexera.com/ITV-REPORT-IT-Priorities)
* About
  + Column 1
    - [Company](https://www.flexera.com/about-us)
      * [About](https://www.flexera.com/about-us)
      * [Careers](https://www.flexera.com/about-us/careers)
      * [Contact](https://www.flexera.com/about-us/contact-us)
      * [Leadership](https://www.flexera.com/about-us/leadership)
    - [Partners](https://www.flexera.com/about-us/partners)
      * [Partner program](https://www.flexera.com/about-us/partners/partner-program)
      * [Partner directory](https://www.flexera.com/about-us/partners/directory)
  + Column 2
    - [Press center](https://www.flexera.com/about-us/press-center)
      * [Press releases](https://www.flexera.com/about-us/all-press-releases)
      * [Awards](https://www.flexera.com/about-us/press-center#awards)
      * [Articles](https://www.flexera.com/about-us/all-articles)
    - Hide group
      * Social responsibility
        + [ESG](https://www.flexera.com/about-us/environmental-social-governance)
        + [Diversity](https://www.flexera.com/about-us/diversity)

  ### More value with technology intelligence

  The unparalleled synergy of Flexera and Snow provides the Technology Intelligence you need for more efficiency, insight and governance than ever before.

  [Discover More](https://www.flexera.com/more-value-with-technology-intelligence)

Search

en

* [English](https://www.flexera.com/products/security/software-vulnerability-research/secunia-research?referrer=secunia)
* [Deutsch](https://www.flexera.de/products/security/software-vulnerability-research/secunia-research?referrer=secunia)

## External Links

* External Links
  + [Community](https://community.flexera.com/)
  + [Product Access](https://app.flexera.com/login)
  + [Partner Portal](https://flexera.channeltivity.com/Login)

[Book a demo](/about-us/contact-us?C_Interest1=sales)

# Secunia Research

## The world’s best vulnerability intelligence

The Secunia Research team from Flexera provides the most accurate and reliable source of vulnerability intelligence.

[Contact Us](https://www.flexera.com/about-us/contact-us?C_Interest1=sales&C_SolutionInterest=SVM)
Watch video (0:29)

Related links

* [Anatomy of a security advisory](https://www.flexera.com/resources/infographics/anatomy-of-a-security-advisory)
* [Software Vulnerability Research](https://www.flexera.com/products/software-vulnerability-research)
* [Software Vulnerability Manager](/products/software-vulnerability-manager)
* [Security advisories from Secunia Research](https://www.flexera.com/products/security/software-vulnerability-advisories)
* [Report a vulnerability](https://www.flexera.com/about-us/contact-us/report-vulnerability)

 ![Secunia Research](/sites/default/files/2022-04/hero-secunia-research-bg.jpg)

Featured Details

## Multiple ways to consume Secunia Research

Secunia delivers software security research that provides reliable, curated and actionable vulnerability intelligence. Organizations can expect to receive standardized, validated and enriched vulnerability research on a specific version of a software product. Secunia Research supports four solutions:

![Software Vulnerability Research](/sites/default/files/2022-04/icon-secunia-research-svr.svg)

### [Software Vulnerability Research](https://www.flexera.com/products/software-vulnerability-research)

Software Vulnerability Research utilizes Secunia Research to drive awareness of vulnerabilities matching your specified criteria

[Learn More](https://www.flexera.com/products/software-vulnerability-research)

![Software Vulnerability Manager](/sites/default/files/2022-04/icon-secunia-research-svm.svg)

### [Software Vulnerability Manager](/products/software-vulnerability-manager)

Software Vulnerability Manager uses Secunia Research data to identify, prioritize and patch known vulnerable software detected in your environment

[Learn More](/products/software-vulnerability-manager)

![Data Platform](/sites/default/files/2022-04/icon-secunia-research-dp.svg)

### [Data Platform](https://www.flexera.com/products/data-platform)

Data Platform leverages Secunia Research to provide high-level insights based on major or minor versions of software in your normalized inventory

[Learn More](https://www.flexera.com/products/data-platform)

![Flexera One](/sites/default/files/2022-04/icon-secunia-research-flexera-one.svg)

### [Flexera One](/flexera-one)

Flexera One utilizes Secunia Research (alongside public NVD data) to provide more granular matching of build-level versions of software in your normalized inventory within its IT Asset Management and IT Visibility solutions

[Learn More](/flexera-one)

How it works

## Accurate, reliable vulnerability insights at your fingertips

The Secunia Research team from Flexera is comprised of several security specialists who conduct vulnerability research in various products in addition to testing, verifying and validating public vulnerability reports. Since its inception in 2002, the goal of the Secunia Research team is to provide the most accurate and reliable source of vulnerability intelligence.

Delivering the world’s best vulnerability intelligence requires skill and passion. Team members continually develop their skills exploring various high-profile closed and open-source software using a variety of approaches, focusing chiefly on thorough code audits and binary analysis. The team has received industry recognition, including naming members to [Microsoft’s Most Valuable Security Researchers](https://msrc-blog.microsoft.com/2019/08/07/announcing-2019-msrc-most-valuable-security-researchers/) list.

Secunia researchers discover hard-to-find vulnerabilities that aren’t normally identified with techniques such as fuzzing, and the results have been impressive. Members of the Secunia Research team have discovered critical vulnerabilities in products from vendors including Microsoft, Symantec, IBM, Adobe, RealNetworks, Trend Micro, HP, Blue Coat, Samba, CA, Mozilla and Apple.

The team produces invaluable security advisories based on research of the vulnerabilities affecting any given software update. Sometimes a single update can address multiple vulnerabilities of varying criticalities and threats; but these advisories aggregate and distill findings down to a single advisory perfect for the prioritization of patching efforts within [Software Vulnerability Manager](/products/software-vulnerability-manager). Criticality scores are consistently applied along with details around attack vector and other valuable details within [Software Vulnerability Research](/products/software-vulnerability-research/secunia-research). Illegitimate vulnerability reports are also investigated and rejected so you can focus only on what truly matters.

Informing IT, Transforming IT

## Industry insights to help keep you informed

[#### Webinar

### Stay Ahead of Cyber Threats: Flexera's Latest Vulnerability Insights

Join us for this session where we'll explore the latest findings from the Flexera Monthly Vulnerability Insights Report.](https://info.flexera.com/SVM-WBNR-Vulnerability-Insights-Roundtable)

[#### Webinar

### Dive deeper into the Flexera Annual Vulnerability Insights

We'll explore the key findings from the Flexera Annual Vulnerability Insights Report. Learn about the latest cybersecurity trends, the most targeted industries, the types of vulnerabilities, plus management and mitigation strategies.](https://info.flexera.com/SVM-WBNR-Flexera-Annual-Vulnerability-Insights?lead_source=Website%20Visitor&id=Flexera.com-Resources)

#### Video

### Close the Risk Window with Software Vulnerability Manager

Stop reacting. Gain control. Stay secure. Build a more effective risk mitigation process leveraging Secunia Research vulnerability intelligence and the largest repository of third-party patch data in the industry.

Remote video URL

[#### Trial

### Software Vulnerability Manager Assessment free trial

Get access to the complete set of modules of Software Vulnerability Manager: Research, Assessment and Patching](https://info.flexera.com/SVM-EVAL-Software-Vulnerability-Manager)

[#### Datasheet

### Protect your ServiceNow® investment with the highest quality data

IT Visibility offers certified ServiceNow integrations that accelerate platform expansion, improve ROI and increase efficiencies across ITIL processes by delivering clean software and hardware asset data directly.](/sites/default/files/datasheet-itv-maximize-servicenow-investment.pdf)

[#### Blog

### Avoid missing crucial vulnerability intelligence amid NVD backlog

Recent developments regarding the National Vulnerability Database (NVD) have some technology leaders on edge. Since February, the U.S. National Institute of Standards and Technology (NIST) has almost completely stopped enriching software vulnerabi...](https://www.flexera.com/blog/vulnerability-management/avoid-missing-crucial-vulnerability-intelligence-amid-nvd-backlog/)

[View all resources](https://www.flexera.com/resources?category%5Bsoftware-vulnerability-management%5D=software-vulnerability-management)

## Footer Menu

* Column
  + Business challenge
    - [Software renewals and audits](https://www.flexera.com/solutions/software-renewals-audits)
    - [Software license management and optimization](https://www.flexera.com/solutions/software-usage-costs)
    - [SaaS spend management](https://www.flexera.com/solutions/saas-spend)
    - [Cloud cost management](https://www.flexera.com/solutions/cloud-cost)
    - [IT asset lifecycle management](https://www.flexera.com/solutions/it-asset-lifecycle)
    - [CMDB data quality](https://www.flexera.com/solutions/cmdb-data-quality)
    - [Accurate IT inventory](https://www.flexera.com/solutions/it-inventory)
    - [Security and regulatory risk management](https://www.flexera.com/solutions/it-security-regulatory-risk)
    - [Sustainable IT](https://www.flexera.com/solutions/sustainable-it)
    - [AI-powered transformation](https://www.flexera.com/solutions/ai-powered-transformation)
    - [Public sector](https://www.flexera.com/solutions/public-sector)
* Column
  + Spend management by vendor
    - [IBM](https://www.flexera.com/solutions/vendor/ibm)
    - [Oracle](https://www.flexera.com/solutions/vendor/oracle)
    - [Microsoft](https://www.flexera.com/solutions/vendor/microsoft)
    - [SAP](https://www.flexera.com/solutions/vendor/sap)
    - [VMware](https://www.flexera.com/solutions/vendor/vmware)
    - [ServiceNow](https://www.flexera.com/solutions/vendor/servicenow)
    - [AWS](https://www.flexera.com/solutions/vendor/aws)
    - [Salesforce](https://www.flexera.com/solutions/vendor/salesforce)
    - [BMC](https://www.flexera.com/solutions/cmdb-data-quality/bmc)
    - [Adobe](https://www.flexera.com/solutions/vendor/adobe)
* Column
  + Products
    - [Flexera One](https://www.flexera.com/products/flexera-one)
    - [Snow Atlas](https://www.flexera.com/products/snow-atlas)
    - [Security](https://www.flexera.com/products/security)
    - [Application Readiness](https://www.flexera.com/products/adminstudio)
    - [All products](https://www.flexera.com/products)
    - [All Snow products](https://www.flexera.com/products/snow)
    - [Integrations](https://www.flexera.com/products/integrations)
* Column
  + Company
    - [About](https://www.flexera.com/about-us)
    - [Careers](https://www.flexera.com/about-us/careers)
    - [Leadership](https://www.flexera.com/about-us/leadership)
    - [Contact us](https://www.flexera.com/about-us/contact-us)
    - [Media / press center](https://www.flexera.com/about-us/press-center)
    - [Revenera.com](https://www.revenera.com)

 +1.800.374.4353

en

* [English](https://www.flexera.com/products/security/software-vulnerability-research/secunia-research?referrer=secunia)
* [Deutsch](https://www.flexera.de/products/security/software-vulnerability-research/secunia-research?referrer=secunia)

 [![Home](/themes/custom/flexera/images/logo.svg)](https://www.flexera.com/)

© 2025 Flexera. All Rights Reserved.

## Footer

* [Privacy Policy](https://www.flexera.com/legal/privacy-policy)
* [Terms and conditions](https://www.flexera.com/legal)
* [Contact Us](https://www.flexera.com/about-us/contact-us)
* [Impressum](https://www.flexera.com/about-us/impressum)
* [Site Map](https://www.flexera.com/sitemap)

#####

×

...



=== Content from www.mandriva.com_8ce59090_20250125_174332.html ===


* [Tuxedo.org](https://tuxedo.org/ "Go to: Tuxedo")
* Store
* Mandriva Linux
* Enterprise Solutions
* Contact Us
* Language ![](/sites/all/themes/mandriva_customer/images/arrow-grey-bottom.gif)
  + English (International)
  + Français
  + Ð ÑÑÑÐºÐ¸Ð¹

# [Mandriva](/mandriva/)

* Download
* Mandriva Linux
* Community
* Help

## One

### The Linux desktopthat's easy to try and easy to keep

Download
![Mandriva One](/sites/all/themes/mandriva_customer/images/front/packshot_Mandriva_One.png)

## Powerpack

### Mandriva Linux- and more

Download
![Mandriva Linux Powerpack](/sites/all/themes/mandriva_customer/images/front/en-49.png)

## Mandriva Flash

### The mobile and installable Linux desktopon a USB key

Buy on Store
![Mandriva Flash](/sites/all/themes/mandriva_customer/images/front/mandriva-flash2.png)

### [Community](community)

* User Forums
* Support - FAQ
* Free Software
* Become a member

### Enterprise Solutions

* Enterprise Linux Products
* Asset Management Solution
* Professional Services
* Support & Maintenance

* Go to site »

### Mandriva Partners

* Worldwide offices
* Partner Program
* Technology Partners
* OEM
* Classmate PC with Mandriva Linux

### News

* Mandriva presents the launch of its new mobile desktop: Mandriva Flash 2008 Spring
* Speaking about Mandriva Linux 2008 Spring in media
* Speaking about Mandriva Linux 2008 Spring in media
* Mandriva presents its latest distribution: Mandriva Linux 2008 Spring
* Mandriva and Novatice Technologies present Edutice, The ready to use solution dedicated to educationand multimedia spaces
* # [Top 50 Online Casinos UK in 2023](https://montycasinos.com/online-casinos/)

more

* Download
  + Mandriva Linux 2008
  + Writing an ISO image
* Mandriva Linux
  + One
  + Powerpack
  + Mandriva Flash
* Community
  + Start
  + Register
  + Stay informed
  + Participate
  + Free software
* Help
  + Getting help
  + Knowledge Base
  + Documentation
  + Forums
  + Support Requests
  + Customer Care
  + Enterprise Support
* Enterprise Solutions
  + Products
  + Support
  + Services
  + Partners
  + Go to site »

Language
English (International)
Français
Ð ÑÑÑÐºÐ¸Ð¹

* © 2007 Mandriva S.A.
* About Us
* Legal Information
* Privacy Policy
* Contact Us



=== Content from www.novell.com_8808054b_20250125_174334.html ===

![](/assets/img/1px-transparent.gif)
![](/assets/img/1px-transparent.gif)

[![SUSE Logo](https://www.suse.com/assets/img/suse-white-logo-green.svg)
![SUSE Federal Logo](https://www.suse.com/assets/img/fed_logo.png)](https://www.suse.com)
Exit SUSE Federal  >

[Customer Center](https://scc.suse.com/home)

Account

Hello
[Update Your Account](https://www.suse.com/account/update/)
[Log Out](https://www.suse.com/saml2/logout/)

[Login](https://www.suse.com/saml2/login/)
[Create Account](https://www.suse.com/account/create/)
[Update Your Account](https://www.suse.com/account/update/)

English

Language
[Deutsch](https://www.suse.com/de-de/support/security/)
[English](https://www.suse.com/support/security/)
[Español](https://www.suse.com/es-es/support/security/)
[Français](https://www.suse.com/fr-fr/support/security/)
[中文(简体)](https://www.suse.com/zh-cn/support/security/)
[日本語](https://www.suse.com/ja-jp/support/security/)
[한국어](https://www.suse.com/ko-kr/support/security/)
[Português (Brasil)](https://www.suse.com/pt-br/support/security/)

[Shop](https://www.suse.com/shop/)

[View Cart](https://buy.suse.com/store?Action=DisplayPage&Env=BASE&SiteID=suse&id=ThreePgCheckoutShoppingCartPage)

[![SUSE Logo](https://www.suse.com/assets/img/suse-white-logo-green.svg)](https://www.suse.com)
Exit SUSE Federal  >

[Shop](https://www.suse.com/shop/)
[SUSECON 25](https://www.suse.com/susecon/)
[Customer](https://scc.suse.com/home)

Federal Solutions

Products

Solutions

Support

Partners

Communities

About

[Contact Us](https://www.suse.com/contact/)

[Free Downloads](https://www.suse.com/products/)

 Back

 Back
[![Icon](https://www.suse.com/assets/img/icons/Linux-one-color.svg)
Linux](https://www.suse.com/solutions/business-critical-linux/ "Linux")

* [SUSE Linux Enterprise Server](https://www.suse.com/products/server/)
* [SUSE Linux Enterprise Server

  for SAP Applications](https://www.suse.com/products/sles-for-sap/)
* [SUSE Linux Micro](https://www.suse.com/products/micro/)
* [SUSE Multi-Linux Support](https://www.suse.com/products/multi-linux-support/)
* [SUSE Multi-Linux Manager](https://www.suse.com/products/multi-linux-manager/)

[![Icon](https://www.suse.com/assets/img/icons/Cloud-native-one-color.svg)
Cloud Native](https://www.suse.com/solutions/enterprise-container-management/ "Cloud Native")

* [SUSE Rancher Prime](https://www.suse.com/products/rancher/)
* [Virtualization (Harvester)](https://www.suse.com/products/rancher/virtualization/)
* [Storage (Longhorn)](https://www.suse.com/products/rancher/storage/)
* [Security (NeuVector)](https://www.suse.com/products/rancher/security/)
* [Observability](https://www.suse.com/solutions/observability/)
* [SUSE Cloud Observability](https://www.suse.com/products/cloud/observability/)

[![Icon](https://www.suse.com/assets/img/icons/Edge-one-color.svg)
Edge](https://www.suse.com/solutions/edge-computing/ "Edge")

* [SUSE Edge](https://www.suse.com/products/edge/)
* [SUSE Edge for Telco](https://www.suse.com/products/edge-for-telco/)

[![Icon](https://www.suse.com/assets/img/icons/AI-one-color.svg)
AI](https://www.suse.com/solutions/edge-computing/ "AI")

* [SUSE AI](https://www.suse.com/products/ai/)

[All Products](https://www.suse.com/products/)

 Back
Foundational

* [![Linux](https://www.suse.com/assets/img/icons/Linux-one-color.svg)](https://www.suse.com/solutions/linux/)
* [![Cloud Native](https://www.suse.com/assets/img/icons/Cloud-native-one-color.svg)](https://www.suse.com/solutions/cloud-native/)
* [![Edge](https://www.suse.com/assets/img/icons/Edge-one-color.svg)](https://www.suse.com/solutions/edge/)
* [![AI](https://www.suse.com/assets/img/icons/AI-one-color.svg)](https://www.suse.com/solutions/ai/)

Solutions

* [Run SAP

  Run & secure cloud and on-prem workloads](https://www.suse.com/solutions/run-sap-solutions/)
* [Public Cloud

  Accelerate and innovate across your cloud environment](https://www.suse.com/solutions/public-cloud/)
* [Observability

  Rapid, full-stack visibility in under 5 minutes](https://www.suse.com/solutions/observability/)
* [Security

  Secure your digital enterprise](https://www.suse.com/solutions/security/)

Industries

* [Automotive](https://www.suse.com/sector/automotive/)
* [Telecom](https://www.suse.com/sector/telco/)
* [Banking and Financial Systems](https://www.suse.com/sector/banking-financial-services/)
* [Healthcare](https://www.suse.com/sector/healthcare/)
* [Manufacturing](https://www.suse.com/sector/manufacturing/)
* [Retail](https://www.suse.com/sector/retail/)
* [Technology & Software](https://www.suse.com/sector/technology/)
* [Federal](https://www.ranchergovernment.com/)
* [Pharma](https://www.suse.com/sector/pharma/)
* [Energy](https://www.suse.com/sector/energy/)

 Back
Support

* [Product Support

  SUSE Customer Center](https://scc.suse.com/home)
* [Premium Support Services

  Dedicated support services from a premium team](https://www.suse.com/services/premium/)
* [Long Term Services Support

  Stay on your existing product version](https://www.suse.com/products/long-term-service-pack-support/)
* [Renew Your Support Subscription

  Partners with cloud providers](https://www.suse.com/renewals/)
* [![AWS](https://www.suse.com/assets/img/icons/320px-Amazon3.svg)](https://aws.amazon.com/marketplace/search/results?searchTerms=suse)
* [![Microsoft Azure](https://www.suse.com/assets/img/icons/Microsoft_Azure3.svg)](https://azure.microsoft.com/en-us/solutions/linux-on-azure/suse/)
* [![Google](https://www.suse.com/assets/img/icons/lockup_GoogleCloud_FullColor_rgb_139x24px 1.svg)](https://console.cloud.google.com/marketplace/browse?q=SUSE)

Services

* [Consulting Services](https://www.suse.com/services/)
* [Training & Certification](https://www.suse.com/training/)
* [Premium Technical Advisory Services](https://www.suse.com/services/premium-technical-advisory/)

Resources

* [SUSE Support User Guide](https://www.suse.com/support/handbook/)
* [Patches & Updates](https://download.suse.com/patch/finder/)
* [Product Documentation](https://documentation.suse.com/)
* [Knowledgebase](https://www.suse.com/support/kb/)
* [Product Support Life Cycle](https://www.suse.com/lifecycle/)
* [Package Hub

  Community packages for SUSE Linux Enterprise Server](https://packagehub.suse.com/)
* [Driver Search](https://drivers.suse.com/)
* [Support Forums](https://forums.suse.com/forum.php)
* [Developer Services](https://www.suse.com/services/support-offerings/developer-services/)
* [Beta Program](https://www.suse.com/betaprogram/)
* [Security](https://www.suse.com/support/security/)

 Back
Partners

* [Partner Program](https://www.suse.com/partners/)
* [Find a Partner](https://www.suse.com/partners/find-partner/)
* [Become a Partner](https://www.suse.com/partners/become-partner/)
* [Login to the SUSE Partner Portal](https://partner.suse.com/)

 Back
Communities

* [Blog](https://www.suse.com/c/blog/)
* [Forum](https://forums.suse.com/forum.php)
* [Open Source Projects](http://opensource.suse.com/)
* [openSUSE.org](https://www.opensuse.org/)

 Back
About

* [About](https://www.suse.com/company/about/)
* [Leadership](https://www.suse.com/leadership/)
* [Careers](https://jobs.suse.com/)
* [Newsroom](https://www.suse.com/news/)
* [Success Stories](https://www.suse.com/success/)
* [Investor Relations](https://ir.suse.com/)
* [Social Impact](https://www.suse.com/esg/)
* [SUSE Logo and Brand](https://brand.suse.com/)
* [Events](https://www.suse.com/events/)
* [Merchandise Store](https://www.susemerchandise.com/)

## SUSE Security

# A Process That Never Ends

### SUSE is committed to delivering best effort security to its customers and to the Open Source community. We believe that trust in Open Source Software security in general, and the user's privacy in particular, are both indispensable and indefeasible.

We treat software security as a process that never ends. This means we:

* Promptly react to security incidents and deliver premium quality security updates
* Continuously improve the security-related functionality in SUSE products
* Continuously contribute to the rapidly growing maturity of Open Source Software
* Respect the Open Source Software security principles of openness, transparency and traceability

Software security is a complex challenge. Software can provide many of its own security features, such as authentication methods, encryption, intrusion prevention and detection, and backup.

At the same time, it can also contain errors (both deliberate and accidental) that can affect the system's security, including design flaws, programming errors, and backdoors.

The SUSE Security Team addresses all of these aspects of software security, on an ongoing basis. Software security cannot be thought of as a state you can achieve at a specific point in time. Instead, it is a process that must be executed with professional expertise and continuous development. This persistent focus is what has given Open Source Software, Linux and SUSE such an excellent reputation for security.

#### SUSE Security Resources

* [Security Updates](/support/update/)
* [Security Overview](/support/security/mission/)
* [Security Contacts](/support/security/contact/)
* [SUSE Security Certificates and Features](/support/security/certifications/)
* [SUSE Linux Enterprise Server download verification](/support/security/download-verification/)
* [Security updates by CVE number](/security/cve/)
* [Security information in OVAL format](/support/security/oval/)
* [Security information in CVRF format](/support/security/cvrf/)
* [Security information in CSAF format](/support/security/csaf/)
* [SUSE Linux Enterprise security rating overview](/support/security/rating/)
* [Flaw Remediation Process](/support/security/flaw-remediation/)
* [SUSE Signing Keys](/support/security/keys/)
* [Rancher Security](/support/security/rancher-security/)
* [SUSE Linux Enterprise Server 15 SP2 Hardening Guide](https://documentation.suse.com/sles/15-SP2/html/SLES-all/book-hardening.html)
* [SUSE Linux Enterprise Server 15 SP2 Security Guide](https://documentation.suse.com/sles/15-SP2/html/SLES-all/book-security.html)
* [SUSE LINUX Enterprise Server 15 SP2 Common Criteria EAL4+ Evaluated Configuration Guide](https://links.imagerelay.com/cdn/3404/ql/0994204932a54966978e4d524bffb4dc/common-criteria-eal4plus-evaluated-configuration-guide-for-suse-linux-enterprise-server-15-sp2.pdf)
* [SUSE LINUX Enterprise Server 15 SP2 Common Criteria NIAP Evaluated Configuration Guide](https://links.imagerelay.com/cdn/3404/ql/816857783fe246caa4e56360c7da38bc/common-criteria-evaluated-configuration-guide-for-suse-linux-enterprise-server-15-sp2-niap.pdf)
* [SUSE Linux Enterprise and SBOM support](https://www.suse.com/support/security/sbom/)
* [SUSE LINUX Enterprise Server 15 SP4 Common Criteria NIAP GPOS Evaluated Configuration Guide](https://links.imagerelay.com/cdn/3404/ql/934dc94e182c425fb2c0193e2ae3d1ab/common-criteria-evaluated-configuration-guide-for-suse-linux-enterprise-server-15-sp4-niap-gpos.pdf)
* [SUSE LINUX Enterprise Micro version 5.3 Common Criteria NIAP GPOS Evaluated Configuration Guide](https://links.imagerelay.com/cdn/3404/ql/feafcb55d1284a27a4aa09cec82b9197/Common-Criteria-Evaluated-SLE-Micro-5.3-NIAP-GPOS-Guide.pdf)

#### SUSE Security Announcements

Stay up to date with the latest security fixes, browsable on the web or by subscribing to the security announcement email list [sle-security-updates](http://lists.suse.com/mailman/listinfo/sle-security-updates).

![SUSE Logo](https://www.suse.com/assets/img/suse-white-logo-green.svg)

* [Careers](https://jobs.suse.com/ "Careers")
* [Legal](https://www.suse.com/company/legal/ "Legal")
* [Anti-Slavery Statement](https://links.imagerelay.com/cdn/3404/ql/811b4f2364b94ff18eb15e315b3e263d/suse_anti_slavery_statement.pdf "Anti-Slavery Statement")
* [Anti-slavery](https://www.suse.com/legal/anti-slavery/ "Anti-slavery")
* [About](https://www.suse.com/company/about/ "About")
* [Communications Preferences](https://www.suse.com/company/subscribe/ "Communications Preferences")
* [Contact Us](https://www.suse.com/contact/ "Contact Us")
* [Let's Chat](#footer-chat-now "Let's Chat")

* [![](https://www.suse.com/assets/img/youtube.png)](https://www.youtube.com/channel/UCHTfqIzPKz4f_dri36lAQGA%20)
* [![](https://www.suse.com/assets/img/fn-fbook-ico-white.png)](https://www.facebook.com/SUSEWorldwide)
* [![](https://www.suse.com/assets/img/logo-black.png)](https://www.twitter.com/SUSE)
* [![](https://www.suse.com/assets/img/fn-link-ico-white.png)](https://www.linkedin.com/company/suse)
* ![WeChat](https://www.suse.com/assets/img/icons/WeChat.png)
* [![](https://www.suse.com/assets/img/icons/bsky-icon.png)](https://bsky.app/profile/suse.com)

![WeChat QR](https://www.suse.com/assets/img/icons/qrcode_for_gh_91d12717ed53_430.jpg)

Support: [Open a Support Case](https://www.suse.com/support/handbook/#open)

©  ©SUSE, All Rights Reserved

Cookie Settings

[Privacy Policy](https://www.suse.com/company/legal/) and
[Cookie Policy](https://www.suse.com/company/legal/cookies-policy/)

2025-01-23

X

×



=== Content from www.redhat.com_9314b19a_20250126_104119.html ===


[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

**We're sorry but cve-details doesn't work properly without JavaScript enabled. Please enable it to continue.**

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2025 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from www.debian.org_ab399778_20250125_174329.html ===

[![Debian](./Pics/openlogo-50.png)](./ "Debian Home")

[Skip Quicknav](#content)

* [Blog](https://bits.debian.org/ "Bits from Debian")
* [Micronews](https://micronews.debian.org "Micronews from Debian")
* [Planet](https://planet.debian.org/ "The Planet of Debian")

# Debian

# The Community

## Debian is a Community of People!

### DC24 Group Photo

![DebConf23 Group Photo](Pics/debconf24_group_photo.jpg)

### MiniDebConf Berlin 2024

![Group photo of the MiniDebConf Berlin 2024](Pics/mini-dc24-berlin.jpg)

### MiniDebConf BrasÃ­lia 2023

![Group photo of the MiniDebConf BrasÃ­lia 2023](Pics/mini-dc23-brasilia.jpg)

### Screenshot Calamares Installer

![Screenshot from the Calamares installer](Pics/calamares-bookworm.png)

### Debian is like a Swiss Army Knife

![Debian is like a Swiss Army Knife](Pics/debian-swiss-knife-hands-1024x576.jpg)

### People have fun with Debian

![Debian people at Debconf18 in Hsinchu really having fun](Pics/debian-funny-people-1024x576.jpg)

[![](Pics/users.svg)](intro/people)

## [People](intro/people)

Who we are and what we do

[![](Pics/heartbeat.svg)](intro/philosophy)

## [Our Philosophy](intro/philosophy)

Why we do it, and how we do it

[![](Pics/user-plus.svg)](devel/join/)

## [Get Involved, Contribute](devel/join/)

How you can join us!

[![](Pics/list.svg)](intro/index#community)

## [More...](intro/index#community)

Additional information about the Debian community

# The Operating System

## Debian is a complete Free Operating System!

![Debian](Pics/debian-logo-1024x576.png)
[Download](https://cdimage.debian.org/debian-cd/current/amd64/iso-cd/debian-12.9.0-amd64-netinst.iso)
[Other downloads](distrib)

[![](Pics/trophy.svg)](intro/why_debian)

## [Why Debian](intro/why_debian)

What makes Debian special

[![](Pics/life-ring.svg)](support)

## [User Support](support)

Getting help and documentation

[![](Pics/security.svg)](security/)

## [Security Updates](security/)

Debian Security Advisories (DSA)

[![](Pics/list.svg)](intro/index#software)

## [More...](intro/index#software)

Further links to downloads and software

---

# Project News

## News and Announcements about Debian

17January2025[The Debian Project mourns the loss of Steve Langasek (vorlon)](News/2025/20250117)
11January2025[Updated Debian 12: 12.9 released](News/2025/20250111)
19November2024[The Debian Project mourns the loss of JÃ©rÃ©my Bobbio (Lunar)](News/2024/20241119)
31August2024[Updated Debian 11: 11.11 released](News/2024/2024083102)
14August2024[Security support for Bullseye handed over to the LTS team](News/2024/20240814)

[All the news](News)
[RSS](News/news)

---

This page is also available in the following languages:
Select your language
català
dansk
Deutsch
español
français
Galego
Indonesia
Italiano
magyar
Nederlands
norsk (bokmål)
polski
Português
suomi
svenska
Tiếng Việt
Български (Bəlgarski)
Русский (Russkij)
українська (ukrajins'ka)
عربية (Arabiya)
中文(简)
中文(HK)
中文(繁)
한국어 (Korean)
Ελληνικά (Ellinika)
فارسی (Farsi)

How to set [the default document language](./intro/cn)

---

See our [contact page](./contact) to get in touch. Web site source code is [available](https://salsa.debian.org/webmaster-team/webwml).

Last Modified: Sat, Sep 16 13:09:56 UTC 2023

Last Built: Sun, Jan 19 23:26:10 UTC 2025

Copyright © 1997-2025 [SPI](https://www.spi-inc.org/) and others; See [license terms](./license)

Debian is a registered [trademark](./trademark) of Software in the Public Interest, Inc.



=== Content from bugzilla.redhat.com_8aca70d5_20250126_104112.html ===


* Login
  + Log in using an SSO provider:- [Fedora Account System](saml2_login.cgi?idp=Fedora%20Account%20System&target=show_bug.cgi%3Fid%3D214288)
    - [Red Hat Associate](saml2_login.cgi?idp=Red%20Hat%20Associate&target=show_bug.cgi%3Fid%3D214288)
    - [Red Hat Customer](saml2_login.cgi?idp=Red%20Hat%20Customer&target=show_bug.cgi%3Fid%3D214288)+ Login using a Red Hat Bugzilla account
  + Forgot Password
  + [Create an Account](createaccount.cgi)

Red Hat Bugzilla – Bug 214288

* [Home](./)
* [New](enter_bug.cgi)
* Search
  + [Simple Search](query.cgi?format=specific)
  + [Advanced Search](query.cgi?format=advanced)
* My Links
  + [Browse](describecomponents.cgi)
  + [Requests](request.cgi)
  + Reports
  + Current State
    - [Search](query.cgi)
    - [Tabular reports](query.cgi?format=report-table)
    - [Graphical reports](query.cgi?format=report-graph)
    - [Duplicates](duplicates.cgi)
  + Other Reports
    - [User Changes](https://bugzilla.redhat.com/page.cgi?id=user_activity.html)
  + Plotly Reports
    - [Bug Status](https://bugzilla.redhat.com/page.cgi?id=bug_status.html)
    - [Bug Severity](https://bugzilla.redhat.com/page.cgi?id=bug_severity.html)
    - [Non-Defaults](https://bugzilla.redhat.com/page.cgi?id=non_defaults.html)
* [Product Dashboard](page.cgi?id=productdashboard.html)

- Help
  * [Page Help!](docs/en/html/using/understanding.html)
  * [Bug Writing Guidelines](page.cgi?id=bug-writing.html)
  * [What's new](page.cgi?id=whats-new.html)
  * [Browser Support Policy](https://access.redhat.com/help/browsers)
  * [5.0.4.rh103 Release notes](page.cgi?id=release-notes.html)
  * [FAQ](page.cgi?id=faq.html)
  * [Guides index](docs/en/html/index.html)
  * [User guide](docs/en/html/using/index.html)
  * [Web Services](docs/en/html/integrating/api/Bugzilla/WebService/Bug.html)
  * [Contact](page.cgi?id=redhat/contact.html)
  * [Legal](page.cgi?id=terms-conditions.html)
- [[?]](page.cgi?id=quicksearch.html "Quicksearch Help")

This site requires JavaScript to be enabled to function correctly, please enable it.

[**Bug 214288**](show_bug.cgi?id=214288)
- [CVE-2006-5757](https://access.redhat.com/security/cve/CVE-2006-5757) ISO9660 \_\_find\_get\_block\_slow() denial of service

[Summary:](page.cgi?id=fields.html#short_desc "The bug summary is a short sentence which succinctly describes what the bug is about.")
CVE-2006-5757 ISO9660 \_\_find\_get\_block\_slow() denial of service

| | [Keywords](describekeywords.cgi): | Security | | --- | --- | | [Status](page.cgi?id=fields.html#bug_status): | CLOSED ERRATA | | [Alias:](page.cgi?id=fields.html#alias "A short, unique name assigned to a bug in order to assist with looking it up and referring to it in other places in Bugzilla.") | None | | [Product:](describecomponents.cgi "Bugs are categorised into Products and Components. Select a Classification to narrow down this list.") | Red Hat Enterprise Linux 4 | | [Classification:](page.cgi?id=fields.html#classification "Bugs are categorised into Classifications, Products and Components. classifications is the top-level categorisation.") | Red Hat | | [Component:](describecomponents.cgi?product=Red Hat Enterprise Linux 4 "Components are second-level categories; each belongs to a particular Product. Select a Product to narrow down this list.") | kernel | | [Sub Component:](page.cgi?id=fields.html#rh_sub_components "The sub component of a specific component") | --- | | [Version:](page.cgi?id=fields.html#version "The version field defines the version of the software the bug was found in.") | 4.0 | | [Hardware:](page.cgi?id=fields.html#rep_platform "The hardware platform the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | All | | [OS:](page.cgi?id=fields.html#op_sys "The operating system the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | Linux | | [Priority:](page.cgi?id=fields.html#priority) | medium | | [Severity:](page.cgi?id=fields.html#bug_severity) | low | | [Target Milestone:](page.cgi?id=fields.html#target_milestone "The Target Milestone field is used to define when the engineer the bug is assigned to expects to fix it.") | --- | | [Target Release](page.cgi?id=fields.html#target_release): | --- | | [Assignee:](page.cgi?id=fields.html#assigned_to "The person in charge of resolving the bug.") | Eric Sandeen | | [QA Contact:](page.cgi?id=fields.html#qa_contact "The person responsible for confirming this bug if it is unconfirmed, and for verifying the fix once the bug has been resolved.") | Brian Brock | | [Docs Contact:](page.cgi?id=fields.html#docs_contact "The person responsible for documenting once the bug has been resolved.") |  | | [URL:](page.cgi?id=fields.html#bug_file_loc "Bugs can have a URL associated with them - for example, a pointer to a web site where the problem is seen.") |  | | [Whiteboard:](page.cgi?id=fields.html#status_whiteboard "Each bug has a free-form single line text entry box for adding tags and status information.") | impact=low,source=internet,reported=2... | | [Depends On:](page.cgi?id=fields.html#dependson "The bugs listed here must be resolved before this bug can be resolved.") |  | | [Blocks:](page.cgi?id=fields.html#blocked "This bug must be resolved before the bugs listed in this field can be resolved.") | [214419](show_bug.cgi?id=214419) | | TreeView+ | [depends on](buglist.cgi?bug_id=214288&bug_id_type=anddependson&format=tvp) / [blocked](buglist.cgi?bug_id=214288&bug_id_type=andblocked&format=tvp&tvp_dir=blocked) |  | |  | | [Reported:](page.cgi?id=fields.html#reporter) | 2006-11-06 22:06 UTC by Marcel Holtmann | | --- | --- | | [Modified:](page.cgi?id=fields.html#modified) | 2007-11-30 22:07 UTC ([History](show_activity.cgi?id=214288)) | | [CC List:](page.cgi?id=fields.html#cclist) | 2 users (show)  esandeen security-response-team | | Fixed In Version: | RHSA-2007-0014 | | | Doc Type: | Bug Fix | | | Doc Text: |  | | | Clone Of: |  | | | Environment: |  | | | Last Closed: | 2007-01-30 14:41:48 UTC | | | Target Upstream Version: |  | | | Embargoed: |  | | |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| --- | | |

| | Attachments | [(Terms of Use)](page.cgi?id=terms-conditions.html) | | | --- | --- | --- | |  | | |    Links | System | ID | Private | Priority | Status | Summary | Last Updated | | Red Hat Product Errata | [RHSA-2007:0014](https://access.redhat.com/errata/RHSA-2007%3A0014) | 0 | normal | SHIPPED\_LIVE | Important: kernel security update | 2007-01-30 14:25:00 UTC | |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |

| [Description](show_bug.cgi?id=214288#c0)  Marcel Holtmann    2006-11-06 22:06:53 UTC  ``` Reported as MOKB-05-11-2006:  <http://projects.info-pull.com/mokb/MOKB-05-11-2006.html>  The ISO9660 filesystem handling code of the Linux 2.6.x kernel fails to properly handle corrupted data structures, leading to an exploitable denial of service condition. This particular vulnerability seems to be caused by a race condition and a signedness issue. When performing a read operation on a corrupted ISO9660 fs stream, the isofs_get_blocks() function will enter an infinite loop when __find_get_block_slow() callback from sb_getblk() fails ("due to various races between file io on the block device and getblk").   ```  [Comment 3](show_bug.cgi?id=214288#c3)  Eric Sandeen    2006-11-06 22:42:21 UTC  ``` This upstream patch resolves the issue: <http://git.kernel.org/git/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commitdiff;h=e5657933863f43cc6bb76a54d659303dafaa9e58;hp=e0ab2928cc2202f13f0574d4c6f567f166d307eb>   ```  [Comment 5](show_bug.cgi?id=214288#c5)  Jason Baron    2006-11-10 21:59:16 UTC  ``` committed in stream U5 build 42.24. A test kernel with this patch is available from <http://people.redhat.com/~jbaron/rhel4/>    ```  [Comment 7](show_bug.cgi?id=214288#c7)  Mike Gahagan    2007-01-18 18:07:24 UTC  ``` verified with the mokb image and numerous runs of fsfuzz have not reproduced similar behavior.     ```  [Comment 9](show_bug.cgi?id=214288#c9)  Red Hat Bugzilla    2007-01-30 14:41:48 UTC  ```  An advisory has been issued which should help the problem described in this bug report. This report is therefore being closed with a resolution of ERRATA. For more information on the solution and/or where to find the updated files, please follow the link below. You may reopen this bug report if the solution does not work for you.  <http://rhn.redhat.com/errata/RHSA-2007-0014.html>    ``` |  |
| --- | --- |

---

| Note You need to [log in](show_bug.cgi?id=214288&GoAheadAndLogIn=1) before you can comment on or make changes to this bug. |
| --- |

---

[Privacy](page.cgi?id=redhat/privacy.html)
[Contact](page.cgi?id=redhat/contact.html)
[FAQ](page.cgi?id=faq.html)
[Legal](page.cgi?id=terms-conditions.html)


