=== Content from bugs.chromium.org_d6897bf0_20250119_113342.html ===



=== Content from git.kernel.org_a75fe79e_20250119_113345.html ===


| [cgit logo](/) | [index](/) : [kernel/git/torvalds/linux.git](/pub/scm/linux/kernel/git/torvalds/linux.git/) | for-next master vsnprintf |
| --- | --- | --- |
| Linux kernel source tree | Linus Torvalds |

| [about](/pub/scm/linux/kernel/git/torvalds/linux.git/about/)[summary](/pub/scm/linux/kernel/git/torvalds/linux.git/)[refs](/pub/scm/linux/kernel/git/torvalds/linux.git/refs/?id=0f2122045b946241a9e549c2a76cea54fa58a7ff)[log](/pub/scm/linux/kernel/git/torvalds/linux.git/log/)[tree](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/?id=0f2122045b946241a9e549c2a76cea54fa58a7ff)[commit](/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=0f2122045b946241a9e549c2a76cea54fa58a7ff)[diff](/pub/scm/linux/kernel/git/torvalds/linux.git/diff/?id=0f2122045b946241a9e549c2a76cea54fa58a7ff)[stats](/pub/scm/linux/kernel/git/torvalds/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Jens Axboe <axboe@kernel.dk> | 2020-09-13 13:09:39 -0600 |
| --- | --- | --- |
| committer | Jens Axboe <axboe@kernel.dk> | 2020-09-30 20:32:32 -0600 |
| commit | [0f2122045b946241a9e549c2a76cea54fa58a7ff](/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=0f2122045b946241a9e549c2a76cea54fa58a7ff) ([patch](/pub/scm/linux/kernel/git/torvalds/linux.git/patch/?id=0f2122045b946241a9e549c2a76cea54fa58a7ff)) | |
| tree | [76cea5c487f38bff85e18933a8477b47d5514e05](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/?id=0f2122045b946241a9e549c2a76cea54fa58a7ff) | |
| parent | [e6c8aa9ac33bd7c968af7816240fc081401fddcd](/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=e6c8aa9ac33bd7c968af7816240fc081401fddcd) ([diff](/pub/scm/linux/kernel/git/torvalds/linux.git/diff/?id=0f2122045b946241a9e549c2a76cea54fa58a7ff&id2=e6c8aa9ac33bd7c968af7816240fc081401fddcd)) | |
| download | [linux-0f2122045b946241a9e549c2a76cea54fa58a7ff.tar.gz](/pub/scm/linux/kernel/git/torvalds/linux.git/snapshot/linux-0f2122045b946241a9e549c2a76cea54fa58a7ff.tar.gz) | |

io\_uring: don't rely on weak ->files referencesGrab actual references to the files\_struct. To avoid circular references
issues due to this, we add a per-task note that keeps track of what
io\_uring contexts a task has used. When the tasks execs or exits its
assigned files, we cancel requests based on this tracking.
With that, we can grab proper references to the files table, and no
longer need to rely on stashing away ring\_fd and ring\_file to check
if the ring\_fd may have been closed.
Cc: stable@vger.kernel.org # v5.5+
Reviewed-by: Pavel Begunkov <asml.silence@gmail.com>
Signed-off-by: Jens Axboe <axboe@kernel.dk>
[Diffstat](/pub/scm/linux/kernel/git/torvalds/linux.git/diff/?id=0f2122045b946241a9e549c2a76cea54fa58a7ff)

| -rw-r--r-- | [fs/exec.c](/pub/scm/linux/kernel/git/torvalds/linux.git/diff/fs/exec.c?id=0f2122045b946241a9e549c2a76cea54fa58a7ff) | 6 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |
| -rw-r--r-- | [fs/file.c](/pub/scm/linux/kernel/git/torvalds/linux.git/diff/fs/file.c?id=0f2122045b946241a9e549c2a76cea54fa58a7ff) | 2 | |  |  |  | | --- | --- | --- | |
| -rw-r--r-- | [fs/io\_uring.c](/pub/scm/linux/kernel/git/torvalds/linux.git/diff/fs/io_uring.c?id=0f2122045b946241a9e549c2a76cea54fa58a7ff) | 306 | |  |  |  | | --- | --- | --- | |
| -rw-r--r-- | [include/linux/io\_uring.h](/pub/scm/linux/kernel/git/torvalds/linux.git/diff/include/linux/io_uring.h?id=0f2122045b946241a9e549c2a76cea54fa58a7ff) | 53 | |  |  |  | | --- | --- | --- | |
| -rw-r--r-- | [include/linux/sched.h](/pub/scm/linux/kernel/git/torvalds/linux.git/diff/include/linux/sched.h?id=0f2122045b946241a9e549c2a76cea54fa58a7ff) | 5 | |  |  |  | | --- | --- | --- | |
| -rw-r--r-- | [init/init\_task.c](/pub/scm/linux/kernel/git/torvalds/linux.git/diff/init/init_task.c?id=0f2122045b946241a9e549c2a76cea54fa58a7ff) | 3 | |  |  |  | | --- | --- | --- | |
| -rw-r--r-- | [kernel/fork.c](/pub/scm/linux/kernel/git/torvalds/linux.git/diff/kernel/fork.c?id=0f2122045b946241a9e549c2a76cea54fa58a7ff) | 6 | |  |  |  | | --- | --- | --- | |

7 files changed, 344 insertions, 37 deletions

| diff --git a/fs/exec.c b/fs/exec.cindex a91003e28eaae2..07910f5032e74a 100644--- a/[fs/exec.c](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/fs/exec.c?id=e6c8aa9ac33bd7c968af7816240fc081401fddcd)+++ b/[fs/exec.c](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/fs/exec.c?id=0f2122045b946241a9e549c2a76cea54fa58a7ff)@@ -62,6 +62,7 @@ #include <linux/oom.h> #include <linux/compat.h> #include <linux/vmalloc.h>+#include <linux/io\_uring.h>  #include <linux/uaccess.h> #include <asm/mmu\_context.h>@@ -1895,6 +1896,11 @@ static int bprm\_execve(struct linux\_binprm \*bprm, struct files\_struct \*displaced; int retval; + /\*+ \* Cancel any io\_uring activity across execve+ \*/+ io\_uring\_task\_cancel();+ retval = unshare\_files(&displaced); if (retval) return retval;diff --git a/fs/file.c b/fs/file.cindex 21c0893f2f1df8..4559b5fec3bd53 100644--- a/[fs/file.c](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/fs/file.c?id=e6c8aa9ac33bd7c968af7816240fc081401fddcd)+++ b/[fs/file.c](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/fs/file.c?id=0f2122045b946241a9e549c2a76cea54fa58a7ff)@@ -21,6 +21,7 @@ #include <linux/rcupdate.h> #include <linux/close\_range.h> #include <net/sock.h>+#include <linux/io\_uring.h>  unsigned int sysctl\_nr\_open \_\_read\_mostly = 1024\*1024; unsigned int sysctl\_nr\_open\_min = BITS\_PER\_LONG;@@ -452,6 +453,7 @@ void exit\_files(struct task\_struct \*tsk) struct files\_struct \* files = tsk->files;  if (files) {+ io\_uring\_files\_cancel(files); task\_lock(tsk); tsk->files = NULL; task\_unlock(tsk);diff --git a/fs/io\_uring.c b/fs/io\_uring.cindex 046d06266a116e..ee75ba7113cfe2 100644--- a/[fs/io\_uring.c](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/fs/io_uring.c?id=e6c8aa9ac33bd7c968af7816240fc081401fddcd)+++ b/[fs/io\_uring.c](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/fs/io_uring.c?id=0f2122045b946241a9e549c2a76cea54fa58a7ff)@@ -79,6 +79,7 @@ #include <linux/splice.h> #include <linux/task\_work.h> #include <linux/pagemap.h>+#include <linux/io\_uring.h>  #define CREATE\_TRACE\_POINTS #include <trace/events/io\_uring.h>@@ -284,8 +285,6 @@ struct io\_ring\_ctx { \*/ struct fixed\_file\_data \*file\_data; unsigned nr\_user\_files;- int ring\_fd;- struct file \*ring\_file;  /\* if used, fixed mapped user buffers \*/ unsigned nr\_user\_bufs;@@ -1433,7 +1432,12 @@ static void \_\_io\_cqring\_fill\_event(struct io\_kiocb \*req, long res, long cflags) WRITE\_ONCE(cqe->user\_data, req->user\_data); WRITE\_ONCE(cqe->res, res); WRITE\_ONCE(cqe->flags, cflags);- } else if (ctx->cq\_overflow\_flushed) {+ } else if (ctx->cq\_overflow\_flushed || req->task->io\_uring->in\_idle) {+ /\*+ \* If we're in ring overflow flush mode, or in task cancel mode,+ \* then we cannot store the request for later flushing, we need+ \* to drop it on the floor.+ \*/ WRITE\_ONCE(ctx->rings->cq\_overflow, atomic\_inc\_return(&ctx->cached\_cq\_overflow)); } else {@@ -1591,8 +1595,12 @@ static bool io\_dismantle\_req(struct io\_kiocb \*req)  static void \_\_io\_free\_req\_finish(struct io\_kiocb \*req) {+ struct io\_uring\_task \*tctx = req->task->io\_uring; struct io\_ring\_ctx \*ctx = req->ctx; + atomic\_long\_inc(&tctx->req\_complete);+ if (tctx->in\_idle)+ wake\_up(&tctx->wait); put\_task\_struct(req->task);  if (likely(!io\_is\_fallback\_req(req)))@@ -1907,6 +1915,7 @@ static void io\_req\_free\_batch\_finish(struct io\_ring\_ctx \*ctx, if (rb->to\_free) \_\_io\_req\_free\_batch\_flush(ctx, rb); if (rb->task) {+ atomic\_long\_add(rb->task\_refs, &rb->task->io\_uring->req\_complete); put\_task\_struct\_many(rb->task, rb->task\_refs); rb->task = NULL; }@@ -1922,8 +1931,10 @@ static void io\_req\_free\_batch(struct req\_batch \*rb, struct io\_kiocb \*req) io\_queue\_next(req);  if (req->task != rb->task) {- if (rb->task)+ if (rb->task) {+ atomic\_long\_add(rb->task\_refs, &rb->task->io\_uring->req\_complete); put\_task\_struct\_many(rb->task, rb->task\_refs);+ } rb->task = req->task; rb->task\_refs = 0; }@@ -3978,8 +3989,7 @@ static int io\_close\_prep(struct io\_kiocb \*req, const struct io\_uring\_sqe \*sqe) return -EBADF;  req->close.fd = READ\_ONCE(sqe->fd);- if ((req->file && req->file->f\_op == &io\_uring\_fops) ||- req->close.fd == req->ctx->ring\_fd)+ if ((req->file && req->file->f\_op == &io\_uring\_fops)) return -EBADF;  req->close.put\_file = NULL;@@ -5667,6 +5677,7 @@ static void io\_req\_drop\_files(struct io\_kiocb \*req) wake\_up(&ctx->inflight\_wait); spin\_unlock\_irqrestore(&ctx->inflight\_lock, flags); req->flags &= ~REQ\_F\_INFLIGHT;+ put\_files\_struct(req->work.files); req->work.files = NULL; } @@ -6067,34 +6078,20 @@ static int io\_req\_set\_file(struct io\_submit\_state \*state, struct io\_kiocb \*req,  static int io\_grab\_files(struct io\_kiocb \*req) {- int ret = -EBADF; struct io\_ring\_ctx \*ctx = req->ctx;  io\_req\_init\_async(req);  if (req->work.files || (req->flags & REQ\_F\_NO\_FILE\_TABLE)) return 0;- if (!ctx->ring\_file)- return -EBADF; - rcu\_read\_lock();+ req->work.files = get\_files\_struct(current);+ req->flags |= REQ\_F\_INFLIGHT;+ spin\_lock\_irq(&ctx->inflight\_lock);- /\*- \* We use the f\_ops->flush() handler to ensure that we can flush- \* out work accessing these files if the fd is closed. Check if- \* the fd has changed since we started down this path, and disallow- \* this operation if it has.- \*/- if (fcheck(ctx->ring\_fd) == ctx->ring\_file) {- list\_add(&req->inflight\_entry, &ctx->inflight\_list);- req->flags |= REQ\_F\_INFLIGHT;- req->work.files = current->files;- ret = 0;- }+ list\_add(&req->inflight\_entry, &ctx->inflight\_list); spin\_unlock\_irq(&ctx->inflight\_lock);- rcu\_read\_unlock();-- return ret;+ return 0; }  static inline int io\_prep\_work\_files(struct io\_kiocb \*req)@@ -6459,6 +6456,7 @@ static int io\_init\_req(struct io\_ring\_ctx \*ctx, struct io\_kiocb \*req, refcount\_set(&req->refs, 2); req->task = current; get\_task\_struct(req->task);+ atomic\_long\_inc(&req->task->io\_uring->req\_issue); req->result = 0;  if (unlikely(req->opcode >= IORING\_OP\_LAST))@@ -6494,8 +6492,7 @@ static int io\_init\_req(struct io\_ring\_ctx \*ctx, struct io\_kiocb \*req, return io\_req\_set\_file(state, req, READ\_ONCE(sqe->fd)); } -static int io\_submit\_sqes(struct io\_ring\_ctx \*ctx, unsigned int nr,- struct file \*ring\_file, int ring\_fd)+static int io\_submit\_sqes(struct io\_ring\_ctx \*ctx, unsigned int nr) { struct io\_submit\_state state; struct io\_kiocb \*link = NULL;@@ -6516,9 +6513,6 @@ static int io\_submit\_sqes(struct io\_ring\_ctx \*ctx, unsigned int nr,  io\_submit\_state\_start(&state, ctx, nr); - ctx->ring\_fd = ring\_fd;- ctx->ring\_file = ring\_file;- for (i = 0; i < nr; i++) { const struct io\_uring\_sqe \*sqe; struct io\_kiocb \*req;@@ -6687,7 +6681,7 @@ static int io\_sq\_thread(void \*data)  mutex\_lock(&ctx->uring\_lock); if (likely(!percpu\_ref\_is\_dying(&ctx->refs)))- ret = io\_submit\_sqes(ctx, to\_submit, NULL, -1);+ ret = io\_submit\_sqes(ctx, to\_submit); mutex\_unlock(&ctx->uring\_lock); timeout = jiffies + ctx->sq\_thread\_idle; }@@ -7516,6 +7510,34 @@ out\_fput: return ret; } +static int io\_uring\_alloc\_task\_context(struct task\_struct \*task)+{+ struct io\_uring\_task \*tctx;++ tctx = kmalloc(sizeof(\*tctx), GFP\_KERNEL);+ if (unlikely(!tctx))+ return -ENOMEM;++ xa\_init(&tctx->xa);+ init\_waitqueue\_head(&tctx->wait);+ tctx->last = NULL;+ tctx->in\_idle = 0;+ atomic\_long\_set(&tctx->req\_issue, 0);+ atomic\_long\_set(&tctx->req\_complete, 0);+ task->io\_uring = tctx;+ return 0;+}++void \_\_io\_uring\_free(struct task\_struct \*tsk)+{+ struct io\_uring\_task \*tctx = tsk->io\_uring;++ WARN\_ON\_ONCE(!xa\_empty(&tctx->xa));+ xa\_destroy(&tctx->xa);+ kfree(tctx);+ tsk->io\_uring = NULL;+}+ static int io\_sq\_offload\_start(struct io\_ring\_ctx \*ctx, struct io\_uring\_params \*p) {@@ -7551,6 +7573,9 @@ static int io\_sq\_offload\_start(struct io\_ring\_ctx \*ctx, ctx->sqo\_thread = NULL; goto err; }+ ret = io\_uring\_alloc\_task\_context(ctx->sqo\_thread);+ if (ret)+ goto err; wake\_up\_process(ctx->sqo\_thread); } else if (p->flags & IORING\_SETUP\_SQ\_AFF) { /\* Can't have SQ\_AFF without SQPOLL \*/@@ -8063,7 +8088,7 @@ static bool io\_wq\_files\_match(struct io\_wq\_work \*work, void \*data) { struct files\_struct \*files = data; - return work->files == files;+ return !files || work->files == files; }  /\*@@ -8218,7 +8243,7 @@ static bool io\_uring\_cancel\_files(struct io\_ring\_ctx \*ctx,  spin\_lock\_irq(&ctx->inflight\_lock); list\_for\_each\_entry(req, &ctx->inflight\_list, inflight\_entry) {- if (req->work.files != files)+ if (files && req->work.files != files) continue; /\* req is being completed, ignore \*/ if (!refcount\_inc\_not\_zero(&req->refs))@@ -8254,18 +8279,217 @@ static bool io\_cancel\_task\_cb(struct io\_wq\_work \*work, void \*data) return io\_task\_match(req, task); } +static bool \_\_io\_uring\_cancel\_task\_requests(struct io\_ring\_ctx \*ctx,+ struct task\_struct \*task,+ struct files\_struct \*files)+{+ bool ret;++ ret = io\_uring\_cancel\_files(ctx, files);+ if (!files) {+ enum io\_wq\_cancel cret;++ cret = io\_wq\_cancel\_cb(ctx->io\_wq, io\_cancel\_task\_cb, task, true);+ if (cret != IO\_WQ\_CANCEL\_NOTFOUND)+ ret = true;++ /\* SQPOLL thread does its own polling \*/+ if (!(ctx->flags & IORING\_SETUP\_SQPOLL)) {+ while (!list\_empty\_careful(&ctx->iopoll\_list)) {+ io\_iopoll\_try\_reap\_events(ctx);+ ret = true;+ }+ }++ ret |= io\_poll\_remove\_all(ctx, task);+ ret |= io\_kill\_timeouts(ctx, task);+ }++ return ret;+}++/\*+ \* We need to iteratively cancel requests, in case a request has dependent+ \* hard links. These persist even for failure of cancelations, hence keep+ \* looping until none are found.+ \*/+static void io\_uring\_cancel\_task\_requests(struct io\_ring\_ctx \*ctx,+ struct files\_struct \*files)+{+ struct task\_struct \*task = current;++ if (ctx->flags & IORING\_SETUP\_SQPOLL)+ task = ctx->sqo\_thread;++ io\_cqring\_overflow\_flush(ctx, true, task, files);++ while (\_\_io\_uring\_cancel\_task\_requests(ctx, task, files)) {+ io\_run\_task\_work();+ cond\_resched();+ }+}++/\*+ \* Note that this task has used io\_uring. We use it for cancelation purposes.+ \*/+static int io\_uring\_add\_task\_file(struct file \*file)+{+ if (unlikely(!current->io\_uring)) {+ int ret;++ ret = io\_uring\_alloc\_task\_context(current);+ if (unlikely(ret))+ return ret;+ }+ if (current->io\_uring->last != file) {+ XA\_STATE(xas, &current->io\_uring->xa, (unsigned long) file);+ void \*old;++ rcu\_read\_lock();+ old = xas\_load(&xas);+ if (old != file) {+ get\_file(file);+ xas\_lock(&xas);+ xas\_store(&xas, file);+ xas\_unlock(&xas);+ }+ rcu\_read\_unlock();+ current->io\_uring->last = file;+ }++ return 0;+}++/\*+ \* Remove this io\_uring\_file -> task mapping.+ \*/+static void io\_uring\_del\_task\_file(struct file \*file)+{+ struct io\_uring\_task \*tctx = current->io\_uring;+ XA\_STATE(xas, &tctx->xa, (unsigned long) file);++ if (tctx->last == file)+ tctx->last = NULL;++ xas\_lock(&xas);+ file = xas\_store(&xas, NULL);+ xas\_unlock(&xas);++ if (file)+ fput(file);+}++static void \_\_io\_uring\_attempt\_task\_drop(struct file \*file)+{+ XA\_STATE(xas, &current->io\_uring->xa, (unsigned long) file);+ struct file \*old;++ rcu\_read\_lock();+ old = xas\_load(&xas);+ rcu\_read\_unlock();++ if (old == file)+ io\_uring\_del\_task\_file(file);+}++/\*+ \* Drop task note for this file if we're the only ones that hold it after+ \* pending fput()+ \*/+static void io\_uring\_attempt\_task\_drop(struct file \*file, bool exiting)+{+ if (!current->io\_uring)+ return;+ /\*+ \* fput() is pending, will be 2 if the only other ref is our potential+ \* task file note. If the task is exiting, drop regardless of count.+ \*/+ if (!exiting && atomic\_long\_read(&file->f\_count) != 2)+ return;++ \_\_io\_uring\_attempt\_task\_drop(file);+}++void \_\_io\_uring\_files\_cancel(struct files\_struct \*files)+{+ struct io\_uring\_task \*tctx = current->io\_uring;+ XA\_STATE(xas, &tctx->xa, 0);++ /\* make sure overflow events are dropped \*/+ tctx->in\_idle = true;++ do {+ struct io\_ring\_ctx \*ctx;+ struct file \*file;++ xas\_lock(&xas);+ file = xas\_next\_entry(&xas, ULONG\_MAX);+ xas\_unlock(&xas);++ if (!file)+ break;++ ctx = file->private\_data;++ io\_uring\_cancel\_task\_requests(ctx, files);+ if (files)+ io\_uring\_del\_task\_file(file);+ } while (1);+}++static inline bool io\_uring\_task\_idle(struct io\_uring\_task \*tctx)+{+ return atomic\_long\_read(&tctx->req\_issue) ==+ atomic\_long\_read(&tctx->req\_complete);+}++/\*+ \* Find any io\_uring fd that this task has registered or done IO on, and cancel+ \* requests.+ \*/+void \_\_io\_uring\_task\_cancel(void)+{+ struct io\_uring\_task \*tctx = current->io\_uring;+ DEFINE\_WAIT(wait);+ long completions;++ /\* make sure overflow events are dropped \*/+ tctx->in\_idle = true;++ while (!io\_uring\_task\_idle(tctx)) {+ /\* read completions before cancelations \*/+ completions = atomic\_long\_read(&tctx->req\_complete);+ \_\_io\_uring\_files\_cancel(NULL);++ prepare\_to\_wait(&tctx->wait, &wait, TASK\_UNINTERRUPTIBLE);++ /\*+ \* If we've seen completions, retry. This avoids a race where+ \* a completion comes in before we did prepare\_to\_wait().+ \*/+ if (completions != atomic\_long\_read(&tctx->req\_complete))+ continue;+ if (io\_uring\_task\_idle(tctx))+ break;+ schedule();+ }++ finish\_wait(&tctx->wait, &wait);+ tctx->in\_idle = false;+}+ static int io\_uring\_flush(struct file \*file, void \*data) { struct io\_ring\_ctx \*ctx = file->private\_data; - io\_uring\_cancel\_files(ctx, data);- /\* \* If the task is going away, cancel work it may have pending \*/ if (fatal\_signal\_pending(current) || (current->flags & PF\_EXITING))- io\_wq\_cancel\_cb(ctx->io\_wq, io\_cancel\_task\_cb, current, true);+ data = NULL; + io\_uring\_cancel\_task\_requests(ctx, data);+ io\_uring\_attempt\_task\_drop(file, !data); return 0; } @@ -8379,8 +8603,11 @@ SYSCALL\_DEFINE6(io\_uring\_enter, unsigned int, fd, u32, to\_submit, wake\_up(&ctx->sqo\_wait); submitted = to\_submit; } else if (to\_submit) {+ ret = io\_uring\_add\_task\_file(f.file);+ if (unlikely(ret))+ goto out; mutex\_lock(&ctx->uring\_lock);- submitted = io\_submit\_sqes(ctx, to\_submit, f.file, fd);+ submitted = io\_submit\_sqes(ctx, to\_submit); mutex\_unlock(&ctx->uring\_lock);  if (submitted != to\_submit)@@ -8590,6 +8817,7 @@ static int io\_uring\_get\_fd(struct io\_ring\_ctx \*ctx) file = anon\_inode\_getfile("[io\_uring]", &io\_uring\_fops, ctx, O\_RDWR | O\_CLOEXEC); if (IS\_ERR(file)) {+err\_fd: put\_unused\_fd(ret); ret = PTR\_ERR(file); goto err;@@ -8598,6 +8826,10 @@ static int io\_uring\_get\_fd(struct io\_ring\_ctx \*ctx) #if defined(CONFIG\_UNIX) ctx->ring\_sock->file = file; #endif+ if (unlikely(io\_uring\_add\_task\_file(file))) {+ file = ERR\_PTR(-ENOMEM);+ goto err\_fd;+ } fd\_install(ret, file); return ret; err:diff --git a/include/linux/io\_uring.h b/include/linux/io\_uring.hnew file mode 100644index 00000000000000..c09135a1ef1323--- /dev/null+++ b/[include/linux/io\_uring.h](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/include/linux/io_uring.h?id=0f2122045b946241a9e549c2a76cea54fa58a7ff)@@ -0,0 +1,53 @@+/\* SPDX-License-Identifier: GPL-2.0-or-later \*/+#ifndef \_LINUX\_IO\_URING\_H+#define \_LINUX\_IO\_URING\_H++#include <linux/sched.h>+#include <linux/xarray.h>+#include <linux/percpu-refcount.h>++struct io\_uring\_task {+ /\* submission side \*/+ struct xarray xa;+ struct wait\_queue\_head wait;+ struct file \*last;+ atomic\_long\_t req\_issue;++ /\* completion side \*/+ bool in\_idle \_\_\_\_cacheline\_aligned\_in\_smp;+ atomic\_long\_t req\_complete;+};++#if defined(CONFIG\_IO\_URING)+void \_\_io\_uring\_task\_cancel(void);+void \_\_io\_uring\_files\_cancel(struct files\_struct \*files);+void \_\_io\_uring\_free(struct task\_struct \*tsk);++static inline void io\_uring\_task\_cancel(void)+{+ if (current->io\_uring && !xa\_empty(&current->io\_uring->xa))+ \_\_io\_uring\_task\_cancel();+}+static inline void io\_uring\_files\_cancel(struct files\_struct \*files)+{+ if (current->io\_uring && !xa\_empty(&current->io\_uring->xa))+ \_\_io\_uring\_files\_cancel(files);+}+static inline void io\_uring\_free(struct task\_struct \*tsk)+{+ if (tsk->io\_uring)+ \_\_io\_uring\_free(tsk);+}+#else+static inline void io\_uring\_task\_cancel(void)+{+}+static inline void io\_uring\_files\_cancel(struct files\_struct \*files)+{+}+static inline void io\_uring\_free(struct task\_struct \*tsk)+{+}+#endif++#endifdiff --git a/include/linux/sched.h b/include/linux/sched.hindex afe01e232935fa..8bf2295ebee48f 100644--- a/[include/linux/sched.h](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/include/linux/sched.h?id=e6c8aa9ac33bd7c968af7816240fc081401fddcd)+++ b/[include/linux/sched.h](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/include/linux/sched.h?id=0f2122045b946241a9e549c2a76cea54fa58a7ff)@@ -63,6 +63,7 @@ struct sighand\_struct; struct signal\_struct; struct task\_delay\_info; struct task\_group;+struct io\_uring\_task;  /\* \* Task state bitmask. NOTE! These bits are also@@ -935,6 +936,10 @@ struct task\_struct { /\* Open file information: \*/ struct files\_struct \*files; +#ifdef CONFIG\_IO\_URING+ struct io\_uring\_task \*io\_uring;+#endif+ /\* Namespaces: \*/ struct nsproxy \*nsproxy; diff --git a/init/init\_task.c b/init/init\_task.cindex f6889fce64af7c..a56f0abb63e934 100644--- a/[init/init\_task.c](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/init/init_task.c?id=e6c8aa9ac33bd7c968af7816240fc081401fddcd)+++ b/[init/init\_task.c](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/init/init_task.c?id=0f2122045b946241a9e549c2a76cea54fa58a7ff)@@ -114,6 +114,9 @@ struct task\_struct init\_task .thread = INIT\_THREAD, .fs = &init\_fs, .files = &init\_files,+#ifdef CONFIG\_IO\_URING+ .io\_uring = NULL,+#endif .signal = &init\_signals, .sighand = &init\_sighand, .nsproxy = &init\_nsproxy,diff --git a/kernel/fork.c b/kernel/fork.cindex da8d360fb0326e..a3795aaaab5c58 100644--- a/[kernel/fork.c](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/kernel/fork.c?id=e6c8aa9ac33bd7c968af7816240fc081401fddcd)+++ b/[kernel/fork.c](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/kernel/fork.c?id=0f2122045b946241a9e549c2a76cea54fa58a7ff)@@ -95,6 +95,7 @@ #include <linux/stackleak.h> #include <linux/kasan.h> #include <linux/scs.h>+#include <linux/io\_uring.h>  #include <asm/pgalloc.h> #include <linux/uaccess.h>@@ -728,6 +729,7 @@ void \_\_put\_task\_struct(struct task\_struct \*tsk) WARN\_ON(refcount\_read(&tsk->usage)); WARN\_ON(tsk == current); + io\_uring\_free(tsk); cgroup\_free(tsk); task\_numa\_free(tsk, true); security\_task\_free(tsk);@@ -1983,6 +1985,10 @@ static \_\_latent\_entropy struct task\_struct \*copy\_process( p->vtime.state = VTIME\_INACTIVE; #endif +#ifdef CONFIG\_IO\_URING+ p->io\_uring = NULL;+#endif+ #if defined(SPLIT\_RSS\_COUNTING) memset(&p->rss\_stat, 0, sizeof(p->rss\_stat)); #endif |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-19 11:32:22 +0000



=== Content from cdn.kernel.org_0cf256a6_20250119_113344.html ===
commit 36a4324fe95cdd1403045d0d1f1871f062179892
Author: Greg Kroah-Hartman
Date: Sun Nov 1 12:47:10 2020 +0100
Linux 5.9.3
Tested-by: Jeffrin Jose T
Tested-by: Guenter Roeck
Tested-by: Linux Kernel Functional Testing
Link: https://lore.kernel.org/r/20201031113500.031279088@linuxfoundation.org
Signed-off-by: Greg Kroah-Hartman
commit 2e9e042576a543eb296bc2f07c1889ac57324a75
Author: Pali Rohár
Date: Wed Sep 2 16:43:43 2020 +0200
phy: marvell: comphy: Convert internal SMCC firmware return codes to errno
commit ea17a0f153af2cd890e4ce517130dcccaa428c13 upstream.
Driver ->power\_on and ->power\_off callbacks leaks internal SMCC firmware
return codes to phy caller. This patch converts SMCC error codes to
standard linux errno codes. Include file linux/arm-smccc.h already provides
defines for SMCC error codes, so use them instead of custom driver defines.
Note that return value is signed 32bit, but stored in unsigned long type
with zero padding.
Tested-by: Tomasz Maciej Nowak
Link: https://lore.kernel.org/r/20200902144344.16684-2-pali@kernel.org
Signed-off-by: Pali Rohár
Signed-off-by: Lorenzo Pieralisi
Reviewed-by: Rob Herring
Signed-off-by: Greg Kroah-Hartman
commit 0aa1346563336cd9123544b53a7fecf4fe7110b1
Author: Ricky Wu
Date: Mon Aug 24 11:00:06 2020 +0800
misc: rtsx: do not setting OC\_POWER\_DOWN reg in rtsx\_pci\_init\_ocp()
commit 551b6729578a8981c46af964c10bf7d5d9ddca83 upstream.
this power saving action in rtsx\_pci\_init\_ocp() cause INTEL-NUC6 platform
missing card reader
Signed-off-by: Ricky Wu
Link: https://lore.kernel.org/r/20200824030006.30033-1-ricky\_wu@realtek.com
Cc: Chris Clayton
Signed-off-by: Greg Kroah-Hartman
commit 753456ece6b47718e2cbde595d3f43b82ef1ebf6
Author: Pavel Begunkov
Date: Tue Oct 20 23:50:27 2020 +0100
io\_uring: don't reuse linked\_timeout
commit ff5771613cd7b3a76cd16cb54aa81d30d3c11d48 upstream.
Clear linked\_timeout for next requests in \_\_io\_queue\_sqe() so we won't
queue it up unnecessary when it's going to be punted.
Signed-off-by: Pavel Begunkov
Cc: stable@vger.kernel.org # v5.9
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit 4683c5407bd5ed473063993b7593f5d8084daceb
Author: Souptick Joarder
Date: Sun Sep 6 12:21:53 2020 +0530
xen/gntdev.c: Mark pages as dirty
commit 779055842da5b2e508f3ccf9a8153cb1f704f566 upstream.
There seems to be a bug in the original code when gntdev\_get\_page()
is called with writeable=true then the page needs to be marked dirty
before being put.
To address this, a bool writeable is added in gnt\_dev\_copy\_batch, set
it in gntdev\_grant\_copy\_seg() (and drop `writeable` argument to
gntdev\_get\_page()) and then, based on batch->writeable, use
set\_page\_dirty\_lock().
Fixes: a4cdb556cae0 (xen/gntdev: add ioctl for grant copy)
Suggested-by: Boris Ostrovsky
Signed-off-by: Souptick Joarder
Cc: John Hubbard
Cc: Boris Ostrovsky
Cc: Juergen Gross
Cc: David Vrabel
Cc: stable@vger.kernel.org
Link: https://lore.kernel.org/r/1599375114-32360-1-git-send-email-jrdr.linux@gmail.com
Reviewed-by: Boris Ostrovsky
Signed-off-by: Boris Ostrovsky
Signed-off-by: Greg Kroah-Hartman
commit 95528c8042a412a77e4769a2ff2abf31fee08b0d
Author: Jens Axboe
Date: Sat Oct 17 08:31:29 2020 -0600
mm: mark async iocb read as NOWAIT once some data has been copied
commit 13bd691421bc191a402d2e0d3da5f248d170a632 upstream.
Once we've copied some data for an iocb that is marked with IOCB\_WAITQ,
we should no longer attempt to async lock a new page. Instead make sure
we return the copied amount, and let the caller retry, instead of
returning -EIOCBQUEUED for a new page.
This should only be possible with read-ahead disabled on the below
device, and multiple threads racing on the same file. Haven't been able
to reproduce on anything else.
Cc: stable@vger.kernel.org # v5.9
Fixes: 1a0a7853b901 ("mm: support async buffered reads in generic\_file\_buffered\_read()")
Reported-by: Kent Overstreet
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit 90adb2b40968fbf079917ee80058da3b57e23f72
Author: Geert Uytterhoeven
Date: Thu Sep 17 15:09:20 2020 +0200
ata: sata\_rcar: Fix DMA boundary mask
commit df9c590986fdb6db9d5636d6cd93bc919c01b451 upstream.
Before commit 9495b7e92f716ab2 ("driver core: platform: Initialize
dma\_parms for platform devices"), the R-Car SATA device didn't have DMA
parameters. Hence the DMA boundary mask supplied by its driver was
silently ignored, as \_\_scsi\_init\_queue() doesn't check the return value
of dma\_set\_seg\_boundary(), and the default value of 0xffffffff was used.
Now the device has gained DMA parameters, the driver-supplied value is
used, and the following warning is printed on Salvator-XS:
DMA-API: sata\_rcar ee300000.sata: mapping sg segment across boundary [start=0x00000000ffffe000] [end=0x00000000ffffefff] [boundary=0x000000001ffffffe]
WARNING: CPU: 5 PID: 38 at kernel/dma/debug.c:1233 debug\_dma\_map\_sg+0x298/0x300
(the range of start/end values depend on whether IOMMU support is
enabled or not)
The issue here is that SATA\_RCAR\_DMA\_BOUNDARY doesn't have bit 0 set, so
any typical end value, which is odd, will trigger the check.
Fix this by increasing the DMA boundary value by 1.
This also fixes the following WRITE DMA EXT timeout issue:
# dd if=/dev/urandom of=/mnt/de1/file1-1024M bs=1M count=1024
ata1.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x6 frozen
ata1.00: failed command: WRITE DMA EXT
ata1.00: cmd 35/00:00:00:e6:0c/00:0a:00:00:00/e0 tag 0 dma 1310720 out
res 40/00:01:00:00:00/00:00:00:00:00/00 Emask 0x4 (timeout)
ata1.00: status: { DRDY }
as seen by Shimoda-san since commit 429120f3df2dba2b ("block: fix
splitting segments on boundary masks").
Fixes: 8bfbeed58665dbbf ("sata\_rcar: correct 'sata\_rcar\_sht'")
Fixes: 9495b7e92f716ab2 ("driver core: platform: Initialize dma\_parms for platform devices")
Fixes: 429120f3df2dba2b ("block: fix splitting segments on boundary masks")
Signed-off-by: Geert Uytterhoeven
Tested-by: Lad Prabhakar
Tested-by: Yoshihiro Shimoda
Reviewed-by: Christoph Hellwig
Reviewed-by: Greg Kroah-Hartman
Reviewed-by: Sergei Shtylyov
Reviewed-by: Ulf Hansson
Cc: stable
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit 70ed5fdd90ffd91385cd5bba1ab4626c00a2feb3
Author: Grygorii Strashko
Date: Fri Sep 18 19:55:18 2020 +0300
PM: runtime: Fix timer\_expires data type on 32-bit arches
commit 6b61d49a55796dbbc479eeb4465e59fd656c719c upstream.
Commit 8234f6734c5d ("PM-runtime: Switch autosuspend over to using
hrtimers") switched PM runtime autosuspend to use hrtimers and all
related time accounting in ns, but missed to update the timer\_expires
data type in struct dev\_pm\_info to u64.
This causes the timer\_expires value to be truncated on 32-bit
architectures when assignment is done from u64 values:
rpm\_suspend()
|- dev->power.timer\_expires = expires;
Fix it by changing the timer\_expires type to u64.
Fixes: 8234f6734c5d ("PM-runtime: Switch autosuspend over to using hrtimers")
Signed-off-by: Grygorii Strashko
Acked-by: Pavel Machek
Acked-by: Vincent Guittot
Cc: 5.0+  # 5.0+
[ rjw: Subject and changelog edits ]
Signed-off-by: Rafael J. Wysocki
Signed-off-by: Greg Kroah-Hartman
commit 43a6a863fa21e9e8473fe386afa40ca3f0fb802f
Author: Peter Zijlstra
Date: Wed Sep 30 13:04:32 2020 +0100
serial: pl011: Fix lockdep splat when handling magic-sysrq interrupt
commit 534cf755d9df99e214ddbe26b91cd4d81d2603e2 upstream.
Issuing a magic-sysrq via the PL011 causes the following lockdep splat,
which is easily reproducible under QEMU:
| sysrq: Changing Loglevel
| sysrq: Loglevel set to 9
|
| ======================================================
| WARNING: possible circular locking dependency detected
| 5.9.0-rc7 #1 Not tainted
| ------------------------------------------------------
| systemd-journal/138 is trying to acquire lock:
| ffffab133ad950c0 (console\_owner){-.-.}-{0:0}, at: console\_lock\_spinning\_enable+0x34/0x70
|
| but task is already holding lock:
| ffff0001fd47b098 (&port\_lock\_key){-.-.}-{2:2}, at: pl011\_int+0x40/0x488
|
| which lock already depends on the new lock.
[...]
| Possible unsafe locking scenario:
|
| CPU0 CPU1
| ---- ----
| lock(&port\_lock\_key);
| lock(console\_owner);
| lock(&port\_lock\_key);
| lock(console\_owner);
|
| \*\*\* DEADLOCK \*\*\*
The issue being that CPU0 takes 'port\_lock' on the irq path in pl011\_int()
before taking 'console\_owner' on the printk() path, whereas CPU1 takes
the two locks in the opposite order on the printk() path due to setting
the "console\_owner" prior to calling into into the actual console driver.
Fix this in the same way as the msm-serial driver by dropping 'port\_lock'
before handling the sysrq.
Cc:  # 4.19+
Cc: Russell King
Cc: Greg Kroah-Hartman
Cc: Jiri Slaby
Link: https://lore.kernel.org/r/20200811101313.GA6970@willie-the-truck
Signed-off-by: Peter Zijlstra
Tested-by: Will Deacon
Signed-off-by: Will Deacon
Link: https://lore.kernel.org/r/20200930120432.16551-1-will@kernel.org
Signed-off-by: Greg Kroah-Hartman
commit 9b08729b47413042b0dc55cb2a7782bdbfffc343
Author: Paras Sharma
Date: Wed Sep 30 11:35:26 2020 +0530
serial: qcom\_geni\_serial: To correct QUP Version detection logic
commit c9ca43d42ed8d5fd635d327a664ed1d8579eb2af upstream.
For QUP IP versions 2.5 and above the oversampling rate is
halved from 32 to 16.
Commit ce734600545f ("tty: serial: qcom\_geni\_serial: Update
the oversampling rate") is pushed to handle this scenario.
But the existing logic is failing to classify QUP Version 3.0
into the correct group ( 2.5 and above).
As result Serial Engine clocks are not configured properly for
baud rate and garbage data is sampled to FIFOs from the line.
So, fix the logic to detect QUP with versions 2.5 and above.
Fixes: ce734600545f ("tty: serial: qcom\_geni\_serial: Update the oversampling rate")
Cc: stable
Signed-off-by: Paras Sharma
Reviewed-by: Akash Asthana
Link: https://lore.kernel.org/r/1601445926-23673-1-git-send-email-parashar@codeaurora.org
Signed-off-by: Greg Kroah-Hartman
commit 124fff22b0622432e3259e099675b903d4c8c9b9
Author: Chris Wilson
Date: Thu Jul 23 18:21:19 2020 +0100
drm/i915/gem: Serialise debugfs i915\_gem\_objects with ctx->mutex
commit 4fe9af8e881d946bf60790eeb37a7c4f96e28382 upstream.
Since the debugfs may peek into the GEM contexts as the corresponding
client/fd is being closed, we may try and follow a dangling pointer.
However, the context closure itself is serialised with the ctx->mutex,
so if we hold that mutex as we inspect the state coupled in the context,
we know the pointers within the context are stable and will remain valid
as we inspect their tables.
Signed-off-by: Chris Wilson
Cc: CQ Tang
Cc: Daniel Vetter
Cc: stable@vger.kernel.org
Reviewed-by: Tvrtko Ursulin
Link: https://patchwork.freedesktop.org/patch/msgid/20200723172119.17649-3-chris@chris-wilson.co.uk
(cherry picked from commit 102f5aa491f262c818e607fc4fee08a724a76c69)
Signed-off-by: Rodrigo Vivi
Signed-off-by: Greg Kroah-Hartman
commit d07ca3e7bab81e6981a2fc006ba6852d5653f174
Author: Gustavo A. R. Silva
Date: Mon Apr 27 14:50:37 2020 -0500
mtd: lpddr: Fix bad logic in print\_drs\_error
commit 1c9c02bb22684f6949d2e7ddc0a3ff364fd5a6fc upstream.
Update logic for broken test. Use a more common logging style.
It appears the logic in this function is broken for the
consecutive tests of
if (prog\_status & 0x3)
...
else if (prog\_status & 0x2)
...
else (prog\_status & 0x1)
...
Likely the first test should be
if ((prog\_status & 0x3) == 0x3)
Found by inspection of include files using printk.
Fixes: eb3db27507f7 ("[MTD] LPDDR PFOW definition")
Cc: stable@vger.kernel.org
Reported-by: Joe Perches
Signed-off-by: Gustavo A. R. Silva
Acked-by: Miquel Raynal
Signed-off-by: Miquel Raynal
Link: https://lore.kernel.org/linux-mtd/3fb0e29f5b601db8be2938a01d974b00c8788501.1588016644.git.gustavo@embeddedor.com
Signed-off-by: Greg Kroah-Hartman
commit 35a1d6270d451d5e7fffca87f965be5e266a7916
Author: Jason Gunthorpe
Date: Wed Sep 30 10:20:07 2020 +0300
RDMA/addr: Fix race with netevent\_callback()/rdma\_addr\_cancel()
commit 2ee9bf346fbfd1dad0933b9eb3a4c2c0979b633e upstream.
This three thread race can result in the work being run once the callback
becomes NULL:
CPU1 CPU2 CPU3
netevent\_callback()
process\_one\_req() rdma\_addr\_cancel()
[..]
spin\_lock\_bh()
set\_timeout()
spin\_unlock\_bh()
spin\_lock\_bh()
list\_del\_init(&req->list);
spin\_unlock\_bh()
req->callback = NULL
spin\_lock\_bh()
if (!list\_empty(&req->list))
// Skipped!
// cancel\_delayed\_work(&req->work);
spin\_unlock\_bh()
process\_one\_req() // again
req->callback() // BOOM
cancel\_delayed\_work\_sync()
The solution is to always cancel the work once it is completed so any
in between set\_timeout() does not result in it running again.
Cc: stable@vger.kernel.org
Fixes: 44e75052bc2a ("RDMA/rdma\_cm: Make rdma\_addr\_cancel into a fence")
Link: https://lore.kernel.org/r/20200930072007.1009692-1-leon@kernel.org
Reported-by: Dan Aloni
Signed-off-by: Leon Romanovsky
Signed-off-by: Jason Gunthorpe
Signed-off-by: Greg Kroah-Hartman
commit 0f6dd1b5f0fa9962c9d8f207138d86f6675f04d4
Author: Frederic Barrat
Date: Tue Apr 7 13:56:01 2020 +0200
cxl: Rework error message for incompatible slots
commit 40ac790d99c6dd16b367d5c2339e446a5f1b0593 upstream.
Improve the error message shown if a capi adapter is plugged on a
capi-incompatible slot directly under the PHB (no intermediate switch).
Fixes: 5632874311db ("cxl: Add support for POWER9 DD2")
Cc: stable@vger.kernel.org # 4.14+
Signed-off-by: Frederic Barrat
Reviewed-by: Andrew Donnellan
Signed-off-by: Michael Ellerman
Link: https://lore.kernel.org/r/20200407115601.25453-1-fbarrat@linux.ibm.com
Signed-off-by: Greg Kroah-Hartman
commit 15cb0bd45fed8914f8e1d547121cb6852db6f7a4
Author: Jia-Ju Bai
Date: Sun Aug 2 21:29:49 2020 +0800
p54: avoid accessing the data mapped to streaming DMA
commit 478762855b5ae9f68fa6ead1edf7abada70fcd5f upstream.
In p54p\_tx(), skb->data is mapped to streaming DMA on line 337:
mapping = pci\_map\_single(..., skb->data, ...);
Then skb->data is accessed on line 349:
desc->device\_addr = ((struct p54\_hdr \*)skb->data)->req\_id;
This access may cause data inconsistency between CPU cache and hardware.
To fix this problem, ((struct p54\_hdr \*)skb->data)->req\_id is stored in
a local variable before DMA mapping, and then the driver accesses this
local variable instead of skb->data.
Cc:
Signed-off-by: Jia-Ju Bai
Acked-by: Christian Lamparter
Signed-off-by: Kalle Valo
Link: https://lore.kernel.org/r/20200802132949.26788-1-baijiaju@tsinghua.edu.cn
Signed-off-by: Greg Kroah-Hartman
commit 7ee1fb69260b226758cf22c597a42af97ebd6061
Author: Roberto Sassu
Date: Fri Sep 4 11:23:30 2020 +0200
evm: Check size of security.evm before using it
commit 455b6c9112eff8d249e32ba165742085678a80a4 upstream.
This patch checks the size for the EVM\_IMA\_XATTR\_DIGSIG and
EVM\_XATTR\_PORTABLE\_DIGSIG types to ensure that the algorithm is read from
the buffer returned by vfs\_getxattr\_alloc().
Cc: stable@vger.kernel.org # 4.19.x
Fixes: 5feeb61183dde ("evm: Allow non-SHA1 digital signatures")
Signed-off-by: Roberto Sassu
Signed-off-by: Mimi Zohar
Signed-off-by: Greg Kroah-Hartman
commit ac35c640f1c251079e017df3ec8ec6fa2ba7eb4b
Author: Song Liu
Date: Thu Sep 10 13:33:14 2020 -0700
bpf: Fix comment for helper bpf\_current\_task\_under\_cgroup()
commit 1aef5b4391f0c75c0a1523706a7b0311846ee12f upstream.
This should be "current" not "skb".
Fixes: c6b5fb8690fa ("bpf: add documentation for eBPF helpers (42-50)")
Signed-off-by: Song Liu
Signed-off-by: Alexei Starovoitov
Cc:
Link: https://lore.kernel.org/bpf/20200910203314.70018-1-songliubraving@fb.com
Signed-off-by: Greg Kroah-Hartman
commit ddd1165e0c694b13ff4bed6a3c7a2abd4c96df5b
Author: Miklos Szeredi
Date: Fri Sep 18 10:36:50 2020 +0200
fuse: fix page dereference after free
commit d78092e4937de9ce55edcb4ee4c5e3c707be0190 upstream.
After unlock\_request() pages from the ap->pages[] array may be put (e.g. by
aborting the connection) and the pages can be freed.
Prevent use after free by grabbing a reference to the page before calling
unlock\_request().
The original patch was created by Pradeep P V K.
Reported-by: Pradeep P V K
Cc:
Signed-off-by: Miklos Szeredi
Signed-off-by: Greg Kroah-Hartman
commit 4e4b514c97d17c0a962d60616a713da3c2897d83
Author: Pali Rohár
Date: Fri Oct 9 10:42:44 2020 +0200
ata: ahci: mvebu: Make SATA PHY optional for Armada 3720
commit 45aefe3d2251e4e229d7662052739f96ad1d08d9 upstream.
Older ATF does not provide SMC call for SATA phy power on functionality and
therefore initialization of ahci\_mvebu is failing when older version of ATF
is using. In this case phy\_power\_on() function returns -EOPNOTSUPP.
This patch adds a new hflag AHCI\_HFLAG\_IGN\_NOTSUPP\_POWER\_ON which cause
that ahci\_platform\_enable\_phys() would ignore -EOPNOTSUPP errors from
phy\_power\_on() call.
It fixes initialization of ahci\_mvebu on Espressobin boards where is older
Marvell's Arm Trusted Firmware without SMC call for SATA phy power.
This is regression introduced in commit 8e18c8e58da64 ("arm64: dts: marvell:
armada-3720-espressobin: declare SATA PHY property") where SATA phy was
defined and therefore ahci\_platform\_enable\_phys() on Espressobin started
failing.
Fixes: 8e18c8e58da64 ("arm64: dts: marvell: armada-3720-espressobin: declare SATA PHY property")
Signed-off-by: Pali Rohár
Tested-by: Tomasz Maciej Nowak
Cc:  # 5.1+: ea17a0f153af: phy: marvell: comphy: Convert internal SMCC firmware return codes to errno
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit be78d4658890d812ed532b028eeebca83591c02c
Author: Pali Rohár
Date: Wed Sep 2 16:43:44 2020 +0200
PCI: aardvark: Fix initialization with old Marvell's Arm Trusted Firmware
commit b0c6ae0f8948a2be6bf4e8b4bbab9ca1343289b6 upstream.
Old ATF automatically power on pcie phy and does not provide SMC call for
phy power on functionality which leads to aardvark initialization failure:
[ 0.330134] mvebu-a3700-comphy d0018300.phy: unsupported SMC call, try updating your firmware
[ 0.338846] phy phy-d0018300.phy.1: phy poweron failed --> -95
[ 0.344753] advk-pcie d0070000.pcie: Failed to initialize PHY (-95)
[ 0.351160] advk-pcie: probe of d0070000.pcie failed with error -95
This patch fixes above failure by ignoring 'not supported' error in
aardvark driver. In this case it is expected that phy is already power on.
Tested-by: Tomasz Maciej Nowak
Link: https://lore.kernel.org/r/20200902144344.16684-3-pali@kernel.org
Fixes: 366697018c9a ("PCI: aardvark: Add PHY support")
Signed-off-by: Pali Rohár
Signed-off-by: Lorenzo Pieralisi
Reviewed-by: Rob Herring
Cc:  # 5.8+: ea17a0f153af: phy: marvell: comphy: Convert internal SMCC firmware return codes to errno
Signed-off-by: Greg Kroah-Hartman
commit 68cd47546d0e6de476e994c4691cfde1edbec519
Author: Juergen Gross
Date: Fri Sep 25 16:07:51 2020 +0200
x86/xen: disable Firmware First mode for correctable memory errors
commit d759af38572f97321112a0852353613d18126038 upstream.
When running as Xen dom0 the kernel isn't responsible for selecting the
error handling mode, this should be handled by the hypervisor.
So disable setting FF mode when running as Xen pv guest. Not doing so
might result in boot splats like:
[ 7.509696] HEST: Enabling Firmware First mode for corrected errors.
[ 7.510382] mce: [Firmware Bug]: Ignoring request to disable invalid MCA bank 2.
[ 7.510383] mce: [Firmware Bug]: Ignoring request to disable invalid MCA bank 3.
[ 7.510384] mce: [Firmware Bug]: Ignoring request to disable invalid MCA bank 4.
[ 7.510384] mce: [Firmware Bug]: Ignoring request to disable invalid MCA bank 5.
[ 7.510385] mce: [Firmware Bug]: Ignoring request to disable invalid MCA bank 6.
[ 7.510386] mce: [Firmware Bug]: Ignoring request to disable invalid MCA bank 7.
[ 7.510386] mce: [Firmware Bug]: Ignoring request to disable invalid MCA bank 8.
Reason is that the HEST ACPI table contains the real number of MCA
banks, while the hypervisor is emulating only 2 banks for guests.
Cc: stable@vger.kernel.org
Signed-off-by: Juergen Gross
Reviewed-by: Boris Ostrovsky
Link: https://lore.kernel.org/r/20200925140751.31381-1-jgross@suse.com
Signed-off-by: Boris Ostrovsky
Signed-off-by: Greg Kroah-Hartman
commit f896655b6177b23e6422b8a04d26aceba4aed2fa
Author: Thomas Gleixner
Date: Mon Oct 12 15:11:47 2020 +0200
x86/traps: Fix #DE Oops message regression
commit 5f1ec1fd32252af5130dac23b5542e8e66fe0bcb upstream.
The conversion of #DE to the idtentry mechanism introduced a change in the
Ooops message which confuses tools which parse crash information in dmesg.
Remove the underscore from 'divide\_error' to restore previous behaviour.
Fixes: 9d06c4027f21 ("x86/entry: Convert Divide Error to IDTENTRY")
Reported-by: Dmitry Vyukov
Signed-off-by: Thomas Gleixner
Cc: stable@vger.kernel.org
Link: https://lore.kernel.org/r/CACT4Y+bTZFkuZd7+bPArowOv-7Die+WZpfOWnEO\_Wgs3U59+oA@mail.gmail.com
Signed-off-by: Greg Kroah-Hartman
commit f8326b029a6b662a6432200eec56836158f083da
Author: Kim Phillips
Date: Tue Sep 8 16:47:36 2020 -0500
arch/x86/amd/ibs: Fix re-arming IBS Fetch
commit 221bfce5ebbdf72ff08b3bf2510ae81058ee568b upstream.
Stephane Eranian found a bug in that IBS' current Fetch counter was not
being reset when the driver would write the new value to clear it along
with the enable bit set, and found that adding an MSR write that would
first disable IBS Fetch would make IBS Fetch reset its current count.
Indeed, the PPR for AMD Family 17h Model 31h B0 55803 Rev 0.54 - Sep 12,
2019 states "The periodic fetch counter is set to IbsFetchCnt [...] when
IbsFetchEn is changed from 0 to 1."
Explicitly set IbsFetchEn to 0 and then to 1 when re-enabling IBS Fetch,
so the driver properly resets the internal counter to 0 and IBS
Fetch starts counting again.
A family 15h machine tested does not have this problem, and the extra
wrmsr is also not needed on Family 19h, so only do the extra wrmsr on
families 16h through 18h.
Reported-by: Stephane Eranian
Signed-off-by: Kim Phillips
[peterz: optimized]
Signed-off-by: Peter Zijlstra (Intel)
Cc: stable@vger.kernel.org
Link: https://bugzilla.kernel.org/show\_bug.cgi?id=206537
Signed-off-by: Greg Kroah-Hartman
commit 592927087b154a69ea60dced33a3e8a668cf8fc4
Author: Gao Xiang
Date: Tue Aug 11 15:00:20 2020 +0800
erofs: avoid duplicated permission check for "trusted." xattrs
commit d578b46db69d125a654f509bdc9091d84e924dc8 upstream.
Don't recheck it since xattr\_permission() already
checks CAP\_SYS\_ADMIN capability.
Just follow 5d3ce4f70172 ("f2fs: avoid duplicated permission check for "trusted." xattrs")
Reported-by: Hongyu Jin
[ Gao Xiang: since it could cause some complex Android overlay
permission issue as well on android-5.4+, it'd be better to
backport to 5.4+ rather than pure cleanup on mainline. ]
Cc:  # 5.4+
Link: https://lore.kernel.org/r/20200811070020.6339-1-hsiangkao@redhat.com
Reviewed-by: Chao Yu
Signed-off-by: Gao Xiang
Signed-off-by: Greg Kroah-Hartman
commit a74045fb9e9cc209c24d2925522992217fcd40da
Author: Leon Romanovsky
Date: Mon Oct 26 14:33:27 2020 +0200
net: protect tcf\_block\_unbind with block lock
[ Upstream commit d6535dca28859d8d9ef80894eb287b2ac35a32e8 ]
The tcf\_block\_unbind() expects that the caller will take block->cb\_lock
before calling it, however the code took RTNL lock and dropped cb\_lock
instead. This causes to the following kernel panic.
WARNING: CPU: 1 PID: 13524 at net/sched/cls\_api.c:1488 tcf\_block\_unbind+0x2db/0x420
Modules linked in: mlx5\_ib mlx5\_core mlxfw ptp pps\_core act\_mirred act\_tunnel\_key cls\_flower vxlan ip6\_udp\_tunnel udp\_tunnel dummy sch\_ingress openvswitch nsh xt\_conntrack xt\_MASQUERADE nf\_conntrack\_netlink nfnetlink xt\_addrtype iptable\_nat nf\_nat nf\_conntrack nf\_defrag\_ipv6 nf\_defrag\_ipv4 br\_netfilter rpcrdma rdma\_ucm ib\_iser libiscsi scsi\_transport\_iscsi ib\_umad ib\_ipoib rdma\_cm iw\_cm ib\_cm ib\_uverbs ib\_core overlay [last unloaded: mlxfw]
CPU: 1 PID: 13524 Comm: test-ecmp-add-v Tainted: G W 5.9.0+ #1
Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS rel-1.13.0-0-gf21b5a4aeb02-prebuilt.qemu.org 04/01/2014
RIP: 0010:tcf\_block\_unbind+0x2db/0x420
Code: ff 48 83 c4 40 5b 5d 41 5c 41 5d 41 5e 41 5f c3 49 8d bc 24 30 01 00 00 be ff ff ff ff e8 7d 7f 70 00 85 c0 0f 85 7b fd ff ff <0f> 0b e9 74 fd ff ff 48 c7 c7 dc 6a 24 84 e8 02 ec fe fe e9 55 fd
RSP: 0018:ffff888117d17968 EFLAGS: 00010246
RAX: 0000000000000000 RBX: ffff88812f713c00 RCX: 1ffffffff0848d5b
RDX: 0000000000000001 RSI: ffff88814fbc8130 RDI: ffff888107f2b878
RBP: 1ffff11022fa2f3f R08: 0000000000000000 R09: ffffffff84115a87
R10: fffffbfff0822b50 R11: ffff888107f2b898 R12: ffff88814fbc8000
R13: ffff88812f713c10 R14: ffff888117d17a38 R15: ffff88814fbc80c0
FS: 00007f6593d36740(0000) GS:ffff8882a4f00000(0000) knlGS:0000000000000000
CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033
CR2: 00005607a00758f8 CR3: 0000000131aea006 CR4: 0000000000170ea0
Call Trace:
tc\_block\_indr\_cleanup+0x3e0/0x5a0
? tcf\_block\_unbind+0x420/0x420
? \_\_mutex\_unlock\_slowpath+0xe7/0x610
flow\_indr\_dev\_unregister+0x5e2/0x930
? mlx5e\_restore\_tunnel+0xdf0/0xdf0 [mlx5\_core]
? mlx5e\_restore\_tunnel+0xdf0/0xdf0 [mlx5\_core]
? flow\_indr\_block\_cb\_alloc+0x3c0/0x3c0
? mlx5\_db\_free+0x37c/0x4b0 [mlx5\_core]
mlx5e\_cleanup\_rep\_tx+0x8b/0xc0 [mlx5\_core]
mlx5e\_detach\_netdev+0xe5/0x120 [mlx5\_core]
mlx5e\_vport\_rep\_unload+0x155/0x260 [mlx5\_core]
esw\_offloads\_disable+0x227/0x2b0 [mlx5\_core]
mlx5\_eswitch\_disable\_locked.cold+0x38e/0x699 [mlx5\_core]
mlx5\_eswitch\_disable+0x94/0xf0 [mlx5\_core]
mlx5\_device\_disable\_sriov+0x183/0x1f0 [mlx5\_core]
mlx5\_core\_sriov\_configure+0xfd/0x230 [mlx5\_core]
sriov\_numvfs\_store+0x261/0x2f0
? sriov\_drivers\_autoprobe\_store+0x110/0x110
? sysfs\_file\_ops+0x170/0x170
? sysfs\_file\_ops+0x117/0x170
? sysfs\_file\_ops+0x170/0x170
kernfs\_fop\_write+0x1ff/0x3f0
? rcu\_read\_lock\_any\_held+0x6e/0x90
vfs\_write+0x1f3/0x620
ksys\_write+0xf9/0x1d0
? \_\_x64\_sys\_read+0xb0/0xb0
? lockdep\_hardirqs\_on\_prepare+0x273/0x3f0
? syscall\_enter\_from\_user\_mode+0x1d/0x50
do\_syscall\_64+0x2d/0x40
entry\_SYSCALL\_64\_after\_hwframe+0x44/0xa9
<...>
---[ end trace bfdd028ada702879 ]---
Fixes: 0fdcf78d5973 ("net: use flow\_indr\_dev\_setup\_offload()")
Signed-off-by: Leon Romanovsky
Link: https://lore.kernel.org/r/20201026123327.1141066-1-leon@kernel.org
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit bddce770def13fc2f19715f658a7f9dceb1de80e
Author: Karsten Graul
Date: Fri Oct 23 20:48:29 2020 +0200
net/smc: fix suppressed return code
[ Upstream commit 96d6fded958d971a3695009e0ed43aca6c598283 ]
The patch that repaired the invalid return code in smcd\_new\_buf\_create()
missed to take care of errno ENOSPC which has a special meaning that no
more DMBEs can be registered on the device. Fix that by keeping this
errno value during the translation of the return code.
Fixes: 6b1bbf94ab36 ("net/smc: fix invalid return code in smcd\_new\_buf\_create()")
Signed-off-by: Karsten Graul
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit e7935fa6b9259de0f10be450bb9f8063edd184ad
Author: Karsten Graul
Date: Wed Oct 14 19:43:29 2020 +0200
net/smc: fix invalid return code in smcd\_new\_buf\_create()
[ Upstream commit 6b1bbf94ab369d97ed3bdaa561521a52c27ef619 ]
smc\_ism\_register\_dmb() returns error codes set by the ISM driver which
are not guaranteed to be negative or in the errno range. Such values
would not be handled by ERR\_PTR() and finally the return code will be
used as a memory address.
Fix that by using a valid negative errno value with ERR\_PTR().
Fixes: 72b7f6c48708 ("net/smc: unique reason code for exceeded max dmb count")
Signed-off-by: Karsten Graul
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit edb2c939d889ef86341f51bda9f60c445710e739
Author: Tung Nguyen
Date: Tue Oct 27 10:24:03 2020 +0700
tipc: fix memory leak caused by tipc\_buf\_append()
[ Upstream commit ceb1eb2fb609c88363e06618b8d4bbf7815a4e03 ]
Commit ed42989eab57 ("tipc: fix the skb\_unshare() in tipc\_buf\_append()")
replaced skb\_unshare() with skb\_copy() to not reduce the data reference
counter of the original skb intentionally. This is not the correct
way to handle the cloned skb because it causes memory leak in 2
following cases:
1/ Sending multicast messages via broadcast link
The original skb list is cloned to the local skb list for local
destination. After that, the data reference counter of each skb
in the original list has the value of 2. This causes each skb not
to be freed after receiving ACK:
tipc\_link\_advance\_transmq()
{
...
/\* release skb \*/
\_\_skb\_unlink(skb, &l->transmq);
kfree\_skb(skb); <-- memory exists after being freed
}
2/ Sending multicast messages via replicast link
Similar to the above case, each skb cannot be freed after purging
the skb list:
tipc\_mcast\_xmit()
{
...
\_\_skb\_queue\_purge(pkts); <-- memory exists after being freed
}
This commit fixes this issue by using skb\_unshare() instead. Besides,
to avoid use-after-free error reported by KASAN, the pointer to the
fragment is set to NULL before calling skb\_unshare() to make sure that
the original skb is not freed after freeing the fragment 2 times in
case skb\_unshare() returns NULL.
Fixes: ed42989eab57 ("tipc: fix the skb\_unshare() in tipc\_buf\_append()")
Acked-by: Jon Maloy
Reported-by: Thang Hoang Ngo
Signed-off-by: Tung Nguyen
Reviewed-by: Xin Long
Acked-by: Cong Wang
Link: https://lore.kernel.org/r/20201027032403.1823-1-tung.q.nguyen@dektech.com.au
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit fcd0345dac289d114fbb2830b8b1f008b603bc33
Author: Arjun Roy
Date: Fri Oct 23 11:47:09 2020 -0700
tcp: Prevent low rmem stalls with SO\_RCVLOWAT.
[ Upstream commit 435ccfa894e35e3d4a1799e6ac030e48a7b69ef5 ]
With SO\_RCVLOWAT, under memory pressure,
it is possible to enter a state where:
1. We have not received enough bytes to satisfy SO\_RCVLOWAT.
2. We have not entered buffer pressure (see tcp\_rmem\_pressure()).
3. But, we do not have enough buffer space to accept more packets.
In this case, we advertise 0 rwnd (due to #3) but the application does
not drain the receive queue (no wakeup because of #1 and #2) so the
flow stalls.
Modify the heuristic for SO\_RCVLOWAT so that, if we are advertising
rwnd<=rcv\_mss, force a wakeup to prevent a stall.
Without this patch, setting tcp\_rmem to 6143 and disabling TCP
autotune causes a stalled flow. With this patch, no stall occurs. This
is with RPC-style traffic with large messages.
Fixes: 03f45c883c6f ("tcp: avoid extra wakeups for SO\_RCVLOWAT users")
Signed-off-by: Arjun Roy
Acked-by: Soheil Hassas Yeganeh
Acked-by: Neal Cardwell
Signed-off-by: Eric Dumazet
Link: https://lore.kernel.org/r/20201023184709.217614-1-arjunroy.kdev@gmail.com
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit 015b4a149a3297db7f0089242ff88453f17234cf
Author: Andrew Gabbasov
Date: Mon Oct 26 05:21:30 2020 -0500
ravb: Fix bit fields checking in ravb\_hwtstamp\_get()
[ Upstream commit 68b9f0865b1ef545da180c57d54b82c94cb464a4 ]
In the function ravb\_hwtstamp\_get() in ravb\_main.c with the existing
values for RAVB\_RXTSTAMP\_TYPE\_V2\_L2\_EVENT (0x2) and RAVB\_RXTSTAMP\_TYPE\_ALL
(0x6)
if (priv->tstamp\_rx\_ctrl & RAVB\_RXTSTAMP\_TYPE\_V2\_L2\_EVENT)
config.rx\_filter = HWTSTAMP\_FILTER\_PTP\_V2\_L2\_EVENT;
else if (priv->tstamp\_rx\_ctrl & RAVB\_RXTSTAMP\_TYPE\_ALL)
config.rx\_filter = HWTSTAMP\_FILTER\_ALL;
if the test on RAVB\_RXTSTAMP\_TYPE\_ALL should be true,
it will never be reached.
This issue can be verified with 'hwtstamp\_config' testing program
(tools/testing/selftests/net/hwtstamp\_config.c). Setting filter type
to ALL and subsequent retrieving it gives incorrect value:
$ hwtstamp\_config eth0 OFF ALL
flags = 0
tx\_type = OFF
rx\_filter = ALL
$ hwtstamp\_config eth0
flags = 0
tx\_type = OFF
rx\_filter = PTP\_V2\_L2\_EVENT
Correct this by converting if-else's to switch.
Fixes: c156633f1353 ("Renesas Ethernet AVB driver proper")
Reported-by: Julia Lawall
Signed-off-by: Andrew Gabbasov
Reviewed-by: Sergei Shtylyov
Link: https://lore.kernel.org/r/20201026102130.29368-1-andrew\_gabbasov@mentor.com
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit 434b20acad6bdf9c01ad149875d9ec9c196d2ab0
Author: Heiner Kallweit
Date: Thu Oct 29 10:18:53 2020 +0100
r8169: fix issue with forced threading in combination with shared interrupts
[ Upstream commit 2734a24e6e5d18522fbf599135c59b82ec9b2c9e ]
As reported by Serge flag IRQF\_NO\_THREAD causes an error if the
interrupt is actually shared and the other driver(s) don't have this
flag set. This situation can occur if a PCI(e) legacy interrupt is
used in combination with forced threading.
There's no good way to deal with this properly, therefore we have to
remove flag IRQF\_NO\_THREAD. For fixing the original forced threading
issue switch to napi\_schedule().
Fixes: 424a646e072a ("r8169: fix operation under forced interrupt threading")
Link: https://www.spinics.net/lists/netdev/msg694960.html
Reported-by: Serge Belyshev
Signed-off-by: Heiner Kallweit
Tested-by: Serge Belyshev
Link: https://lore.kernel.org/r/b5b53bfe-35ac-3768-85bf-74d1290cf394@gmail.com
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit 196cec63017d61d1b81d67b3df4d9fe28b38dac4
Author: Guillaume Nault
Date: Mon Oct 26 11:29:45 2020 +0100
net/sched: act\_mpls: Add softdep on mpls\_gso.ko
TCA\_MPLS\_ACT\_PUSH and TCA\_MPLS\_ACT\_MAC\_PUSH might be used on gso
packets. Such packets will thus require mpls\_gso.ko for segmentation.
v2: Drop dependency on CONFIG\_NET\_MPLS\_GSO in Kconfig (from Jakub and
David).
Fixes: 2a2ea50870ba ("net: sched: add mpls manipulation actions to TC")
Signed-off-by: Guillaume Nault
Link: https://lore.kernel.org/r/1f6cab15bbd15666795061c55563aaf6a386e90e.1603708007.git.gnault@redhat.com
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit 50dd09c87b3104df56f0b565f91eee56e20598bd
Author: Alex Elder
Date: Wed Oct 21 20:00:29 2020 -0500
net: ipa: command payloads already mapped
[ Upstream commit df833050cced27e1b343cc8bc41f90191b289334 ]
IPA transactions describe actions to be performed by the IPA
hardware. Three cases use IPA transactions: transmitting a socket
buffer; providing a page to receive packet data; and issuing an IPA
immediate command. An IPA transaction contains a scatter/gather
list (SGL) to hold the set of actions to be performed.
We map buffers in the SGL for DMA at the time they are added to the
transaction. For skb TX transactions, we fill the SGL with a call
to skb\_to\_sgvec(). Page RX transactions involve a single page
pointer, and that is recorded in the SGL with sg\_set\_page(). In
both of these cases we then map the SGL for DMA with a call to
dma\_map\_sg().
Immediate commands are different. The payload for an immediate
command comes from a region of coherent DMA memory, which must
\*not\* be mapped for DMA. For that reason, gsi\_trans\_cmd\_add()
sort of hand-crafts each SGL entry added to a command transaction.
This patch fixes a problem with the code that crafts the SGL entry
for an immediate command. Previously a portion of the SGL entry was
updated using sg\_set\_buf(). However this is not valid because it
includes a call to virt\_to\_page() on the buffer, but the command
buffer pointer is not a linear address.
Since we never actually map the SGL for command transactions, there
are very few fields in the SGL we need to fill. Specifically, we
only need to record the DMA address and the length, so they can be
used by \_\_gsi\_trans\_commit() to fill a TRE. We additionally need to
preserve the SGL flags so for\_each\_sg() still works. For that we
can simply assign a null page pointer for command SGL entries.
Fixes: 9dd441e4ed575 ("soc: qcom: ipa: GSI transactions")
Reported-by: Stephen Boyd
Tested-by: Stephen Boyd
Signed-off-by: Alex Elder
Link: https://lore.kernel.org/r/20201022010029.11877-1-elder@linaro.org
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit fb596e9432ac78f180b698ce4d997fb9579d7c7f
Author: Zenghui Yu
Date: Fri Oct 23 13:15:50 2020 +0800
net: hns3: Clear the CMDQ registers before unmapping BAR region
[ Upstream commit e3364c5ff3ff975b943a7bf47e21a2a4bf20f3fe ]
When unbinding the hns3 driver with the HNS3 VF, I got the following
kernel panic:
[ 265.709989] Unable to handle kernel paging request at virtual address ffff800054627000
[ 265.717928] Mem abort info:
[ 265.720740] ESR = 0x96000047
[ 265.723810] EC = 0x25: DABT (current EL), IL = 32 bits
[ 265.729126] SET = 0, FnV = 0
[ 265.732195] EA = 0, S1PTW = 0
[ 265.735351] Data abort info:
[ 265.738227] ISV = 0, ISS = 0x00000047
[ 265.742071] CM = 0, WnR = 1
[ 265.745055] swapper pgtable: 4k pages, 48-bit VAs, pgdp=0000000009b54000
[ 265.751753] [ffff800054627000] pgd=0000202ffffff003, p4d=0000202ffffff003, pud=00002020020eb003, pmd=00000020a0dfc003, pte=0000000000000000
[ 265.764314] Internal error: Oops: 96000047 [#1] SMP
[ 265.830357] CPU: 61 PID: 20319 Comm: bash Not tainted 5.9.0+ #206
[ 265.836423] Hardware name: Huawei TaiShan 2280 V2/BC82AMDDA, BIOS 1.05 09/18/2019
[ 265.843873] pstate: 80400009 (Nzcv daif +PAN -UAO -TCO BTYPE=--)
[ 265.843890] pc : hclgevf\_cmd\_uninit+0xbc/0x300
[ 265.861988] lr : hclgevf\_cmd\_uninit+0xb0/0x300
[ 265.861992] sp : ffff80004c983b50
[ 265.881411] pmr\_save: 000000e0
[ 265.884453] x29: ffff80004c983b50 x28: ffff20280bbce500
[ 265.889744] x27: 0000000000000000 x26: 0000000000000000
[ 265.895034] x25: ffff800011a1f000 x24: ffff800011a1fe90
[ 265.900325] x23: ffff0020ce9b00d8 x22: ffff0020ce9b0150
[ 265.905616] x21: ffff800010d70e90 x20: ffff800010d70e90
[ 265.910906] x19: ffff0020ce9b0080 x18: 0000000000000004
[ 265.916198] x17: 0000000000000000 x16: ffff800011ae32e8
[ 265.916201] x15: 0000000000000028 x14: 0000000000000002
[ 265.916204] x13: ffff800011ae32e8 x12: 0000000000012ad8
[ 265.946619] x11: ffff80004c983b50 x10: 0000000000000000
[ 265.951911] x9 : ffff8000115d0888 x8 : 0000000000000000
[ 265.951914] x7 : ffff800011890b20 x6 : c0000000ffff7fff
[ 265.951917] x5 : ffff80004c983930 x4 : 0000000000000001
[ 265.951919] x3 : ffffa027eec1b000 x2 : 2b78ccbbff369100
[ 265.964487] x1 : 0000000000000000 x0 : ffff800054627000
[ 265.964491] Call trace:
[ 265.964494] hclgevf\_cmd\_uninit+0xbc/0x300
[ 265.964496] hclgevf\_uninit\_ae\_dev+0x9c/0xe8
[ 265.964501] hnae3\_unregister\_ae\_dev+0xb0/0x130
[ 265.964516] hns3\_remove+0x34/0x88 [hns3]
[ 266.009683] pci\_device\_remove+0x48/0xf0
[ 266.009692] device\_release\_driver\_internal+0x114/0x1e8
[ 266.030058] device\_driver\_detach+0x28/0x38
[ 266.034224] unbind\_store+0xd4/0x108
[ 266.037784] drv\_attr\_store+0x40/0x58
[ 266.041435] sysfs\_kf\_write+0x54/0x80
[ 266.045081] kernfs\_fop\_write+0x12c/0x250
[ 266.049076] vfs\_write+0xc4/0x248
[ 266.052378] ksys\_write+0x74/0xf8
[ 266.055677] \_\_arm64\_sys\_write+0x24/0x30
[ 266.059584] el0\_svc\_common.constprop.3+0x84/0x270
[ 266.064354] do\_el0\_svc+0x34/0xa0
[ 266.067658] el0\_svc+0x38/0x40
[ 266.070700] el0\_sync\_handler+0x8c/0xb0
[ 266.074519] el0\_sync+0x140/0x180
It looks like the BAR memory region had already been unmapped before we
start clearing CMDQ registers in it, which is pretty bad and the kernel
happily kills itself because of a Current EL Data Abort (on arm64).
Moving the CMDQ uninitialization a bit early fixes the issue for me.
Fixes: 862d969a3a4d ("net: hns3: do VF's pci re-initialization while PF doing FLR")
Signed-off-by: Zenghui Yu
Link: https://lore.kernel.org/r/20201023051550.793-1-yuzenghui@huawei.com
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit b8858e01902391ce0fc0c83b947dc011a6a65bba
Author: Aleksandr Nogikh
Date: Wed Oct 28 17:07:31 2020 +0000
netem: fix zero division in tabledist
[ Upstream commit eadd1befdd778a1eca57fad058782bd22b4db804 ]
Currently it is possible to craft a special netlink RTM\_NEWQDISC
command that can result in jitter being equal to 0x80000000. It is
enough to set the 32 bit jitter to 0x02000000 (it will later be
multiplied by 2^6) or just set the 64 bit jitter via
TCA\_NETEM\_JITTER64. This causes an overflow during the generation of
uniformly distributed numbers in tabledist(), which in turn leads to
division by zero (sigma != 0, but sigma \* 2 is 0).
The related fragment of code needs 32-bit division - see commit
9b0ed89 ("netem: remove unnecessary 64 bit modulus"), so switching to
64 bit is not an option.
Fix the issue by keeping the value of jitter within the range that can
be adequately handled by tabledist() - [0;INT\_MAX]. As negative std
deviation makes no sense, take the absolute value of the passed value
and cap it at INT\_MAX. Inside tabledist(), switch to unsigned 32 bit
arithmetic in order to prevent overflows.
Fixes: 1da177e4c3f4 ("Linux-2.6.12-rc2")
Signed-off-by: Aleksandr Nogikh
Reported-by: syzbot+ec762a6342ad0d3c0d8f@syzkaller.appspotmail.com
Acked-by: Stephen Hemminger
Link: https://lore.kernel.org/r/20201028170731.1383332-1-aleksandrnogikh@gmail.com
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit d021dd25153c9a3494e7d8082b6c62da78ff15a3
Author: Amit Cohen
Date: Sat Oct 24 16:37:31 2020 +0300
mlxsw: Only advertise link modes supported by both driver and device
[ Upstream commit 1601559be3e4213148b4cb4a1abe672b00bf4f67 ]
During port creation the driver instructs the device to advertise all
the supported link modes queried from the device.
Since cited commit not all the link modes supported by the device are
supported by the driver. This can result in the device negotiating a
link mode that is not recognized by the driver causing ethtool to show
an unsupported speed:
$ ethtool swp1
...
Speed: Unknown!
This is especially problematic when the netdev is enslaved to a bond, as
the bond driver uses unknown speed as an indication that the link is
down:
[13048.900895] net\_ratelimit: 86 callbacks suppressed
[13048.900902] t\_bond0: (slave swp52): failed to get link speed/duplex
[13048.912160] t\_bond0: (slave swp49): failed to get link speed/duplex
Fix this by making sure that only link modes that are supported by both
the device and the driver are advertised.
Fixes: b97cd891268d ("mlxsw: Remove 56G speed support")
Signed-off-by: Amit Cohen
Signed-off-by: Ido Schimmel
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit f267b0a20cd01c4145feb48c13c7fb9624546533
Author: Ido Schimmel
Date: Sat Oct 24 16:37:32 2020 +0300
mlxsw: core: Fix memory leak on module removal
[ Upstream commit adc80b6cfedff6dad8b93d46a5ea2775fd5af9ec ]
Free the devlink instance during the teardown sequence in the non-reload
case to avoid the following memory leak.
unreferenced object 0xffff888232895000 (size 2048):
comm "modprobe", pid 1073, jiffies 4295568857 (age 164.871s)
hex dump (first 32 bytes):
00 01 00 00 00 00 ad de 22 01 00 00 00 00 ad de ........".......
10 50 89 32 82 88 ff ff 10 50 89 32 82 88 ff ff .P.2.....P.2....
backtrace:
[<00000000c704e9a6>] \_\_kmalloc+0x13a/0x2a0
[<00000000ee30129d>] devlink\_alloc+0xff/0x760
[<0000000092ab3e5d>] 0xffffffffa042e5b0
[<000000004f3f8a31>] 0xffffffffa042f6ad
[<0000000092800b4b>] 0xffffffffa0491df3
[<00000000c4843903>] local\_pci\_probe+0xcb/0x170
[<000000006993ded7>] pci\_device\_probe+0x2c2/0x4e0
[<00000000a8e0de75>] really\_probe+0x2c5/0xf90
[<00000000d42ba75d>] driver\_probe\_device+0x1eb/0x340
[<00000000bcc95e05>] device\_driver\_attach+0x294/0x300
[<000000000e2bc177>] \_\_driver\_attach+0x167/0x2f0
[<000000007d44cd6e>] bus\_for\_each\_dev+0x148/0x1f0
[<000000003cd5a91e>] driver\_attach+0x45/0x60
[<000000000041ce51>] bus\_add\_driver+0x3b8/0x720
[<00000000f5215476>] driver\_register+0x230/0x4e0
[<00000000d79356f5>] \_\_pci\_register\_driver+0x190/0x200
Fixes: a22712a96291 ("mlxsw: core: Fix devlink unregister flow")
Signed-off-by: Ido Schimmel
Reported-by: Vadim Pasternak
Tested-by: Oleksandr Shamray
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit 8cf5f59cf4a89e42fbc4896b6279e6bf165cb83d
Author: Lijun Pan
Date: Tue Oct 27 17:04:56 2020 -0500
ibmvnic: fix ibmvnic\_set\_mac
[ Upstream commit 8fc3672a8ad3e782bac80e979bc2a2c10960cbe9 ]
Jakub Kicinski brought up a concern in ibmvnic\_set\_mac().
ibmvnic\_set\_mac() does this:
ether\_addr\_copy(adapter->mac\_addr, addr->sa\_data);
if (adapter->state != VNIC\_PROBED)
rc = \_\_ibmvnic\_set\_mac(netdev, addr->sa\_data);
So if state == VNIC\_PROBED, the user can assign an invalid address to
adapter->mac\_addr, and ibmvnic\_set\_mac() will still return 0.
The fix is to validate ethernet address at the beginning of
ibmvnic\_set\_mac(), and move the ether\_addr\_copy to
the case of "adapter->state != VNIC\_PROBED".
Fixes: c26eba03e407 ("ibmvnic: Update reset infrastructure to support tunable parameters")
Signed-off-by: Lijun Pan
Link: https://lore.kernel.org/r/20201027220456.71450-1-ljp@linux.ibm.com
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit fa14e0a603e28eb37aa0e3857d598e1bff005466
Author: Thomas Bogendoerfer
Date: Mon Oct 26 11:42:21 2020 +0100
ibmveth: Fix use of ibmveth in a bridge.
[ Upstream commit 2ac8af0967aaa2b67cb382727e784900d2f4d0da ]
The check for src mac address in ibmveth\_is\_packet\_unsupported is wrong.
Commit 6f2275433a2f wanted to shut down messages for loopback packets,
but now suppresses bridged frames, which are accepted by the hypervisor
otherwise bridging won't work at all.
Fixes: 6f2275433a2f ("ibmveth: Detect unsupported packets before sending to the hypervisor")
Signed-off-by: Michal Suchanek
Signed-off-by: Thomas Bogendoerfer
Link: https://lore.kernel.org/r/20201026104221.26570-1-msuchanek@suse.de
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit d0cf5ae966570dbdd3407ceead2e5ace909c0ca6
Author: Masahiro Fujiwara
Date: Tue Oct 27 20:48:46 2020 +0900
gtp: fix an use-before-init in gtp\_newlink()
[ Upstream commit 51467431200b91682b89d31317e35dcbca1469ce ]
\*\_pdp\_find() from gtp\_encap\_recv() would trigger a crash when a peer
sends GTP packets while creating new GTP device.
RIP: 0010:gtp1\_pdp\_find.isra.0+0x68/0x90 [gtp]
Call Trace:
gtp\_encap\_recv+0xc2/0x2e0 [gtp]
? gtp1\_pdp\_find.isra.0+0x90/0x90 [gtp]
udp\_queue\_rcv\_one\_skb+0x1fe/0x530
udp\_queue\_rcv\_skb+0x40/0x1b0
udp\_unicast\_rcv\_skb.isra.0+0x78/0x90
\_\_udp4\_lib\_rcv+0x5af/0xc70
udp\_rcv+0x1a/0x20
ip\_protocol\_deliver\_rcu+0xc5/0x1b0
ip\_local\_deliver\_finish+0x48/0x50
ip\_local\_deliver+0xe5/0xf0
? ip\_protocol\_deliver\_rcu+0x1b0/0x1b0
gtp\_encap\_enable() should be called after gtp\_hastable\_new() otherwise
\*\_pdp\_find() will access the uninitialized hash table.
Fixes: 1e3a3abd8b28 ("gtp: make GTP sockets in gtp\_newlink optional")
Signed-off-by: Masahiro Fujiwara
Link: https://lore.kernel.org/r/20201027114846.3924-1-fujiwara.masahiro@gmail.com
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit 185161b46a0596a93057e51f2cd20dfc90d43f87
Author: Raju Rangoju
Date: Fri Oct 23 17:28:52 2020 +0530
cxgb4: set up filter action after rewrites
[ Upstream commit 937d8420588421eaa5c7aa5c79b26b42abb288ef ]
The current code sets up the filter action field before
rewrites are set up. When the action 'switch' is used
with rewrites, this may result in initial few packets
that get switched out don't have rewrites applied
on them.
So, make sure filter action is set up along with rewrites
or only after everything else is set up for rewrites.
Fixes: 12b276fbf6e0 ("cxgb4: add support to create hash filters")
Signed-off-by: Raju Rangoju
Link: https://lore.kernel.org/r/20201023115852.18262-1-rajur@chelsio.com
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit 676a2b8478ea04cfa38cddd5dff8981098ace06f
Author: Vinay Kumar Yadav
Date: Fri Oct 23 00:35:57 2020 +0530
chelsio/chtls: fix tls record info to user
[ Upstream commit 4f3391ce8f5a69e7e6d66d0a3fc654eb6dbdc919 ]
chtls\_pt\_recvmsg() receives a skb with tls header and subsequent
skb with data, need to finalize the data copy whenever next skb
with tls header is available. but here current tls header is
overwritten by next available tls header, ends up corrupting
user buffer data. fixing it by finalizing current record whenever
next skb contains tls header.
v1->v2:
- Improved commit message.
Fixes: 17a7d24aa89d ("crypto: chtls - generic handling of data and hdr")
Signed-off-by: Vinay Kumar Yadav
Link: https://lore.kernel.org/r/20201022190556.21308-1-vinay.yadav@chelsio.com
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit a368a6efeeb0e06cb98010f12127e9584faaa95b
Author: Vinay Kumar Yadav
Date: Mon Oct 26 01:12:29 2020 +0530
chelsio/chtls: fix memory leaks in CPL handlers
[ Upstream commit 6daa1da4e262b0cd52ef0acc1989ff22b5540264 ]
CPL handler functions chtls\_pass\_open\_rpl() and
chtls\_close\_listsrv\_rpl() should return CPL\_RET\_BUF\_DONE
so that caller function will do skb free to avoid leak.
Fixes: cc35c88ae4db ("crypto : chtls - CPL handler definition")
Signed-off-by: Vinay Kumar Yadav
Link: https://lore.kernel.org/r/20201025194228.31271-1-vinay.yadav@chelsio.com
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit 6e3163c742580630cf8bba172ef84c3a5f2a9295
Author: Vinay Kumar Yadav
Date: Mon Oct 26 01:05:39 2020 +0530
chelsio/chtls: fix deadlock issue
[ Upstream commit 28e9dcd9172028263c8225c15c4e329e08475e89 ]
In chtls\_pass\_establish() we hold child socket lock using bh\_lock\_sock
and we are again trying bh\_lock\_sock in add\_to\_reap\_list, causing deadlock.
Remove bh\_lock\_sock in add\_to\_reap\_list() as lock is already held.
Fixes: cc35c88ae4db ("crypto : chtls - CPL handler definition")
Signed-off-by: Vinay Kumar Yadav
Link: https://lore.kernel.org/r/20201025193538.31112-1-vinay.yadav@chelsio.com
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit c4fd583ab0932fead8c02b7f106d0154e148bc71
Author: Vasundhara Volam
Date: Mon Oct 26 00:18:21 2020 -0400
bnxt\_en: Send HWRM\_FUNC\_RESET fw command unconditionally.
[ Upstream commit 825741b071722f1c8ad692cead562c4b5f5eaa93 ]
In the AER or firmware reset flow, if we are in fatal error state or
if pci\_channel\_offline() is true, we don't send any commands to the
firmware because the commands will likely not reach the firmware and
most commands don't matter much because the firmware is likely to be
reset imminently.
However, the HWRM\_FUNC\_RESET command is different and we should always
attempt to send it. In the AER flow for example, the .slot\_reset()
call will trigger this fw command and we need to try to send it to
effect the proper reset.
Fixes: b340dc680ed4 ("bnxt\_en: Avoid sending firmware messages when AER error is detected.")
Reviewed-by: Edwin Peer
Signed-off-by: Vasundhara Volam
Signed-off-by: Michael Chan
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit c32f632d114c9eff8e8ee073c0cf0d3ebf4c9347
Author: Vasundhara Volam
Date: Mon Oct 26 00:18:19 2020 -0400
bnxt\_en: Re-write PCI BARs after PCI fatal error.
[ Upstream commit f75d9a0aa96721d20011cd5f8c7a24eb32728589 ]
When a PCIe fatal error occurs, the internal latched BAR addresses
in the chip get reset even though the BAR register values in config
space are retained.
pci\_restore\_state() will not rewrite the BAR addresses if the
BAR address values are valid, causing the chip's internal BAR addresses
to stay invalid. So we need to zero the BAR registers during PCIe fatal
error to force pci\_restore\_state() to restore the BAR addresses. These
write cycles to the BAR registers will cause the proper BAR addresses to
latch internally.
Fixes: 6316ea6db93d ("bnxt\_en: Enable AER support.")
Signed-off-by: Vasundhara Volam
Signed-off-by: Michael Chan
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit 01236943c44899153e73da1412710b8e53d156ba
Author: Vasundhara Volam
Date: Mon Oct 26 00:18:18 2020 -0400
bnxt\_en: Invoke cancel\_delayed\_work\_sync() for PFs also.
[ Upstream commit 631ce27a3006fc0b732bfd589c6df505f62eadd9 ]
As part of the commit b148bb238c02
("bnxt\_en: Fix possible crash in bnxt\_fw\_reset\_task()."),
cancel\_delayed\_work\_sync() is called only for VFs to fix a possible
crash by cancelling any pending delayed work items. It was assumed
by mistake that the flush\_workqueue() call on the PF would flush
delayed work items as well.
As flush\_workqueue() does not cancel the delayed workqueue, extend
the fix for PFs. This fix will avoid the system crash, if there are
any pending delayed work items in fw\_reset\_task() during driver's
.remove() call.
Unify the workqueue cleanup logic for both PF and VF by calling
cancel\_work\_sync() and cancel\_delayed\_work\_sync() directly in
bnxt\_remove\_one().
Fixes: b148bb238c02 ("bnxt\_en: Fix possible crash in bnxt\_fw\_reset\_task().")
Reviewed-by: Pavan Chebbi
Reviewed-by: Andy Gospodarek
Signed-off-by: Vasundhara Volam
Signed-off-by: Michael Chan
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit 9959fdafebfadb9e6fb0c4d009ed849f5feb0bec
Author: Vasundhara Volam
Date: Mon Oct 26 00:18:17 2020 -0400
bnxt\_en: Fix regression in workqueue cleanup logic in bnxt\_remove\_one().
[ Upstream commit 21d6a11e2cadfb8446265a3efff0e2aad206e15e ]
A recent patch has moved the workqueue cleanup logic before
calling unregister\_netdev() in bnxt\_remove\_one(). This caused a
regression because the workqueue can be restarted if the device is
still open. Workqueue cleanup must be done after unregister\_netdev().
The workqueue will not restart itself after the device is closed.
Call bnxt\_cancel\_sp\_work() after unregister\_netdev() and
call bnxt\_dl\_fw\_reporters\_destroy() after that. This fixes the
regession and the original NULL ptr dereference issue.
Fixes: b16939b59cc0 ("bnxt\_en: Fix NULL ptr dereference crash in bnxt\_fw\_reset\_task()")
Signed-off-by: Vasundhara Volam
Signed-off-by: Michael Chan
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit 524dfe6c892aed857381d8c42b683860a4e14fbe
Author: Michael Chan
Date: Mon Oct 26 00:18:20 2020 -0400
bnxt\_en: Check abort error state in bnxt\_open\_nic().
[ Upstream commit a1301f08c5acf992d9c1fafddc84c3a822844b04 ]
bnxt\_open\_nic() is called during configuration changes that require
the NIC to be closed and then opened. This call is protected by
rtnl\_lock. Firmware reset can be happening at the same time. Only
critical portions of the entire firmware reset sequence are protected
by the rtnl\_lock. It is possible that bnxt\_open\_nic() can be called
when the firmware reset sequence is aborting. In that case,
bnxt\_open\_nic() needs to check if the ABORT\_ERR flag is set and
abort if it is. The configuration change that resulted in the
bnxt\_open\_nic() call will fail but the NIC will be brought to a
consistent IF\_DOWN state.
Without this patch, if bnxt\_open\_nic() were to continue in this error
state, it may crash like this:
[ 1648.659736] BUG: unable to handle kernel NULL pointer dereference at (null)
[ 1648.659768] IP: [] bnxt\_alloc\_mem+0x50a/0x1140 [bnxt\_en]
[ 1648.659796] PGD 101e1b3067 PUD 101e1b2067 PMD 0
[ 1648.659813] Oops: 0000 [#1] SMP
[ 1648.659825] Modules linked in: xt\_CHECKSUM iptable\_mangle ipt\_MASQUERADE nf\_nat\_masquerade\_ipv4 iptable\_nat nf\_nat\_ipv4 nf\_nat nf\_conntrack\_ipv4 nf\_defrag\_ipv4 xt\_conntrack nf\_conntrack ipt\_REJECT nf\_reject\_ipv4 tun bridge stp llc ebtable\_filter ebtables ip6table\_filter ip6\_tables iptable\_filter sunrpc dell\_smbios dell\_wmi\_descriptor dcdbas amd64\_edac\_mod edac\_mce\_amd kvm\_amd kvm irqbypass crc32\_pclmul ghash\_clmulni\_intel aesni\_intel lrw gf128mul glue\_helper ablk\_helper vfat cryptd fat pcspkr ipmi\_ssif sg k10temp i2c\_piix4 wmi ipmi\_si ipmi\_devintf ipmi\_msghandler tpm\_crb acpi\_power\_meter sch\_fq\_codel ip\_tables xfs libcrc32c sd\_mod crc\_t10dif crct10dif\_generic mgag200 i2c\_algo\_bit drm\_kms\_helper syscopyarea sysfillrect sysimgblt fb\_sys\_fops ttm ahci drm libahci megaraid\_sas crct10dif\_pclmul crct10dif\_common
[ 1648.660063] tg3 libata crc32c\_intel bnxt\_en(OE) drm\_panel\_orientation\_quirks devlink ptp pps\_core dm\_mirror dm\_region\_hash dm\_log dm\_mod fuse
[ 1648.660105] CPU: 13 PID: 3867 Comm: ethtool Kdump: loaded Tainted: G OE ------------ 3.10.0-1152.el7.x86\_64 #1
[ 1648.660911] Hardware name: Dell Inc. PowerEdge R7515/0R4CNN, BIOS 1.2.14 01/28/2020
[ 1648.661662] task: ffff94e64cbc9080 ti: ffff94f55df1c000 task.ti: ffff94f55df1c000
[ 1648.662409] RIP: 0010:[] [] bnxt\_alloc\_mem+0x50a/0x1140 [bnxt\_en]
[ 1648.663171] RSP: 0018:ffff94f55df1fba8 EFLAGS: 00010202
[ 1648.663927] RAX: 0000000000000000 RBX: ffff94e6827e0000 RCX: 0000000000000000
[ 1648.664684] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffff94e6827e08c0
[ 1648.665433] RBP: ffff94f55df1fc20 R08: 00000000000001ff R09: 0000000000000008
[ 1648.666184] R10: 0000000000000d53 R11: ffff94f55df1f7ce R12: ffff94e6827e08c0
[ 1648.666940] R13: ffff94e6827e08c0 R14: ffff94e6827e08c0 R15: ffffffffb9115e40
[ 1648.667695] FS: 00007f8aadba5740(0000) GS:ffff94f57eb40000(0000) knlGS:0000000000000000
[ 1648.668447] CS: 0010 DS: 0000 ES: 0000 CR0: 0000000080050033
[ 1648.669202] CR2: 0000000000000000 CR3: 0000001022772000 CR4: 0000000000340fe0
[ 1648.669966] Call Trace:
[ 1648.670730] [] ? bnxt\_need\_reserve\_rings+0x9d/0x170 [bnxt\_en]
[ 1648.671496] [] \_\_bnxt\_open\_nic+0x8a/0x9a0 [bnxt\_en]
[ 1648.672263] [] ? bnxt\_close\_nic+0x59/0x1b0 [bnxt\_en]
[ 1648.673031] [] bnxt\_open\_nic+0x1b/0x50 [bnxt\_en]
[ 1648.673793] [] bnxt\_set\_ringparam+0x6c/0xa0 [bnxt\_en]
[ 1648.674550] [] dev\_ethtool+0x1334/0x21a0
[ 1648.675306] [] dev\_ioctl+0x1ef/0x5f0
[ 1648.676061] [] sock\_do\_ioctl+0x4d/0x60
[ 1648.676810] [] sock\_ioctl+0x1eb/0x2d0
[ 1648.677548] [] do\_vfs\_ioctl+0x3a0/0x5b0
[ 1648.678282] [] ? \_\_do\_page\_fault+0x238/0x500
[ 1648.679016] [] SyS\_ioctl+0xa1/0xc0
[ 1648.679745] [] system\_call\_fastpath+0x25/0x2a
[ 1648.680461] Code: 9e 60 01 00 00 0f 1f 40 00 45 8b 8e 48 01 00 00 31 c9 45 85 c9 0f 8e 73 01 00 00 66 0f 1f 44 00 00 49 8b 86 a8 00 00 00 48 63 d1 <48> 8b 14 d0 48 85 d2 0f 84 46 01 00 00 41 8b 86 44 01 00 00 c7
[ 1648.681986] RIP [] bnxt\_alloc\_mem+0x50a/0x1140 [bnxt\_en]
[ 1648.682724] RSP
[ 1648.683451] CR2: 0000000000000000
Fixes: ec5d31e3c15d ("bnxt\_en: Handle firmware reset status during IF\_UP.")
Reviewed-by: Vasundhara Volam
Reviewed-by: Pavan Chebbi
Signed-off-by: Michael Chan
Signed-off-by: Jakub Kicinski
Signed-off-by: Greg Kroah-Hartman
commit 4e6767ce5116f72e21caf891aededf2cc0ef832a
Author: Michael Schaller
Date: Fri Sep 25 09:45:02 2020 +0200
efivarfs: Replace invalid slashes with exclamation marks in dentries.
commit 336af6a4686d885a067ecea8c3c3dd129ba4fc75 upstream.
Without this patch efivarfs\_alloc\_dentry creates dentries with slashes in
their name if the respective EFI variable has slashes in its name. This in
turn causes EIO on getdents64, which prevents a complete directory listing
of /sys/firmware/efi/efivars/.
This patch replaces the invalid shlashes with exclamation marks like
kobject\_set\_name\_vargs does for /sys/firmware/efi/vars/ to have consistently
named dentries under /sys/firmware/efi/vars/ and /sys/firmware/efi/efivars/.
Signed-off-by: Michael Schaller
Link: https://lore.kernel.org/r/20200925074502.150448-1-misch@google.com
Signed-off-by: Ard Biesheuvel
Signed-off-by: dann frazier
Signed-off-by: Greg Kroah-Hartman
commit 4f28b1fb9d1daf3b98710a4b0520fa0c1767cd16
Author: Dan Williams
Date: Mon Oct 5 20:40:25 2020 -0700
x86/copy\_mc: Introduce copy\_mc\_enhanced\_fast\_string()
commit 5da8e4a658109e3b7e1f45ae672b7c06ac3e7158 upstream.
The motivations to go rework memcpy\_mcsafe() are that the benefit of
doing slow and careful copies is obviated on newer CPUs, and that the
current opt-in list of CPUs to instrument recovery is broken relative to
those CPUs. There is no need to keep an opt-in list up to date on an
ongoing basis if pmem/dax operations are instrumented for recovery by
default. With recovery enabled by default the old "mcsafe\_key" opt-in to
careful copying can be made a "fragile" opt-out. Where the "fragile"
list takes steps to not consume poison across cachelines.
The discussion with Linus made clear that the current "\_mcsafe" suffix
was imprecise to a fault. The operations that are needed by pmem/dax are
to copy from a source address that might throw #MC to a destination that
may write-fault, if it is a user page.
So copy\_to\_user\_mcsafe() becomes copy\_mc\_to\_user() to indicate
the separate precautions taken on source and destination.
copy\_mc\_to\_kernel() is introduced as a non-SMAP version that does not
expect write-faults on the destination, but is still prepared to abort
with an error code upon taking #MC.
The original copy\_mc\_fragile() implementation had negative performance
implications since it did not use the fast-string instruction sequence
to perform copies. For this reason copy\_mc\_to\_kernel() fell back to
plain memcpy() to preserve performance on platforms that did not indicate
the capability to recover from machine check exceptions. However, that
capability detection was not architectural and now that some platforms
can recover from fast-string consumption of memory errors the memcpy()
fallback now causes these more capable platforms to fail.
Introduce copy\_mc\_enhanced\_fast\_string() as the fast default
implementation of copy\_mc\_to\_kernel() and finalize the transition of
copy\_mc\_fragile() to be a platform quirk to indicate 'copy-carefully'.
With this in place, copy\_mc\_to\_kernel() is fast and recovery-ready by
default regardless of hardware capability.
Thanks to Vivek for identifying that copy\_user\_generic() is not suitable
as the copy\_mc\_to\_user() backend since the #MC handler explicitly checks
ex\_has\_fault\_handler(). Thanks to the 0day robot for catching a
performance bug in the x86/copy\_mc\_to\_user implementation.
[ bp: Add the "why" for this change from the 0/2th message, massage. ]
Fixes: 92b0729c34ca ("x86/mm, x86/mce: Add memcpy\_mcsafe()")
Reported-by: Erwin Tsaur
Reported-by: 0day robot
Signed-off-by: Dan Williams
Signed-off-by: Borislav Petkov
Reviewed-by: Tony Luck
Tested-by: Erwin Tsaur
Cc:
Link: https://lkml.kernel.org/r/160195562556.2163339.18063423034951948973.stgit@dwillia2-desk3.amr.corp.intel.com
Signed-off-by: Greg Kroah-Hartman
commit a85748ed9eb70108f9605558f2754ca94ee91401
Author: Dan Williams
Date: Mon Oct 5 20:40:16 2020 -0700
x86, powerpc: Rename memcpy\_mcsafe() to copy\_mc\_to\_{user, kernel}()
commit ec6347bb43395cb92126788a1a5b25302543f815 upstream.
In reaction to a proposal to introduce a memcpy\_mcsafe\_fast()
implementation Linus points out that memcpy\_mcsafe() is poorly named
relative to communicating the scope of the interface. Specifically what
addresses are valid to pass as source, destination, and what faults /
exceptions are handled.
Of particular concern is that even though x86 might be able to handle
the semantics of copy\_mc\_to\_user() with its common copy\_user\_generic()
implementation other archs likely need / want an explicit path for this
case:
On Fri, May 1, 2020 at 11:28 AM Linus Torvalds  wrote:
>
> On Thu, Apr 30, 2020 at 6:21 PM Dan Williams  wrote:
> >
> > However now I see that copy\_user\_generic() works for the wrong reason.
> > It works because the exception on the source address due to poison
> > looks no different than a write fault on the user address to the
> > caller, it's still just a short copy. So it makes copy\_to\_user() work
> > for the wrong reason relative to the name.
>
> Right.
>
> And it won't work that way on other architectures. On x86, we have a
> generic function that can take faults on either side, and we use it
> for both cases (and for the "in\_user" case too), but that's an
> artifact of the architecture oddity.
>
> In fact, it's probably wrong even on x86 - because it can hide bugs -
> but writing those things is painful enough that everybody prefers
> having just one function.
Replace a single top-level memcpy\_mcsafe() with either
copy\_mc\_to\_user(), or copy\_mc\_to\_kernel().
Introduce an x86 copy\_mc\_fragile() name as the rename for the
low-level x86 implementation formerly named memcpy\_mcsafe(). It is used
as the slow / careful backend that is supplanted by a fast
copy\_mc\_generic() in a follow-on patch.
One side-effect of this reorganization is that separating copy\_mc\_64.S
to its own file means that perf no longer needs to track dependencies
for its memcpy\_64.S benchmarks.
[ bp: Massage a bit. ]
Signed-off-by: Dan Williams
Signed-off-by: Borislav Petkov
Reviewed-by: Tony Luck
Acked-by: Michael Ellerman
Cc:
Link: http://lore.kernel.org/r/CAHk-=wjSqtXAqfUJxFtWNwmguFASTgB0dz1dT3V-78Quiezqbg@mail.gmail.com
Link: https://lkml.kernel.org/r/160195561680.2163339.11574962055305783722.stgit@dwillia2-desk3.amr.corp.intel.com
Signed-off-by: Greg Kroah-Hartman
commit ff0028e0a1c22e2f784d645fb13102b54af5ab9a
Author: Randy Dunlap
Date: Fri Aug 21 17:10:27 2020 -0700
x86/PCI: Fix intel\_mid\_pci.c build error when ACPI is not enabled
commit 035fff1f7aab43e420e0098f0854470a5286fb83 upstream.
Fix build error when CONFIG\_ACPI is not set/enabled by adding the header
file  which contains a stub for the function in the build
error.
../arch/x86/pci/intel\_mid\_pci.c: In function ‘intel\_mid\_pci\_init’:
../arch/x86/pci/intel\_mid\_pci.c:303:2: error: implicit declaration of function ‘acpi\_noirq\_set’; did you mean ‘acpi\_irq\_get’? [-Werror=implicit-function-declaration]
acpi\_noirq\_set();
Fixes: a912a7584ec3 ("x86/platform/intel-mid: Move PCI initialization to arch\_init()")
Link: https://lore.kernel.org/r/ea903917-e51b-4cc9-2680-bc1e36efa026@infradead.org
Signed-off-by: Randy Dunlap
Signed-off-by: Bjorn Helgaas
Reviewed-by: Andy Shevchenko
Reviewed-by: Jesse Barnes
Acked-by: Thomas Gleixner
Cc: stable@vger.kernel.org # v4.16+
Cc: Jacob Pan
Cc: Len Brown
Cc: Jesse Barnes
Cc: Arjan van de Ven
Signed-off-by: Greg Kroah-Hartman
commit 4497727c3c098a1826daad098ff476ca8d4adf0a
Author: Nick Desaulniers
Date: Fri Oct 16 10:53:39 2020 -0700
arm64: link with -z norelro regardless of CONFIG\_RELOCATABLE
commit 3b92fa7485eba16b05166fddf38ab42f2ff6ab95 upstream.
With CONFIG\_EXPERT=y, CONFIG\_KASAN=y, CONFIG\_RANDOMIZE\_BASE=n,
CONFIG\_RELOCATABLE=n, we observe the following failure when trying to
link the kernel image with LD=ld.lld:
error: section: .exit.data is not contiguous with other relro sections
ld.lld defaults to -z relro while ld.bfd defaults to -z norelro. This
was previously fixed, but only for CONFIG\_RELOCATABLE=y.
Fixes: 3bbd3db86470 ("arm64: relocatable: fix inconsistencies in linker script and options")
Signed-off-by: Nick Desaulniers
Cc: stable@vger.kernel.org
Link: https://lore.kernel.org/r/20201016175339.2429280-1-ndesaulniers@google.com
Signed-off-by: Will Deacon
Signed-off-by: Greg Kroah-Hartman
commit 0c4636da01ffcead429c67906a74e3783f23f394
Author: Marc Zyngier
Date: Thu Jul 16 17:11:10 2020 +0100
arm64: Run ARCH\_WORKAROUND\_2 enabling code on all CPUs
commit 39533e12063be7f55e3d6ae21ffe067799d542a4 upstream.
Commit 606f8e7b27bf ("arm64: capabilities: Use linear array for
detection and verification") changed the way we deal with per-CPU errata
by only calling the .matches() callback until one CPU is found to be
affected. At this point, .matches() stop being called, and .cpu\_enable()
will be called on all CPUs.
This breaks the ARCH\_WORKAROUND\_2 handling, as only a single CPU will be
mitigated.
In order to address this, forcefully call the .matches() callback from a
.cpu\_enable() callback, which brings us back to the original behaviour.
Fixes: 606f8e7b27bf ("arm64: capabilities: Use linear array for detection and verification")
Cc:
Reviewed-by: Suzuki K Poulose
Signed-off-by: Marc Zyngier
Signed-off-by: Will Deacon
Signed-off-by: Greg Kroah-Hartman
commit 32b38af1d7bc49144ec4f08d68c49b8346b8cea9
Author: Marc Zyngier
Date: Thu Jul 16 17:11:09 2020 +0100
arm64: Run ARCH\_WORKAROUND\_1 enabling code on all CPUs
commit 18fce56134c987e5b4eceddafdbe4b00c07e2ae1 upstream.
Commit 73f381660959 ("arm64: Advertise mitigation of Spectre-v2, or lack
thereof") changed the way we deal with ARCH\_WORKAROUND\_1, by moving most
of the enabling code to the .matches() callback.
This has the unfortunate effect that the workaround gets only enabled on
the first affected CPU, and no other.
In order to address this, forcefully call the .matches() callback from a
.cpu\_enable() callback, which brings us back to the original behaviour.
Fixes: 73f381660959 ("arm64: Advertise mitigation of Spectre-v2, or lack thereof")
Cc:
Reviewed-by: Suzuki K Poulose
Signed-off-by: Marc Zyngier
Signed-off-by: Will Deacon
Signed-off-by: Greg Kroah-Hartman
commit 0baaa4a41f34ac057b714631d729ee63e0b46ad1
Author: Kees Cook
Date: Fri Oct 2 10:38:14 2020 -0700
fs/kernel\_read\_file: Remove FIRMWARE\_EFI\_EMBEDDED enum
commit 06e67b849ab910a49a629445f43edb074153d0eb upstream.
The "FIRMWARE\_EFI\_EMBEDDED" enum is a "where", not a "what". It
should not be distinguished separately from just "FIRMWARE", as this
confuses the LSMs about what is being loaded. Additionally, there was
no actual validation of the firmware contents happening.
Fixes: e4c2c0ff00ec ("firmware: Add new platform fallback mechanism and firmware\_request\_platform()")
Signed-off-by: Kees Cook
Reviewed-by: Luis Chamberlain
Acked-by: Scott Branden
Cc: stable@vger.kernel.org
Link: https://lore.kernel.org/r/20201002173828.2099543-3-keescook@chromium.org
Signed-off-by: Greg Kroah-Hartman
commit 5a91009aa24960736549df3eafc915152359cdbb
Author: Ard Biesheuvel
Date: Sat Sep 26 10:52:42 2020 +0200
efi/arm64: libstub: Deal gracefully with EFI\_RNG\_PROTOCOL failure
commit d32de9130f6c79533508e2c7879f18997bfbe2a0 upstream.
Currently, on arm64, we abort on any failure from efi\_get\_random\_bytes()
other than EFI\_NOT\_FOUND when it comes to setting the physical seed for
KASLR, but ignore such failures when obtaining the seed for virtual
KASLR or for early seeding of the kernel's entropy pool via the config
table. This is inconsistent, and may lead to unexpected boot failures.
So let's permit any failure for the physical seed, and simply report
the error code if it does not equal EFI\_NOT\_FOUND.
Cc:  # v5.8+
Reported-by: Heinrich Schuchardt
Signed-off-by: Ard Biesheuvel
Signed-off-by: Greg Kroah-Hartman
commit fb66242eed3d6f28afadc5861107ad8e8772a3a7
Author: Rasmus Villemoes
Date: Thu Sep 17 08:56:11 2020 +0200
scripts/setlocalversion: make git describe output more reliable
commit 548b8b5168c90c42e88f70fcf041b4ce0b8e7aa8 upstream.
When building for an embedded target using Yocto, we're sometimes
observing that the version string that gets built into vmlinux (and
thus what uname -a reports) differs from the path under /lib/modules/
where modules get installed in the rootfs, but only in the length of
the -gabc123def suffix. Hence modprobe always fails.
The problem is that Yocto has the concept of "sstate" (shared state),
which allows different developers/buildbots/etc. to share build
artifacts, based on a hash of all the metadata that went into building
that artifact - and that metadata includes all dependencies (e.g. the
compiler used etc.). That normally works quite well; usually a clean
build (without using any sstate cache) done by one developer ends up
being binary identical to a build done on another host. However, one
thing that can cause two developers to end up with different builds
[and thus make one's vmlinux package incompatible with the other's
kernel-dev package], which is not captured by the metadata hashing, is
this `git describe`: The output of that can be affected by
(1) git version: before 2.11 git defaulted to a minimum of 7, since
2.11 (git.git commit e6c587) the default is dynamic based on the
number of objects in the repo
(2) hence even if both run the same git version, the output can differ
based on how many remotes are being tracked (or just lots of local
development branches or plain old garbage)
(3) and of course somebody could have a core.abbrev config setting in
~/.gitconfig
So in order to avoid `uname -a` output relying on such random details
of the build environment which are rather hard to ensure are
consistent between developers and buildbots, make sure the abbreviated
sha1 always consists of exactly 12 hex characters. That is consistent
with the current rule for -stable patches, and is almost always enough
to identify the head commit unambigously - in the few cases where it
does not, the v5.4.3-00021- prefix would certainly nail it down.
Signed-off-by: Rasmus Villemoes
Signed-off-by: Masahiro Yamada
Signed-off-by: Greg Kroah-Hartman
commit db4d1a3818e0456dd3c5bf82add8afa07e922aaf
Author: Matthew Wilcox (Oracle)
Date: Fri Oct 9 13:49:53 2020 +0100
io\_uring: Convert advanced XArray uses to the normal API
commit 5e2ed8c4f45093698855b1f45cdf43efbf6dd498 upstream.
There are no bugs here that I've spotted, it's just easier to use the
normal API and there are no performance advantages to using the more
verbose advanced API.
Signed-off-by: Matthew Wilcox (Oracle)
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit a05b5f7d2db6b617cd6dadc73620babdecea88d2
Author: Matthew Wilcox (Oracle)
Date: Fri Oct 9 13:49:52 2020 +0100
io\_uring: Fix XArray usage in io\_uring\_add\_task\_file
commit 236434c3438c4da3dfbd6aeeab807577b85e951a upstream.
The xas\_store() wasn't paired with an xas\_nomem() loop, so if it couldn't
allocate memory using GFP\_NOWAIT, it would leak the reference to the file
descriptor. Also the node pointed to by the xas could be freed between
the call to xas\_load() under the rcu\_read\_lock() and the acquisition of
the xa\_lock.
It's easier to just use the normal xa\_load/xa\_store interface here.
Signed-off-by: Matthew Wilcox (Oracle)
[axboe: fix missing assign after alloc, cur\_uring -> tctx rename]
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit 4f0cc46b76ee57a16fec70b67100642da50323a5
Author: Matthew Wilcox (Oracle)
Date: Fri Oct 9 13:49:51 2020 +0100
io\_uring: Fix use of XArray in \_\_io\_uring\_files\_cancel
commit ce765372bc443573d1d339a2bf4995de385dea3a upstream.
We have to drop the lock during each iteration, so there's no advantage
to using the advanced API. Convert this to a standard xa\_for\_each() loop.
Reported-by: syzbot+27c12725d8ff0bfe1a13@syzkaller.appspotmail.com
Signed-off-by: Matthew Wilcox (Oracle)
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit f048478e282edcb45c5459d8427c0990dde56312
Author: Jens Axboe
Date: Thu Oct 8 07:46:52 2020 -0600
io\_uring: no need to call xa\_destroy() on empty xarray
commit ca6484cd308a671811bf39f3119e81966eb476e3 upstream.
The kernel test robot reports this lockdep issue:
[child1:659] mbind (274) returned ENOSYS, marking as inactive.
[child1:659] mq\_timedsend (279) returned ENOSYS, marking as inactive.
[main] 10175 iterations. [F:7781 S:2344 HI:2397]
[ 24.610601]
[ 24.610743] ================================
[ 24.611083] WARNING: inconsistent lock state
[ 24.611437] 5.9.0-rc7-00017-g0f2122045b9462 #5 Not tainted
[ 24.611861] --------------------------------
[ 24.612193] inconsistent {SOFTIRQ-ON-W} -> {IN-SOFTIRQ-W} usage.
[ 24.612660] ksoftirqd/0/7 [HC0[0]:SC1[3]:HE0:SE0] takes:
[ 24.613086] f00ed998 (&xa->xa\_lock#4){+.?.}-{2:2}, at: xa\_destroy+0x43/0xc1
[ 24.613642] {SOFTIRQ-ON-W} state was registered at:
[ 24.614024] lock\_acquire+0x20c/0x29b
[ 24.614341] \_raw\_spin\_lock+0x21/0x30
[ 24.614636] io\_uring\_add\_task\_file+0xe8/0x13a
[ 24.614987] io\_uring\_create+0x535/0x6bd
[ 24.615297] io\_uring\_setup+0x11d/0x136
[ 24.615606] \_\_ia32\_sys\_io\_uring\_setup+0xd/0xf
[ 24.615977] do\_int80\_syscall\_32+0x53/0x6c
[ 24.616306] restore\_all\_switch\_stack+0x0/0xb1
[ 24.616677] irq event stamp: 939881
[ 24.616968] hardirqs last enabled at (939880): [<8105592d>] \_\_local\_bh\_enable\_ip+0x13c/0x145
[ 24.617642] hardirqs last disabled at (939881): [<81b6ace3>] \_raw\_spin\_lock\_irqsave+0x1b/0x4e
[ 24.618321] softirqs last enabled at (939738): [<81b6c7c8>] \_\_do\_softirq+0x3f0/0x45a
[ 24.618924] softirqs last disabled at (939743): [<81055741>] run\_ksoftirqd+0x35/0x61
[ 24.619521]
[ 24.619521] other info that might help us debug this:
[ 24.620028] Possible unsafe locking scenario:
[ 24.620028]
[ 24.620492] CPU0
[ 24.620685] ----
[ 24.620894] lock(&xa->xa\_lock#4);
[ 24.621168]
[ 24.621381] lock(&xa->xa\_lock#4);
[ 24.621695]
[ 24.621695] \*\*\* DEADLOCK \*\*\*
[ 24.621695]
[ 24.622154] 1 lock held by ksoftirqd/0/7:
[ 24.622468] #0: 823bfb94 (rcu\_callback){....}-{0:0}, at: rcu\_process\_callbacks+0xc0/0x155
[ 24.623106]
[ 24.623106] stack backtrace:
[ 24.623454] CPU: 0 PID: 7 Comm: ksoftirqd/0 Not tainted 5.9.0-rc7-00017-g0f2122045b9462 #5
[ 24.624090] Call Trace:
[ 24.624284] ? show\_stack+0x40/0x46
[ 24.624551] dump\_stack+0x1b/0x1d
[ 24.624809] print\_usage\_bug+0x17a/0x185
[ 24.625142] mark\_lock+0x11d/0x1db
[ 24.625474] ? print\_shortest\_lock\_dependencies+0x121/0x121
[ 24.625905] \_\_lock\_acquire+0x41e/0x7bf
[ 24.626206] lock\_acquire+0x20c/0x29b
[ 24.626517] ? xa\_destroy+0x43/0xc1
[ 24.626810] ? lock\_acquire+0x20c/0x29b
[ 24.627110] \_raw\_spin\_lock\_irqsave+0x3e/0x4e
[ 24.627450] ? xa\_destroy+0x43/0xc1
[ 24.627725] xa\_destroy+0x43/0xc1
[ 24.627989] \_\_io\_uring\_free+0x57/0x71
[ 24.628286] ? get\_pid+0x22/0x22
[ 24.628544] \_\_put\_task\_struct+0xf2/0x163
[ 24.628865] put\_task\_struct+0x1f/0x2a
[ 24.629161] delayed\_put\_task\_struct+0xe2/0xe9
[ 24.629509] rcu\_process\_callbacks+0x128/0x155
[ 24.629860] \_\_do\_softirq+0x1a3/0x45a
[ 24.630151] run\_ksoftirqd+0x35/0x61
[ 24.630443] smpboot\_thread\_fn+0x304/0x31a
[ 24.630763] kthread+0x124/0x139
[ 24.631016] ? sort\_range+0x18/0x18
[ 24.631290] ? kthread\_create\_worker\_on\_cpu+0x17/0x17
[ 24.631682] ret\_from\_fork+0x1c/0x28
which is complaining about xa\_destroy() grabbing the xa lock in an
IRQ disabling fashion, whereas the io\_uring uses cases aren't interrupt
safe. This is really an xarray issue, since it should not assume the
lock type. But for our use case, since we know the xarray is empty at
this point, there's no need to actually call xa\_destroy(). So just get
rid of it.
Fixes: 0f2122045b94 ("io\_uring: don't rely on weak ->files references")
Reported-by: kernel test robot
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit 36a44d253ee85cb54063016103cf8100988dc9c7
Author: Hillf Danton
Date: Sat Sep 26 21:26:55 2020 +0800
io-wq: fix use-after-free in io\_wq\_worker\_running
commit c4068bf898ddaef791049a366828d9b84b467bda upstream.
The smart syzbot has found a reproducer for the following issue:
==================================================================
BUG: KASAN: use-after-free in instrument\_atomic\_write include/linux/instrumented.h:71 [inline]
BUG: KASAN: use-after-free in atomic\_inc include/asm-generic/atomic-instrumented.h:240 [inline]
BUG: KASAN: use-after-free in io\_wqe\_inc\_running fs/io-wq.c:301 [inline]
BUG: KASAN: use-after-free in io\_wq\_worker\_running+0xde/0x110 fs/io-wq.c:613
Write of size 4 at addr ffff8882183db08c by task io\_wqe\_worker-0/7771
CPU: 0 PID: 7771 Comm: io\_wqe\_worker-0 Not tainted 5.9.0-rc4-syzkaller #0
Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
Call Trace:
\_\_dump\_stack lib/dump\_stack.c:77 [inline]
dump\_stack+0x198/0x1fd lib/dump\_stack.c:118
print\_address\_description.constprop.0.cold+0xae/0x497 mm/kasan/report.c:383
\_\_kasan\_report mm/kasan/report.c:513 [inline]
kasan\_report.cold+0x1f/0x37 mm/kasan/report.c:530
check\_memory\_region\_inline mm/kasan/generic.c:186 [inline]
check\_memory\_region+0x13d/0x180 mm/kasan/generic.c:192
instrument\_atomic\_write include/linux/instrumented.h:71 [inline]
atomic\_inc include/asm-generic/atomic-instrumented.h:240 [inline]
io\_wqe\_inc\_running fs/io-wq.c:301 [inline]
io\_wq\_worker\_running+0xde/0x110 fs/io-wq.c:613
schedule\_timeout+0x148/0x250 kernel/time/timer.c:1879
io\_wqe\_worker+0x517/0x10e0 fs/io-wq.c:580
kthread+0x3b5/0x4a0 kernel/kthread.c:292
ret\_from\_fork+0x1f/0x30 arch/x86/entry/entry\_64.S:294
Allocated by task 7768:
kasan\_save\_stack+0x1b/0x40 mm/kasan/common.c:48
kasan\_set\_track mm/kasan/common.c:56 [inline]
\_\_kasan\_kmalloc.constprop.0+0xbf/0xd0 mm/kasan/common.c:461
kmem\_cache\_alloc\_node\_trace+0x17b/0x3f0 mm/slab.c:3594
kmalloc\_node include/linux/slab.h:572 [inline]
kzalloc\_node include/linux/slab.h:677 [inline]
io\_wq\_create+0x57b/0xa10 fs/io-wq.c:1064
io\_init\_wq\_offload fs/io\_uring.c:7432 [inline]
io\_sq\_offload\_start fs/io\_uring.c:7504 [inline]
io\_uring\_create fs/io\_uring.c:8625 [inline]
io\_uring\_setup+0x1836/0x28e0 fs/io\_uring.c:8694
do\_syscall\_64+0x2d/0x70 arch/x86/entry/common.c:46
entry\_SYSCALL\_64\_after\_hwframe+0x44/0xa9
Freed by task 21:
kasan\_save\_stack+0x1b/0x40 mm/kasan/common.c:48
kasan\_set\_track+0x1c/0x30 mm/kasan/common.c:56
kasan\_set\_free\_info+0x1b/0x30 mm/kasan/generic.c:355
\_\_kasan\_slab\_free+0xd8/0x120 mm/kasan/common.c:422
\_\_cache\_free mm/slab.c:3418 [inline]
kfree+0x10e/0x2b0 mm/slab.c:3756
\_\_io\_wq\_destroy fs/io-wq.c:1138 [inline]
io\_wq\_destroy+0x2af/0x460 fs/io-wq.c:1146
io\_finish\_async fs/io\_uring.c:6836 [inline]
io\_ring\_ctx\_free fs/io\_uring.c:7870 [inline]
io\_ring\_exit\_work+0x1e4/0x6d0 fs/io\_uring.c:7954
process\_one\_work+0x94c/0x1670 kernel/workqueue.c:2269
worker\_thread+0x64c/0x1120 kernel/workqueue.c:2415
kthread+0x3b5/0x4a0 kernel/kthread.c:292
ret\_from\_fork+0x1f/0x30 arch/x86/entry/entry\_64.S:294
The buggy address belongs to the object at ffff8882183db000
which belongs to the cache kmalloc-1k of size 1024
The buggy address is located 140 bytes inside of
1024-byte region [ffff8882183db000, ffff8882183db400)
The buggy address belongs to the page:
page:000000009bada22b refcount:1 mapcount:0 mapping:0000000000000000 index:0x0 pfn:0x2183db
flags: 0x57ffe0000000200(slab)
raw: 057ffe0000000200 ffffea0008604c48 ffffea00086a8648 ffff8880aa040700
raw: 0000000000000000 ffff8882183db000 0000000100000002 0000000000000000
page dumped because: kasan: bad access detected
Memory state around the buggy address:
ffff8882183daf80: ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff
ffff8882183db000: fa fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
>ffff8882183db080: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
^
ffff8882183db100: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
ffff8882183db180: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
==================================================================
which is down to the comment below,
/\* all workers gone, wq exit can proceed \*/
if (!nr\_workers && refcount\_dec\_and\_test(&wqe->wq->refs))
complete(&wqe->wq->done);
because there might be multiple cases of wqe in a wq and we would wait
for every worker in every wqe to go home before releasing wq's resources
on destroying.
To that end, rework wq's refcount by making it independent of the tracking
of workers because after all they are two different things, and keeping
it balanced when workers come and go. Note the manager kthread, like
other workers, now holds a grab to wq during its lifetime.
Finally to help destroy wq, check IO\_WQ\_BIT\_EXIT upon creating worker
and do nothing for exiting wq.
Cc: stable@vger.kernel.org # v5.5+
Reported-by: syzbot+45fa0a195b941764e0f0@syzkaller.appspotmail.com
Reported-by: syzbot+9af99580130003da82b1@syzkaller.appspotmail.com
Cc: Pavel Begunkov
Signed-off-by: Hillf Danton
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit 89e5193ace1af78a2cee0fc83dfcf73b4c5c83d8
Author: Sebastian Andrzej Siewior
Date: Tue Sep 1 10:41:46 2020 +0200
io\_wq: Make io\_wqe::lock a raw\_spinlock\_t
commit 95da84659226d75698a1ab958be0af21d9cc2a9c upstream.
During a context switch the scheduler invokes wq\_worker\_sleeping() with
disabled preemption. Disabling preemption is needed because it protects
access to `worker->sleeping'. As an optimisation it avoids invoking
schedule() within the schedule path as part of possible wake up (thus
preempt\_enable\_no\_resched() afterwards).
The io-wq has been added to the mix in the same section with disabled
preemption. This breaks on PREEMPT\_RT because io\_wq\_worker\_sleeping()
acquires a spinlock\_t. Also within the schedule() the spinlock\_t must be
acquired after tsk\_is\_pi\_blocked() otherwise it will block on the
sleeping lock again while scheduling out.
While playing with `io\_uring-bench' I didn't notice a significant
latency spike after converting io\_wqe::lock to a raw\_spinlock\_t. The
latency was more or less the same.
In order to keep the spinlock\_t it would have to be moved after the
tsk\_is\_pi\_blocked() check which would introduce a branch instruction
into the hot path.
The lock is used to maintain the `work\_list' and wakes one task up at
most.
Should io\_wqe\_cancel\_pending\_work() cause latency spikes, while
searching for a specific item, then it would need to drop the lock
during iterations.
revert\_creds() is also invoked under the lock. According to debug
cred::non\_rcu is 0. Otherwise it should be moved outside of the locked
section because put\_cred\_rcu()->free\_uid() acquires a sleeping lock.
Convert io\_wqe::lock to a raw\_spinlock\_t.c
Signed-off-by: Sebastian Andrzej Siewior
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit bfa36f7c002c8b0ad88f45b121668d1d8a4cf1cd
Author: Jens Axboe
Date: Fri Sep 18 20:13:06 2020 -0600
io\_uring: reference ->nsproxy for file table commands
commit 9b8284921513fc1ea57d87777283a59b05862f03 upstream.
If we don't get and assign the namespace for the async work, then certain
paths just don't work properly (like /dev/stdin, /proc/mounts, etc).
Anything that references the current namespace of the given task should
be assigned for async work on behalf of that task.
Cc: stable@vger.kernel.org # v5.5+
Reported-by: Al Viro
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit adb6bf5ea1ac14bc78bdd5fc0cbe232d97870169
Author: Jens Axboe
Date: Sun Sep 13 13:09:39 2020 -0600
io\_uring: don't rely on weak ->files references
commit 0f2122045b946241a9e549c2a76cea54fa58a7ff upstream.
Grab actual references to the files\_struct. To avoid circular references
issues due to this, we add a per-task note that keeps track of what
io\_uring contexts a task has used. When the tasks execs or exits its
assigned files, we cancel requests based on this tracking.
With that, we can grab proper references to the files table, and no
longer need to rely on stashing away ring\_fd and ring\_file to check
if the ring\_fd may have been closed.
Cc: stable@vger.kernel.org # v5.5+
Reviewed-by: Pavel Begunkov
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit eeb3eb7c3c4fc83def66837340143dec2953ee87
Author: Jens Axboe
Date: Mon Sep 28 13:10:13 2020 -0600
io\_uring: enable task/files specific overflow flushing
commit e6c8aa9ac33bd7c968af7816240fc081401fddcd upstream.
This allows us to selectively flush out pending overflows, depending on
the task and/or files\_struct being passed in.
No intended functional changes in this patch.
Reviewed-by: Pavel Begunkov
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit 776dcd221b790acf29da9cd768adc42c01aee4c3
Author: Jens Axboe
Date: Sat Sep 26 15:05:03 2020 -0600
io\_uring: return cancelation status from poll/timeout/files handlers
commit 76e1b6427fd8246376a97e3227049d49188dfb9c upstream.
Return whether we found and canceled requests or not. This is in
preparation for using this information, no functional changes in this
patch.
Reviewed-by: Pavel Begunkov
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit 30db0a0f1f547351a499d1600d6aff9d650968d9
Author: Jens Axboe
Date: Thu Sep 24 08:45:57 2020 -0600
io\_uring: unconditionally grab req->task
commit e3bc8e9dad7f2f83cc807111d4472164c9210153 upstream.
Sometimes we assign a weak reference to it, sometimes we grab a
reference to it. Clean this up and make it unconditional, and drop the
flag related to tracking this state.
Reviewed-by: Pavel Begunkov
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit 89197cd7d569e89d6edcc46daeeec22d4bd43581
Author: Jens Axboe
Date: Mon Sep 14 10:45:53 2020 -0600
io\_uring: stash ctx task reference for SQPOLL
commit 2aede0e417db846793c276c7a1bbf7262c8349b0 upstream.
We can grab a reference to the task instead of stashing away the task
files\_struct. This is doable without creating a circular reference
between the ring fd and the task itself.
Reviewed-by: Pavel Begunkov
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit cf383607a5826f2a124540ef5cf3a25ff658bf9c
Author: Jens Axboe
Date: Tue Sep 22 10:19:24 2020 -0600
io\_uring: move dropping of files into separate helper
commit 0444ce1e0b5967393447dcd5adbf2bb023a50aab upstream.
No functional changes in this patch, prep patch for grabbing references
to the files\_struct.
Reviewed-by: Pavel Begunkov
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit 2c5401763d967390d7285abdb8f00e8a8d80959f
Author: Jens Axboe
Date: Tue Sep 22 08:18:24 2020 -0600
io\_uring: allow timeout/poll/files killing to take task into account
commit 07d3ca52b0056f25eef61b1c896d089f8d365468 upstream.
We currently cancel these when the ring exits, and we cancel all of
them. This is in preparation for killing only the ones associated
with a given task.
Reviewed-by: Pavel Begunkov
Signed-off-by: Jens Axboe
Signed-off-by: Greg Kroah-Hartman
commit 10cf2d801e22c531efb085d89e773a5922882f9b
Author: Saeed Mirzamohammadi
Date: Tue Oct 20 13:41:36 2020 +0200
netfilter: nftables\_offload: KASAN slab-out-of-bounds Read in nft\_flow\_rule\_create
commit 31cc578ae2de19c748af06d859019dced68e325d upstream.
This patch fixes the issue due to:
BUG: KASAN: slab-out-of-bounds in nft\_flow\_rule\_create+0x622/0x6a2
net/netfilter/nf\_tables\_offload.c:40
Read of size 8 at addr ffff888103910b58 by task syz-executor227/16244
The error happens when expr->ops is accessed early on before performing the boundary check and after nft\_expr\_next() moves the expr to go out-of-bounds.
This patch checks the boundary condition before expr->ops that fixes the slab-out-of-bounds Read issue.
Add nft\_expr\_more() and use it to fix this problem.
Signed-off-by: Saeed Mirzamohammadi
Signed-off-by: Pablo Neira Ayuso
Signed-off-by: Greg Kroah-Hartman
commit 0e26e64bb38aec25efe7917e1f18ed9775d0020c
Author: Viresh Kumar
Date: Tue Oct 13 10:42:47 2020 +0530
cpufreq: Improve code around unlisted freq check
commit 97148d0ae5303bcc18fcd1c9b968a9485292f32a upstream.
The cpufreq core checks if the frequency programmed by the bootloaders
is not listed in the freq table and programs one from the table in such
a case. This is done only if the driver has set the
CPUFREQ\_NEED\_INITIAL\_FREQ\_CHECK flag.
Currently we print two separate messages, with almost the same content,
and do this with a pr\_warn() which may be a bit too much as the driver
only asked us to check this as it expected this to be the case. Lower
down the severity of the print message by switching to pr\_info() instead
and print a single message only.
Reported-by: Sumit Gupta
Signed-off-by: Viresh Kumar
Reviewed-by: Sumit Gupta
Tested-by: Sumit Gupta
Signed-off-by: Rafael J. Wysocki
Cc: Jon Hunter
Signed-off-by: Greg Kroah-Hartman

