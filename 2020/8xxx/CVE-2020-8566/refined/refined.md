Based on the provided content, here's a breakdown of the vulnerability described by CVE-2020-8566:

**Root cause of vulnerability:**
- The vulnerability stems from insufficient sanitization of Ceph RBD admin secrets before they are written to logs when the logging level is set to 4 or higher in Kubernetes clusters using Ceph RBD as a storage provisioner.

**Weaknesses/vulnerabilities present:**
- Sensitive Ceph RBD admin secrets are being included in the logs, which are intended for debugging and auditing, not for storing credentials.
- The logging level is a configuration parameter that can be modified.

**Impact of exploitation:**
- Unauthorized disclosure of Ceph RBD admin secrets. An attacker who gains access to these logs can then use the disclosed secrets for malicious purposes. The provided CVSS score is 4.7, which is rated as medium severity.

**Attack vectors:**
- An attacker needs to gain access to the logs of the kube-controller-manager component in Kubernetes.
- The logging level for the kube-controller-manager must be set to 4 or higher.
- The Kubernetes cluster must use Ceph RBD for storage provisioning.
- Attackers need to have access to the log files to retrieve the secrets.

**Required attacker capabilities/position:**
- An attacker needs to have access to the kube-controller-manager logs which can be achieved through compromised nodes/containers/accounts or through some form of log exfiltration if the logs are exposed without proper access controls.
- They need to know that the Kubernetes cluster is using Ceph RBD as a storage provisioner.

**Additional details:**
- The vulnerability affects Kubernetes versions v1.19.0 - v1.19.2, v1.18.0 - v1.18.9, and v1.17.0 - v1.17.12.
- The fix for this vulnerability involves masking the Ceph RBD admin secrets in the logs.
- Mitigation strategies include not enabling verbose logging in production and limiting access to logs.
- Fixed versions are v1.19.3, v1.18.10, and v1.17.13
- The issue was reported by Kaizhe Huang (derek0405)