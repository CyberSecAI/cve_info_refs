=== Content from www.openwall.com_ff0141a7_20250126_005637.html ===


| [Openwall](/) * [Products](/)   + [Openwall GNU/\*/Linux   *server OS*](/Owl/)+ [Linux Kernel Runtime Guard](/lkrg/)+ [John the Ripper   *password cracker*](/john/)         - [Free & Open Source for any platform](/john/)- [in the cloud](/john/cloud/)- [Pro for Linux](/john/pro/linux/)- [Pro for macOS](/john/pro/macosx/)+ [Wordlists   *for password cracking*](/wordlists/)+ [passwdqc   *policy enforcement*](/passwdqc/)             - [Free & Open Source for Unix](/passwdqc/)- [Pro for Windows (Active Directory)](/passwdqc/windows/)+ [yescrypt   *KDF & password hashing*](/yescrypt/)+ [yespower   *Proof-of-Work (PoW)*](/yespower/)+ [crypt\_blowfish   *password hashing*](/crypt/)+ [phpass   *ditto in PHP*](/phpass/)+ [tcb   *better password shadowing*](/tcb/)+ [Pluggable Authentication Modules](/pam/)+ [scanlogd   *port scan detector*](/scanlogd/)+ [popa3d   *tiny POP3 daemon*](/popa3d/)+ [blists   *web interface to mailing lists*](/blists/)+ [msulogin   *single user mode login*](/msulogin/)+ [php\_mt\_seed   *mt\_rand() cracker*](/php_mt_seed/)* [Services](/services/)* Publications       + [Articles](/articles/)+ [Presentations](/presentations/)* Resources         + [Mailing lists](/lists/)+ [Community wiki](https://openwall.info/wiki/)+ [Source code repositories (GitHub)](https://github.com/openwall)+ [Source code repositories (CVSweb)](https://cvsweb.openwall.com)+ [File archive & mirrors](/mirrors/)+ [How to verify digital signatures](/signatures/)+ [OVE IDs](/ove/)* [What's new](/news) | |
| --- | --- |

| | [Follow @Openwall on Twitter for new release announcements and other news](https://twitter.com/openwall) | | --- | |
| --- | --- |

# blists - web interface to mailing list archives

blists is a web interface to mailing list archives that works off indexed mbox files.
There are two programs: *bindex* and *bit*.
*bindex* generates or updates the index file (yes, incremental updates are supported).
*bit* is a CGI/SSI program that generates web pages on the fly.
Both programs are written in C and are very fast.

You can view the latest <README> file,
which describes blists in more detail and provides installation instructions.
It is also included in the archive below.

Download ([release notes](/lists/announce/2017/11/19/1)):

* [blists 2.0](blists-2.0.tar.gz) and
  its [signature](blists-2.0.tar.gz.sign)* [blists 1.0](blists-1.0.tar.gz) and
    its [signature](blists-1.0.tar.gz.sign)

These files are also
[available from the Openwall file archive](https://download.openwall.net/pub/projects/blists/).
The source code of blists can be browsed on
[GitHub](https://github.com/openwall/blists) or via
[CVSweb](https://cvsweb.openwall.com/blists).

Follow [this link](/signatures/) for information on verifying the signatures.

To see blists in action, check out our
[Open Source and information security mailing list archives](https://lists.openwall.net).

blists is a registered project with
[Open Hub](https://www.openhub.net/p/blists).

Quick Comment:

413066



=== Content from lists.openwall.net_ae5d8845_20250126_005626.html ===


| [lists.openwall.net](https://lists.openwall.net) [lists](/)  /  [announce](https://www.openwall.com/lists/announce/)  [owl-users](https://www.openwall.com/lists/owl-users/)  [owl-dev](https://www.openwall.com/lists/owl-dev/)  [john-users](https://www.openwall.com/lists/john-users/)  [john-dev](https://www.openwall.com/lists/john-dev/)  [passwdqc-users](https://www.openwall.com/lists/passwdqc-users/)  [yescrypt](https://www.openwall.com/lists/yescrypt/)  [popa3d-users](https://www.openwall.com/lists/popa3d-users/)  /  [oss-security](https://www.openwall.com/lists/oss-security/)  [kernel-hardening](https://www.openwall.com/lists/kernel-hardening/)  [musl](https://www.openwall.com/lists/musl/)  [sabotage](https://www.openwall.com/lists/sabotage/)  [tlsify](https://www.openwall.com/lists/tlsify/)  [passwords](https://www.openwall.com/lists/passwords/)  /  [crypt-dev](https://www.openwall.com/lists/crypt-dev/)  [xvendor](https://www.openwall.com/lists/xvendor/)  /  [Bugtraq](/bugtraq/)  [Full-Disclosure](/full-disclosure/)  [linux-kernel](/linux-kernel/)  linux-[netdev](/netdev/)  [linux-ext4](/linux-ext4/)  [linux-hardening](/linux-hardening/)  [linux-cve-announce](/linux-cve-announce/)  [PHC](/phc-discussions/)| *Open Source and information security mailing list archives*|  | | | | |
| --- | --- | --- | --- | --- |

| | [Hash Suite: Windows password security audit tool. GUI, reports in PDF.](https://hashsuite.openwall.net) | | --- | |
| --- | --- |

# Open Source and information security mailing list archives

### Openwall-hosted community mailing lists

* [oss-security](https://www.openwall.com/lists/oss-security/)
  ([info](https://oss-security.openwall.org/wiki/mailing-lists/oss-security)) -
  Open Source software security discussions
  (there's also a [wiki](https://oss-security.openwall.org/wiki/))* [kernel-hardening](https://www.openwall.com/lists/kernel-hardening/) -
    Linux kernel security hardening discussions (see also linux-hardening below)* [libc-coord](https://www.openwall.com/lists/libc-coord/) -
      [coordination of work on standard C libraries (libc)](https://www.openwall.com/lists/libc-coord/2020/01/30/1)* [musl](https://www.openwall.com/lists/musl/) - discussions around
        [musl](https://www.musl-libc.org),
        a new standard C library for Linux* [passwords](https://www.openwall.com/lists/passwords/) - discussions on anything related to passwords
          except what better fits on other mailing lists* [sabotage](https://www.openwall.com/lists/sabotage/) -
            discussions around Sabotage Linux,
            an experimental distribution based on musl and BusyBox* [tlsify](https://www.openwall.com/lists/tlsify/) - [a TLS API](https://www.openwall.com/lists/tlsify/2015/09/28/1)
              for file-descriptor-oriented applications to make use of secure (TLS) sockets
              without invasive changes to their programming model

### Openwall mailing lists

* [announce](https://www.openwall.com/lists/announce/) - announcements only, very low traffic* [owl-users](https://www.openwall.com/lists/owl-users/) -
    [Openwall GNU/\*/Linux](https://www.openwall.com/Owl/) (Owl) user discussions* [owl-dev](https://www.openwall.com/lists/owl-dev/) - Owl development discussions* [lkrg-users](https://www.openwall.com/lists/lkrg-users/) -
        [Linux Kernel Runtime Guard](https://www.openwall.com/lkrg/) user discussions* [john-users](https://www.openwall.com/lists/john-users/) -
          [John the Ripper](https://www.openwall.com/john/) password cracker user discussions

          See also:
          [selected most useful and currently relevant postings](https://openwall.info/wiki/john/mailing-list-excerpts)* [john-dev](https://www.openwall.com/lists/john-dev/) -
            John the Ripper development discussions* [passwdqc-users](https://www.openwall.com/lists/passwdqc-users/) -
              [passwdqc](https://www.openwall.com/passwdqc/)
              password/passphrase strength checking and policy enforcement toolset user discussions* [yescrypt](https://www.openwall.com/lists/yescrypt/) -
                discussions around [yescrypt](https://www.openwall.com/yescrypt/) KDF and password hashing scheme* [popa3d-users](https://www.openwall.com/lists/popa3d-users/) -
                  [popa3d](https://www.openwall.com/popa3d/) Unix POP3 daemon user discussions

### Obsolete/inactive Openwall(-hosted) mailing lists

* [crypt-dev](https://www.openwall.com/lists/crypt-dev/) -
  [design and implementation of a new password hashing method for servers](https://www.openwall.com/lists/crypt-dev/2011/04/05/2)* [xvendor](https://www.openwall.com/lists/xvendor/)
    ([info](https://www.openwall.com/community/xvendor)) -
    collaboration and information exchange between OS distribution vendors
    (mostly Linux) on non-security topics

### Other (third-party) mailing lists

* [Bugtraq](bugtraq/) -
  security vulnerability announcements and discussions, pre-moderated* [Full-Disclosure](full-disclosure/) -
    security vulnerability announcements and discussions, originally not moderated but now also pre-moderated* [linux-kernel](linux-kernel/) -
      Linux kernel development discussions, very high volume* [netdev](netdev/) -
        Linux networking subsystem development discussions, high volume* [linux-ext4](linux-ext4/) -
          Linux ext4 filesystem development* [linux-hardening](linux-hardening/) -
            Linux kernel security hardening discussions (focused on upstream maintenance of the changes)* [linux-cve-announce](linux-cve-announce/) -
              [Linux kernel CVE announcements](https://docs.kernel.org/process/cve.html)* [PHC discussions](phc-discussions/) -
                [Password Hashing Competition](https://password-hashing.net)
                discussions

Quick Comment:

| [Powered by Openwall GNU/*/Linux](https://www.openwall.com/Owl/ "Powered by Openwall GNU/*/Linux - security-enhanced \"Linux distribution\"") [Powered by OpenVZ](https://openvz.org "Powered by OpenVZ - OS virtualization solution for Linux") 783441 | |
| --- | --- |



=== Content from openwall.com_5e4d2ed6_20250124_115502.html ===


| [Openwall](/) * [Products](/)   + [Openwall GNU/\*/Linux   *server OS*](/Owl/)+ [Linux Kernel Runtime Guard](/lkrg/)+ [John the Ripper   *password cracker*](/john/)         - [Free & Open Source for any platform](/john/)- [in the cloud](/john/cloud/)- [Pro for Linux](/john/pro/linux/)- [Pro for macOS](/john/pro/macosx/)+ [Wordlists   *for password cracking*](/wordlists/)+ [passwdqc   *policy enforcement*](/passwdqc/)             - [Free & Open Source for Unix](/passwdqc/)- [Pro for Windows (Active Directory)](/passwdqc/windows/)+ [yescrypt   *KDF & password hashing*](/yescrypt/)+ [yespower   *Proof-of-Work (PoW)*](/yespower/)+ [crypt\_blowfish   *password hashing*](/crypt/)+ [phpass   *ditto in PHP*](/phpass/)+ [tcb   *better password shadowing*](/tcb/)+ [Pluggable Authentication Modules](/pam/)+ [scanlogd   *port scan detector*](/scanlogd/)+ [popa3d   *tiny POP3 daemon*](/popa3d/)+ [blists   *web interface to mailing lists*](/blists/)+ [msulogin   *single user mode login*](/msulogin/)+ [php\_mt\_seed   *mt\_rand() cracker*](/php_mt_seed/)* [Services](/services/)* Publications       + [Articles](/articles/)+ [Presentations](/presentations/)* Resources         + [Mailing lists](/lists/)+ [Community wiki](https://openwall.info/wiki/)+ [Source code repositories (GitHub)](https://github.com/openwall)+ [Source code repositories (CVSweb)](https://cvsweb.openwall.com)+ [File archive & mirrors](/mirrors/)+ [How to verify digital signatures](/signatures/)+ [OVE IDs](/ove/)* [What's new](/news) | |
| --- | --- |

| | [Follow @Openwall on Twitter for new release announcements and other news](https://twitter.com/openwall) | | --- | |
| --- | --- |

[[<prev]](6) [[next>]](8) [[<thread-prev]](../../../2010/12/31/3) [[day]](.) [[month]](..) [[year]](../..) [[list]](../../..)
```

Message-ID: <1767014887.126919.1294083734165.JavaMail.root@zmail01.collab.prod.int.phx2.redhat.com>
Date: Mon, 3 Jan 2011 14:42:14 -0500 (EST)
From: Josh Bressers <bressers@...hat.com>
To: oss-security@...ts.openwall.com
Cc: coley  <coley@...re.org>
Subject: Re: CVE Request: CrawlTrack < 3.2.7 - remote php
 code execution

----- Original Message -----
> Versions of CrawlTrack prior to 3.2.7 are, according to the vendor,
> vulnerable to a remote PHP code execution attack if the stats pages
> are public
>
> Vendor changelog: <http://www.crawltrack.net/changelog.php>
>
> The attack vector isn't disclosed but a diff between 3.2.6 and 3.2.7
> show the vendor's fix was to escape special characters (using
> <http://php.net/htmlspecialchars> ) in values supplied through POST
> variables.

Please use CVE-2010-4537

Thanks.

--
    JB

```

[Powered by blists](https://www.openwall.com/blists/) - [more mailing lists](https://lists.openwall.net)

Please check out the
[Open Source Software Security Wiki](https://oss-security.openwall.org/wiki/), which is counterpart to this
[mailing list](https://oss-security.openwall.org/wiki/mailing-lists/oss-security).

Confused about [mailing lists](/lists/) and their use?
[Read about mailing lists on Wikipedia](https://en.wikipedia.org/wiki/Electronic_mailing_list)
and check out these
[guidelines on proper formatting of your messages](https://www.complang.tuwien.ac.at/anton/mail-news-errors.html).



=== Content from openwall.com_c137aa28_20250124_115502.html ===


| [Openwall](/) * [Products](/)   + [Openwall GNU/\*/Linux   *server OS*](/Owl/)+ [Linux Kernel Runtime Guard](/lkrg/)+ [John the Ripper   *password cracker*](/john/)         - [Free & Open Source for any platform](/john/)- [in the cloud](/john/cloud/)- [Pro for Linux](/john/pro/linux/)- [Pro for macOS](/john/pro/macosx/)+ [Wordlists   *for password cracking*](/wordlists/)+ [passwdqc   *policy enforcement*](/passwdqc/)             - [Free & Open Source for Unix](/passwdqc/)- [Pro for Windows (Active Directory)](/passwdqc/windows/)+ [yescrypt   *KDF & password hashing*](/yescrypt/)+ [yespower   *Proof-of-Work (PoW)*](/yespower/)+ [crypt\_blowfish   *password hashing*](/crypt/)+ [phpass   *ditto in PHP*](/phpass/)+ [tcb   *better password shadowing*](/tcb/)+ [Pluggable Authentication Modules](/pam/)+ [scanlogd   *port scan detector*](/scanlogd/)+ [popa3d   *tiny POP3 daemon*](/popa3d/)+ [blists   *web interface to mailing lists*](/blists/)+ [msulogin   *single user mode login*](/msulogin/)+ [php\_mt\_seed   *mt\_rand() cracker*](/php_mt_seed/)* [Services](/services/)* Publications       + [Articles](/articles/)+ [Presentations](/presentations/)* Resources         + [Mailing lists](/lists/)+ [Community wiki](https://openwall.info/wiki/)+ [Source code repositories (GitHub)](https://github.com/openwall)+ [Source code repositories (CVSweb)](https://cvsweb.openwall.com)+ [File archive & mirrors](/mirrors/)+ [How to verify digital signatures](/signatures/)+ [OVE IDs](/ove/)* [What's new](/news) | |
| --- | --- |

| | [Follow @Openwall on Twitter for new release announcements and other news](https://twitter.com/openwall) | | --- | |
| --- | --- |

[[<prev]](2) [[next>]](4) [[thread-next>]](../../../2011/01/03/7) [[day]](.) [[month]](..) [[year]](../..) [[list]](../../..)
```

Message-ID: <AANLkTikosdxx3yFKdV7t1FA3vqkRgA+Wbhsv1kyBE55J@mail.gmail.com>
Date: Fri, 31 Dec 2010 02:16:53 -0500
From: Anthon Pang <anthon.pang@...il.com>
To: oss-security <oss-security@...ts.openwall.com>
Subject: CVE Request: CrawlTrack < 3.2.7 - remote php code execution

Versions of CrawlTrack prior to 3.2.7 are, according to the vendor,
vulnerable to a remote PHP code execution attack if the stats pages
are public

Vendor changelog:  <http://www.crawltrack.net/changelog.php>

The attack vector isn't disclosed but a diff between 3.2.6 and 3.2.7
show the vendor's fix was to escape special characters (using
<http://php.net/htmlspecialchars> ) in values supplied through POST
variables.

```

[Powered by blists](https://www.openwall.com/blists/) - [more mailing lists](https://lists.openwall.net)

Please check out the
[Open Source Software Security Wiki](https://oss-security.openwall.org/wiki/), which is counterpart to this
[mailing list](https://oss-security.openwall.org/wiki/mailing-lists/oss-security).

Confused about [mailing lists](/lists/) and their use?
[Read about mailing lists on Wikipedia](https://en.wikipedia.org/wiki/Electronic_mailing_list)
and check out these
[guidelines on proper formatting of your messages](https://www.complang.tuwien.ac.at/anton/mail-news-errors.html).



=== Content from www.crawltrack.net_538b91fc_20250124_115502.html ===

CrawlTrack, crawler tracking script, changelog

| [protection](/) | [CrawlTrack](/), webmaster dashboard. Web analytic and SEO [CrawlProtect](/crawlprotect/), your website safety. Protection against hacking, spam and content theft Two php/MySQL scripts, free and easy to install  The tools you need to manage and keep control of your site. | diable |
| --- | --- | --- |

[CrawlTrack](/), webmaster dashboard.
Web analytic and SEO

[CrawlProtect](/crawlprotect/), your website safety.
Protection against hacking, spam and content theft

Two php/MySQL scripts, free and easy to install

The tools you need to manage and keep control of your site.

[CrawlTrack](/)

      [Presentation](/)

      [Download](/download.php)

      [Documentation](/documentation.php)

[CrawlProtect](/crawlprotect/)

      [Presentation](/crawlprotect/)

      [Download](/crawlprotect/download.php)

      [Documentation](/crawlprotect/documentation.php)

[Community](/forumuk/index.php)

      [Support forum](/forumuk/index.php)

      [CrawlTrack blog](/infoseo.php)

      [Thanks](/thanks.php)

[They like it](/)

**hubpages.com**

The lastest release of Crawltrack now tracks indexed pages within Yahoo and MSN. And also it tracks the keywords and entry pages to your site from the search engines. Very cool. And did I mention that it is free?

**mark8t.com**

So, while Google Analytics (or scripts of that kind), do a wonderful job of tracking human visitors, they cannot give you any information on spider (or User-Agent) behavior. Truthfully, to measure, or make the most of your SEO efforts, you need to know when a spider is coming in, what pages they're requesting, and how often there coming back (if ever). With this in mind, we suggest you try out the free Robot Tracker CrawlTrack.

**phpfusion-mods.net**

It is quite easy to protect your phpFusion installation against any hacking attempt.
For this you use a free script called Crawltrack which you can find at crawltrack.net. It comes with a detailed instruction on how to set it up for use with many GNU scripts including phpFusion.

**forums.digitalpoint.com**

Remember, a Web Analytics that is based on Javascript cannot track bots, so you will either need to implement this solution or get a bot tracker. Our recommendation for a software focused solely on bots is CrawlTrack, very impressive so far!

**searchmaestro.co.uk**

One way to monitor the search engines crawlers is to install a small, but powerful not to mention free program that is designed to track only the crawlers and search engine spiders. The software is called CrawlTrack and is available in a wide range of languages. It is deigned for specifically for use with PHP but it is a valuable piece of software to monitor and track the activity of search engines on your website.

**branica.com**

Learn how to use Crawltrack to track search engine spiders. It is a great piece of free software.

**secure.agaresmedia.com**

This is a useful little script for tracking crawlers, the other plus is it'll help block out hackersk.

###### CrawlTrack version changelog

#### Version 3.3.2   November 26th 2011

-Aol et Yandex are added in the list of search engine which are specially follow-up.

-Possibility to limit the display to the selected search engines on the keyword and entry pages.

-Add of the last 7 days tendency curve on the hits/hours graph.

-Modification of the main crawlers list (group per search engine)

-Connection cookie validity time is increase to 30mn.

-A message is displayed if the user PC block cookies and so mmake login impossible.

-Limitation to the 100 first pages on the page view per crawler page to avoid time-out.

-Display of an error message if Google API isn't responding (keywordposition page)

-Correction of bug: Specials characters in login and password.

-Correction of bug: htmlspecialchars on referer (security)

#### Version 3.3.1   November 6th 2011

-Google Images is added in the list of search engine which are specially follow-up.

-Adapt the script to the new (not provided) keyword Google policy.

-Big update of the list of host used by Google, Bing, Yahoo, Ask and Baidu.

-Jersey and Isle of Man added in the country list

-Update of GeoIP database.

-Utilisation of Google API for the keywordposition page (display of Google inside an iFrame is no more possible).

-Indexation follow up is now only for Google (number of backlinks and number of indexed pages); Bing, Yahoo et Delicious don't give anymore informations.

#### Version 3.3.0   May 8th 2011

-Visitors using Internet Explorer 9 are now counted.

-Error 404 pages are not any more listed in the page view table.

-Modification to avoid the blocage of the Alexa Widget by CrawlProtect when the site url has been entered with http://

-Number of pages view filter evolution (200 instead of 50).

#### Version 3.2.9   March 10th 2011

-php 4 compatibility is back.

-Add the day name before the date (period displayed).

-Some MySQL optimisations to accelerate calculations.

-Replace split() (deprecated) with preg\_split().

-Correction of bug: Site choice on tag creation page.

#### Version 3.2.8   February 19th 2011

-Italian translation

-A token CSRF to reinforce script security.

-Usage of an iframe for the Alexa widget to accelerate page loading.

-Downloading of the period are highlighted (in red).

-Possibility to suppress more than 2 years old datas.

-Cachecloseperiod folder is automatically emptied if there is more than 200 files in it.

-New code optimizations by Philippe Villiers.

-Correction of bug: Column sorting for ended periods.

#### Version 3.2.7   09th November 2010

-Security fix: remote php code execution vulnaribility if stats are public, update needed

-Correction of bug: Issue on footer character coding if use of iso encoding.

-Change of chmod level to avoid blockage during installation.

-Correction of bug: Number of Bingbot visits on dashboard.

-Evolution of IE6 filter.

#### Version 3.2.6   13th September 2010

-An alert message will be seen on login page if a new release of CrawlTrack is available.

-Correction of bug: graph were not showing on server without antiliasing function.

-New code optimizations by Philippe Villiers.

-Update of Maxmind geoip library.

#### Version 3.2.5   07th September 2010

-Preparation for the new Bing crawler, Bingbot (if you update from a previous release, don't forget to update also your crawlers list).

-Correction of bug: timeshift setup page was not working with some browsers.

-Correction of bug: Ipad were detected as Safari.

-Thanks to Philippe Villiers (Kissifrot on the board), complete code cleaning and lightening and update to NuSoap, Artichow and Maxmind last release.

-Update of the Turkish translation done by Korhan Mulcar.

#### Version 3.2.4   19th June 2010

-Correction of bug: some visit with a Google image referer were not taken in account.

-Correction of bug: incompatibility with GeoIP php module

-Correction of bug: issue on rounded value on Trend graph.

#### Version 3.2.3   02nd June 2010

-Bulgarian translation.

-Update of geolocalisation database.

-Update of Google host name list.

#### Version 3.2.2   28th April 2010

-The site menu is now sort in alphabetical order.

-Visitors using Internet Explorer 8 with Windows XP are now counted.

-Visitors using an Ipad are now counted.

-Optimisation of filter to better detect site copier which can give false visits statistics.

#### Version 3.2.1   04th February 2010

-Alexa Widget integration to display Alexa rank.

-Correction of bug: they was an error in the one crawler page when it was visited by a one site only user.

-Correction of bug: some Internet Explorer 8 users were not taken in account.

-Correction of bug: add a user-agent in the long tag request to avoid blocage by some protection script.

-Correction of bug: error 500 on some hosting.

#### Version 3.2.0   08th January 2010

-The number of pages indexed by Google is now available.

-The number of backlinks seen by Google (link: commande) is now available.

-For each keyword, the position in Google index is available (per country).

-Change of Yahoo API (SiteExplorerService).

-Possibility to choose the numbers of days of data saved when using CrawlTrack-Lite.

-Simplification of server load graph.

-Baidu replace Exalead in the list of search engine which are specially follow-up .

-Correction of bug: the update of crawler list using a local file was faulty .

#### Version 3.1.3   22th December 2009

-Security fix for phpMailer vulnaribility.

#### Version 3.1.2   12th September 2009

-Correction of bug: Exalead indexation datas were no more collected.

-Correction of bug: error in some filter query which could stop the filtering or even blocked the display.

-Correction of bug: the choice of number of lane to display was not working on some page.

-Correction of bug: change of chmod level used by the script during installation to avoid issue with some hosting.

#### Version 3.1.1   01st June 2009

The new Microsoft search engine: Bing, replace Live Search.

#### Version 3.1.0   10th May 2009

First evolution of CrawlTrack version 3:

-You can now change your CrawlTrack to CrawlTrack-Lite if you don't want to keep all the datas in the database. The base is purge after the daily email (see crawltrack-lite.txt file for explanation).

-CrawlTrack give you now, in addition to the site bounce rate, the page bounce rate.

-CrawlTrack give you now statistics about browsers used by your visitors.

-On the visitors page, a new graph gives the number of hits per hours.

-You will find new graphs on all sites summary page.

-CrawlTrack is now available in Russian.

#### Version 3.0.0   2nd April 2009

CrawlTrack is now a complete webmaster dashboard with the following features:

-Crawler and spider visits statistics

-Complete visitor statistics (number, origine, pages view ...).

-Daily follow-up of your site indexation in the main search engines.

-Detection and blocage of hacking attempts.

-Detection and record of 404 errors

-Downloading counter.

#### Version 2.3.0   27th September 2007

-CrawlTrack is now able to detect and block hacking attempts.

*You will have to change the CrawlTrack tag on your pages to be able to use that new feature.*

-During archiving of old data, the pages tables is also cleaned, this will help to reduce the database size.

-You can now change your password.

-You can choose not to record session identifier in page url, this will avoid multiple recording of the same page in the database and so will help to reduce the database size.

-On the Indexation page, when looking for long period data (week, month, year); it's no more the average value on the period which is displayed but the evolution during the period, like this: start value --> end value.

#### Version 2.2.1   01st July 2007

-You can now change the character encoding use.

-You can now choose the daily Email format (html or text).

-Correction of bug: the calculation of the variation compare to the last three monthes (in the Email) was wrong.

#### Version 2.2.0   24th June 2007

-On tool page you can have access to a new page giving the list of CrawlTrack tables,
number of data for each table and the size of the database.

-The daily Email is fully rework (new datas, new presentation (html)).

-You can enter as much Email address as you want to have the daily Email send to several users.

-Use of utf-8 encoding.

-New number format to have an easy reading.

-New optimized archiving script.

-On indexation page your are now able to refresh the indexation data (backlinks, indexed pages, bookmarks),
this will allow you to get the data if the automatic query has failed.

-New language: Dutch.

-A lot of code optimization to have a quicker display of the statistics pages.

-You can now choose the number of row to display and the default order of the tables.

#### Version 2.1.0   18th February 2007

-A new choice in the period selection menu to see all the visits since Crawltrack installation.

-New graphs on the indexation page.

-All the correction of bugs and improvements made since the launch of 2.0.0 are in that new version.

#### Version 2.0.0   21st January 2007

-New page giving informations about site indexation (number of backlinks and pages indexed in searchengines, number of bookmark in Del.icio.us)
and number of visitors send by the main searchengines.

-New page giving the list of keywords used to reach your site, and foreach keyword the page on which the visitor arrived.

-New page giving the list of pages on which the visitors arrived on your site and foreach page the keywords used.

-Site indexation and searchengine visits data added in the daily Email.

-On each bar or line graph you will have the display of the point value on mouse over.

-On each bar or line graph by clicking on one day (or one month for the yearly graph) value, you go directly to that day (or month) page.

-By clicking on the pie graph you change his position in the page.

-You can now modify your site name or url.

-For the tag display you can now choose the site for which you want to see the tag to avoid too long page if you have numerous sites.

-New menu.

-The last 8 days choice come back in the selection menu.

-Numerous code improvments.

-Cache is cleared at each new session opening to avoid oversizing.

-New page display adapted to 1024px width page.

-Numerous display improvments.

-Turkish translation.

#### Version 1.7.1   19th November 2006

-Correction of bug: first day of the week was not shown on the week graph (and taken in account in calculation) in case of timeshift between server time and local time.

-Correction of bug: the cache folder is now emptied when we clear the cache, this will avoid to have too big cache folder.

#### Version 1.7.0   3rd November 2006

-New calendar periods to display statistics (actual week, actual month and actual year).

-For each of these periods possibility to go back to see the previous period statistics.

-You can set-up the start of the week either to Monday or Sunday.

-Possibility to refresh the display (empty the cache) if necessary.

-When there is more than 100 lines in a table, there is now an option to display all the lines.

-During installation, if there is a problem with the IP table filling, it's possible now to continue without that table.
This will allow those for who it was impossible to go further to run CrawlTrack without crawlers country identification.

-During crawler table update, the list of the added crawlers is display.

-Upgrade to release 1.0.8 of Artichow.

-Graphs improvments: usage of TTF fonts if they are available, review of data labels position to avoid overlap.

-Display of CrawlTrack news in the tools page, to be informed of the last evolution of Crawltrack.

-Correction of bug: problem on 8 days and 1 year graphs since change to winter time.

#### Version 1.6.0   24th August 2006

-Possibility to go back to see the previous days statistics.

-Code optimization and page caching (see 'others questions' in documentation) to be able to treat a greater number of visits
while saving server load.

-Correction of bug: error during sorting of pages viewed table columns.

-Correction of bug: problem when a detection by IP crawler is added in the database.

#### Version 1.5.1   30th July 2006

-Code optimization (display pages and graphs) to be able to treat a greater number of visits.

-Limitation to 100 of the number of pages to display on the crawler detail page.

-Correction of bug: php error on the add a crawler page.

#### Version 1.5.0   14th July 2006

-New crawler detection algorythme, quicker.

-A new page giving informations about crawler source, Ip address and country of origin.
That new page is using the Geolite database create by Maxmind available at the following address: (the database is supplied with the script).

-On the search page you can now track an IP address, still using the Geolite database create by Maxmind available at the following address:.

-Simplification of the install procedure.

-The graphics didn't need anymore TTF support, this will allow the usage of CrawlTrack on nearly all the type of hosting.

-Configuration datas are now store in the database, this will greatly improve the compatibility of Crawltrack with
numerous hosting (less CHMOD problem) .

-Possibilty for those who want to, to give free access to the statistics (no password).

-Possibility to set-up the sending of a daily summary by Email.

-Numerous new graphics, for a better reading of the informations.

-New informations available: number of page of the site, part of the site visited.

-You have now in the table near the visited pages name, a direct link to it.

-The suppression of the oldest datas is replace by the archiving of them, this will allow to keep a part of the informations
but still dramatically reduce the size of the database.

-There is now a print button in the menu, this will allow the printing with an adapted page set-up.

-The tag to put on your pages is now valid XHTML 1.0.

-There is now 922 crawlers listed in the database supplied.The list will continue to be updated weekly.

#### Version 1.4.1   30th April 2006

-Correction of bugs: that version include all correction made on version 1.4.0 during the day of the 30 (see forum).

-Some display improvements (alignment to the left of pages names and graph modification to allow the y axis label to be
always visible).

#### Version 1.4.0   29th April 2006

-You can now choose the time used if there is a time shift between the time of the Crawltrack host and your local time.

-If your pages url are very long, the table display is now better.

-Numerous script and sql optimisations have drastically reduce the treatment times.

#### Version 1.3.1   01st April 2006

-Correction of bugs: if you are using pages url with more than one GET value, you were directed to an Hacking Attempt message
when you were trying to see the visits detail of that type of page.

-Correction of bugs: on some installation, you were unable to see the "since 8 days" and "since one year" graphs.

#### Version 1.3.0   12th March 2006

-The detection of a crawler by using his IP is now possible; you will have the choice when you will create a new crawler
(if you were using a previous version of CrawlTrack, you will have to replace the tag on your pages).

-You can now choose the CrawlTrack logo to display on your pages, or decided not to display any logo; the tag will be modified
accordingly .

-You can now easily suppress the oldest data in the visits table.

-A new navigation menu based on a model from .

#### Version 1.2.0   28th January 2006

-You can now update your crawlers list online, you just have to click on a link in the set-up page. Updates will be available almost
once a week.

-Eighteen new crawlers added to the database, there is now 725 crawlers listed. But the first update is already
available.

-German language is now available.

#### Version 1.1.1   30th December 2005

-Correction of bugs: the monthly and yearly graphs were not displayed on site running a version 4 of php.

-Six new crawlers added to the database, there is now 707 crawlers listed.

#### Version 1.1.0   17th December 2005

-There is now a logout button.

-You can now delete an account, a site or a crawler.

-You can automatically create a test crawler to validate your installation.

-Correction of bugs: you can't anymore create several time the same site or account.

-Correction of bugs: the url in the tag was false in some case, it's corrected.

-Fifteen new crawlers added to the database, there is now 701 crawlers listed.

#### Version 1.0.2   3rd December 2005

-Spanish language is now available.

-Nine new crawlers added to the database, there is now 686 crawlers listed.

#### Version 1.0.1   27th November 2005

-Site name can now be up to 45 caracters long.

-Correction of the bug which was existing when you had more than 1 site and you were wanted to
reorder the column in the results table, previously you was always send back to site n°1 results.

-Correction of the bug which was existing when site n°1 had been deleted (admin or user account
didn't see any datas).

-Three new crawlers added to the database, there is now 677 crawlers listed.

#### Version 1.0.0   5th November 2005

The first version of CrawlTrack, with a database of 674 crawlers.

#### How to change from an older version to the new one?

1)Upload the new files in your CrawlTrack folder, taking care to keep the crawltrack.php file (at the root of your crawltrack
folder) and the configconnect.php file (in the include folder).

2)Visit your Crawltrack page, the update will be done automatically.

Your CrawlTrack now is up to date.

Note: If you were using release 1.0.0 and you want to be able to use long site name, with phpmyadmin, change in the table crawlt\_site the type for the name field
from VARCHAR(20) to VARCHAR(45).

[![Webmaster tool: free crawlers and spiders tracking script- SEO script - Outil pour webmaster: script gratuit de statistiques des visites des robots](/crawler/images/logo8.png)](/)
[Mentions légales](/mention-legales.php)

copyright@2023 [crawltrack](https://crawltrack.net/).All rights reserved


